{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Knowledge Base","text":""},{"location":"#about","title":"About","text":"<p>This knowledge base is a large collection of pages detailing acronyms, tools, technologies, and terminologies encountered over the years. It is a constantly evolving knowledge base with new notes added on a consistent basis. </p> <p>If anything is missing or wrong, please feel free to send a request to update or add a note. This is now a community-driven effort to give back to the cyber security world.</p>"},{"location":"#how-to-contribute","title":"How to Contribute","text":"<ul> <li>Review existing content</li> <li>Submit new topics or updates</li> <li>Share your cybersecurity insights</li> <li>Submit requests through the Github repository located here</li> </ul>"},{"location":"#contact","title":"Contact","text":"<ul> <li>For requests or inquiries, please contact jonathan@complexsecurity.io</li> </ul> <p>Info</p> <p>We welcome contributions and suggestions from the community to help enrich this resource further.</p> <p></p>"},{"location":"ad/","title":"Active Directory","text":"<p>For anything relating to Windows Active Directory, including Kerberos and everything that beast entails. We're all in the same boat. Nobody really knows how AD works, do they?</p> <p></p>"},{"location":"cloud/","title":"Cloud","text":"<p>For anything relating to the mysterious cloud including the popular platforms like Microsoft Azure, Amazon Web Services (AWS) and Google Cloud Platform (GCP). Again, not much here yet.</p> <p></p>"},{"location":"cryptography/","title":"Cryptography","text":"<p>For anything relating to cryptography and the incredibly fun subject of encryption and mathematics. It hurts my head too.</p> <p></p>"},{"location":"databases/","title":"Databases","text":"<p>For anything relating to databases including various types such as relational and non-relational as well as specific software such as MSSQL, Cassandra, CouchDB and so many more.</p> <p></p>"},{"location":"frameworks/","title":"Frameworks","text":"<p>For anything relating to frameworks - including web frameworks such as ReactJS and Express as well as other fra,es for things like Java and C2.</p> <p></p>"},{"location":"linux/","title":"Linux","text":"<p>For anything relating to Linux including command line tools, tips and general Linux things.</p> <p></p>"},{"location":"misc/","title":"Miscellaneous","text":"<p>For anything that doesn't fit elsewhere including things like Docker, Ansible, Java platforms and many other things.</p> <p></p>"},{"location":"mobile/","title":"Mobile","text":"<p>For anything relating to mobile devices including Android and Apple devices. Very little content so far - mobile is a rare, strange world to me.</p> <p></p>"},{"location":"networking/","title":"Networking","text":"<p>For all things networking! Includes network protocols such as ARP, DHCP, DNS as well as general terms such as handshake, port, router and so on.</p> <p>Anything to do with computer networking is located in here.</p> <p></p>"},{"location":"programming/","title":"Programming","text":"<p>For all programming related things. Mainly from a security perspective. Covers functions in various languages that may be vulnerable if used incorrectly.</p> <p>Warning</p> <p>We are not programmers. There may be mistakes or inconsistencies. Coding is a mysterious beast.</p> <p></p>"},{"location":"protocols/","title":"Protocols","text":"<p>For information about various protocols including things like SSH, FTP, IMAP, SMB and many more.</p> <p></p>"},{"location":"security/","title":"Security","text":"<p>For anything related to security including things like certain attacks such as Blind SSRF, Clickjacking, Directory Traversal as well as more general security terms like authentication, authorization, firewalls, WAFs and so on.</p> <p></p>"},{"location":"terms/","title":"Terms","text":"<p>For anything terminology that doesn't fit anywhere else including DLLs, ACID, CRM and more.</p> <p></p>"},{"location":"tools/","title":"Tools","text":"<p>For information about various tools used in cyber security including common tools like Burp Suite, Nmap, Gobuster, and Aircrack-ng.</p> <p></p>"},{"location":"web/","title":"Web","text":"<p>For anything relating to the web and websites including web vulnerabilities like XSS, SSRF, SQLi as well as more general web things like AJAX, CDNs, HTTP headers and so on.</p> <p></p>"},{"location":"activedirectory/aad/","title":"Microsoft Azure Active Directory (Entra ID)","text":"<p>Microsoft Azure Active Directory (Azure AD) is Microsoft's cloud-based identity and access management service, which helps employees sign in and access resources in:</p> <ol> <li>External Resources: Such as Microsoft 365, the Azure portal, and thousands of other SaaS applications.</li> <li>Internal Resources: Like apps on your corporate network and intranet, along with any cloud apps developed by your own organization.</li> </ol> <p>Azure AD provides SSO capabilities, allowing users to access multiple services and applications with a single set of credentials. MFA enhances security by requiring multiple methods of verification to prove identity when accessing applications.</p> <p>Azure AD allows the management of applications, both on-premises and in the cloud. You can also integrate your own developed applications with Azure AD for streamlined access control. It offers integration with Microsoft Intune for mobile device and application management, allowing control over how corporate data is accessed and used.</p> <p>Azure AD provides automatic threat detection and remediation capabilities, helping to protect against identity-based security risks. These policies provide granular access control to apps and data based on specific conditions like user role, location, device health, and risk detection.</p> <p>It integrates seamlessly with other Microsoft services like Office 365, Azure, and Dynamics 365, providing a unified identity across all Microsoft cloud services. Azure AD enables secure collaboration with external partners and contractors while maintaining control over your own corporate data.</p> <p>It can also be used to manage and secure customer identities, enabling easy and secure access for customers to your applications. It includes a comprehensive set of directory services such as an LDAP, Azure AD Domain Services, and the ability to integrate with Active Directory on-premises.</p>"},{"location":"activedirectory/activedirectory/","title":"Active Directory","text":"<p>Active Directory (AD) is a directory service for use in a Windows Server environment. It is a distributed, hierarchical database structure that shares infrastructure information for locating, securing, managing, and organizing computer and network resources including files, users, groups, peripherals and network devices.</p> <p>Active Directory is Microsoft\u2019s own directory service for use in Windows domain networks. It provides authentication and authorization functions, as well as providing a framework for other such services. The directory itself is an LDAP database that contains networked objects. Active Directory uses the Windows Server operating system.</p> <p>When people talk about Active Directory, they typically mean Active Directory Domain Services, which provides full-scale, integrated authentication and authorization services.</p> <p>Before Windows 2000, Microsoft\u2019s authentication and authorization model required breaking down a network into domains, and then linking those domains with a complicated, and sometimes, unpredictable system of one- and two-way trusts. Active Directory was introduced in Windows 2000 as a way to provide directory services to larger more complex environments.</p>"},{"location":"activedirectory/adds/","title":"Active Directory Domain Services (AD DS)","text":"<p>Active Directory Domain Services (AD DS) is a core feature in Windows Server operating systems that provides a variety of network services, including a directory service, to manage users, computers, and other resources within a domain-based network. It's the most commonly used directory service for Windows domains and is central to the Windows Server operating system's identity and access capabilities.</p> <p>AD DS stores information about objects on the network and makes this information easy for administrators and users to find and use. Objects can include users, computers, printers, and shared folders. It allows network administrators to manage domain resources centrally, including creating and managing user accounts, assigning and enforcing security policies, and deploying programs to many computers simultaneously.</p> <p>AD DS provides a mechanism for authenticating and authorizing all users and computers in a Windows domain network. It uses the Kerberos protocol for secure authentication. Administrators use Group Policy to implement specific configurations for users and computers within the domain. These policies are pushed down to each object within the domain.</p> <p>OUs help organize objects within a domain and can be used to manage administrative tasks like delegation of permissions or application of group policies. The global catalog is a distributed data repository that contains information about every object within the Active Directory forest. It allows users and administrators to find directory information regardless of which domain in the forest actually contains the data.</p> <p>AD DS supports LDAP, a protocol used to access and manage directory information.</p>"},{"location":"activedirectory/adfs/","title":"Active Directory Federation Services","text":"<p>AD FS (Active Directory Federation Services) is a Single Sign-On (SSO) solution created by Microsoft. It provides users with authenticated access to applications that aren't capable of using Integrated Windows Authentication (IWA) through Active Directory (AD). </p> <p>Essentially, AD FS extends the ability to use single sign-on functionality beyond corporate boundaries, making it an essential tool for businesses that use cloud-based services or have partnerships with other organizations.</p> <p>AD FS allows different organizations to share their identity data securely. When two organizations trust each other's identity systems, they are said to be in a federation, and AD FS manages this trust. Users can authenticate once and gain access to multiple applications, both within and outside their organization. This reduces the need for multiple passwords and login steps.</p> <p>AD FS acts as an STS, issuing security tokens to clients, which then use these tokens to access different applications. AD FS uses a claims-based access control authorization model to maintain application security. It issues tokens containing a series of claims about a user, like their identity, role, or group membership.</p> <p>AD FS supports standard web services protocols like WS-Federation, WS-Trust, and SAML (Security Assertion Markup Language).</p> <p>AD FS can be used to provide SSO access to cloud-based services like Office 365, Salesforce, or any other SAML-compliant application. It simplifies collaboration between businesses by allowing users from one organization to access applications in another without needing separate credentials.</p>"},{"location":"activedirectory/as/","title":"Authentication Service","text":"<p>The Authentication Service (AS) is a fundamental component of the Kerberos authentication protocol, which is widely used in secure network environments. Operating as part of the Kerberos Key Distribution Center (KDC), the AS is responsible for the initial verification of a user's credentials when they attempt to access a network service.</p> <p>When a user attempts to log into a network service, the first step is to authenticate with the AS. The user's client software sends a request to the AS, typically including the user's username and a timestamp encrypted with their password. If the user's credentials are valid, the AS issues a Ticket Granting Ticket (TGT). This TGT is encrypted with a secret key shared between the AS and the Ticket Granting Service (TGS).</p> <p>The TGT serves as a credential for the user to request service tickets from the TGS. The user doesn\u2019t need to re-authenticate with the AS each time they access different services; the TGT proves that they have already been authenticated.</p> <p>The user's client sends a request to the AS (part of the KDC). This request includes information identifying the user. The AS verifies the user's credentials (such as matching the encrypted timestamp with its record). Upon successful authentication, the AS sends back two important pieces of information encrypted with the user's password: a TGT and a session key. The user's client decrypts this information using the user's password. The session key is used for further encrypted communication with the TGS when requesting access to specific services.</p> <p>The use of encryption ensures that sensitive information, such as passwords and session keys, is not exposed during the authentication process. The actual user passwords never leave the client machine; only the encrypted timestamp is sent to the AS. The TGT obtained from the AS enables a single sign-on experience for the user, reducing the need for multiple authentications.</p>"},{"location":"activedirectory/asreq/","title":"Authentication Request (AS-REQ)","text":"<p>The Authentication Request (AS-REQ) is a critical part of the initial authentication phase in the Kerberos authentication protocol. It is the request sent by a client (usually a user or a service) to the Kerberos Authentication Service (AS) when seeking authentication within a network environment.</p> <p>The process begins with the client generating an AS-REQ. This request is sent to the AS to obtain a Ticket Granting Ticket (TGT). The AS-REQ includes the client's principal name (essentially their identity in the Kerberos realm, like a username). </p> <p>Info</p> <p>To protect against replay attacks, the AS-REQ typically includes a timestamp, which is encrypted with the client's password or a derived key. This encryption confirms that the request is from the legitimate user and has not been tampered with.</p> <p>The AS-REQ also indicates the service for which authentication is being requested. Initially, this is usually the Ticket Granting Service (TGS). </p> <p>The AS-REQ is the first step in the Kerberos authentication process. It initiates the sequence of securing a TGT, which is then used for obtaining service tickets for various services within the network. Upon receiving the AS-REQ, the AS verifies the encrypted timestamp using the password (or key) stored in its database for the principal. This confirms the identity of the user.</p> <p>If the verification is successful, the AS responds with an Authentication Service Response (AS-REP), which includes the TGT and a session key for further communication.</p> <p>The use of an encrypted timestamp in the AS-REQ helps mitigate replay attacks, where an attacker might try to reuse a valid request to gain unauthorized access. The encryption ensures the confidentiality and integrity of the authentication request, essential in a secure network environment.</p>"},{"location":"activedirectory/asresponse/","title":"Authentication Service Response","text":"<p>The Authentication Service Response (AS-REP) is a key component in the Kerberos authentication protocol. It is the response sent by the Kerberos Authentication Service (AS) to a client's request for authentication. </p> <p>When a user or service first attempts to log in or access a resource within a Kerberos-secured environment, the AS-REP is the message they receive from the AS after their credentials have been verified.</p> <p>The AS-REP includes the TGT, which is encrypted with a key known only to the Ticket Granting Service (TGS) and the AS. The TGT is used for requesting access to various services within the network without needing to re-authenticate.</p> <p>Alongside the TGT, the AS-REP contains a session key, which is used for encrypting communication between the client and the TGS. This session key is encrypted with the user's password or a key derived from it, ensuring that only the legitimate user can use it. The AS-REP also includes information like timestamps and the validity period of the TGT, providing details about the session's lifespan.</p> <p>The process begins with the user's client sending an authentication request (AS-REQ) to the AS, usually including the user's principal name and a timestamp encrypted with the user's password. The AS verifies the user's credentials. If they are valid, the AS constructs the AS-REP, which includes the TGT and session key. Upon receiving the AS-REP, the client decrypts the session key using the user's password. The TGT remains encrypted (as the client cannot decrypt it) and is used for subsequent communications with the TGS.</p> <p>The AS-REP is a fundamental part of the secure authentication process in Kerberos, ensuring that users are authenticated before they can access services within the Kerberos realm. The issuance of the TGT facilitates SSO, allowing the user to access multiple services without repeatedly entering credentials. By encrypting the session key and the TGT with the user's password and the TGS's key, respectively, the AS-REP ensures that these critical pieces of information are securely transmitted.</p>"},{"location":"activedirectory/bdc/","title":"Backup Domain Controller","text":"<p>In older versions of Windows, specifically in the Windows NT era (prior to Windows 2000), the concept of a Backup Domain Controller (BDC) was an integral part of the domain model for network security and user management. </p> <p>The BDC was used to replicate user and computer account information from the Primary Domain Controller (PDC). This replication ensured that the BDC had an up-to-date copy of the domain's security and user data. BDCs were used to handle authentication requests from clients within the network. This was particularly important for load balancing and redundancy; if the PDC was unavailable, a BDC could step in to authenticate users.</p> <p>BDCs were used to handle authentication requests from clients within the network. This was particularly important for load balancing and redundancy; if the PDC was unavailable, a BDC could step in to authenticate users. In the Windows NT domain model, the BDC held a read-only copy of the domain's database. While it could authenticate users and computers, it couldn't make changes to the domain database. All changes had to be made on the PDC, which would then replicate to the BDCs.</p> <p>Microsoft shifted from the Windows NT domain model to Active Directory (AD). In AD:</p> <ul> <li>Multi-Master Model: Unlike the PDC/BDC model, Active Directory uses a multi-master model, where each domain controller holds a writable copy of the domain database.</li> <li>Flexible Single Master Operations (FSMO) Roles: Certain specialized tasks are still handled by individual domain controllers designated for specific FSMO roles, but these roles do not represent the same PDC/BDC division of labor.</li> <li>Improved Replication and Fault Tolerance: Active Directory provides improved mechanisms for data replication, fault tolerance, and load balancing across domain controllers.</li> </ul>"},{"location":"activedirectory/dc/","title":"Domain Controller","text":"<p>A domain controller is a server in a network that responds to security authentication requests (logging in, checking permissions, etc.) within a Windows Server domain. It's a vital component of Microsoft's Active Directory (AD) service, which manages the user and computer accounts in a corporate network.</p> <p>When a user logs into a computer that's part of a Windows domain, the authentication request is handled by a domain controller. It verifies user names and passwords and grants or denies access to the network. A domain controller stores and manages the central directory of all users, computers, and other resources in the domain. This includes organizational units, security policies, and access rights.</p> <p>Domain controllers enforce security policies set by network administrators, such as password policies, permissions, and group policies. Modern domain controllers use the Kerberos protocol for authentication, providing a secure and efficient authentication mechanism. In environments with multiple domain controllers, they replicate directory information among each other to ensure consistency and reliability of data.</p> <p>A domain controller runs AD DS, which is responsible for managing domain resources, storing information about network objects, managing relationships between them, and controlling user access. In older versions of Windows (like NT), there was a distinction between PDC and BDC. In modern Windows environments, all domain controllers are typically peers, although one holds the primary roles (FSMO roles) for certain operations.</p>"},{"location":"activedirectory/gticket/","title":"Golden Ticket","text":"<p>A Golden Ticket is a term used in cybersecurity to describe a specific type of attack against Microsoft Windows Active Directory systems. This attack exploits the Kerberos authentication protocol and involves the creation of a forged Ticket Granting Ticket (TGT).</p> <p>To create a Golden Ticket, an attacker first needs to gain access to the Key Distribution Center (KDC), specifically the domain controller in an Active Directory environment. The primary target is the NTLM hash of the <code>krbtgt</code> account, which is used by the domain controller to encrypt and sign all TGTs.</p> <p>With the <code>krbtgt</code> account\u2019s NTLM hash, the attacker can create a valid, forged TGT, commonly referred to as a Golden Ticket. This ticket can grant the attacker unrestricted access to any service within the domain. </p> <p>The Golden Ticket can be used to authenticate as any user (including domain administrators), to any service that uses Kerberos. It effectively allows the attacker to maintain persistence within the network and gain access to critical resources and data.</p> <p>An example workflow may be:</p> <ul> <li>An attacker gains administrative access to a domain controller.</li> <li>They extract the NTLM hash of the <code>krbtgt</code> account using tools like Mimikatz.</li> <li>The attacker generates a Golden Ticket using the extracted hash, granting them administrator-level access to the network.</li> <li>Using this Golden Ticket, they can access sensitive data, deploy malware, create new accounts, or carry out other malicious activities without being detected.</li> </ul>"},{"location":"activedirectory/kdc/","title":"Kerberos Key Distribution Center (KDC)","text":"<p>The Kerberos Key Distribution Center (KDC) is a critical component of the Kerberos network authentication protocol, which is widely used for secure authentication in computer networks. The KDC plays a central role in managing authentication and is responsible for issuing tickets used in the Kerberos protocol for authenticating users and services.</p> <p>The Authentication Service (AS) is a part of the KDC that authenticates users when they log into the network. It verifies the user's credentials (typically a username and password) and provides a Ticket Granting Ticket (TGT) if the authentication is successful. Once a user has a TGT, they can request access to various network services. The TGS, another part of the KDC, receives these requests. It checks the TGT and, if valid, issues service tickets that grant the user access to specific network resources or services.</p> <p>When a user logs on, the AS component of the KDC verifies the user's credentials. If they are valid, the KDC issues a TGT, encrypted with a secret key known only to the KDC and the TGS. When the user needs to access a network service (like a file server), their client software requests a service ticket from the TGS, using the TGT to authenticate this request.</p> <p>The TGS decrypts the TGT, verifies it, and issues a service ticket for the requested service. This ticket is encrypted with a key known only to the TGS and the specific service. The user\u2019s client software presents the service ticket to the desired service. The service decrypts the ticket and grants access if it is valid.</p> <p>The KDC is a critical security component. If compromised, an attacker could issue valid tickets for any user, leading to a complete breakdown of the security in the Kerberos-reliant environment. Given its central role in authentication, the KDC is often implemented with high availability and redundancy to prevent downtime. In large organizations, multiple KDCs might be deployed to handle authentication requests efficiently.</p>"},{"location":"activedirectory/kerb/","title":"Kerberos Authentication","text":"<p>Kerberos is a computer network security protocol that authenticates service requests between two or more trusted hosts across an untrusted network, like the internet. It is now a default authorization technology in Microsoft Windows and is also implemented in other operating systems like Apple OS, FreeBSD, UNIX, and\u00a0Linux.</p> <p>Kerberos employs secret-key\u00a0cryptography\u00a0and a trusted third party, the Key Distribution Center (KDC), to authenticate client-server applications and verify user identities. The KDC provides authentication and ticket-granting services, issuing \"tickets\" for secure identity verification. This process uses shared secret cryptography, protecting against eavesdropping and replay attacks.</p> <p>Kerberos is employed heavily on secure systems that depend on reliable auditing and authentication features. Kerberos is used in Posix authentication, and Active Directory, NFS, and Samba. It's also an alternative authentication system to SSH, POP, and SMTP.</p> <p>Kerberos protocol represents the following three things:</p> <ul> <li>Client</li> <li>Network Resource (Application server)</li> <li>Key Distribution Center (KDC)</li> </ul> <p>With these three components, Kerberos enables trusted host authentication over untrusted networks. Kerberos ensures that only authorized users can access the network resources. Additionally, it provides AAA security: Authentication, Authorization, and Accounting.\u00a0\u00a0</p> <p>In Kerberos, KDC grants tickets. These allow different hosts to prove their identity. In addition, the developers intended for Kerberos' authentication that supports authorizations. That means a client authenticated by Kerberos also has access.</p> <p>Kerberos Authentication Protocols works by the following:</p> <ul> <li>Authentication Server Request: The client requests authentication from KDC. This authentication request would be in plain text.\u00a0</li> <li>Authentication Server Response: KDC sends a TGT and a session key if the client exists in the database. If the client is not in the database, the authentication fails.\u00a0\u00a0</li> <li>Service Ticket Request: The client asks for the service ticket along with the TGT sent earlier by the KDC.\u00a0</li> <li>Service Ticket Response: KDC sends the ticket encrypted with the session key. The client can use the session key sent earlier by KDC to decrypt the service ticket.</li> <li>Application Server Request: The client requests the application server for access using the service ticket. </li> <li>Application Server Response: The application server authenticates the client. It sends a ticket that will grant access to that particular service.\u00a0</li> </ul> <p>The service ticket has a specific expiry time. You can use the same session ticket to access services until it expires. The default lifetime of a Kerberos ticket is 600 minutes.</p>"},{"location":"activedirectory/pdc/","title":"Primary Domain Controller","text":"<p>In older versions of Microsoft Windows, specifically in the Windows NT 4.0 and earlier environments, the concept of a Primary Domain Controller (PDC) was a key element in the network architecture for managing user accounts and security.</p> <p>The PDC was responsible for storing and managing the master copy of the user and computer accounts database for the domain. It handled all changes to the domain's user accounts, computer accounts, and security policies. The PDC served as the main authentication server for the domain. It processed login requests and verified user credentials.</p> <p>The PDC automatically replicated all changes to the domain's database to Backup Domain Controllers (BDCs) within the domain. This replication ensured that BDCs had an up-to-date, read-only copy of the domain database.</p> <p>The PDC was responsible for processing password changes and account lockout information. When a user changed their password, the change was first made on the PDC before being replicated to BDCs. Each Windows NT domain had exactly one PDC. This setup was a single point of failure, as the loss of the PDC could significantly impact network operations until a BDC was promoted to take its place.</p> <p>In a multiple domain environment, the PDC also played a key role in establishing and maintaining trust relationships with other domains.</p> <p>Microsoft introduced Active Directory, replacing the PDC/BDC model with a multi-master replication model. In this new model:</p> <ul> <li>Multiple Writable Domain Controllers: All domain controllers hold a writable copy of the Active Directory database, eliminating the single point of failure inherent in the PDC/BDC model.</li> <li>Flexible Single Master Operations (FSMO) Roles: Certain specialized roles, similar in concept to the PDC's unique responsibilities, are assigned to individual domain controllers in an Active Directory domain.</li> <li>Improved Scalability and Reliability: The new model provided better scalability, reliability, and easier management of network resources.</li> </ul>"},{"location":"activedirectory/pth/","title":"Pass-the-Hash Attacks","text":"<p>A pass-the-hash (PtH) attack is a technique used by attackers to authenticate to a remote server or service using a hashed version of a user's password, rather than requiring the actual plaintext password. This type of attack exploits the way Windows and other systems handle and store password hashes.</p> <p>First, an attacker obtains the hashed version of a user's password. This can be done through various methods, such as extracting the hashes from a compromised system (often from the SAM file in Windows) or intercepting the hash over the network.</p> <p>Instead of cracking the password hash to reveal the plaintext password (which can be time-consuming and difficult), the attacker uses the hash itself to authenticate. Many systems use a challenge-response mechanism for authentication, where the hash plays a crucial role. The attacker essentially responds to the authentication challenge by using the acquired hash.</p> <p>Consider a scenario where an attacker has gained access to a Windows system and has extracted password hashes from the system, typically from the Security Account Manager (SAM) database or the Active Directory database.</p> <p>Using tools like Mimikatz, an attacker extracts the NTLM hash of a user's password from the compromised system. The attacker then uses this hash to authenticate to another system or service within the network as the user whose hash was stolen. This is often done using tools that allow the specification of an NTLM hash instead of a plaintext password.</p> <p>If successful, the attacker gains access to the target system or service with the same level of privileges as the user whose hash was used. This can lead to lateral movement within the network, accessing sensitive data, or further compromising network security.</p> <p>Several tools are commonly used in cybersecurity, particularly in penetration testing and ethical hacking, to perform pass-the-hash (PtH) attacks. These include:</p> <ol> <li>Mimikatz: Perhaps the most well-known tool in this category, Mimikatz can extract password hashes from memory, perform pass-the-hash attacks, pass-the-ticket, and more. It's a versatile tool for various types of Windows credentials-related attacks.</li> <li>Metasploit Framework: Metasploit, a widely used penetration testing framework, includes modules that can perform pass-the-hash attacks. These modules allow testers to use extracted hashes to authenticate to other systems.</li> <li>Windows Credential Editor (WCE): WCE is a tool similar to Mimikatz that can be used for extracting NTLM password hashes and performing pass-the-hash attacks.</li> <li>Hashcat: While primarily known as a password cracking tool, Hashcat can be used in certain scenarios to perform pass-the-hash attacks, especially where the hash mode supports it.</li> <li>CrackMapExec: This is a post-exploitation tool that automates the assessment of large Active Directory networks. It includes functionality for pass-the-hash attacks.</li> <li>PTH-Toolkit: A collection of scripts that enable some tools to use NTLM hashes for authentication, effectively enabling pass-the-hash capabilities in those tools.</li> <li>Empire: A Pass-the-Hash Attacks and Python post-exploitation agent, Empire has capabilities for performing pass-the-hash attacks among its many features for exploiting Windows systems.</li> </ol>"},{"location":"activedirectory/ptt/","title":"Pass-the-Ticket Attacks","text":"<p>\"Pass the Ticket\" (PtT) attacks are a type of cybersecurity threat targeting networks that use the Kerberos authentication protocol, primarily seen in Microsoft Windows environments. In a PtT attack, an attacker steals a Kerberos ticket from one machine and then uses it to gain unauthorized access to resources on another machine within the network.</p> <p>The attacker first obtains a valid Kerberos ticket from a user or service account. This can be done by extracting the ticket from memory on a compromised machine using tools like Mimikatz. The stolen ticket (which can be a Ticket Granting Ticket or a service ticket) is then used on a different machine within the same domain. The attacker \"passes\" this ticket to authenticate as the ticket's original owner, bypassing the need for a password.</p> <p>With the stolen ticket, the attacker can access network resources (such as file shares, servers, databases) that the ticket's original owner has rights to, potentially escalating their privileges or moving laterally within the network.</p> <p>An example workflow may be:</p> <ul> <li>An attacker compromises a low-level employee's workstation and extracts Kerberos tickets from memory. They use these tickets to access a file server containing sensitive company data, impersonating the employee.</li> <li>A service account's ticket is stolen and used to gain unauthorized access to a critical server. The service account has elevated privileges, which the attacker exploits to install malware or exfiltrate data.</li> <li>After gaining initial access to a network, an attacker uses a stolen TGT to authenticate to a domain controller, allowing them to create new accounts or modify existing ones for further malicious activities.</li> </ul>"},{"location":"activedirectory/relayatt/","title":"Relay Attacks","text":"<p>In the context of penetration testing and network security, relay attacks are often associated with exploiting weaknesses in authentication protocols, particularly within Active Directory (AD) environments. These attacks can allow an attacker to gain unauthorized access to network resources, escalate privileges, or compromise network security.</p> <p>One of the most prominent examples of relay attacks in networking and penetration testing is the NTLM (NT LAN Manager) relay attack. NTLM is an authentication protocol used in Windows networks, and it's vulnerable to relay attacks under certain conditions.</p> <p>This is how NTLM Relay attacks work:</p> <ol> <li>Capture Authentication Request: The attacker captures an NTLM authentication request from a client. This can be done using tools like responder, which tricks clients into sending their NTLM authentication requests to the attacker's machine.</li> <li>Relay to Another Service: The attacker then relays this captured authentication request to another server or service on the network. If this target server accepts the relayed authentication, the attacker gains access to the server with the credentials of the victim client.</li> <li>Access Network Resources: The attacker can potentially access or modify network resources, execute commands, or escalate privileges depending on the level of access of the compromised account.</li> </ol> <p>Some example tools include:</p> <ul> <li>Impacket's ntlmrelayx: A tool that can perform NTLM relay attacks by relaying NTLM authentication requests to a specified target. It can also automatically execute commands or exploit known vulnerabilities upon successful relay.</li> <li>Responder: A tool for LLMNR, NBT-NS, and MDNS poisoning, which can force clients to send their authentication requests to the attacker\u2019s machine, facilitating NTLM relay attacks.</li> </ul>"},{"location":"activedirectory/roasting/","title":"Kerberoasting","text":"<p>Kerberoasting is a type of cyber attack that targets the Kerberos authentication protocol in Windows networks. It specifically exploits the Service Principal Names (SPNs) used to uniquely identify service instances on the network. Attackers use Kerberoasting to crack the passwords of service accounts, which often have high privileges and are typically less monitored than user accounts.</p> <p>In a Windows environment, services running under a service account can have an SPN associated with them. This SPN is used by the Kerberos protocol to authenticate the service. An attacker, who has already gained limited access to the network, enumerates the SPNs for service accounts on the domain and requests a Kerberos ticket for each one. These tickets are encrypted using the hash of the service account's password.</p> <p>The attacker extracts the Kerberos tickets from memory and then attempts to crack the encrypted tickets offline to retrieve the service account's plaintext password. This is often feasible because service account passwords are not always as strong or frequently changed. If successful in cracking a password, the attacker can impersonate the service account, potentially gaining access to sensitive areas of the network.</p> <p>Imagine a company with a network where various services are running under different service accounts. One of these accounts, <code>svc_account</code>, has an associated SPN for a database service it runs:</p> <ol> <li>An attacker with basic user privileges on the network lists all SPNs using a tool like SetSPN or Windows PowerShell commands.</li> <li>They find the SPN associated with <code>svc_account</code> and request a service ticket for this account.</li> <li>Once they have the service ticket, they use tools like tgsrepcrack or John the Ripper to crack the encrypted part of the ticket, which contains the hash of the <code>svc_account</code>'s password.</li> <li>If <code>svc_account</code>'s password is weak, the attacker successfully retrieves it and gains access to the database service with the privileges of <code>svc_account</code>.</li> </ol>"},{"location":"activedirectory/servtick/","title":"Service Ticket","text":"<p>In the Kerberos authentication protocol, a service ticket is a key element that allows a user to access a specific network service securely. After initially authenticating with the Kerberos Key Distribution Center (KDC), the user is granted a service ticket, which is then used to authenticate to the desired service within the network.</p> <p>First, the user authenticates to the Kerberos Authentication Service (AS) and receives a TGT. The user's client system then requests a service ticket for a specific network service from the Ticket Granting Service (TGS). This request includes the TGT and the name of the service the user wants to access.</p> <p>The TGS validates the TGT and, if the user is authorized to access the service, issues a service ticket. This ticket is encrypted with a key known only to the TGS and the specific service. The user presents the service ticket to the desired service. The service decrypts the ticket and, if valid, grants access to the user.</p> <p>As an example, imagine a user wants to access a file server within the company network:</p> <ol> <li>Initial Authentication: Alice logs into her workstation and is authenticated by the Kerberos AS. She receives a TGT.</li> <li>Requesting File Server Access: When Alice tries to access FileServer1, her client system requests a service ticket from the TGS, using her TGT. The request specifies that she needs access to FileServer1.</li> <li>Service Ticket Issuance: The TGS verifies Alice's TGT, confirms that she is permitted to access FileServer1, and issues a service ticket for this purpose. The ticket is encrypted with a secret key known only to the TGS and FileServer1.</li> <li>Accessing FileServer1: Alice's client system presents the service ticket to FileServer1. FileServer1 decrypts the ticket, verifies it, and grants Alice access to the requested files.</li> </ol>"},{"location":"activedirectory/smbrelay/","title":"SMB Relay Attacks","text":"<p>SMB Relay attacks are a type of network attack where an attacker intercepts and relays authentication requests from a client to another server. This attack exploits the Server Message Block (SMB) protocol, particularly its authentication mechanism, and is effective in networks where SMB Signing is not enforced.</p> <p>The attacker positions themselves to intercept SMB authentication traffic, which often involves tricking a client into sending its authentication request to the attacker's machine. Instead of trying to decrypt or crack the authentication data, the attacker simply relays this request to another server or service on the network. If the target server accepts the relayed authentication (i.e., it trusts the client's machine), the attacker gains access to the target server with the same rights as the intercepted user. a Some popular tools for performing it include:</p> <p>Impacket ntlmrelayx:</p> <ul> <li>A popular tool for performing NTLM relay attacks (which includes SMB relaying). An example usage may be:</li> </ul> <pre><code>python ntlmrelayx.py -t smb://&lt;TARGET_IP&gt; -smb2support\n</code></pre> <p>Info</p> <p>This command relays intercepted SMB authentication requests to the specified target IP address.</p> <p>Responder:</p> <ul> <li>Often used in conjunction with ntlmrelayx, Responder can poison network traffic to intercept authentication requests. An example usage may be:</li> </ul> <pre><code>python Responder.py -I &lt;INTERFACE&gt; -wrf\n</code></pre> <p>Info</p> <p>This command runs Responder on a specified network interface, intercepting network traffic.</p>"},{"location":"activedirectory/smbsign/","title":"SMB Signing","text":"<p>SMB Signing is a security feature in the Server Message Block (SMB) protocol, which is used for network file and printer sharing in Windows environments. SMB signing is designed to add an additional layer of security by ensuring the authenticity and integrity of SMB communications.</p> <p>SMB signing verifies that the data has not been tampered with in transit. Each packet in the SMB communication is signed with a digital signature, which the receiving party checks to confirm its authenticity. </p> <p>By verifying that each packet is from the legitimate source, SMB signing can prevent certain types of man-in-the-middle attacks where an attacker might intercept or modify the data being transmitted over the network.</p> <p>When SMB signing is enabled, each packet in an SMB session is signed with a cryptographic hash. The recipient of the packet calculates its own hash of the packet and compares it to the signature. If the hashes match, it confirms the packet has not been altered. If the hashes do not match, it indicates the packet may have been tampered with, and the recipient can take appropriate action (like dropping the connection).</p> <p>While SMB signing enhances security, there are scenarios where it can be misconfigured or bypassed:</p> <ol> <li>Performance Overhead: SMB signing can introduce a performance overhead. In some cases, administrators might disable SMB signing for performance reasons, inadvertently weakening security.</li> <li>Inconsistent Policies: If SMB signing policies are not consistently enforced across the network, certain systems might be left vulnerable to attack. For example, if a client requires SMB signing but connects to a server where SMB signing is optional, the server may allow an unsigned (and potentially insecure) connection.</li> <li>Fallback to Insecure Connections: Some configurations may allow clients and servers to fall back to using SMB without signing if they cannot establish a signed connection. This fallback can be exploited by attackers to force the use of an unsigned, less secure connection.</li> </ol>"},{"location":"activedirectory/tgs/","title":"Ticket Granting Service (TGS)","text":"<p>The Ticket Granting Service (TGS) is a key component of the Kerberos authentication protocol. It operates as part of the Kerberos Key Distribution Center (KDC) and is responsible for issuing service tickets, which are used by clients to access various network resources and services in a secure manner.</p> <p>When a user first authenticates on the network, the Authentication Service (AS), another component of the KDC, verifies their credentials. Upon successful authentication, the AS issues a Ticket Granting Ticket (TGT).</p> <p>When the user wants to access a specific network service (like a file server or database), their client software sends a request to the TGS, including the TGT and the name of the service they wish to access. The TGS decrypts the TGT using its secret key. If the TGT is valid, the TGS knows that the user has been authenticated and is who they claim to be.</p> <p>The TGS then creates a service ticket for the requested service. This ticket contains the user's identity and permissions and is encrypted with a key that only the TGS and the requested service know. The client receives the service ticket and presents it to the desired network service. The service decrypts the ticket, verifies the user's credentials, and grants or denies access based on the permissions in the ticket.</p> <p>The TGS enhances security by ensuring that users are authenticated before accessing services and that each service access request is individually authorized. Users' credentials are not exposed to network services; instead, access is mediated through tickets issued by the TGS.</p> <p>The TGS supports single sign-on (SSO). Once a user is initially authenticated, they can access multiple services without re-entering credentials, as long as their TGT is valid. The TGS enables scalable authentication for large numbers of users and services within an organization.</p>"},{"location":"activedirectory/tgt/","title":"Kerberos Ticket Granting Ticket (TGT)","text":"<p>The Kerberos Ticket Granting Ticket (TGT) is a crucial component in the Kerberos authentication protocol, used in many secure network environments. The TGT is central to the Kerberos method of authentication and plays a key role in the process of granting users access to network resources.</p> <p>When a user first logs into the network, they provide their credentials (username and password) to the Kerberos Authentication Service (AS). The AS verifies these credentials against the user database. Upon successful authentication, the AS issues a TGT to the user. This TGT is encrypted using a secret key known only to the AS and the Ticket Granting Service (TGS).</p> <p>The TGT serves as proof that the user has been authenticated. It contains the user's identity and a timestamp indicating its validity period. The user cannot decrypt the TGT themselves, as it is encrypted with the TGS's secret key. When the user requires access to a specific network service, they request a service ticket from the TGS. This request includes the TGT and the name of the service they want to access.</p> <p>The TGS decrypts the TGT, validates it, and if the user is permitted to access the service, issues a service ticket for that service. This service ticket is then used by the user to access the desired network service.</p> <p>The TGT is securely stored on the user's machine and is encrypted throughout its lifecycle to prevent tampering and unauthorized access. TGTs have a limited validity period, after which they expire and can no longer be used to request service tickets. This reduces the risk of long-term abuse if a TGT is compromised. Users can request a renewal of the TGT without re-entering their credentials, as long as the TGT hasn't expired.</p> <p>In cybersecurity attacks, particularly those seeking to move laterally within a network, attackers often target TGTs. If an attacker can obtain a TGT (especially of a privileged account), they can potentially access multiple services within the network. </p>"},{"location":"activedirectory/tickets/","title":"Kerberos Tickets","text":"<p>Kerberos tickets are a fundamental part of the Kerberos protocol, which is a network authentication system. In a Kerberos-enabled environment, these tickets enable users to prove their identity to various network services securely and without needing to repeatedly enter their credentials.</p> <p>There are two types of Kerberos tickets:</p> <ol> <li>Ticket Granting Ticket (TGT): Issued by the Key Distribution Center's Authentication Service (AS) when a user first authenticates. The TGT is used to obtain other tickets and is encrypted with a key known only to the Ticket Granting Service (TGS) and the AS.</li> <li>Service Ticket: Used to access specific network services. Service tickets are obtained from the TGS using the TGT and are encrypted with a key known only to the TGS and the specific service.</li> </ol> <p>When a user logs in, they present their credentials (such as a username and password) to the AS. The AS verifies these credentials and issues a TGT. To access a network service, the user's system requests a service ticket from the TGS, using the TGT to authenticate this request. The service ticket is then presented to the desired network service. The service decrypts the ticket and grants access if it is valid.</p> <p>Kerberos tickets have a limited validity period, after which they expire. This limits the time window in which a ticket can be used if compromised. Tickets are encrypted, ensuring that only the intended recipient can use them. The TGT is encrypted with the TGS's key, while service tickets are encrypted with the destination service's key. The TGT allows users to obtain service tickets for different services without re-entering their credentials, enabling SSO within the Kerberos realm.</p>"},{"location":"cloud/aws-waf/","title":"AWS WAF","text":"<p>AWS WAF, or Amazon Web Services [[Web Application Firewall (WAF)|Web Application Firewall]], is a cloud-based security service provided by Amazon Web Services. It is designed to protect web applications from common web exploits and attacks that could affect application availability, compromise security, or consume excessive resources. </p> <p>AWS WAF allows for the creation of custom rules that control web traffic. These rules can be designed to block, allow or monitor web requests based on specific conditions such as [[IP Address|IP addresses]], [[HTTP Headers]], HTTP body, URI strings, [[SQL injection]] and [[Cross-Site Scripting]].</p> <p>It offers protection against common attack vectors like SQLi and XSS. </p>"},{"location":"cloud/aws/","title":"AWS","text":"<p>AWS is made up of many different\u00a0[[Cloud Computing|cloud computing]]\u00a0products and services. The highly profitable division of Amazon provides servers, storage, networking, remote computing, email, mobile development, and security. AWS can be broken into three main products: EC2, Amazon\u2019s virtual machine service, Glacier, a low-cost cloud storage service, and S3, Amazon\u2019s storage system.</p> <p>AWS offers PaaS (platform as a service), IaaS (infrastructure as a service), serverless computing, and much more, with well over 70 different services.</p>"},{"location":"cloud/azure/","title":"Azure","text":"<p>Microsoft Azure is a cloud computing service offered by Microsoft.\u202fThere are over 600 services that fall under the Azure umbrella, but broadly speaking, it\u202fis\u202fa web-based platform on which applications and services can be built, tested, managed, and deployed.</p> <p>A wide range of Microsoft\u2019s\u202fsoftware as a service (SaaS), platform as a service (PaaS) and infrastructure as a service (IaaS)\u202fproducts are hosted on Azure.\u202fAzure offers three core areas of functionality; Virtual Machines, cloud services, and app services.</p>"},{"location":"cloud/cc/","title":"Cloud Computing","text":"<p>Cloud computing is the delivery of computing services\u2014including [[Server|servers]], storage, databases, networking, software, analytics, and intelligence\u2014over the Internet (\"the cloud\") to offer faster innovation, flexible resources, and economies of scale.</p> <p>Rather than owning their own computing infrastructure or data centres, companies can rent access to anything from applications to storage from a cloud service provider.</p> <p>One benefit of using cloud-computing services is that firms can avoid the upfront cost and complexity of owning and maintaining their own IT infrastructure, and instead simply pay for what they use, when they use it.</p> <p>In turn, providers of cloud-computing services can benefit from significant economies of scale by delivering the same services to a wide range of customers.</p>"},{"location":"cloud/gcp/","title":"GCP","text":"<p>GCP (Google Cloud Platform) is a public [[Cloud Computing|cloud]] vendor \u2014 like competitors\u00a0[[AWS|Amazon Web Services]] and [[Azure|Microsoft Azure]]. With GCP and other cloud vendors, customers are able to access computer resources housed in Google\u2019s data centers around the world for free or on a pay-per-use basis.</p> <p>GCP offers a suite of computing services to do everything from\u00a0GCP cost management\u00a0to data management to delivering web and video over the web to AI and machine learning tools.</p> <p>Google Cloud consists of a set of physical assets, such as computers and hard disk drives, and virtual resources, such as virtual machines (VMs), that are contained in\u00a0data centers\u00a0around the globe. </p> <p>This distribution of resources provides several benefits, including redundancy in case of failure and reduced latency by locating resources closer to clients. This distribution also introduces some rules about how resources can be used together.</p>"},{"location":"cryptography/25519/","title":"Curve25519","text":"<p>Curve25519 is a state-of-the-art elliptic curve offering high security and great performance, particularly designed for use in elliptic curve cryptography (ECC).</p> <p>Curve25519 is designed to be resistant to a wide array of cryptographic attacks, including the most common ones like timing attacks. Its design choices, such as a large prime field and specific curve construction, contribute to its robustness against attacks.</p> <p>It offers fast performance, especially in comparison to older elliptic curves. This efficiency makes it particularly suitable for systems with limited computational resources, like mobile devices. Curve25519 has a simple mathematical structure, which reduces the complexity of implementation and minimizes the risk of security flaws.</p> <p>Curve25519 is most commonly used for ECDH (Elliptic Curve Diffie-Hellman) key exchange, allowing two parties to securely establish a shared secret over an insecure channel. It's used in a variety of encryption protocols and software, including TLS, Signal Protocol, Tor, and many others.</p> <p>Curve25519 forms the basis for several cryptographic algorithms and protocols:</p> <ul> <li>ECDH Key Exchange: The most common use of Curve25519 is in the ECDH algorithm for securely exchanging cryptographic keys over a public channel.</li> <li>Ed25519: This is a signature scheme derived from Curve25519 (though it technically uses a different curve called \"Edwards25519\" for technical reasons). Ed25519 is known for its strong security and high-speed operation.</li> <li>Encryption and Digital Signatures: In addition to key exchange, Curve25519 and its variants are used for encryption and creating digital signatures in various cryptographic systems.</li> </ul> <p>A conceptual example of using Curve25519 in an ECDH key exchange process might look like this:</p> <pre><code># Pseudo-code example\nalice_private_key = generate_private_key()\nalice_public_key = curve25519(alice_private_key)\n\nbob_private_key = generate_private_key()\nbob_public_key = curve25519(bob_private_key)\n\n# Alice and Bob exchange public keys over an insecure channel\n\n# Both generate a shared secret\nalice_shared_secret = curve25519(alice_private_key, bob_public_key)\nbob_shared_secret = curve25519(bob_private_key, alice_public_key)\n\n# alice_shared_secret and bob_shared_secret should be the same\n</code></pre> <p>Info</p> <p>In real-world applications, using Curve25519 would involve cryptographic libraries that handle the low-level details of key generation, curve operations, and security considerations.</p>"},{"location":"cryptography/3des/","title":"Triple Des (3DES)","text":"<p>Triple DES (3DES) is an enhancement of the original Data Encryption Standard (DES) algorithm, providing a more secure encryption option. It was developed to overcome the vulnerabilities of DES, particularly its relatively small key size which made it susceptible to brute-force attacks.</p> <p>While DES uses a 56-bit key, Triple DES applies the DES algorithm three times with either two or three different keys, effectively increasing the key size and making it more secure against brute-force attacks.</p> <p>Like DES, 3DES is a block cipher, which means it encrypts data in fixed-size blocks (64 bits in this case). 3DES can operate in several modes, including Electronic Codebook (ECB), Cipher Block Chaining (CBC), and others. These modes offer different security features and can be chosen based on the specific requirements of the application.</p> <p>In its most common form, 3DES processes each block of data three times, first encrypting with one key, then decrypting with a second key, and finally encrypting again with a third key. This is known as the encrypt-decrypt-encrypt (EDE) mode.</p> <p>There are three keying options in 3DES: - Keying Option 1: Uses three different keys for a total of 168 bits (3 x 56-bit). - Keying Option 2: Uses two different keys for a total of 112 bits. The first and third stages use the same key. - Keying Option 3: Uses the same key for all three stages, effectively making it equivalent to regular DES in terms of key strength.</p> <p>The use of multiple encryption stages significantly increases the security of 3DES over DES, making it more resistant to brute-force attacks. Due to its triple encryption process, 3DES is inherently slower than DES and other more modern encryption algorithms like AES.</p> <p>While 3DES is more secure than DES, it is still considered less secure than AES. However, it's often used in legacy systems where upgrading to AES is not feasible.</p> <p>3DES has been adopted and endorsed by various standards organizations and is used in a variety of applications, particularly in financial services and other industries requiring a higher level of security.</p> <p>With the advent of more advanced encryption methods like AES, the use of 3DES is gradually decreasing. It's recommended to use more modern algorithms for new systems requiring encryption.</p>"},{"location":"cryptography/448/","title":"Curve448","text":"<p>Curve448 is a modern elliptic curve used in public-key cryptography, known for its high security level and efficiency. It is also referred to as \"Goldilocks\" curve, a name that suggests it's \"just right\" in terms of balancing security and performance. Curve448 is part of a family of curves that includes Curve25519, another popular curve used in cryptography.</p> <p>The primary feature of Curve448 is its 448-bit key size, which offers a very high level of security. It's designed to be resistant against current foreseeable cryptographic attacks, including those using quantum computers. Despite its large size, Curve448 is designed for efficient computation, making it practical for use even in environments where computing resources are constrained.</p> <p>Curve448 is constructed to minimize common pitfalls in elliptic curve cryptography, such as issues with weak keys or side-channel attacks. Its design choices aim to simplify secure implementations.</p> <p>Curve448 is recommended for use in various cryptographic protocols. For instance, it's one of the curves specified for use in TLS (Transport Layer Security) 1.3, which is the protocol underlying secure web communications.</p> <p>Curve448 can be used for securely exchanging cryptographic keys over an unsecured channel, providing confidentiality for subsequent communications. In conjunction with algorithms like EdDSA (Edwards-curve Digital Signature Algorithm), Curve448 is used for creating digital signatures. For example, Ed448uses Curve448 for high-security signature needs.</p> <p>In a cryptographic application, using Curve448 might involve operations like key generation, key exchange, and digital signatures, though the specific implementations would rely on cryptographic libraries that handle the complex mathematics involved. For instance:</p> <ul> <li>In a TLS 1.3 handshake, Curve448 might be used to securely agree on a shared secret between a client and a server, enabling encrypted communication.</li> <li>In a digital signature scenario, Ed448 (which uses Curve448) would be used to sign and verify messages, ensuring their authenticity and integrity.</li> </ul>"},{"location":"cryptography/aes/","title":"Advanced Encryption Standard (AES)","text":"<p>AES (Advanced Encryption Standard) is a Symmetric Encryption algorithm widely used across the globe to secure data. It was established as an encryption standard by the U.S. National Institute of Standards and Technology (NIST) in 2001. AES is used in various software and hardware products to encrypt sensitive data.</p> <p>AES is a symmetric key algorithm, meaning the same key is used for both encrypting and decrypting the data. This contrasts with asymmetric key algorithms, where different keys are used for encryption and decryption.</p> <p>It encrypts data in fixed-size blocks. AES operates on 128-bit blocks of data, applying a series of transformations to encrypt the data. </p> <p>AES supports three key lengths: 128, 192, and 256 bits. The choice of key size determines the number of rounds of transformation that the data undergoes. More rounds mean increased security but can also lead to slower processing times.</p> <p>Depending on the key size, AES applies multiple rounds of encryption to the data block: 10 rounds for 128-bit keys, 12 rounds for 192-bit keys, and 14 rounds for 256-bit keys.</p> <p>AES uses a combination of substitution and permutation in its rounds. Data is substituted and shuffled systematically, making it extremely secure against known cryptographic attacks.</p> <p>AES is used worldwide in various applications, including SSL/TLS for securing internet connections, [[Virtual Private Network|VPNs]], file encryption, and securing wireless networks (like in WPA2 and WPA3).</p> <p>AES is considered very secure and is used by governments, financial institutions, and other entities to protect sensitive information. It is believed to be resistant to all known practical cryptanalytic attacks when implemented correctly.</p> <p>AES is efficient in both software and hardware, which makes it suitable for a wide range of devices, from high-powered servers to low-resource IoT devices.</p>"},{"location":"cryptography/aesgcm/","title":"AES-GCM","text":"<p>AES-GCM, or Advanced Encryption Standard in Galois/Counter Mode, is a cryptographic mode of operation that provides both confidentiality (encryption) and data integrity (authentication). It combines the AES block cipher with a mode of operation called Galois/Counter Mode (GCM). AES-GCM is widely used because of its efficiency and security, and it is one of the standard modes recommended by various cryptographic organizations and standards.</p> <p>AES-GCM performs both encryption and authentication in a single step, providing efficient and secure protection of data. It uses AES in counter mode for encryption, which turns AES into a stream cipher. This mode encrypts plaintext blocks by combining them with an encrypted counter block.</p> <p>The Galois mode provides message authentication using a mechanism known as GMAC (Galois Message Authentication Code). It ensures data integrity and authenticity. AES-GCM requires a unique nonce (number used once) for each encryption operation with the same key. The nonce ensures that the same plaintext encrypts differently each time, enhancing security.</p> <p>AES-GCM is efficient in both hardware and software implementations. It's particularly well-suited for high-throughput, low-latency applications. Since it operates in a stream cipher mode, AES-GCM doesn't require padding of the plaintext to a multiple of the block size.</p> <p>Widely used in TLS (Transport Layer Security) and VPNs (Virtual Private Networks) for securing internet traffic. It is used for encrypting sensitive data both in transit and at rest, such as in disk encryption or database encryption. AES-GCM's authentication capability ensures that data has not been tampered with, making it suitable for scenarios where data integrity is critical.</p> <p>In a programming context, using AES-GCM might look like this:</p> <pre><code># Pseudo-code example\nfrom Crypto.Cipher import AES\nfrom Crypto.Random import get_random_bytes\n\nkey = get_random_bytes(16)  # AES key\nnonce = get_random_bytes(12)  # Unique nonce for each encryption\n\n# Creating AES-GCM cipher\ncipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n\n# Encrypting data\nplaintext = \"Sensitive data\"\nciphertext, tag = cipher.encrypt_and_digest(plaintext)\n\n# Decrypting data (in a separate process with the same key and nonce)\ndecryptor = AES.new(key, AES.MODE_GCM, nonce=nonce)\ndecrypted_text = decryptor.decrypt_and_verify(ciphertext, tag)\n</code></pre> <p>It's crucial to use a unique nonce for each encryption with the same key. Nonce reuse in AES-GCM can significantly compromise security, particularly revealing information about the plaintext and authentication keys. As with any encryption standard, secure key management practices are essential to maintain the overall security of the system.</p>"},{"location":"cryptography/asym/","title":"Asymmetric Encryption","text":"<p>Asymmetric encryption, also known as public key cryptography, is a method of encrypting data using a pair of keys: a public key and a private key. This cryptographic system is distinct for its use of two separate keys, in contrast to symmetric encryption which uses the same key for both encryption and decryption.</p> <p>The process begins with the generation of a pair of keys. The public key, as the name suggests, can be shared with anyone, while the private key is kept secret by the owner. </p> <p>When someone wants to send a secure message, they encrypt it using the recipient's public key. This encrypted data can only be decrypted by the corresponding private key. Upon receiving the encrypted message, the recipient uses their private key to decrypt it. Since the private key is not shared, only the intended recipient can decrypt the message.</p> <p>The strength of asymmetric encryption lies in the difficulty of deriving the private key from the public key. This is usually based on complex mathematical problems, such as the factoring of large numbers in RSA (Rivest-Shamir-Adleman) encryption.</p> <p>Asymmetric encryption is widely used for secure data transmission over the internet. It\u2019s fundamental for technologies like SSL/TLS in securing online communications, as well as in digital signatures which verify the authenticity and integrity of data.</p> <p>The key advantage of asymmetric encryption is the security it provides in open networks like the internet, where exchanging secret keys (as required in symmetric encryption) is not always safe or practical. </p> <p>However, it's generally slower than symmetric encryption due to its computational complexity, which is why in practice, often a combination of both methods is used (e.g., using asymmetric encryption to exchange a symmetric key safely).</p>"},{"location":"cryptography/bcrypt/","title":"Bcrypt","text":"<p><code>bcrypt</code> is a cryptographic hashing algorithm used for securing passwords. It was designed to build a cryptographically secure hash that is resilient against brute-force search attacks, even with increasing computation power. </p> <p>The <code>bcrypt</code> algorithm is particularly notable for incorporating a salt (a random value) automatically and allowing the specification of a computational cost (work factor), which can be adjusted as hardware capabilities improve.</p> <p>It automatically generates and applies a salt to each password. This prevents the use of rainbow tables (precomputed tables used to crack password hashes). It also allows the specification of the computational complexity (work factor), making the hash calculation slower. As hardware gets faster, the work factor can be increased to make brute-force attacks more difficult and time-consuming.</p> <p>As computing power increases, the algorithm can be adjusted to be more computationally intensive, providing long-term security.</p> <p>In PHP, <code>bcrypt</code> is commonly used for password hashing and is accessible through the password_hash() and password_verify() functions, which were introduced in PHP 5.5.0. These functions simplify secure password hashing and verification.</p> <p>For example, hashing a password:</p> <pre><code>$password = \"user_password\";\n$hash = password_hash($password, PASSWORD_BCRYPT);\n</code></pre> <p>This creates a hashed version of the password using bcrypt.</p> <p>You can also verify a password:</p> <pre><code>$isPasswordCorrect = password_verify($password, $hash);\n</code></pre> <p>This checks a password against its hashed version and returns True if they match.</p> <p><code>bcrypt</code> is a robust algorithm that provides strong protection against password cracking. PHP's built-in functions abstract the complexities of salt generation and hash comparison, reducing the risk of implementation errors. The ability to adjust the work factor means <code>bcrypt</code> can remain secure against increasing computational power.</p>"},{"location":"cryptography/blowfish/","title":"Blowfish","text":"<p>Blowfish is a symmetric-key block cipher algorithm designed in 1993 by Bruce Schneier as a fast, free alternative to existing encryption algorithms. It has been widely used for its efficiency and effectiveness in securing data.</p> <p>Blowfish is a block cipher, meaning it encrypts data in fixed-size blocks. It has a 64-bit block size, which was common at the time of its development.</p> <p>One of the distinctive features of Blowfish is its variable key length, which can range from 32 bits to 448 bits. This flexibility allows for a wide range of security options and makes it adaptable to different security needs.</p> <p>Blowfish uses a combination of key-dependent S-boxes (substitution boxes) and a P-array (permutation array). These are used in the encryption and decryption processes and are initialized using the secret key.</p> <p>The algorithm applies 16 rounds of encryption to the data blocks, irrespective of the key size. Each round includes a combination of key-dependent permutations and substitutions.</p> <p>Blowfish is known for its speed and efficiency, particularly in software implementations. This made it a popular choice for applications where processing power was limited. Blowfish is unpatented and license-free, and it can be freely used for any purpose, which contributed to its widespread adoption.</p> <p>While Blowfish is considered secure, its small block size (64 bits) makes it potentially vulnerable to certain types of attacks, such as birthday attacks, especially when large amounts of data are encrypted under a single key.</p> <p>Blowfish has been employed in a wide array of applications, including software encryption, secure file transfer protocols, password hashing schemes, and e-commerce platforms.</p> <p>Bruce Schneier designed Twofish, an advanced and more complex successor to Blowfish, as a candidate for the Advanced Encryption Standard (AES). Twofish has a larger block size and additional security features.</p> <p>While Blowfish was widely acclaimed and used, it has largely been superseded by newer algorithms like AES and Twofish, especially for new applications requiring high-security encryption.</p>"},{"location":"cryptography/caeser/","title":"Caesar Cipher","text":"<p>The Caesar cipher is a type of substitution cipher originally used by Julius Caesar in his private correspondence. It's named after him and is one of the simplest and most widely known encryption techniques.</p> <p>It involves shifting the letters of the plaintext a certain number of places down or up the alphabet. For example, with a shift of 3, A would be replaced by D, B would become E, and so on. The same shift is used for encrypting and decrypting the message.</p> <p>The Caesar cipher can be used to obfuscate text to hide it from casual observation. This is useful in situations where the text isn't highly sensitive but should not be immediately readable.</p> <p>The Caesar cipher provides very low security. It can be easily broken with frequency analysis or brute-force attacks (trying every possible shift). Because of its simplicity and the ease with which it can be deciphered, it is not suitable for encrypting sensitive information.</p>"},{"location":"cryptography/cbc/","title":"Cipher Block Chaining (CBC)","text":"<p>Cipher Block Chaining (CBC) is a mode of operation used in block cipher encryption algorithms. In CBC mode, each block of plaintext is XORed (exclusive or) with the previous ciphertext block before being encrypted. This method of encryption provides enhanced security compared to the basic Electronic Codebook (ECB) mode.</p> <p>In CBC mode, the encryption of each block of plaintext depends on the previous ciphertext block. This creates a chain of dependency among all the blocks, hence the name \"Cipher Block Chaining.\"</p> <p>CBC mode requires an Initialization Vector (IV) for the first block of data. The IV is a random or pseudo-random string of bits that is the same length as the block size. It ensures that the same plaintext block will encrypt to different ciphertext blocks each time, increasing security.</p> <p>Before a plaintext block is encrypted, it is XORed with the preceding ciphertext block. For the first block, the IV is used for the XOR operation. Due to the chaining mechanism, an error in one ciphertext block affects the decryption of all subsequent blocks. This also means that the entire message must be received without error for proper decryption.</p> <p>CBC mode provides more security than ECB mode because it obscures patterns in the plaintext. In ECB mode, identical plaintext blocks result in identical ciphertext blocks, which can reveal patterns and weaken security.</p> <p>CBC mode has been widely used in various encryption protocols, including SSL-TLS for secure web communications and in standards like PGP (Pretty Good Privacy) for email encryption.</p> <p>Since block ciphers require input blocks of a fixed size, plaintext often needs to be padded to the appropriate block length before encryption in CBC mode. Standard padding schemes must be used to ensure proper encryption and decryption.</p> <p>Unlike some other modes, CBC encryption is not parallelizable due to the dependency of each block on the previous block. However, decryption can be performed in parallel.</p> <p>While more secure than ECB, CBC mode is susceptible to certain types of cryptographic attacks, such as padding oracle attacks, especially if implemented without proper precautions. While CBC has been a popular mode of operation, newer and more secure modes like Galois/Counter Mode (GCM) are recommended for high-security applications.</p>"},{"location":"cryptography/cfb/","title":"CFB (Cipher Feedback)","text":"<p>CFB, or Cipher Feedback mode, is a mode of operation used with block ciphers to turn them into a stream cipher. It allows a block cipher like AES (Advanced Encryption Standard) to encrypt data of arbitrary length, and not just data that fits into a block. CFB mode is used in various cryptographic applications for secure data transmission and storage.</p> <p>CFB mode begins with an IV, which should be a unique value for each encryption operation to ensure security. The IV is usually the size of the block cipher's block size.</p> <ul> <li>The IV is encrypted with the block cipher.</li> <li>The output of this encryption is then XORed (exclusive OR) with a segment of the plaintext to produce the ciphertext segment.</li> <li>For the next block, a segment of the previously generated ciphertext is used (rather than the IV) and encrypted with the block cipher. This output is again XORed with the next segment of plaintext to produce the next segment of ciphertext.</li> <li>This process continues until all plaintext is encrypted.</li> </ul> <p>The same process is used for decryption, with the ciphertext being fed back into the cipher after each block is processed. The IV is encrypted, then XORed with the first segment of ciphertext to recover the first segment of plaintext. Subsequent segments of ciphertext are encrypted and XORed with the next segment of ciphertext to produce the next segment of plaintext.</p> <p>CFB turns a block cipher into a stream cipher, making it suitable for encrypting data of any size. If a few bits of ciphertext are lost in transmission, decryption can resynchronize after the loss. However, the bits following the error up to the next block boundary will be corrupted. An error in a ciphertext block affects the decryption of this block and the next block; after that, the decryption process synchronizes correctly.</p> <p>Since CFB mode can process data in segments smaller than the block size, it does not require padding the plaintext to a multiple of the block size. CFB mode is useful in scenarios where data is streaming or the total data size is not known upfront. It's also used when error propagation is a desirable property, such as in some secure communication protocols.</p> <p>An example:</p> <pre><code># Pseudo-code example using a block cipher in CFB mode\ncipher = BlockCipher(key, mode=CFB, iv=initialization_vector)\n\n# Encrypt\nciphertext = cipher.encrypt(plaintext)\n\n# Decrypt\ndecrypted_text = cipher.decrypt(ciphertext)\n</code></pre>"},{"location":"cryptography/chacha/","title":"ChaCha20","text":"<p>ChaCha20 is a stream cipher designed for high-speed encryption while maintaining a high level of security. It was created by Daniel J. Bernstein and is widely regarded for its efficiency and performance, especially in software implementations. ChaCha20 is part of the family of ciphers known as Salsa20/ChaCha, which are known for their simplicity and speed in software.</p> <p>ChaCha20 is designed to be fast and efficient, especially in software implementations. This makes it particularly well-suited for use in modern applications and on a wide range of hardware, including devices with limited processing power.</p> <p>Despite its simplicity and speed, ChaCha20 is considered to be very secure. It has been analyzed extensively by the cryptographic community and is not known to have any significant weaknesses. ChaCha20 is designed to be resistant to various forms of cryptanalysis, including differential and linear cryptanalysis.</p> <p>ChaCha20, often combined with the Poly1305 MAC (Message Authentication Code) for authentication, is used in various cryptographic protocols and standards, including TLS and VPN technologies.</p> <p>ChaCha20-Poly1305 is used as an encryption method in TLS, providing an alternative to AES-GCM. Some VPN protocols use ChaCha20 for encryption due to its high performance and strong security. Its efficiency makes it a popular choice for encryption on mobile and low-power devices.</p> <p>ChaCha20 is often preferred in software implementations where AES hardware acceleration is not available, as it can outperform AES in these environments.</p> <p>The actual use of ChaCha20 for encryption/decryption typically involves a few steps \u2013 key setup, nonce setup, and then encryption/decryption of data. Here's a conceptual example:</p> <pre><code># This is a pseudo-code example\nkey = generateSecureKey()  # Generate a secure key\nnonce = generateNonce()    # Generate a unique nonce (number used once)\n\n# Encrypt\nplaintext = \"This is a secret message.\"\nciphertext = chacha20_encrypt(plaintext, key, nonce)\n\n# Decrypt\ndecrypted_text = chacha20_decrypt(ciphertext, key, nonce)\n</code></pre> <p>Info</p> <p>In real-world applications, the usage of ChaCha20 would involve specific cryptographic libraries and careful management of keys and nonces to ensure security.</p>"},{"location":"cryptography/cmac/","title":"CMAC (Cipher-Based MAC)","text":"<p>CMAC (Cipher-based Message Authentication Code) is a type of Message Authentication Code (MAC) that uses a block cipher to provide data integrity and authenticity assurances. Developed as a replacement for older MAC algorithms like CBC-MAC, CMAC addresses some of their limitations and provides a more secure approach for authenticating messages.</p> <p>CMAC operates on block ciphers like AES (Advanced Encryption Standard) or Triple DES. It uses the block cipher as a building block to create the MAC. Regardless of the size of the input data, CMAC produces a MAC of a fixed length, determined by the block size of the underlying cipher (e.g., 128 bits for AES).</p> <p>CMAC provides strong security guarantees, including resistance to various cryptographic attacks such as replay and forgery attacks, when used with a secure block cipher. Like other MACs, CMAC requires a secret key shared between the sender and receiver. The MAC is generated using this key and can only be verified by someone who possesses the same key.</p> <p>CMAC processes the input message in blocks. If the last block is not the size of the cipher's block size, it's padded. The algorithm maintains an internal state, which is updated with each block of the message. After processing all blocks, CMAC applies the encryption key to the final state to produce the MAC.</p> <p>CMAC is used in scenarios where it's essential to verify that a message hasn't been altered and to confirm its origin. This is critical in secure communications, financial transactions, and data storage systems.</p> <p>It is used in protocols like IPsec (Internet Protocol Security) and TLS (Transport Layer Security), CMAC can be used for message authentication. CMAC is often employed in custom cryptographic protocols and systems, particularly where block cipher algorithms like AES are already in use for encryption.</p>"},{"location":"cryptography/cnsa/","title":"Commercial National Security Algorithm (CNSA) Suite","text":"<p>The Commercial National Security Algorithm (CNSA) Suite, previously known as the Suite B Cryptography, is a set of cryptographic algorithms recommended by the National Security Agency (NSA) for the protection of US government data classified up to the level of Top Secret.</p> <p>It's part of the NSA's initiative to secure national security systems with robust encryption standards.</p> <p>The CNSA Suite is designed to protect sensitive national security information and systems. It provides guidelines on cryptographic algorithms that are deemed secure and effective for safeguarding such information.</p> <p>The suite includes algorithms for encryption, digital signatures, key exchange, and hashing. These are intended to ensure confidentiality, integrity, and authentication of sensitive data.</p> <p>The suite recommends the use of strong encryption standards. For example, it endorses AES (Advanced Encryption Standard) with key sizes of 128 bits or higher for encrypting classified information.</p> <p>For key exchange and digital signatures, the suite includes public key cryptographic standards such as Elliptic Curve Cryptography (ECC). CNSA recommends using secure hashing algorithms like SHA-256 or higher for ensuring data integrity.</p> <p>The CNSA Suite is an evolution from the earlier Suite B Cryptography, reflecting advancements in cryptographic research and the changing landscape of cybersecurity threats.</p> <p>While the CNSA Suite is intended for national security systems, its recommendations are often followed by commercial products and systems that require a high level of security, especially those used in government contracting.</p> <p>Organizations and entities that deal with classified or sensitive government data are often required or advised to implement the CNSA Suite to ensure compliance with NSA guidelines.</p>"},{"location":"cryptography/ctr/","title":"Counter (CTR)","text":"<p>Counter (CTR) mode is a mode of operation for block cipher encryption that turns a block cipher into a stream cipher. It generates the next keystream block by encrypting successive values of a \"counter\". The counter can be any function which produces a sequence which is guaranteed not to repeat for a long time, although an actual increment-by-one counter is the simplest and most popular.</p> <p>In CTR mode, a counter, typically a simple increasing value, is encrypted to create a keystream block. This keystream is then XORed (exclusive or) with the plaintext to produce ciphertext.</p> <p>Unlike traditional block modes, which encrypt block by block, CTR mode allows a block cipher to operate as a stream cipher. It encrypts individual bits/bytes of data, making it more flexible in handling data of varying lengths.</p> <p>One of the advantages of CTR mode is that it allows for parallel encryption and decryption, as each block can be processed independently. This can lead to performance improvements in multi-core processors.</p> <p>The counter values must be unique for each plaintext block across all messages encrypted with the same key. Typically, a nonce (number used once) is combined with a simple counter to ensure uniqueness.</p> <p>In CTR mode, an error in one ciphertext block does not propagate to other blocks. This is different from modes like CBC, where an error can affect subsequent blocks.</p> <p>CTR mode allows random access to the encrypted data blocks. You can decrypt any block of ciphertext without needing to process previous blocks, which is beneficial for certain applications like database encryption.</p> <p>The security of CTR mode heavily depends on never using the same counter value with the same key. The unique counter and key combination ensures that the keystream is unpredictable.</p> <p>CTR mode is widely used in various cryptographic protocols and applications, including AES-GCM (Galois Counter Mode), which is a variant of CTR.</p> <p>The simplicity of CTR mode and its ability to precompute keystream blocks make it efficient for various implementations. The nonce part of the counter must be generated in a secure manner to prevent vulnerabilities. Using a predictable nonce can severely compromise the security of the encryption.</p>"},{"location":"cryptography/des/","title":"Data Encryption Standard (DES)","text":"<p>DES (Data Encryption Standard) is a symmetric-key algorithm for the encryption of electronic data. Developed in the early 1970s and adopted as a federal standard for encryption in the United States in 1977, DES has historically been influential in the advancement of modern cryptography. However, it is now considered outdated and insecure for many applications.</p> <p>DES is a Symmetric Encryption algorithm, which means the same key is used for both encrypting and decrypting the data. DES operates on 64-bit blocks of data, meaning it encrypts and decrypts data in 64-bit chunks.</p> <p>Despite operating on 64-bit blocks, DES uses a 56-bit key (plus 8 bits for parity), which was initially believed to offer sufficient security. However, the key size is now considered too small to withstand modern brute-force attacks.</p> <p>DES employs a Feistel Network, a specific method of breaking the plaintext into two halves and then performing operations (like substitution and permutation) on them. In the encryption process, DES applies a series of 16 rounds or iterations of substitution and permutation operations, which form the core of the algorithm.</p> <p>The DES encryption process starts and ends with initial and final permutations (IP and FP), which are fixed and known.</p> <p>DES can be used in various modes of operation, including Electronic Codebook (ECB), Cipher Block Chaining (CBC), and others, to enhance its security for different applications.</p> <p>The major vulnerability of DES is its relatively small key size, making it feasible to crack the encryption using brute-force attacks. This was demonstrated in the late 1990s. To overcome the limitations of DES, Triple DES (3DES) was developed, which applies the DES algorithm three times to each data block. 3DES significantly increases security and has been widely used as a more secure alternative.</p> <p>Info</p> <p>DES was officially withdrawn as a standard by the National Institute of Standards and Technology (NIST) in 2005 and replaced by the Advanced Encryption Standard (AES), which offers greater security.</p>"},{"location":"cryptography/dh/","title":"Diffie-Hellman","text":"<p>Diffie-Hellman is a key exchange algorithm used for securely exchanging cryptographic keys over a public channel. This method allows two parties to establish a shared secret key, which can then be used for encrypted communication. The strength of Diffie-Hellman lies in the fact that while it's relatively easy for the involved parties to agree on the shared secret, it is extremely difficult for an eavesdropper to determine the key, even if they can observe the entire key exchange process.</p> <p>Both parties agree on two prime numbers. One is a large prime (p), and the other is a base (g) which is a primitive root modulo p. These numbers are public and can be known by an eavesdropper without compromising the security of the key exchange.</p> <p>Each party selects a private key, which is a secret number. Each then computes their public key by raising the base (g) to the power of their private key and then taking the modulus of p (g^private_key mod p). The resulting public keys are then exchanged over the public channel.</p> <p>After receiving the other party\u2019s public key, each party raises it to the power of their own private key and again takes the modulus of p. This operation results in both parties arriving at the same number, which becomes the shared secret key.</p> <p>The security of the Diffie-Hellman key exchange lies in the difficulty of the Discrete Logarithm Problem. While it's computationally easy to raise g to a power and take a modulus p, it's hard to do the inverse \u2014 that is, to start with g^x mod p and then find x.</p> <p>It\u2019s widely used in various protocols for secure key exchange, like in SSL/TLS for establishing secure web connections. When used in protocols like TLS, Diffie-Hellman can provide [[Perfect Forward Secrecy]], meaning that even if a long-term private key is compromised, session keys cannot be deduced.</p> <p>Without additional authentication measures, Diffie-Hellman is vulnerable to man-in-the-middle attacks, where an attacker intercepts and replaces public keys. The security of Diffie-Hellman depends on using sufficiently large primes and unique private keys.</p>"},{"location":"cryptography/dhe/","title":"Diffie-Hellman Ephemeral","text":"<p>Diffie-Hellman Ephemeral (DHE) is a variation of the Diffie-Hellman key exchange protocol that provides Perfect Forward Secrecy (PFS). In this context, \"ephemeral\" refers to the short-lived nature of the keys used in the key exchange process. Unlike the basic Diffie-Hellman algorithm, which can use fixed keys, DHE generates new, temporary keys for each session.</p> <p>In DHE, both parties involved in the communication generate temporary, or \"ephemeral,\" keys for each session. These keys are used only once and then discarded.</p> <p>The client and server each send their respective ephemeral public keys to the other party. As in standard Diffie-Hellman, they then use their private keys and the received public key to generate a shared secret, which is used to derive the session key for encryption.</p> <p>Data transmitted during the session is encrypted using the session key. After the session ends, the ephemeral keys are discarded.</p> <p>The primary advantage of using DHE is PFS. Even if a server\u2019s long-term private key is compromised, past communication sessions remain secure since the session keys, generated uniquely for each session, cannot be retroactively deciphered. DHE adds an extra layer of security in communication protocols, making it more difficult for attackers to decrypt intercepted data.</p> <p>DHE is commonly used in TLS (Transport Layer Security) and SSL (Secure Sockets Layer) protocols. When you see \"DHE\" as part of a cipher suite in SSL/TLS, it indicates that the connection uses Diffie-Hellman Ephemeral for key exchange.</p> <p>The process of generating ephemeral keys for each session can be more computationally intensive than using fixed keys. Proper implementation and configuration are crucial for ensuring the security benefits of DHE. Older or improperly configured systems may not support or optimally use DHE.</p>"},{"location":"cryptography/dlp/","title":"Discrete Logarithm Problem","text":"<p>The Discrete Logarithm Problem (DLP) is a mathematical problem that forms the basis of certain types of cryptographic algorithms, particularly those used in asymmetric key cryptography. It is considered a \"hard\" problem in computational mathematics, meaning that no efficient method is currently known for solving it in all cases, especially for large numbers. This difficulty is what makes it useful for cryptography.</p> <p>The problem can be stated as follows: Given a prime number $p$, a generator $g$ (a number less than $p$ that has certain properties), and a number $p$ which is a result of raising $g$ to some power $x$ modulo $p$ (i.e., $y$=$g$$^x$ mod\u2009\u2009$p$), find the value of $x$. In other words, given $g$, $y$, and $p$, find $x$ in the equation:</p> <ul> <li>$g$$^x$ = $y$ (mod\u2009\u2009$p$)</li> </ul> <p>The \"discrete\" part of the name comes from the fact that the problem deals with discrete rather than continuous values. The security of many cryptographic systems relies on the difficulty of solving the DLP. In practice, the values of $g$, $y$, and $p$ are known, but $x$ is kept secret. The infeasibility of solving for $x$ in a reasonable amount of time is what makes the cryptographic system secure.</p> <p>DLP is particularly important in public key cryptographic systems like Diffie-Hellman key exchange and the ElGamal encryption system. These systems allow secure communication over an insecure channel without the need to share a secret key in advance.</p> <p>A variant of the DLP, known as the Elliptic Curve Discrete Logarithm Problem (ECDLP), is used in elliptic curve cryptography. ECDLP is similar to the traditional DLP but is defined over elliptic curves rather than the multiplicative group of integers modulo $p$.</p> <p>The difficulty of the DLP increases significantly with the size of $p$$. For small values, it is relatively easy to solve, but for large values (hundreds of digits), no efficient general solution method is known. This asymmetry \u2013 easy to perform, hard to reverse \u2013 is a cornerstone of cryptographic systems based on the DLP, providing a way to create secure keys and encrypt data.</p>"},{"location":"cryptography/dpapi/","title":"DPAPI (Data Protection API)","text":"<p>DPAPI (Data Protection API) is a set of cryptographic protection services provided by Microsoft Windows, starting from Windows 2000. The primary purpose of DPAPI is to protect sensitive data such as passwords, keys, and other confidential information in a secure manner.</p> <p>DPAPI provides a simple interface for developers to encrypt and decrypt data. It abstracts the complexities of cryptographic operations, making it easier to securely store sensitive data. DPAPI allows data to be encrypted in two ways:</p> <ul> <li>User-Level Encryption: Data is encrypted in such a way that only the encrypting user's profile can decrypt it, usually by using credentials like the user's login password.</li> <li>Machine-Level Encryption: Data is encrypted so that it can be decrypted by any profile on the same machine. This uses machine-specific secrets for encryption.</li> </ul> <p>DPAPI integrates closely with the user and machine security models in Windows, leveraging user credentials and machine-specific secrets to generate cryptographic keys. For developers, DPAPI simplifies the process of adding data protection features to their applications. It eliminates the need for applications to handle raw cryptographic keys.</p> <p>When an application requests data encryption, DPAPI generates a key derived from the user's credentials or machine-specific factors. The data is encrypted using this key and can be stored securely. Decryption requires the same user context (for user-level encryption) or machine context (for machine-level encryption), ensuring that only authorized access is possible.</p> <p>User-level DPAPI encryption is tied to the user's login credentials. If a user's password is reset by an administrator (without the old password), access to DPAPI-encrypted data might be lost. For critical data, it's important to have backup and recovery processes, as DPAPI-encrypted data might become inaccessible if the user profile is corrupted or the machine is compromised.</p> <p>While the Data Protection API (DPAPI) in Windows is designed to protect sensitive data, like any security system, it can potentially be targeted or exploited by attackers, particularly in scenarios where an attacker has gained access to a system.</p> <p>If an attacker gains access to a system, especially with administrative privileges, they can extract DPAPI keys. These keys can be used to decrypt sensitive data protected by DPAPI on the compromised system.</p> <p>By obtaining a user's credentials (such as through phishing, keylogging, or credential dumping), an attacker might decrypt DPAPI-protected data associated with that user's account. Malware running on a user's system could potentially access and decrypt DPAPI-protected data by running in the context of a logged-in user.</p> <p>If an application improperly implements DPAPI (such as storing keys insecurely), it can be vulnerable to attacks that compromise the encrypted data.</p>"},{"location":"cryptography/dra/","title":"Double Ratchet Algorithm","text":"<p>The Double Ratchet Algorithm is a key management algorithm designed to provide secure end-to-end encryption for instant messaging applications. It was developed as part of the Signal Protocol by Open Whisper Systems, and it's used in popular messaging apps like Signal, WhatsApp, and Facebook Messenger. The algorithm is named for its dual mechanisms, or \"ratchets,\" which are used to update the keys for each message.</p> <p>The algorithm frequently changes encryption keys, using a new key for every message. This practice, known as \"ratcheting,\" ensures that even if a key is compromised, only a small part of the conversation can be decrypted. Because it constantly updates keys, the algorithm provides forward secrecy. If a key is compromised, past messages remain secure since they were encrypted with different keys.</p> <p>The Double Ratchet Algorithm is designed to work in environments where both parties are not always online at the same time, typical in modern messaging applications.</p> <p>The Double Ratchet Algorithm combines a Diffie-Hellman key exchange with a symmetric-key ratchet to update the keys for each message:</p> <ol> <li>Diffie-Hellman Ratchet: Used intermittently to provide new key material. When two parties exchange messages, they also periodically send new Diffie-Hellman public keys. Each party combines the other's public key with their own private key to derive new shared secrets.</li> <li>Symmetric-Key Ratchet: Also known as the \"KDF-chain\" (Key Derivation Function chain), this ratchet is used for every message. It takes the output of the Diffie-Hellman ratchet and derives new keys for each message, ensuring that each message has a unique encryption key.</li> </ol> <p>In a messaging app, when a user sends a message:</p> <ol> <li>The app uses the Double Ratchet Algorithm to generate a new message key.</li> <li>The message is encrypted with this key.</li> <li>The receiver uses the same algorithm to generate the corresponding key to decrypt the message.</li> </ol> <p>A conceptual example:</p> <pre><code># Pseudo-code example\n# Assuming Alice and Bob have already established shared secrets\nalice_ratchet = DoubleRatchet(alice_shared_secret)\nbob_ratchet = DoubleRatchet(bob_shared_secret)\n\n# Alice sends a message\nalice_key = alice_ratchet.next_key()\nencrypted_message = encrypt(alice_key, \"Hello, Bob!\")\n\n# Bob receives and decrypts the message\nbob_key = bob_ratchet.next_key()\ndecrypted_message = decrypt(bob_key, encrypted_message)\n</code></pre>"},{"location":"cryptography/dsa/","title":"Digital Signature Algorithm (DSA)","text":"<p>The Digital Signature Algorithm (DSA) is a Federal Information Processing Standard for digital signatures. It was developed by the National Institute of Standards and Technology (NIST) in the early 1990s for use in their Digital Signature Standard (DSS). DSA is based on asymmetric cryptographic principles and is used for digital signing and verification, not for encryption.</p> <p>DSA is an asymmetric algorithm, meaning it uses a pair of keys: a private key for signing and a public key for verification. The private key must be kept secret, while the public key can be openly distributed.</p> <p>The primary purpose of DSA is to create digital signatures. A digital signature ensures the authenticity and integrity of a message or document. In DSA, a signature is generated using the signer's private key and can be verified by anyone using the corresponding public key. The signature is unique to both the document and the private key used.</p> <p>Unlike some other asymmetric algorithms like RSA, DSA cannot be used for encrypting and decrypting messages. It is solely designed for signing and verifying digital signatures. The security of DSA relies on the difficulty of computing discrete logarithms in a finite field, which is a well-known hard problem in mathematics.</p> <p>The length of the keys used in DSA affects the security of the signature. Longer keys provide higher security. NIST has guidelines on the recommended key lengths for various security levels.</p> <p>DSA was one of the first digital signature schemes widely adopted and used. It has been implemented in various cryptographic software and protocols. There are variants of DSA, such as the Elliptic Curve Digital Signature Algorithm (ECDSA), which uses elliptic curve cryptography to provide the same functionality but with shorter keys and improved efficiency.</p>"},{"location":"cryptography/ebc/","title":"Electronic Codebook (ECB)","text":"<p>Electronic Codebook (ECB) is a mode of operation for a block cipher, where a plaintext is divided into blocks, and each block is encrypted separately. This method of encryption, while straightforward, has several weaknesses, especially when dealing with large amounts of data or data with repetitive patterns.</p> <p>In ECB, the plaintext is divided into blocks of a fixed size, and each block is encrypted independently using the same key. The size of each block is determined by the block cipher being used.</p> <p>Since each block is encrypted independently, there is no dependency or linkage between the blocks. The same plaintext block will always encrypt to the same ciphertext block when using the same key.</p> <p>One of the major weaknesses of ECB is that it does not hide data patterns well. Identical blocks of plaintext result in identical blocks of ciphertext. This can be a security risk if the plaintext contains repetitive or structured data.</p> <p>A benefit of ECB is that it allows for parallel processing of blocks, which can be an advantage in terms of encryption and decryption speed.</p> <p>Due to its vulnerabilities, ECB is generally not recommended for encrypting large amounts of data, particularly data with patterns. It might be used for small, random, and unstructured pieces of data.</p> <p>In ECB mode, each block is independent; therefore, an error in one block during transmission does not affect other blocks. This can be advantageous in certain scenarios where error correction is vital.</p> <p>ECB is the simplest encryption mode and is relatively easy to implement. However, this simplicity comes at the cost of security. Given its vulnerability to pattern analysis, ECB mode is not suitable for encrypting confidential or sensitive data over networks.</p> <p>The weakness of ECB is often demonstrated with bitmap images. When an image is encrypted using ECB, the outlines and contours of the image can sometimes still be discerned, revealing information about the original.</p> <p>More secure modes of operation, like Cipher Block Chaining (CBC), Counter (CTR), or Galois Counter Mode (GCM), are generally preferred over ECB, as they introduce an element of randomness and link the blocks of ciphertext.</p>"},{"location":"cryptography/ecc/","title":"Elliptic Curve Cryptography (ECC)","text":"<p>ECC (Elliptic Curve Cryptography) is a method of public-key cryptography based on the algebraic structure of elliptic curves over finite fields. ECC provides the same level of cryptographic strength as other public-key cryptographic systems (like RSA) but uses smaller key sizes, leading to faster computations, lower power consumption, and reduced storage and bandwidth requirements.</p> <p>ECC is built upon the mathematics of elliptic curves, which are curves defined by a specific type of cubic equation in two variables. The properties of these curves provide the foundation for cryptographic techniques.</p> <p>One of the major advantages of ECC is that it can achieve the same level of security as RSA with much smaller key sizes. For instance, a 256-bit key in ECC is considered to be as secure as a 3072-bit key in RSA.</p> <p>Due to smaller key sizes, ECC operations can be performed more quickly than equivalent RSA operations. This efficiency makes ECC particularly attractive for use in mobile devices or environments where computing resources are limited.</p> <p>ECC provides strong security mechanisms. The difficulty of solving the Elliptic Curve Discrete Logarithm Problem (ECDLP) is what provides security in ECC. ECC is widely used in various security protocols and standards, such as TLS/SSL for secure web browsing, VPNs, and encryption standards like PGP and GPG for secure communications.</p> <p>ECC is used in digital signature algorithms like the Elliptic Curve Digital Signature Algorithm (ECDSA). ECDSA is a variant of the Digital Signature Algorithm (DSA) which uses elliptic curve cryptography.</p> <p>ECC can be used in key agreement protocols, like Elliptic Curve Diffie-Hellman (ECDH), allowing two parties to establish a shared secret over an insecure channel.</p> <p>While still a developing field, ECC is considered to be more resistant to attacks by quantum computers compared to RSA, although quantum-resistant algorithms are still an area of active research.</p> <p>Implementing ECC securely requires careful attention to the choice of elliptic curves and implementation details, as poor implementation can lead to security vulnerabilities.</p> <p>ECC is certified and recommended by various governmental and international standards bodies, including NIST, for protecting sensitive information.</p>"},{"location":"cryptography/ecdh/","title":"Elliptic Curve Diffie-Hellman (ECDH)","text":"<p>The Elliptic Curve Digital Signature Algorithm (ECDSA) is a variant of the Digital Signature Algorithm (DSA) which uses elliptic curve cryptography. It was proposed for the Digital Signature Standard (DSS) by the National Institute of Standards and Technology (NIST) and is used to create a digital signature for the authentication of digital documents or data.</p> <p>ECDSA employs the principles of elliptic curve cryptography (ECC) for digital signatures, unlike the original DSA which is based on the discrete logarithm problem in finite fields. Like DSA, ECDSA uses a pair of keys for signing (private key) and verification (public key). The private key is kept secret, while the public key is shared publicly.</p> <p>One of the major advantages of ECDSA over traditional DSA is that it provides equivalent security with smaller key sizes. This results in faster computations, smaller signatures, and reduced storage requirements.</p> <p>In ECDSA, a signature is generated using the signer's private key and can be verified by anyone having the corresponding public key. The signature proves the authenticity and integrity of the message.</p> <p>ECDSA is widely used in various applications, especially where high security with efficient performance is required. It's employed in SSL/TLS certificates, cryptocurrency wallets (like Bitcoin and Ethereum), and other secure communication protocols.</p> <p>The security of ECDSA is based on the hardness of the elliptic curve discrete logarithm problem (ECDLP). Breaking ECDSA requires solving this computationally difficult problem.</p> <p>Different elliptic curves can be used in ECDSA, and the choice of curve affects the security and performance of the algorithm. NIST and other organizations have recommended specific curves that are considered secure and efficient.</p> <p>While ECDSA offers strong security against current cryptographic attacks, like other elliptic curve-based and discrete logarithm problem-based algorithms, it is potentially vulnerable to attacks by future quantum computers.</p>"},{"location":"cryptography/ecdlp/","title":"Elliptic Curve Discrete Logarithm Problem (ECDLP)","text":"<p>The Elliptic Curve Discrete Logarithm Problem (ECDLP) is a mathematical problem that serves as the foundation for elliptic curve cryptography (ECC), a form of public key cryptography. Similar to the discrete logarithm problem (DLP) in its traditional form, ECDLP is considered hard to solve, which is what makes it useful for cryptographic purposes.</p> <p>The main difference lies in the mathematical structure used: ECDLP is based on the arithmetic of elliptic curves, whereas traditional DLP relies on the arithmetic of finite fields.</p> <p>In the context of elliptic curves, the ECDLP can be described as follows:</p> <ul> <li>Given an elliptic curve $E$ over a finite field, a point $P$ on $E$, and another point $Q$ on $E$, the Elliptic Curve Discrete Logarithm Problem is to find an integer $k$, if it exists, such that $Q$ = $k$$P$. Here, $P$ and $Q$ are known, and the goal is to determine $k$.</li> </ul> <p>The ECDLP is believed to be much more difficult to solve than the traditional discrete logarithm problem for a given key size, providing higher security with smaller key sizes. Due to the increased difficulty of ECDLP, elliptic curve cryptography can achieve comparable levels of security to other public key systems like RSA but with much smaller keys. Smaller keys mean less computational overhead, leading to faster processing and lower energy consumption.</p> <p>ECC, and thus ECDLP, is used in a variety of cryptographic applications, including encryption, digital signatures, and key agreement protocols. It's widely used in mobile and wireless devices due to its efficiency.</p> <p>The assumption that ECDLP is hard to solve underpins the security of ECC. If an efficient solution to ECDLP were found, it would compromise the security of all cryptographic systems based on ECC.</p> <p>Due to its efficiency and strong security, ECC has seen widespread adoption, especially in areas where computational resources are limited or where high performance is required, such as in IoT devices, smartphones, and secure web communications (TLS/SSL).</p>"},{"location":"cryptography/ecdsa/","title":"Elliptic Curve Digital Signature Algorithm (ECDSA)","text":"<p>The Elliptic Curve Digital Signature Algorithm (ECDSA) is a variant of the Digital Signature Algorithm (DSA) that utilizes the principles of elliptic curve cryptography (ECC). It's a method used for digital signing and verification of data, ensuring data integrity and authentication.</p> <p>ECDSA is based on elliptic curve theory, which involves the mathematics of elliptic curves over finite fields. ECC provides a higher degree of security with smaller key sizes compared to non-ECC cryptography like RSA.</p> <p>In ECDSA, a digital signature is generated in two parts, commonly referred to as 'r' and 's', using the sender's private key. The signature is then attached to the data and sent to the receiver. The receiver uses the sender's public key to verify the signature. If the signature is valid, it proves that the data hasn't been tampered with and that it was indeed signed by the private key corresponding to the public key used.</p> <p>ECDSA offers equivalent security to DSA and RSA but with smaller key sizes, making it more efficient. For instance, a 256-bit key in ECDSA is roughly equivalent in security to a 3072-bit key in RSA.</p> <p>Due to smaller key sizes, ECDSA is efficient in terms of computational resources, making it well-suited for systems with limited processing power or where fast processing is needed.</p> <p>ECDSA is widely used in cryptocurrencies like Bitcoin and Ethereum for securing transactions. It ensures that funds can only be spent by their rightful owners. ECDSA is used in SSL/TLS certificates as an alternative to RSA for authentication and securing communications over the internet.</p> <p>The security of ECDSA greatly depends on the choice of the elliptic curve and its parameters. Some curves are considered more secure and efficient than others.</p>"},{"location":"cryptography/ed/","title":"Ed448","text":"<p>Ed448 is a public-key signature algorithm that is part of the EdDSA (Edwards-curve Digital Signature Algorithm) family. Similar to its more commonly known counterpart, Ed25519, Ed448 is designed for high security and performance, but it uses a larger elliptic curve for enhanced security. The \"448\" in its name refers to the size of the curve it uses, which is 448 bits, making it suitable for higher-security requirements.</p> <p>The larger key size of 448 bits in Ed448 provides a higher security level compared to Ed25519. It's designed to be secure against even the most powerful foreseeable attacks. Despite the increased key size, Ed448 is still efficient in terms of computational requirements. This efficiency makes it practical for use in a variety of applications.</p> <p>Like Ed25519, Ed448 is designed to be resistant to a wide range of cryptographic attacks, including Side-Channel Attacks. Its deterministic nature reduces the risk of security vulnerabilities due to random number generation. Ed448 uses Edwards curves, which offer several advantages in terms of security and performance over other types of elliptic curves.</p> <p>When used in protocols like Diffie-Hellman key exchange, Ed448 can provide forward secrecy, ensuring that the compromise of long-term keys does not compromise past session keys.</p> <p>Ed448 is used in scenarios where higher security levels are required. Its applications include:</p> <ul> <li>Digital Signatures: It's used for signing digital documents and software, ensuring their integrity and authenticity.</li> <li>Secure Communication Protocols: Ed448 can be used in protocols like TLS for secure internet communications, offering a higher security alternative to Ed25519.</li> <li>Cryptographic Authentication: It's suitable for authenticating entities in various security-sensitive applications.</li> </ul> <p>While the actual implementation involves complex mathematical operations, here\u2019s a simplified conceptual view of how Ed448 might be used:</p> <pre><code># Pseudo-code example\ned448_keypair = generate_ed448_keypair()  # Generate Ed448 key pair\n\n# Signing a message\nmessage = \"High-security message\"\nsignature = ed448_sign(message, ed448_keypair.private_key)\n\n# Verifying a signature\nif ed448_verify(signature, message, ed448_keypair.public_key):\n    print(\"Signature is valid\")\nelse:\n    print(\"Signature is invalid\")\n</code></pre>"},{"location":"cryptography/ed2/","title":"Ed25519","text":"<p>Ed25519 is a public-key signature system with several attractive features: it's fast, has small signatures, and is resistant to several types of cryptographic attacks. It's a specific implementation of the EdDSA (Edwards-curve Digital Signature Algorithm) using the Curve25519 elliptic curve. Ed25519 has gained popularity and widespread adoption in various cryptographic applications and protocols.</p> <p>Ed25519 offers fast signature generation and verification. This makes it suitable for environments where these operations need to be performed frequently or rapidly, such as in web servers or mobile applications. Ed25519 is designed to be resistant to a variety of attacks, including Side-Channel Attacks. It's also not vulnerable to many common pitfalls of elliptic curve cryptography, such as weak random number generation.</p> <p>The public and private keys are relatively small compared to other cryptographic systems. The signatures generated are also compact, which is beneficial for systems where bandwidth or storage space is a concern.</p> <p>Unlike some other signature systems, Ed25519 generates deterministic signatures, meaning the same message signed with the same key will always produce the same signature. This avoids the need for a high-quality random number generator for each signature and reduces the risk of key leakage.</p> <p>The algorithm is designed to be \"constant-time\", avoiding secret-dependent branches and array indices, which helps in resisting side-channel attacks.</p> <p>Ed25519 is used for SSH keys due to its security and performance advantages. Some TLS certificate authorities offer Ed25519 as an option for signing certificates. Ed25519 is used in several cryptocurrency wallets and systems for securely signing transactions. It's also used for signing software packages and ensuring their integrity and authenticity.</p> <p>Here's a simplified conceptual example of using Ed25519 for signing and verifying a message:</p> <pre><code># Pseudo-code example\ned25519_keypair = generate_ed25519_keypair()\n\n# Signing a message\nmessage = \"Secure message\"\nsignature = ed25519_sign(message, ed25519_keypair.private_key)\n\n# Verifying a signature\nif ed25519_verify(signature, message, ed25519_keypair.public_key):\n    print(\"Signature is valid\")\nelse:\n    print(\"Signature is invalid\")\n</code></pre>"},{"location":"cryptography/eddsa/","title":"EdDSA (Edwards-Curve Digital Signature Algorithm)","text":"<p>EdDSA, or Edwards-curve Digital Signature Algorithm, is a public-key signature system that uses elliptic curve cryptography. It is a variant of the Digital Signature Algorithm (DSA) which leverages elliptic curves, specifically Edwards curves, for enhanced security and performance.</p> <p>EdDSA was developed as an alternative to existing signature schemes like ECDSA (Elliptic Curve Digital Signature Algorithm) and DSA, and it addresses some of their limitations. EdDSA is designed to be secure against several types of cryptographic attacks. It is less prone to certain vulnerabilities that can affect other signature algorithms, particularly those related to the implementation and random number generation.</p> <p>EdDSA is generally faster than ECDSA, especially in verification, which is a critical operation in many applications. It's also more efficient in terms of computation and memory usage. EdDSA has a simpler and more straightforward implementation compared to other elliptic curve-based algorithms. This simplicity reduces the likelihood of security flaws.</p> <p>Unlike ECDSA, which requires a unique random value for each signature (and can be vulnerable if this value is weak or reused), EdDSA does not have this requirement. It uses deterministic generation of per-signature randomness, which helps in avoiding potential security pitfalls.</p> <p>EdDSA signatures are inherently non-malleable, meaning that it's infeasible to alter a valid signature into another valid signature for the same message and key pair.</p> <p>Some common variants include:</p> <ul> <li>Ed25519: Perhaps the most well-known variant of EdDSA, it uses the Curve25519 elliptic curve and offers a good balance of security and performance. It's widely used in various cryptographic applications, including SSH keys and TLS certificates.</li> <li>Ed448: This variant uses a larger curve (Curve448) and provides higher security levels. It is suitable for applications where maximum security is paramount.</li> </ul> <p>EdDSA is used for generating and verifying digital signatures in various cryptographic applications, including:</p> <ul> <li>Secure Communication Protocols: Like TLS and SSH, where Ed25519 is a popular choice for key exchange and authentication.</li> <li>Cryptocurrency Wallets: For signing transactions in several blockchain and cryptocurrency platforms.</li> <li>Software Security: In code signing to ensure the integrity and authenticity of software packages.</li> </ul> <p>A simplified example of using EdDSA for signing and verifying a message:</p> <pre><code># Pseudo-code example\neddsa_keypair = generate_eddsa_keypair()  # Generate EdDSA key pair\n\n# Signing a message\nmessage = \"Secure message\"\nsignature = eddsa_sign(message, eddsa_keypair.private_key)\n\n# Verifying a signature\nif eddsa_verify(signature, message, eddsa_keypair.public_key):\n    print(\"Signature is valid\")\nelse:\n    print(\"Signature is invalid\")\n</code></pre>"},{"location":"cryptography/egl/","title":"ElGamal","text":"<p>ElGamal is a cryptographic algorithm used for both encryption and digital signatures. It's based on the Diffie-Hellman key exchange and the Discrete Logarithm Problem, making it part of the family of public key cryptographic systems. ElGamal was introduced by Taher Elgamal in 1985 and remains relevant due to its security properties and its basis in mathematical problems for which no efficient solving algorithm is known.</p> <p>The ElGamal encryption system is an asymmetric key encryption algorithm for public-key cryptography which is based on the Diffie-Hellman key exchange.</p> <p>Like other public-key systems, ElGamal uses two keys: a public key, which can be shared openly, and a private key, which must be kept secret. It involves choosing a large prime number $p$, a generator $g$ of the multiplicative group of integers modulo $p$, and a private key $x$ which is a random number. The public key $u$ is then calculated as $y$=$g$$^x$ mod\u2009\u2009$p$.</p> <p>The encryption process is:</p> <ol> <li>The sender, who knows the receiver's public key $y$, picks a random number $k$ and computes the shared secret $s$=$y$$^k$ mod\u2009\u2009$p$</li> <li>The sender then encrypts the message $m$ by multiplying it with $s$ and sends both $g$$^k$ mod $p$ and the encrypted message.</li> </ol> <p>The decryption process is:</p> <ol> <li>The receiver uses their private key $x$ and the received $g$$^k$ mod\u2009\u2009$p$ to reconstruct the shared secret $s$ and then decrypts the message.</li> </ol> <p>ElGamal can also be used for digital signatures. Its signature scheme is based on the difficulty of computing discrete logarithms.</p>"},{"location":"cryptography/egl/#signature-generation","title":"Signature Generation","text":"<ol> <li>A hash or digest of the message is created.</li> <li>The signer then uses their private key to generate a signature on the message hash.</li> </ol>"},{"location":"cryptography/egl/#signature-verification","title":"Signature Verification","text":"<ol> <li>Anyone with the signer's public key can verify the authenticity of the signature by relating it to the hash of the original message.</li> </ol> <p>The security of ElGamal encryption depends on the difficulty of solving the discrete logarithm problem. ElGamal is generally slower than some other public-key algorithms and generates larger ciphertexts, making it less efficient for encrypting large messages. However, it's often used for securely transmitting keys rather than the message content itself.</p> <p>ElGamal encryption is used in various cryptographic applications, including secure email communication, digital signatures in software distribution, and more.</p>"},{"location":"cryptography/fes/","title":"Feistel Network","text":"<p>A Feistel network is a design model used in the construction of block ciphers. This structure is known for its simplicity and effectiveness in encrypting data.</p> <p>The Feistel network is a symmetric structure, which means that the same steps and keys can be used for both encryption and decryption, with only a minor modification (reversing the key schedule). This symmetry simplifies the design of the cipher.</p> <p>In a Feistel cipher, each data block is divided into two equal-sized halves. The operation of the cipher proceeds through multiple rounds, each of which processes these halves.</p> <p>During each round, one half of the block is processed through a round function and then XORed (exclusive OR operation) with the other half. The round function typically involves substitution and permutation steps and is driven by a subkey derived from the main key.</p> <p>After each round, the two halves of the block are swapped. This means that the half that was modified in the current round becomes the unmodified half in the next round. The Feistel structure typically involves multiple rounds of processing. The number of rounds depends on the specific cipher design and the desired level of security.</p> <p>A key schedule is used to generate a series of round keys from the main key. These round keys are used in each round of the Feistel cipher. A crucial feature of the Feistel network is its reversibility, which ensures that decryption is possible. The decryption process is essentially the same as the encryption process, just using the round keys in the reverse order.</p> <p>Some well-known block ciphers based on the Feistel structure include the Data Encryption Standard (DES), Triple DES (3DES), and the Blowfish algorithm.</p> <p>The security of a Feistel cipher depends on the specifics of the round function, the number of rounds, and the complexity of the key schedule. Properly designed Feistel ciphers are considered secure and effective for many cryptographic applications.</p>"},{"location":"cryptography/gcm/","title":"Galois Counter Mode (GCM)","text":"<p>Galois/Counter Mode (GCM) is an encryption mode that combines the counter mode (CTR) of block cipher encryption with the Galois mode of authentication. It's widely used for its efficiency and security, particularly in encrypting and authenticating data in communication protocols like TLS and IPsec. </p> <p>GCM is a mode of operation for symmetric key cryptographic block ciphers such as AES. GCM combines the counter mode (CTR) for encryption, which turns a block cipher into a stream cipher, with a Galois field multiplication operation to provide data authenticity (integrity checking).</p> <p>One of the significant advantages of GCM is that it provides both confidentiality (encryption) and integrity/authentication in a single, efficient process.</p> <p>GCM is known for its high performance and efficiency, particularly in hardware implementations. It can process large amounts of data quickly, making it suitable for high-speed communication channels.</p> <p>GCM is used in various secure communication protocols, including TLS (Transport Layer Security) and IPsec (Internet Protocol Security), to provide secure data transmission.</p> <p>GCM provides protection against replay attacks, where an adversary attempts to disrupt communication by repeating or delaying data packets. GCM requires a unique nonce (number used once) for each encryption operation with the same key. Nonce reuse can severely compromise security, particularly the confidentiality of the data.</p> <p>In GCM, the counter mode operates as a stream cipher. It generates keystream blocks, which are XORed with the plaintext blocks for encryption. GCM produces an authentication tag as part of the encryption process, which can be used to verify the integrity and authenticity of the data upon decryption.</p>"},{"location":"cryptography/gmac/","title":"GMAC (Galois Counter Mode MAC)","text":"<p>GMAC (Galois/Counter Mode MAC) is a type of Message Authentication Code (MAC) used in cryptographic communications. It is specifically associated with Galois/Counter Mode (GCM), which is a mode of operation for symmetric key cryptographic block ciphers. GMAC provides a way to ensure both the integrity and authenticity of a message.</p> <p>GMAC is often used in conjunction with Galois/Counter Mode, a mode that combines the counter mode of encryption with the Galois mode of authentication. The GCM, which includes GMAC, is used for encrypting and authenticating data.</p> <p>It operates within the realm of symmetric key encryption, meaning the same key is used for both encryption and decryption. GMAC (and GCM) is designed to provide high-performance authenticated encryption and is particularly efficient for hardware implementations. It is highly secure and resistant to various cryptographic attacks when used correctly.</p> <p>GMAC is typically used with block ciphers like AES (Advanced Encryption Standard). In GCM, the block cipher operates in counter mode for encryption, while GMAC provides message authentication.</p> <p>In GCM, data is encrypted in a stream cipher mode (using the counter mode of encryption) and authenticated using GMAC. GMAC generates an authentication tag (MAC) for a message and a nonce (number used once). This tag is used to verify the integrity and authenticity of the message at the receiving end. A unique nonce is used for each message to ensure the security of the encryption and authentication process.</p> <p>GMAC is widely used in secure communication protocols, especially where high throughput and strong security are required. It's used in protocols like TLS (Transport Layer Security) and IPsec (Internet Protocol Security).</p> <p>Given its efficiency, GMAC is suitable for environments with limited computational resources, such as wireless and mobile applications.</p>"},{"location":"cryptography/hmac/","title":"HMAC (Hash-Based Message Authentication Code)","text":"<p>HMAC (Hash-based Message Authentication Code) is a type of cryptographic function used to create a message authentication code (MAC) involving a cryptographic hash function in combination with a secret cryptographic key. It provides both integrity and authentication of a message. HMAC is widely used in various security applications and protocols, including TLS and SSL, IPsec, and more.</p> <p>HMAC combines a user-provided secret key with the data/message to be authenticated. The key is used in conjunction with the hash function to create a unique MAC for the data. A cryptographic hash function (like SHA-256) is used to compute the hash. This function takes an input (or 'message') and returns a fixed-size string of bytes. The output is typically a hash value or digest.</p> <p>The process is as follows:</p> <ul> <li>The key is combined with the input message.</li> <li>The combined key and message are then passed through the hash function.</li> <li>The output hash (MAC) is then used to verify the integrity and authenticity of the message.</li> </ul> <p>To verify the message, the receiver uses the same key and hash function to generate an HMAC from the received message. If this HMAC matches the one sent with the message, it confirms that the message has not been altered and is authentic.</p> <p>HMAC provides security against certain types of cryptographic attacks (like collision attacks) inherent in traditional hash functions when used for MAC purposes. The security of an HMAC depends on the secrecy of the key; as long as the key is kept secret, it is very difficult to forge a MAC.</p> <p>HMAC can be used with any cryptographic hash function, like MD5 or SHA-256 with the security strength being contingent upon the underlying hash function.</p> <p>It is commonly used for the following:</p> <ul> <li>Data Integrity: Ensuring that data has not been altered during transmission.</li> <li>Authentication: Verifying that a message was sent by the holder of the secret key.</li> <li>Secure Communications: Used in various network security protocols (like SSL/TLS) for secure data transmission.</li> <li>API Security: Often used to authenticate API requests between a client and a server.</li> </ul>"},{"location":"cryptography/hmaco/","title":"HMAC-Based One-Time Password (HOTP)","text":"<p>The HMAC-based One-Time Password algorithm (HOTP) is a method for generating a [[One-Time Password (OTP)]] using a cryptographic hash function and a counter. HOTP is an open standard and is defined in the Request for Comments (RFC) 4226 by the Internet Engineering Task Force (IETF). It's widely used for authentication purposes, especially in systems that require strong security, such as online banking and corporate networks.</p> <p>Both the server and the user have a pre-shared secret key. This key is usually set up when the user enrolls in the service. HOTP uses a counter as an input to the algorithm. The counter is typically a simple incrementing integer and is synchronized between the server and the user's token. Each time an OTP is generated, the counter is incremented.</p> <p>The algorithm combines the shared secret key and the current counter value using a cryptographic hash function (typically SHA-1) to generate an HMAC (Hash-based Message Authentication Code).</p> <p>The HMAC is then truncated to create a shorter value, which is the OTP. The truncation process ensures that the OTP is a manageable size, typically 6 to 8 digits. When a user attempts to authenticate, they enter the OTP generated by their device. The server, which also knows the secret key and the current counter value, generates its own OTP. If the server's OTP matches the user's OTP, the authentication is successful.</p> <p>HOTP is considered secure because it uses strong cryptographic hash functions. The OTP is difficult to guess without access to the secret key and the current counter value. Unlike time-based OTPs, HOTP doesn't rely on time synchronization between the server and the client, which can be an advantage in environments where time sync is challenging.</p> <p>Both the server and the client need to keep track of the counter state, which can be a disadvantage if the counter values on the server and the client become unsynchronized.</p> <p>Info</p> <p>HOTP is commonly used in hardware tokens (like key fobs) for two-factor authentication. When a user presses a button on the token, it displays a new OTP generated using the HOTP algorithm.</p> <p>HOTP is similar to TOTP (Time-based One-Time Password) but, unlike TOTP, which generates OTPs based on a moving time window, HOTP generates OTPs based on a counter value. Each approach has its own advantages and is suited to different application requirements.</p>"},{"location":"cryptography/md5/","title":"MD5","text":"<p>MD5, which stands for \"Message Digest Algorithm 5,\" is a widely used cryptographic hash function that generates a fixed-size, 128-bit (16-byte) hash value or checksum from input data of arbitrary length. It quickly gained popularity and was widely used in various software applications and systems for tasks such as data integrity checking, password storage, and digital signatures.</p> <p>MD5 produces a 128-bit hash value, regardless of the size or length of the input data. This results in a fixed-length representation of the data. For the same input data, MD5 will always produce the same hash value. This determinism is crucial for verifying data integrity. MD5 is relatively fast and efficient to compute, making it suitable for various applications where performance is a consideration.</p> <p>It should be computationally infeasible to reverse the hash value to obtain the original input data (pre-image resistance). This property ensures that the original data remains confidential.</p> <p>MD5 has been found to have significant vulnerabilities, which have led to its deprecation and discouragement for use in security-sensitive applications. These vulnerabilities include:</p> <ol> <li>Collision Vulnerabilities: Researchers have demonstrated that it is possible to find two different inputs that produce the same MD5 hash value (collision attacks). This undermines the integrity and security of data verification systems that rely on MD5.</li> <li>Cryptographic Weakness: MD5 is no longer considered a secure cryptographic hash function due to advances in cryptanalysis techniques. It is vulnerable to various attacks, including collision attacks and pre-image attacks.</li> <li>Non-Security Use Cases: While MD5 is unsuitable for cryptographic security, it is still used in non-security-critical applications, such as checksums for data integrity checking or generating unique identifiers for non-cryptographic purposes.</li> </ol> <p>As a result of its security weaknesses, MD5 has been replaced by more secure cryptographic hash functions, such as SHA-256 (part of the SHA-2 family) and SHA-3. These newer hash functions provide better security guarantees and are recommended for use in security-sensitive applications.</p>"},{"location":"cryptography/ofb/","title":"OFB (Output Feedback)","text":"<p>OFB, or Output Feedback mode, is a mode of operation for block ciphers. It effectively turns a block cipher into a synchronous stream cipher. OFB mode enables the encryption of plaintext messages of any length, and it's particularly useful in scenarios where the same encryption key is used multiple times.</p> <p>OFB mode starts with an IV, which must be unique for each encryption operation with the same key. The IV is typically the size of the block cipher's block size.</p> <ul> <li>The IV is encrypted with the block cipher.</li> <li>The output of this encryption (not the plaintext) is then XORed with the plaintext to produce the ciphertext.</li> <li>For the next block, this encrypted output (not the ciphertext) is encrypted again with the block cipher, and the output of this is XORed with the next segment of plaintext to produce the next segment of ciphertext.</li> <li>This process continues for the entire length of the plaintext.</li> </ul> <p>The decryption process in OFB mode is essentially the same as the encryption process. The same sequence of blocks that was XORed with the plaintext during encryption is XORed with the ciphertext during decryption to recover the plaintext.</p> <p>Like CFB, OFB turns a block cipher into a stream cipher. It is suitable for encrypting data of any size. In OFB mode, errors in a ciphertext do not propagate; a bit error in the ciphertext results in a corresponding bit error in the plaintext. </p> <p>OFB relies on synchronization between the sender and receiver. If they become desynchronized (e.g., due to lost or inserted bits), decryption will fail until they are resynchronized. OFB can process data in segments smaller than the block size, so it does not require padding the plaintext to a multiple of the block size.</p> <p>OFB mode is often used in scenarios where error propagation is undesirable and the transmission channel might introduce errors, such as in satellite or wireless communication.</p> <p>An example:</p> <pre><code># Pseudo-code example using a block cipher in OFB mode\ncipher = BlockCipher(key, mode=OFB, iv=initialization_vector)\n\n# Encrypt\nciphertext = cipher.encrypt(plaintext)\n\n# Decrypt\ndecrypted_text = cipher.decrypt(ciphertext)\n</code></pre>"},{"location":"cryptography/pfs/","title":"Perfect Forward Secrecy","text":"<p>Perfect Forward Secrecy (PFS) is a property of secure communication protocols that ensures a session's encryption keys cannot be compromised even if the long-term secret keys used for encrypted communications are compromised in the future. PFS is crucial for maintaining the confidentiality of past communication sessions.</p> <p>PFS typically involves generating a unique session key for each communication session. These keys are used for encrypting and decrypting messages during the session. PFS is often achieved through key agreement protocols like Diffie-Hellman, which allow two parties to establish a shared secret key over an open channel without the key itself ever being transmitted or exposed.</p> <p>Once the communication session is over, the session keys are discarded. Without these keys, it becomes impossible to decrypt the session data, even if the attacker obtains the long-term keys.</p> <p>If a server\u2019s private key is compromised (for instance, if a hacker breaches the server or if future advances in computing make cracking the key feasible), any past communications encrypted with keys associated with that private key are still secure, as those specific session keys cannot be retroactively deciphered.</p> <p>PFS adds an additional layer of security in data transmission, particularly in cases where sensitive information is being communicated over a period.</p> <p>Modern implementations of SSL/TLS protocols (like TLS 1.3) use PFS by default by employing ephemeral versions of key exchange algorithms (like Diffie-Hellman Ephemeral or DHE, and Elliptic Curve Diffie-Hellman Ephemeral or ECDHE).</p> <p>Implementing PFS can increase the computational load on a server since it requires generating new keys for each session. PFS doesn't protect against the disclosure of session keys that are currently in use or against the compromise of the data before encryption or after decryption.</p>"},{"location":"cryptography/pgp/","title":"PGP (Pretty Good Privacy)","text":"<p>PGP (Pretty Good Privacy) is an encryption program that provides cryptographic privacy and authentication for data communication. PGP is used for securing emails, files, and other forms of data transmission.</p> <p>PGP uses a combination of symmetric-key cryptography and public-key cryptography. This hybrid approach provides the benefits of both methods: the efficiency of symmetric-key encryption and the secure key distribution of public-key encryption.</p> <p>When sending an encrypted message, PGP first compresses the plaintext. It then encrypts the compressed message using a symmetric encryption algorithm with a one-time, randomly generated key (known as the session key).</p> <p>The session key is then encrypted using the recipient's public key. This encrypted session key is sent along with the encrypted message to the recipient.</p> <p>The recipient uses their private key to decrypt the session key, which is then used to decrypt the encrypted message. PGP allows users to sign their messages digitally using their private key. Recipients can verify the signature using the sender's public key, ensuring the authenticity and integrity of the message.</p> <p>PGP uses a decentralized trust model known as the \"web of trust.\" Unlike a Certificate Authority (CA) in other encryption models, PGP users endorse the validity of each other's keys. Users build a network of trust by signing and verifying each other's public keys.</p> <p>Users generate a pair of keys, a public key, and a private key. The public key is shared with others to receive encrypted messages or verify digital signatures, while the private key is kept secure and is used to decrypt messages or sign messages.</p> <p>Public keys can be stored on PGP key servers, making them easily accessible to anyone wanting to send an encrypted message. </p> <p>PGP is widely used for securing email communication, but it can also encrypt files, directories, and disk partitions. It\u2019s a standard tool in secure data transmission and is often used in situations where sensitive information needs to be protected.</p>"},{"location":"cryptography/pki/","title":"Public Key Infrastructure (PKI)","text":"<p>Public Key Infrastructure (PKI) is a framework of policies, technologies, and procedures that provide secure electronic transactions and communication over networks. It utilizes asymmetric cryptography to ensure secure data exchange and authentication. PKI is foundational to many aspects of digital security and trust.</p> <p>At the heart of PKI are digital certificates, which are electronic documents used to verify the identity of entities (such as individuals, organizations, or devices) and associate them with a corresponding public key.</p> <p>CAs are trusted entities that issue and manage digital certificates. They validate the identity of certificate applicants and issue certificates to affirm that identity.</p> <p>PKI uses asymmetric encryption, which involves a pair of keys \u2013 a public key and a private key. The public key is shared openly, while the private key is kept secret. Data encrypted with a public key can only be decrypted with the corresponding private key, and vice versa.</p> <p>PKI enables encryption for confidentiality and digital signatures for authentication and integrity. A digital signature is created using a private key and can be verified by anyone with the corresponding public key.</p> <p>CRLs (Certificate Revocation Lists) are lists of certificates that have been revoked before their expiration dates, usually because the private key has been compromised or the user's credentials have changed.</p> <p>Online Certificate Status Protocol (OCSP) is an alternative to CRLs for checking a certificate's revocation status. It provides real-time verification, which is more efficient than downloading CRLs.</p> <p>PKI often involves a hierarchy of certificates. Root certificates are at the top of this hierarchy and are used to sign intermediate certificates, which in turn are used to sign end-user certificates. PKI establishes a chain of trust. If you trust the CA (and by extension, its root certificate), you can trust the certificates it has issued.</p> <p>PKI is used in various applications, including securing web communications (SSL/TLS), encrypting emails (S/MIME), authenticating users and devices in various systems, and ensuring secure transactions in e-commerce.</p>"},{"location":"cryptography/poly/","title":"Poly1305","text":"<p>Poly1305 is a cryptographic message authentication code (MAC) used for verifying the integrity and authenticity of data. It is often used in conjunction with encryption algorithms, particularly stream ciphers like ChaCha20, to provide a combined encryption and authentication solution. Poly1305 is known for its high speed and security, making it a popular choice in modern cryptographic protocols.</p> <p>Poly1305 is designed for high performance. It's particularly efficient in software implementations, making it suitable for a wide range of hardware, from high-end servers to low-power devices. It provides strong security assurances and is resistant to various cryptographic attacks, including timing attacks. Poly1305's design ensures that it's difficult for attackers to forge a valid MAC without knowing the secret key.</p> <p>Poly1305 uses a one-time key for each message. This design choice enhances security but also means that the key must never be reused across different messages. While Poly1305 itself is not an encryption algorithm but a MAC, it's commonly used in combination with encryption algorithms like ChaCha20. The ChaCha20-Poly1305 combination is a popular choice for encrypting and authenticating data in protocols like TLS and for applications like secure messaging.</p> <p>Poly1305 is used to ensure not only the confidentiality of data (through encryption) but also its integrity and authenticity. This is crucial in many communication protocols where it's important to detect any tampering with the data. In TLS (especially version 1.3 and later), ChaCha20-Poly1305 is a recommended cipher suite, providing both encryption and authentication.</p> <p>Poly1305 is used in various VPN technologies and secure messaging applications to protect data in transit. </p> <p>In an application, you might use Poly1305 in conjunction with an encryption algorithm like ChaCha20. Here's a simplified conceptual overview:</p> <pre><code># Pseudo-code example\nkey = generateEncryptionKey()\nnonce = generateNonce()\n\n# Encrypt message using ChaCha20\nencrypted_message = chacha20_encrypt(message, key, nonce)\n\n# Generate MAC using Poly1305\nmac = poly1305(encrypted_message, key)\n\n# Send or store both the encrypted_message and mac\n\n# To verify and decrypt the message\nreceived_mac = receive_mac()  # Assume this retrieves the MAC\nif poly1305_verify(received_mac, encrypted_message, key):\n    decrypted_message = chacha20_decrypt(encrypted_message, key, nonce)\nelse:\n    raise Exception(\"Authentication failed\")\n</code></pre>"},{"location":"cryptography/psk/","title":"Pre-Shared Key (PSK)","text":"<p>A pre-shared key (PSK) is a secret key used in cryptography that is shared between two parties before being used in a security protocol, such as an encryption or authentication process. PSK is commonly used in various network security contexts, including Wi-Fi networks and VPNs.</p> <p>The key must be shared between parties before it can be used for secure communication. This sharing is typically done over a secure channel or through a secure method of distribution.</p> <p>PSKs are used in symmetric key cryptography, where the same key is used for both encryption and decryption of messages. In Wi-Fi networks, a PSK is often used in WPA and WPA2 (Wi-Fi Protected Access) security protocols. The PSK is what is commonly referred to as the \"Wi-Fi password\".</p> <p>PSKs are relatively simple to implement compared to more complex key management systems. They don't require a certificate infrastructure or extensive authentication processes. In VPNs (Virtual Private Networks), PSKs can be used to authenticate the endpoints of the VPN connection. Each endpoint must know the PSK to establish a secure connection.</p> <p>The strength of a PSK-based system depends on the secrecy and randomness of the key. A weak or compromised PSK can lead to security vulnerabilities. PSK systems can become cumbersome in large-scale environments because the key must be securely distributed to each party and maintained. This can become a logistical challenge as the number of users increases.</p> <p>In IPsec protocols, PSKs are one method of establishing the identity of the communicating parties, especially in IKE (Internet Key Exchange) to set up secure IPsec connections. If a PSK is exposed, all data previously transmitted using that key can potentially be decrypted, assuming an attacker has access to the encrypted data.</p>"},{"location":"cryptography/rij/","title":"RIJNDAEL","text":"<p>Rijndael is a symmetric key encryption algorithm that was selected as the Advanced Encryption Standard (AES) by the U.S. National Institute of Standards and Technology (NIST) in 2001.</p> <p>Rijndael is a block cipher, meaning it encrypts data in fixed-size blocks. The standard block size is 128 bits, but Rijndael can be implemented with block sizes of 192 or 256 bits as well. It uses the same key for both encryption and decryption. Key sizes can be 128, 192, or 256 bits, offering a good balance between security and performance.</p> <p>AES is widely regarded as highly secure and is used globally for various security applications. Its adoption as a standard reflects its strength and the confidence of the cryptographic community in its security properties. </p> <p>Rijndael/AES is efficient in both software and hardware implementations, making it suitable for a wide range of applications, from high-end servers to small embedded devices. While AES itself is a block cipher, it can be used in different modes of operation (like CBC, GCM, CTR) to encrypt data streams of arbitrary length or to provide additional security features.</p> <p>AES is used in SSL/TLS for secure web communications, VPNs, and many other types of secure data transmission. It's used in various file and disk encryption systems to protect data at rest. Given its security, AES is used in sensitive government and military communications. AES is also used in cryptocurrency wallets and blockchain technologies for securing transactions.</p> <p>Here's a conceptual example of using AES in a programming context:</p> <pre><code># Pseudo-code example\nfrom Crypto.Cipher import AES\n\nkey = generate_aes_key()  # Generate a secure AES key\ncipher = AES.new(key, AES.MODE_CBC)  # Create a new AES cipher\n\n# Encrypting data\nplaintext = \"Secret Data\"\nciphertext = cipher.encrypt(pad(plaintext, AES.block_size))\n\n# Decrypting data\ndecrypted = unpad(cipher.decrypt(ciphertext), AES.block_size)\n</code></pre> <p>While AES is based on Rijndael, the term \"AES\" specifically refers to the standard adopted by NIST, which uses the Rijndael algorithm with a fixed block size of 128 bits and key sizes of 128, 192, or 256 bits. The original Rijndael algorithm was designed to be more flexible with both block and key sizes, but this flexibility is not part of the AES standard.</p>"},{"location":"cryptography/rot13/","title":"ROT13","text":"<p>ROT13 (\"rotate by 13 places\") is a simple letter substitution cipher that replaces a letter with the 13th letter after it in the alphabet. ROT13 is a special case of the Caesar cipher which was developed in ancient Rome.</p> <p>Each letter in the plaintext is replaced by a letter located 13 positions down the alphabet. Because the alphabet has 26 letters, ROT13 is its own inverse. Applying ROT13 to encrypted text decodes it, and applying it again re-encrypts it. For example, \"hello\" becomes \"uryyb\" under ROT13.</p> <p>Websites sometimes use ROT13 to encode email addresses in HTML source code, intending to prevent them from being easily harvested by spambots. While this can reduce the amount of spam, many sophisticated bots can easily decode ROT13.</p> <p>In some programming contexts, ROT13 might be used to obfuscate strings within the code. This can serve to lightly conceal messages, URLs, or other data within the source code from immediate recognition.</p> <p>It's important to understand that ROT13 offers no real security. It's a very weak form of obfuscation that can be easily reversed by anyone who recognizes the technique or has access to a ROT13 decoder, which are readily available online. </p> <p>Consequently, ROT13 should never be used for any serious or sensitive data protection. Its value lies in its simplicity and in situations where only a basic level of obfuscation is sufficient.</p>"},{"location":"cryptography/rsa/","title":"RSA (Rivest-Shamir-Adleman)","text":"<p>RSA (Rivest-Shamir-Adleman) is one of the first public-key cryptosystems and is widely used for secure data transmission. Named after its inventors, Ron Rivest, Adi Shamir, and Leonard Adleman, who first publicly described it in 1977, RSA has become one of the most important algorithms in asymmetric encryption.</p> <p>The Rivest-Shamir-Adleman (RSA) encryption algorithm is an asymmetric encryption algorithm that is widely used in many products and services. Asymmetric Encryption uses a key pair that is mathematically linked to encrypt and decrypt data. </p> <p>A private and public key are created, with the public key being accessible to anyone and the private key being a secret known only by the key pair creator. With RSA, either the private or public key can encrypt the data, while the other key decrypts it. This is one of the reasons RSA is the most used asymmetric encryption algorithm.</p> <p>The option to encrypt with either the private or public key provides a multitude of services to RSA users. If the public key is used for encryption, the private key must be used to decrypt the data. This is perfect for sending sensitive information across a network or Internet connection, where the recipient of the data sends the data sender their public key. </p> <p>The sender of the data then encrypts the sensitive information with the public key and sends it to the recipient. Since the public key encrypted the data, only the owner of the private key can decrypt the sensitive data. Thus, only the intended recipient of the data can decrypt it, even if the data were taken in transit.</p> <p>The other method of asymmetric encryption with RSA is encrypting a message with a private key. In this example, the sender of the data encrypts the data with their private key and sends encrypted data and their public key along to the recipient of the data. </p> <p>The recipient of the data can then decrypt the data with the sender\u2019s public key, thus verifying the sender is who they say they are. With this method, the data could be stolen and read in transit, but the true purpose of this type of encryption is to prove the identity of the sender. </p> <p>If the data were stolen and modified in transit, the public key would not be able to decrypt the new message, and so the recipient would know the data had been modified in transit.</p> <p>The technical details of RSA work on the idea that it is easy to generate a number by multiplying two sufficiently large numbers together, but factorizing that number back into the original prime numbers is extremely difficult. </p> <p>The public and private key are created with two numbers, one of which is a product of two large prime numbers. Both use the same two prime numbers to compute their value. RSA keys tend to be 1024 or 2048 bits in length, making them extremely difficult to factorize, though 1024 bit keys are believed to breakable soon.</p>"},{"location":"cryptography/sha1/","title":"SHA-1","text":"<p>SHA-1 (Secure Hash Algorithm 1) is a cryptographic hash function designed by the National Security Agency (NSA) and published by the National Institute of Standards and Technology (NIST) in 1995. It produces a 160-bit (20-byte) hash value, typically rendered as a 40-digit hexadecimal number. SHA-1 is part of the SHA family of algorithms.</p> <p>Regardless of the input size, SHA-1 generates a fixed-size 160-bit hash. The hash is designed to be unique; different inputs should yield different hashes (though this has been compromised over time). The same input always results in the same hash output.</p> <p>It was initially favored for its speed and efficiency in generating hashes. It's computationally infeasible to reverse the hash function to retrieve the original input data.</p> <p>It is used to ensure data integrity by generating a hash of the data and then verifying the hash at the receiving end. Utilized in digital signature algorithms to ensure the authenticity of digital documents.</p> <p>It is also employed in SSL/TLS certificates for securing websites (though this use has been phased out). It was also used to verify the integrity of software packages by comparing the hash of the downloaded file with a published hash.</p> <p>Over time, vulnerabilities in SHA-1 have been discovered, including the potential for collision attacks (where two different inputs produce the same hash). These vulnerabilities compromise its security effectiveness. Due to these vulnerabilities, SHA-1 has been increasingly phased out in favor of more secure algorithms like SHA-256 and SHA-3.</p> <p>An example of a SHA-1 hash of the string \"Hello, world!\" might look like this:</p> <pre><code>7f83b1657ff1fc53b92dc18148a1d65dfc2d4b1f\n</code></pre>"},{"location":"cryptography/sha256/","title":"SHA-256","text":"<p>SHA-256, which stands for Secure Hash Algorithm 256-bit, is one of the members of the SHA-2 (Secure Hash Algorithm 2) family of cryptographic hash functions. It is a widely used and respected cryptographic hash function designed to take an input (often referred to as a \"message\") and produce a fixed-size 256-bit (32-byte) hash value. SHA-256 is known for its security and resistance to collision attacks.</p> <p>SHA-256 always produces a 256-bit (32-byte) hash value, regardless of the size of the input data. SHA-256 is considered a cryptographic hash function, meaning it is designed to provide a high level of security. It is resistant to preimage attacks, second preimage attacks, and collision attacks, making it suitable for various security-critical applications.</p> <p>A given input will consistently produce the same SHA-256 hash value, ensuring predictability and consistency. A small change in the input data results in a significantly different hash value. This property ensures that similar inputs produce very dissimilar hash values.</p> <p>Common Uses:</p> <ul> <li>Password Hashing: SHA-256 is often used to securely hash user passwords for storage. It provides a one-way transformation of passwords, making it difficult for attackers to reverse-engineer the original passwords from the hash values.</li> <li>Data Integrity: SHA-256 is used to verify the integrity of data during transmission. By comparing the hash of received data with a precomputed hash, it's possible to check if the data has been tampered with.</li> <li>Digital Signatures: SHA-256 is a component of various digital signature algorithms, including those used in secure communication and public key infrastructure (PKI).</li> <li>Blockchain and Cryptocurrencies: SHA-256 is extensively used in blockchain technologies and cryptocurrencies like Bitcoin to create secure and immutable transaction records.</li> <li>Secure File Verification: SHA-256 can be used to verify the authenticity and integrity of downloaded files or software by comparing the computed hash with a trusted hash value provided by the source.</li> </ul>"},{"location":"cryptography/sha3/","title":"SHA-3","text":"<p>SHA-3 (Secure Hash Algorithm 3) is the latest member of the Secure Hash Algorithm family of standards, released by the National Institute of Standards and Technology (NIST) in 2015. SHA-3 was developed as a part of a public competition to create a new hash algorithm that would be more resistant to the types of attacks that had started to threaten its predecessors like SHA-1 and SHA-2.</p> <p>SHA-3 can produce hash values of different lengths \u2013 224, 256, 384, or 512 bits, making it versatile for various security requirements. It offers strong resistance against known types of cryptographic attacks, including the ones that have started to affect SHA-1 and SHA-2 (like collision attacks).</p> <p>SHA-3 uses a mathematical model known as \"sponge construction,\" which differs from the Merkle-Damg\u00e5rd construction used in previous SHA versions. This construction allows SHA-3 to have flexibility in terms of input and output lengths and makes it suitable for a variety of cryptographic applications beyond just hashing.</p> <p>Despite being a part of the SHA family, SHA-3 is not derived from its predecessors and uses a unique design approach. </p> <p>Like other hash functions, SHA-3 is used to ensure the integrity of data in various information security applications. It is employed in digital signature algorithms to verify the authenticity and integrity of messages. Some cryptocurrencies use SHA-3 or its variants for added security.</p> <p>While SHA-3 is not intended to replace SHA-2 (which is still considered secure), it provides an alternative in the cryptographic toolkit. The development of SHA-3 is more about having a diversity of secure options available than about SHA-2 being inadequate.</p> <p>An example of a SHA-3 hash of the string \"Hello, world!\" with a 256-bit output might look something like this (though the actual output can vary based on specific implementation details):</p> <pre><code>a7ffc6f8bf1ed76651c14756a061d662f580ff4de43b49fa82d80a4b80f8434a\n</code></pre>"},{"location":"cryptography/ssl/","title":"OpenSSL","text":"<p>OpenSSL is an open-source software library that provides a robust, full-featured toolkit for the Transport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols. It's widely used to secure communications over computer networks and for encrypting sensitive data.</p> <p>OpenSSL supports various encryption algorithms, allowing for both symmetric (e.g., AES, DES) and asymmetric (e.g., RSA, ECC) encryption. This makes it suitable for a range of security needs, from encrypting data in transit to securing files on disk.</p> <p>It offers comprehensive support for SSL and TLS protocols, essential for secure communication over the internet, like in HTTPS. OpenSSL can create and manage SSL/TLS certificates. It's often used for generating private keys, creating Certificate Signing Requests (CSRs), and managing certificate authorities (CAs).</p> <p>It includes a library of cryptographic functions, such as hashing, digital signatures, and random number generation.</p> <p>It is used to implement SSL/TLS for securing websites, particularly in popular web servers like Apache and Nginx. Developers use OpenSSL in a variety of programming languages to add encryption and secure communication capabilities to their applications. </p> <p>OpenSSL also provides a powerful command-line tool for performing a multitude of cryptographic operations, such as encrypting/decrypting files, managing SSL/TLS certificates, and testing SSL/TLS connections.</p>"},{"location":"cryptography/ssltls/","title":"SSL/TLS","text":"<p>SSL (Secure Sockets Layer) and TLS (Transport Layer Security) are cryptographic protocols designed to provide secure communication over a computer network, with TLS being the successor to SSL. These protocols are most famously used for securing internet connections, ensuring that the data exchanged between a web server and a web browser remains private and integral.</p> <p>SSL/TLS protocols encrypt data transmitted over the network, protecting it from eavesdropping and tampering. This encryption ensures that any data sent between the user and the server is unreadable to anyone else.</p> <p>SSL/TLS provides authentication of the server (and optionally the client). When you visit a website with SSL/TLS, you can be sure you're connecting to the intended server and not an impostor (e.g., in a man-in-the-middle attack).</p> <p>SSL/TLS includes a handshake process that establishes the secure connection before any data is transferred. During the handshake, the server (and optionally the client) is authenticated, encryption algorithms are agreed upon, and cryptographic keys are exchanged.</p> <p>SSL/TLS uses digital certificates to authenticate the server (and optionally the client). These certificates are issued by trusted entities called Certificate Authorities (CAs).</p> <p>SSL had several versions (SSL 1.0, 2.0, and 3.0), but due to security vulnerabilities, it was superseded by TLS. TLS has multiple versions (1.0, 1.1, 1.2, and 1.3), with TLS 1.3 being the latest and most secure.</p> <p>When SSL/TLS is used for securing web traffic, the protocol is HTTP over SSL/TLS, known as HTTPS. In a web browser, HTTPS is indicated by a padlock icon in the URL bar.</p> <p>In addition to encryption, SSL/TLS ensures the integrity of data. This means that data cannot be tampered with during transmission without detection. </p> <p>Beyond securing web traffic, SSL/TLS is used in other applications like email (SMTPS, IMAPS, POPS), VoIP, and messaging. Older versions of SSL and early versions of TLS have known vulnerabilities (like POODLE and BEAST) and are considered insecure. It's recommended to use the latest version of TLS for secure communications.</p> <p>The use of SSL/TLS is a standard practice for securing communications on the internet, especially for transactions involving sensitive data like personal information, login credentials, and credit card numbers.</p>"},{"location":"cryptography/symmetric/","title":"Symmetric Encryption","text":"<p>Symmetric encryption is a type of encryption where the same key is used to both encrypt and decrypt data. It is one of the two main types of encryption, the other being Asymmetric Encryption. </p> <p>In symmetric encryption, the same secret key is used for both encryption (converting the original data into an unreadable format) and decryption (converting the encrypted data back to its original format).</p> <p>Symmetric encryption algorithms are generally faster and less computationally intensive than asymmetric algorithms. This makes them well-suited for encrypting large amounts of data.</p> <p>Common symmetric encryption algorithms include Advanced Encryption Standard (AES), Data Encryption Standard (DES), Triple DES (3DES), and Blowfish.</p> <p>One of the main challenges with symmetric encryption is the secure distribution and management of the secret key. Since the same key needs to be used by both the sender and the recipient, it must be shared or distributed in a secure manner.</p> <p>The strength of symmetric encryption largely depends on the length of the key and the security of the key exchange process. Longer keys provide higher security.</p> <p>Symmetric encryption is widely used in various applications, such as encrypting data on a hard drive, securing data transmission over networks, and in ATM PIN verification processes. It primarily ensures confidentiality, meaning only the parties who have the secret key can decrypt and understand the data.</p> <p>Symmetric encryption algorithms can operate in different modes, such as Cipher Block Chaining (CBC) or Electronic Codebook (ECB), which define how blocks of text are encrypted and chained together.</p> <p>Due to its efficiency, symmetric encryption is particularly suitable for scenarios where large volumes of data need to be encrypted, such as database encryption or file encryption.</p> <p>Important</p> <p>Proper key management is essential in symmetric encryption, as the security of the encrypted data is directly tied to the protection of the key.</p>"},{"location":"cryptography/tkip/","title":"Temporal Key Integrity Protocol (TKIP)","text":"<p>Temporal Key Integrity Protocol (TKIP) is an encryption protocol designed to enhance the security of the IEEE 802.11 wireless networking standard, commonly known as Wi-Fi. TKIP was introduced as a stopgap solution to address the vulnerabilities in WEP (Wired Equivalent Privacy), the original encryption protocol for Wi-Fi.</p> <p>TKIP was developed to provide improvements in security over WEP without requiring the replacement of legacy hardware. It was part of the WPA (Wi-Fi Protected Access) standard.</p> <p>Unlike WEP, which uses static keys, TKIP implements a key mixing function that combines the root key with the packet's initialization vector. This process creates a unique key for each packet, significantly improving security.</p> <p>TKIP changes the encryption key for each packet, making it much more difficult for attackers to decipher the key by analyzing patterns in data packets.</p> <p>TKIP includes a stronger integrity check called Michael to provide better protection against data tampering and integrity attacks compared to the CRC32 check used in WEP. It also introduces a re-keying mechanism to change the temporal keys at regular intervals, further enhancing security.</p> <p>TKIP was designed to be implemented on existing hardware through a firmware upgrade, making it an attractive option for improving security on devices that originally only supported WEP.</p> <p>TKIP still uses the RC4 stream cipher (also used in WEP) for encrypting data, but with a more secure implementation that addresses WEP's weaknesses. While TKIP provided improvements over WEP, it was not without its vulnerabilities. Over time, several weaknesses were identified in TKIP, making it susceptible to certain types of cryptographic attacks.</p> <p>In WPA2 (Wi-Fi Protected Access II), the AES (Advanced Encryption Standard) with CCMP (Counter Mode Cipher Block Chaining Message Authentication Code Protocol) replaced TKIP as the preferred encryption method, offering a higher level of security.</p> <p>Due to its vulnerabilities, TKIP is now considered deprecated. Modern Wi-Fi networks and devices use WPA2 with AES for encryption, which is more secure and efficient than TKIP.</p>"},{"location":"cryptography/tls/","title":"TLS","text":"<p>TLS, or Transport Layer Security, is a cryptographic protocol designed to provide secure communication over a computer network. It is the successor to Secure Sockets Layer (SSL), although the term \"SSL\" is still commonly used to refer to both SSL and TLS. TLS ensures privacy between communicating applications and their users on the internet, preventing eavesdropping, tampering, or message forgery.</p> <p>TLS operates between the transport (e.g., TCP) and application layers (e.g., HTTP for web browsers). The protocol works through a process that involves the following steps:</p> <p>Handshake:</p> <ul> <li>This is the initial phase where the TLS parameters are negotiated between the client (e.g., a web browser) and the server (e.g., a web server).</li> <li>During the handshake, the server presents its TLS certificate for authentication, and the client and server agree on the version of TLS to use, select cryptographic algorithms, and optionally authenticate the client.</li> <li>They also generate shared secret keys for encrypting the data transferred in the session.</li> </ul> <p>Data Transfer:</p> <ul> <li>Once the secure connection is established, data can be transferred between the client and server over this secure channel.</li> <li>The data is encrypted using the agreed-upon encryption standards and keys, ensuring that it remains confidential and intact during transit.</li> </ul> <p>Session Closure:</p> <ul> <li>When the session is completed, a closure alert is sent to terminate the session, ensuring a clean shutdown of the session.</li> </ul> <p>There have been several versions of TLS since its inception:</p> <ul> <li>TLS 1.0: Released in 1999 as an upgrade of SSL 3.0.</li> <li>TLS 1.1: Introduced in 2006, provided improved protection against certain types of cryptographic attacks.</li> <li>TLS 1.2: Released in 2008, added stronger cryptographic algorithms and better security practices.</li> <li>TLS 1.3: The latest version, finalized in 2018, provides improved speed and security. It simplifies the handshake process and supports modern cryptographic algorithms.</li> </ul> <p>TLS ensures that data exchanged between the client and server is not readable by others. It protects data from being altered or tampered with during transmission. TLS facilitates the authentication of servers (and optionally clients), ensuring that users are communicating with legitimate entities.</p> <p>Used in HTTPS, the secure version of HTTP, for secure web browsing. Used in protocols like SMTPS, POP3S, and IMAPS for secure email communication. Utilized in protocols like FTPS  for secure file transfers.</p>"},{"location":"cryptography/twofish/","title":"Twofish","text":"<p>Twofish is a symmetric key block cipher and one of the finalists in the Advanced Encryption Standard (AES) contest, intended to become a replacement for the older and less secure Data Encryption Standard (DES). Twofish is known for its speed and versatility.</p> <p>Twofish operates on 128-bit blocks of data, providing a good balance between efficiency and security. One of the notable features of Twofish is its flexibility in key sizes. It can support key sizes of 128 bits, 192 bits, or 256 bits, making it adaptable to various security requirements.</p> <p>Twofish uses a Feistel network, a common method in block cipher design. This structure involves dividing the data block into two halves and then running several rounds of encryption operations on them.</p> <p>Twofish applies a series of 16 rounds of encryption, regardless of the key size. Each round consists of key mixing, a substitution step using a structure known as the S-box, and a permutation. Twofish's key schedule involves precomputing a large number of subkeys before the actual data encryption or decryption. This precomputation contributes to the cipher's efficiency.</p> <p>Twofish uses complex, key-dependent S-boxes (substitution boxes), which are tables used to transform data in a non-linear way. These S-boxes contribute to Twofish's resistance to cryptographic attacks.</p> <p>Twofish is known for its speed, especially in software implementations. It performs well on a wide range of hardware, from low-end devices to high-performance servers. As of now, Twofish is considered secure, with no significant vulnerabilities identified. It has withstood considerable scrutiny from the cryptographic community.</p> <p>While Twofish was a strong contender in the AES contest, it was not selected as the final standard. The AES title went to the Rijndael algorithm, which was deemed to be more efficient in a wider range of hardware environments.</p> <p>Like its predecessor Blowfish, Twofish is unencumbered by patents and freely available for anyone to use without licensing or royalty fees.</p>"},{"location":"cryptography/x3dh/","title":"X3DH (Extended Triple Diffie-Hellman)","text":"<p>X3DH, which stands for Extended Triple Diffie-Hellman, is a key agreement protocol designed to establish a shared secret between two parties. It's part of the Signal Protocol, developed by Open Whisper Systems and used in encrypted messaging services like Signal, WhatsApp, and Facebook Messenger.</p> <p>X3DH is specifically designed to facilitate secure and private communication in an asynchronous environment, such as modern messaging systems where both parties might not be online simultaneously.</p> <p>X3DH works by combining public key cryptography with the Diffie-Hellman key exchange principle to establish a shared secret that can then be used to encrypt messages. The protocol involves several keys to ensure security, even if some of them become compromised. The key components include:</p> <ol> <li>Identity Keys: These are long-term public-private key pairs that are used to verify the identity of each user.</li> <li>Signed Prekey: A long-term public-private key pair, where the public key is signed by the user's identity key. It provides a fallback for cases where one-time prekeys are not available.</li> <li>One-time Prekeys: These are pre-generated one-time-use key pairs that add an additional layer of security. They are used only once and then discarded.</li> <li>Ephemeral Keys: These are temporary public-private key pairs generated for each new key exchange process.</li> </ol> <p>When a user wants to initiate a conversation, they retrieve the recipient's identity key, signed prekey, and one of the one-time prekeys from the server. The sender combines their ephemeral key with the recipient's keys (identity key, signed prekey, and one-time prekey) using the Diffie-Hellman process to generate shared secret components. The shared secret components are then combined (typically concatenated and then hashed) to form a master secret. This master secret is further used to derive encryption keys for secure communication.</p> <p>Even if long-term keys are compromised, past session keys cannot be retroactively decrypted, as each session has its unique set of keys. X3DH is designed to work in scenarios where both parties are not necessarily online at the same time, which is common in messaging applications. By using a combination of long-term and ephemeral keys, X3DH is robust against various types of cryptographic attacks, even if some keys are compromised.</p> <p>X3DH is an integral part of the Signal Protocol and is used in various encrypted messaging applications. Its role is to securely establish the keys necessary for encrypting messages, ensuring that the content of the communication remains private and secure.</p>"},{"location":"cryptography/xor/","title":"XOR","text":"<p>XOR, or exclusive OR, is a logical bitwise operator that compares two binary inputs; it outputs true (or 1) only when the inputs are different. In the context of binary numbers, XOR compares each bit of two values and returns 1 if the bits are different and 0 if they are the same.</p> <p>For two inputs, A and B, the XOR operation can be represented as follows:</p> <ul> <li>A XOR B = 1 if A \u2260 B</li> <li>A XOR B = 0 if A = B</li> </ul> <p>XOR is often used in encryption algorithms. One simple form is XOR cipher, where a key is applied to plaintext using the XOR operation. The same key is used to decrypt the ciphertext by XORing it again with the key.</p> <ul> <li>Example: <code>plaintext XOR key = ciphertext</code>, and then <code>ciphertext XOR key = plaintext</code>.</li> <li>This is effective when the key is random, used only once (one-time pad), and is as long as the plaintext.</li> </ul> <p>In software, XOR is used to obfuscate code or data to hide its purpose or content from users or analysis tools. This can protect software from reverse engineering. XOR is a fundamental operation in many cryptographic hash functions, contributing to their ability to create a unique hash value from input data.</p> <p>XOR is used in some algorithms for generating pseudo-random numbers, which are important in various cryptographic applications.</p>"},{"location":"databases/access/","title":"Microsoft Access","text":"<p>Microsoft Access is a [[Database Management Systems|database management system]] (DBMS) from Microsoft that combines the relational Microsoft Jet Database Engine with a graphical user interface and software-development tools. </p> <p>It is part of the Microsoft Office suite of applications, included in the Professional and higher editions.</p> <p>Access is known for its user-friendly interface that allows users to create and manage databases without requiring extensive knowledge of database programming. It provides a range of templates to get started quickly.</p> <p>Users can create databases from scratch or by using pre-built templates. Access provides tools for defining, modifying, and managing data tables, queries, forms, and reports. Although Access is more accessible to non-programmers, it is based on a [[relational database]] model. It allows users to establish relationships between different data tables.</p>"},{"location":"databases/altibase/","title":"Altibase","text":"<p>Altibase is a [[relational database management system]] (RDBMS) that provides high-performance data processing and real-time data analysis. It is known for being an in-memory database, meaning it stores data primarily in main memory (RAM) for faster data access, but it also supports disk-resident databases. </p> <p>Altibase is used in various sectors, including finance, telecommunications, manufacturing, and services.</p> <p>Altibase combines the speed of an in-memory database with the storage capacity of an on-disk database, offering the benefits of both in a single unified system. Due to its in-memory architecture, Altibase provides extremely fast data processing, making it suitable for applications that require real-time or near-real-time data processing.</p> <p>Altibase adheres to ACID (Atomicity, Consistency, Isolation, Durability) properties, ensuring reliable transaction processing and data integrity. Altibase supports horizontal and vertical scalability, allowing it to handle increasing loads by adding more servers (horizontal) or adding resources like CPUs or memory to existing servers (vertical).</p> <p>It offers high availability features, including replication and failover capabilities, to ensure continuous operation and data availability. Altibase supports [[Structured Query Language|SQL]] standards, making it accessible to developers familiar with SQL and traditional relational databases.</p> <p>It is compatible with various platforms and provides integration capabilities with other databases and external systems.</p> <p>Altibase is used in various applications that require fast data access and processing, such as telecommunications billing systems, finance (for trading and risk management), manufacturing (for supply chain management), and [[IoT]] data processing.</p> <p>Altibase was made open source in 2019, allowing wider access to its technology. It also offers a commercial version with enterprise-grade features and support.</p>"},{"location":"databases/cassandra/","title":"Apache Cassandra","text":"<p>Apache Cassandra is an open-source, [[Non-relational Database|NoSQL database]] designed to store data for applications that require fast read and write performance. For example, you can use Cassandra to store user profile information for online video games, device metadata for internet of things (IoT) applications, or records for events.</p> <p>Cassandra is a NoSQL distributed database. By design, NoSQL databases are lightweight, open-source, non-relational, and largely distributed. Counted among their strengths are horizontal scalability, distributed architectures, and a flexible approach to schema definition.</p> <p>NoSQL databases enable rapid, ad-hoc organization and analysis of extremely high-volume, disparate data types. That\u2019s become more important in recent years, with the advent of Big Data and the need to rapidly scale databases in the cloud. </p> <p>Cassandra is among the NoSQL databases that have addressed the constraints of previous data management technologies, such as [[Relational Database|SQL databases]].</p> <p>One important Cassandra attribute is that its databases are distributed. That yields both technical and business advantages. Cassandra databases easily scale when an application is under high stress, and the distribution also prevents data loss from any given datacenter\u2019s hardware failure. </p> <p>A distributed architecture also brings technical power; for example, a developer can tweak the throughput of read queries or write queries in isolation.</p> <p>\"Distributed\" means that Cassandra can run on multiple machines while appearing to users as a unified whole. There is little point in running Cassandsra as a single node, although it is very helpful to do so to help you get up to speed on how it works. </p> <p>But to get the maximum benefit out of Cassandra, you would run it on multiple machines.</p> <p>Since it is a distributed database, Cassandra can (and usually does) have multiple nodes. A node represents a single instance of Cassandra. These nodes communicate with one another through a protocol called gossip, which is a process of computer peer-to-peer communication. </p> <p>Cassandra also has a masterless architecture \u2013 any node in the database can provide the exact same functionality as any other node \u2013 contributing to Cassandra\u2019s robustness and resilience. </p> <p>Multiple nodes can be organized logically into a cluster, or \"ring\". You can also have multiple datacenters.</p>"},{"location":"databases/cock/","title":"CockroachDB","text":"<p>CockroachDB is a distributed [[Structured Query Language|SQL]] database designed for cloud-native and scalable applications. It provides horizontal scalability, strong consistency, and resilience, making it suitable for a wide range of applications that require reliable, available, and fault-tolerant data storage.</p> <p>CockroachDB is designed to be a distributed database. It scales horizontally, meaning you can add more nodes to the system to increase capacity and throughput. One of the core features of CockroachDB is its strong resilience against failures. Data is automatically replicated across multiple nodes, which helps in ensuring high availability and protecting against server or data center outages.</p> <p>It offers serializable isolation, which is the highest level of isolation in databases, ensuring strong consistency across distributed data. Transactions are atomic, consistent, isolated, and durable (ACID).</p> <p>Despite being a [[Non-relational Database|NoSQL]] database in architecture, CockroachDB supports a full SQL interface for querying data, which makes it familiar and accessible to developers who are used to traditional SQL databases.</p> <p>CockroachDB supports geo-distributed configurations, allowing data to be stored in multiple geographic locations, optimizing access times for distributed users, and ensuring data locality compliance.</p> <p>The database provides automated healing in the face of hardware or software failures. It automatically rebalances and redistributes data as nodes are added or removed. CockroachDB is designed with cloud applications in mind, offering easy deployment in cloud environments, including [[Kubernetes]] integration.</p> <p>It has built-in security features such as encryption at rest and in transit, along with strong access controls. CockroachDB is available as an open-source solution, with a commercial version offering additional features like enterprise-grade support and enhanced database management tools.</p> <p>CockroachDB is wire-compatible with [[PostgreSQL]], meaning that applications built for PostgreSQL can often switch to CockroachDB without significant changes.</p>"},{"location":"databases/couch/","title":"CouchDB","text":"<p>CouchDB, officially Apache CouchDB, is an open-source [[Non-relational Database|NoSQL]] database developed by the Apache Software Foundation. It is a document-oriented database, which means it stores data as [[JavaScript Object Notation|JSON]]-like documents.</p> <p>CouchDB is known for its ease of use, scalability, and a unique set of features that differentiate it from other NoSQL databases.</p> <p>In CouchDB, data is stored in documents, each of which is identified by a unique ID and contains JSON data. This structure allows for storing complex data structures in a single document.</p> <p>CouchDB provides a [[REST APIs|RESTful HTTP API]] for reading, creating, editing, and deleting documents. This makes it accessible from any environment that can send HTTP requests, making it easy to use with various programming languages and frameworks.</p> <p>One of the standout features of CouchDB is its built-in replication and synchronization capability. This allows CouchDB databases to be replicated across multiple servers or devices, supporting offline access and data synchronization when connectivity is restored.</p> <p>CouchDB is often used in applications that require easy and reliable replication across various devices and locations, like mobile apps, web applications, and in distributed or decentralized systems.</p>"},{"location":"databases/crate/","title":"CrateDB","text":"<p>CrateDB is an open-source, distributed [[Structured Query Language|SQL]] database designed for real-time analytics of large-scale data. It combines the scalability and performance of [[Non-relational Database|NoSQL]] systems with the ease of use and familiarity of SQL. CrateDB is particularly known for its ability to handle massive amounts of machine data in real-time.</p> <p>CrateDB is built to be a distributed database. It automatically replicates and partitions data across multiple nodes in a cluster, enhancing performance, scalability, and resilience.</p> <p>While CrateDB supports standard SQL for querying data, it also offers NoSQL-like features, such as schema-less document storage, making it a versatile choice for various types of data.</p> <p>One of the key strengths of CrateDB is its capability to perform real-time analytics on large datasets, making it suitable for applications like [[IoT]], machine data analysis, and log data management.</p> <p>CrateDB can scale horizontally, meaning you can add more nodes to the cluster to increase capacity and improve performance. This makes it well-suited for handling large-scale data workloads.</p> <p>The distributed nature of CrateDB ensures high availability. Data is replicated across different nodes, ensuring that the system can withstand node failures without data loss. CrateDB includes full-text search capabilities, allowing for efficient searching through large volumes of text-based data.</p> <p>It offers support for geospatial data and queries, which is valuable for location-based services and applications. CrateDB supports a variety of data types, including object, array, geospatial, full-text, and traditional scalar types, accommodating a wide range of data modeling requirements.</p> <p>CrateDB is designed to be easy to set up and operate. It can run on commodity hardware or be deployed in cloud environments. Typical use cases for CrateDB include industrial sensor data analysis, system and application logs, IoT applications, and any context where real-time insights into large volumes of data are essential.</p>"},{"location":"databases/cub/","title":"Cubrid","text":"<p>CUBRID is an open-source [[relational database management system]] (RDBMS) highly optimized for web applications. It provides enterprise-grade features comparable to leading commercial database systems. CUBRID is particularly known for its scalability and high performance in handling large-scale data and web services.</p> <p>As an open-source database, CUBRID offers a cost-effective solution with the flexibility of modification and customization, making it appealing for businesses and developers who prefer open-source ecosystems.</p> <p>It is specifically designed for web applications, offering features such as high-performance data processing and advanced optimization for complex online transactions.</p> <p>CUBRID is built to handle large-scale data volumes with ease. It supports sharding, a method of database architecture that partitions and distributes data across multiple database instances to manage large datasets efficiently.</p> <p>The database system provides high availability features, including data replication and failover capabilities, ensuring that applications remain accessible and data is not lost in case of system failures.</p> <p>CUBRID supports a wide range of [[Structured Query Language|SQL]] standards and is compatible with many SQL-based applications. This makes it easy to integrate into existing systems or for developers familiar with SQL.</p> <p>It employs a multi-volume architecture, allowing data to be distributed across multiple disk volumes, which can improve performance and data management efficiency. CUBRID provides robust transaction management, supporting [[ACID]] (Atomicity, Consistency, Isolation, Durability) properties to ensure reliable and secure data processing.</p> <p>The database includes a comprehensive set of features like stored procedures, triggers, views, and updatable views, catering to complex application requirements. CUBRID supports various character sets and has multilingual functionalities, making it suitable for global applications with diverse user bases.</p>"},{"location":"databases/db/","title":"Databases","text":"<p>A database is an organized collection of structured information, or data, typically stored electronically in a computer system. A database is usually controlled by a\u00a0database management system (DBMS). Together, the data and the DBMS, along with the applications that are associated with them, are referred to as a database system, often shortened to just database.</p> <p>Data within the most common types of databases in operation today is typically modelled in rows and columns in a series of tables to make processing and data querying efficient. The data can then be easily accessed, managed, modified, updated, controlled, and organized. Most databases use [[Structured Query Language|structured query language]] (SQL) for writing and querying data.</p>"},{"location":"databases/dbd/","title":"Document-Based Databases","text":"<p>Document-based [[Non-relational Database|NoSQL]] databases are a type of non-relational database that store data in the form of documents. These databases are designed to handle a wide variety of data types and structures, and they are particularly well-suited for managing semi-structured and unstructured data.</p> <p>In these databases, data is stored in documents, which are typically represented in formats like JSON ([[JavaScript Object Notation]]), BSON ([[Binary JSON]]), or [[Extensible Markup Language|XML]]. Each document can contain a complex hierarchy of nested elements and can represent an entire entity with various attributes and their values.</p> <p>Document-based databases are often schema-less or schema-flexible, meaning they do not require a predefined schema for the data. Each document can have its own unique structure, and the structure can evolve over time without the need to alter a centralized database schema.</p> <p>These databases provide robust querying capabilities. They allow indexing of documents for efficient data retrieval and can support complex queries, including those that operate within the nested structures of the documents.</p> <p>Common use cases include content management systems, e-commerce platforms, real-time analytics, and any application dealing with diverse data sets that do not fit neatly into tabular structures like those used in relational databases.</p> <p>These databases often integrate well with modern web applications, offering [[REST APIs|RESTful APIs]], and are compatible with various programming languages and frameworks.</p>"},{"location":"databases/derby/","title":"Apache Derby","text":"<p>Apache Derby, an [[Apache]] DB subproject, is a [[relational database management system]] (RDBMS) implemented entirely in [[Java]]. Known for its small footprint, ease of use, and embeddable nature, it's particularly well-suited for development, testing, and deployment of Java applications.</p> <p>Being written in Java, Derby can be easily embedded in Java applications. It runs within the Java Virtual Machine (JVM) of the application it supports, making deployment and management relatively straightforward.</p> <p>One of Derby's main features is its ability to be embedded into a Java application. In embedded mode, the database runs within the same JVM as the application and is invisible to the user.</p> <p>Derby is lightweight, with a disk footprint of about 3.5MB for the base engine and embedded JDBC driver. This makes it an excellent choice for applications where a full-scale DBMS would be unnecessary or cumbersome.</p> <p>Apart from being embedded, Derby can also run in a stand-alone server mode. In this mode, the database is accessible from other JVMs running on different machines.</p> <p>Derby supports a significant subset of SQL and JDBC standards. It allows developers to use standard SQL queries and JDBC APIs for database operations. Derby supports transactions and is ACID-compliant (Atomicity, Consistency, Isolation, Durability), ensuring reliable data processing and integrity.</p> <p>It offers a reasonable level of security, including user authentication and authorization. Derby also supports encrypted database files. Derby can run as an in-memory database, which is useful for applications that require fast data access and where data persistence between restarts is not necessary.</p> <p>From being embedded in open-source projects and commercial products to being used for small web applications, Derby's flexibility makes it suitable for a wide range of use cases.</p> <p>Apache Derby is open source and free to use. It benefits from community support, regular updates, and a pool of developers who contribute to its ongoing development.</p>"},{"location":"databases/directml/","title":"Direct Manipulation Language (DML)","text":"<p>Direct Manipulation Language (DML) is a term generally used in the context of databases, referring to a subset of SQL ([[Structured Query Language]]) used for adding, updating, and deleting data in a database. DML is concerned with the manipulation and handling of data records.</p> <p>The <code>INSERT</code> statement in SQL is used to add new records to a table. It allows you to specify the table to insert into and the values for the fields of the new record. The <code>UPDATE</code> statement is used to modify existing records in a table. It can update one or multiple records based on a specified condition (WHERE clause).</p> <p>The <code>DELETE</code> statement is used to remove records from a table. Like <code>UPDATE</code>, it can delete a single record or multiple records based on a condition. Although the <code>SELECT</code> statement is primarily used for querying and retrieving data from a database (and thus often associated with [[Data Query Language]], or DQL), it is sometimes included in DML discussions since it's about handling data.</p> <p>DML operations often involve transaction control statements like <code>COMMIT</code>, <code>ROLLBACK</code>, and <code>SAVEPOINT</code>, which help in maintaining data integrity. DML statements are non-destructive, meaning they modify the data without altering the schema or structure of the database.</p> <p>DML is used in various database operations across multiple domains, making it a fundamental aspect of database and application development. DML is a part of the functionality provided by [[Database Management Systems|DBMS]] like [[MySQL]], [[Oracle Database|Oracle]], [[Microsoft SQL Server|SQL Server]], [[PostgreSQL]], and others.</p> <p>In the context of application development, DML is crucial for [[CRUD API|CRUD]] (Create, Read, Update, Delete) operations, which form the backbone of data handling in most applications. When executing DML statements, especially in application code, it\u2019s important to guard against [[SQL injection]] attacks, typically by using prepared statements or ORM frameworks.</p>"},{"location":"databases/dml/","title":"Data Manipulation Language (DML)","text":"<p>Data Manipulation Language (DML) is a subset of SQL ([[Structured Query Language]]) used for adding (inserting), deleting, and modifying (updating) data in a database. DML is one of the key elements of SQL and is essential for managing and manipulating the data stored in relational databases.</p> <p>DML primarily includes three types of operations:</p> <ul> <li>Insert: Adding new rows of data to a table.</li> <li>Update: Modifying existing data within a table.</li> <li>Delete: Removing data from a table.</li> </ul> <p>The <code>INSERT</code> statement is used to add new records to a database table. It allows specifying both the columns and the values to insert. The <code>UPDATE</code> statement modifies existing records in a table. It typically involves specifying a condition to identify which rows to update and what new values should be assigned to specific columns.</p> <p>The <code>DELETE</code> statement removes existing records from a table, usually based on a condition that specifies which rows should be deleted. DML operations often involve transactional control commands like <code>COMMIT</code>, <code>ROLLBACK</code>, and <code>SAVEPOINT</code>. These commands manage transaction processing, ensuring data integrity and consistency.</p> <p>DML statements are considered non-destructive in terms of database schema. They modify the data within the tables without altering the table structure itself. DML statements are fundamental to [[CRUD API|CRUD]] (Create, Read, Update, Delete) operations in database systems, forming the backbone of most database interactions in applications.</p> <p>When performing DML operations, especially in application development, it\u2019s important to guard against SQL injection attacks. This is often achieved through the use of prepared statements or ORM ([[Object-Relational Mapping]]) frameworks.</p> <p>DML commands are used in various [[Database Management Systems]] (DBMS), like [[MySQL (KB)|MySQL]], [[Oracle Database|Oracle]], [[Microsoft SQL Server|SQL Server]], [[PostgreSQL]], and others, making them a core skill for database professionals and developers.</p>"},{"location":"databases/dms/","title":"Database Management Systems (DBMS)","text":"<p>Database Management Systems (DBMS) are software systems designed to manage databases. A DBMS serves as an interface between the database and its users or other application programs, ensuring that the data is consistently organized and remains easily accessible.</p> <p>A DBMS stores data in a structured format, typically in tables that consist of rows and columns. It allows users to create, read, update, and delete data in the database, often referred to as [[CRUD API|CRUD]] operations.</p> <p>There are several types of DBMS, including:</p> <ul> <li>Relational Database Management Systems (RDBMS) - Data stored in relations (tables). Examples include [[MySQL (KB)]], [[Oracle Database]], [[Microsoft SQL Server]] and [[PostgreSQL]].</li> <li>Object-oriented Database Management Systems - Data stored in the form of objects as used in object-oriented programming.</li> <li>NoSQL databases - designed for specific data models and have flexible schemas. Examples include [[MongoDB]], [[Apache Cassandra]] and [[Redis]].</li> <li>Hierarchical Database Systems - data is organized into a tree-like structure.</li> <li>Network Database Systems - data is represented as collections of records connected to one another through links.</li> </ul>"},{"location":"databases/dql/","title":"Data Query Language (DQL)","text":"<p>Data Query Language (DQL) is a subset of SQL ([[Structured Query Language]]) used specifically for querying and retrieving data from databases. Unlike [[Data Manipulation Language (DML)]], which includes commands for inserting, updating, and deleting data, DQL is focused solely on the retrieval of data.</p> <p>The primary command in DQL is the <code>SELECT</code> statement. It is used to fetch data from a database table, which then returns this data in the form of a result set. DQL allows for specifying particular columns to retrieve, filtering data using conditions (<code>WHERE</code> clause), sorting the result set (<code>ORDER BY</code>), grouping data for aggregate functions (<code>GROUP BY</code>), and having clauses to filter groups (<code>HAVING</code> clause).</p> <p>Through DQL, you can perform various types of joins (like INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN) to combine rows from two or more tables based on related columns between them. DQL supports the use of subqueries, where a query is nested inside another query, allowing for complex data retrieval operations.</p> <p>DQL operations are read-only, meaning they don\u2019t modify the data in the database. They are used solely to query and extract data. DQL is extensively used in generating reports, performing data analysis, and creating dashboards where data retrieval is required without the need to change the underlying data.</p> <p>DQL can be used with various SQL functions, including string functions, numeric functions, date functions, and more, to manipulate the output format of the retrieved data. Knowledge of DQL is fundamental for database professionals, analysts, and anyone working with SQL databases, as it forms the basis of data extraction for analysis and decision-making.</p>"},{"location":"databases/drizz/","title":"Drizzle","text":"<p>Drizzle is an open-source [[relational database management system]] (RDBMS) that was forked from the popular [[MySQL (KB)|MySQL]] database. The project aimed to create a lightweight, cloud-friendly, and scalable database optimized for web applications and cloud infrastructure. Drizzle was designed to be simpler and more modular than MySQL, focusing on modern web development needs.</p> <p>Drizzle was developed with a focus on being lightweight and modular. It aimed to remove unnecessary features and code from MySQL to make it leaner and more efficient, especially for web and cloud applications.</p> <p>It was forked from MySQL, one of the most popular open-source relational databases, but with significant changes in its architecture and features to serve a different set of requirements.</p> <p>Drizzle was optimized for cloud and net-centric applications. It was designed to work efficiently in distributed environments with a focus on high concurrency and low-latency operations.</p> <p>One of the distinctive features of Drizzle was its microkernel architecture, allowing for a more pluggable and maintainable codebase. This architecture made it easier to add or remove specific functionalities based on the requirements.</p> <p>Drizzle targeted web applications and aimed to improve query performance and scalability to handle large numbers of concurrent database connections, which are common in web environments.</p> <p>Drizzle maintained [[ACID]] (Atomicity, Consistency, Isolation, Durability) compliance for transactions, ensuring the reliability and integrity of data. Despite its focus on simplicity, Drizzle still supported key database features like stored procedures and triggers.</p> <p>As an open-source project, Drizzle had active community support and contributions, although its development and popularity have been overshadowed by MySQL and other databases like [[PostgreSQL]] and [[MariaDB]].</p>"},{"location":"databases/extreme/","title":"eXtremeDB","text":"<p>eXtremeDB is a high-performance, in-memory [[Database Management Systems|database management system]] (DBMS) designed for embedded systems and real-time applications. Developed by McObject, eXtremeDB is known for its small footprint, efficiency, and speed.</p> <p>It's widely used in fields such as telecommunications, industrial control, consumer electronics, military and aerospace, and financial services.</p> <p>eXtremeDB primarily operates as an in-memory database, storing data directly in the main memory (RAM) of the computer, which provides faster data access compared to disk-based databases.</p> <p>Its in-memory nature makes eXtremeDB particularly suitable for real-time applications where quick data access and processing are critical. One of the notable features of eXtremeDB is its small code size, making it ideal for embedded systems where memory and storage resources are limited.</p> <p>eXtremeDB can scale across multiple processors and cores, making it suitable for high-performance computing environments.</p> <p>It provides [[ACID]] (Atomicity, Consistency, Isolation, Durability) compliance, ensuring the reliability and integrity of database transactions. eXtremeDB supports [[Structured Query Language|SQL]] querying, which is beneficial for developers familiar with SQL. It also offers a native [[APIs|API]] for more efficient data access.</p> <p>The system is designed to be cross-platform, supporting a wide range of hardware platforms and operating systems.</p> <p>eXtremeDB offers a distributed database option, allowing data to be stored across multiple hardware nodes, which can enhance performance and fault tolerance.</p> <p>eXtremeDB has special features for time series data, making it suitable for financial systems, [[IoT]] applications, and other scenarios where large volumes of sequential data are processed.</p> <p>eXtremeDB supports high availability configurations and data replication, ensuring continuous operation and data integrity. It offers various options for customization and optimization based on specific application requirements, including different indexing options and storage configurations.</p> <p>Due to its reliability and performance, eXtremeDB is used in mission-critical applications, including aerospace and defense systems, telecommunications, and financial systems.</p>"},{"location":"databases/fdbms/","title":"File Based Database Management System","text":"<p>A file-based [[Database Management Systems|Database Management System]] (DBMS) is a simple system that manages data in a file-storage mechanism. In this approach, data is stored in plain files, and the file-based system manages access to these files. </p> <p>This is distinct from more advanced database systems like relational or NoSQL DBMSs, which use a more complex mechanism for data management.</p> <p>Data is stored in files such as text files, CSV files, or other simple formats. Each file typically represents a table of data, with rows and columns. In file-based systems, operations like data retrieval and manipulation are performed using file handling and processing techniques provided by the programming language or scripts.</p> <p>File-based DBMSs do not usually support advanced features like complex querying, transaction processing, concurrent access handling, or data integrity enforcement. These systems are straightforward to understand and implement but are limited in their capabilities, especially in handling large volumes of data or complex operations efficiently.</p> <p>They are used in small-scale or simple applications where the complexity and overhead of a full-fledged DBMS are unnecessary. Examples include small businesses, simple applications, or cases where data usage is minimal and straightforward.</p>"},{"location":"databases/firebird/","title":"Firebird","text":"<p>Firebird is an open-source [[relational database management system]] (RDBMS) that offers many ANSI SQL standard features. It's a descendant of Borland's InterBase SQL Server and was initially released as open source in 2000.</p> <p>Firebird can run on various platforms, including Windows, Linux, macOS, and several Unix flavors, offering flexibility in deployment. Being open-source, Firebird is free for use and modification, which makes it an attractive option for small to medium-sized businesses or anyone needing a cost-effective database solution.</p> <p>It supports standard [[Structured Query Language|SQL]] features, stored procedures, triggers, and supports ACID-compliant transactions. This makes it suitable for a wide range of applications.</p> <p>It provides robust security features, including support for SSL encryption and robust user authentication.</p>"},{"location":"databases/frontbase/","title":"FrontBase","text":"<p>FrontBase is a [[relational database management system]] (RDBMS) that was designed for high-demand, scalable, and fault-tolerant environments. It is known for its robustness and support for the [[Structured Query Language|SQL]] standards. </p> <p>FrontBase was developed by FrontBase, Inc. and is used in various applications, ranging from web applications to enterprise-level solutions.</p> <p>FrontBase is designed to be in compliance with SQL-92 and SQL-99 standards, offering broad compatibility with SQL-based applications and tools. The database ensures [[ACID]] (Atomicity, Consistency, Isolation, Durability) compliance, which is crucial for transactional integrity and reliability.</p> <p>FrontBase is built to handle large-scale data requirements and high-concurrency environments, making it suitable for enterprise applications that demand high performance.</p> <p>It supports multiple platforms, including various versions of UNIX, Linux, Windows, and macOS. This cross-platform capability allows for flexibility in deployment and integration with various systems.</p> <p>The database offers comprehensive Unicode support, which is essential for applications that require multi-language support. FrontBase includes strong security features, like SSL support for encrypted connections and robust access control mechanisms to protect data.</p> <p>It has been used in both web-based applications, including dynamic websites, and more traditional enterprise environments. FrontBase provides graphical tools for database management, making it easier to administer, even for those who are not command-line experts.</p> <p>The RDBMS supports stored procedures and triggers, allowing for advanced data manipulation and automated database operations. Designed for fault-tolerant environments, FrontBase offers features that ensure high availability of data and services, which is a key requirement for mission-critical systems.</p>"},{"location":"databases/graph/","title":"Graph-Based Database Management Systems","text":"<p>Graph-based [[Database Management Systems]] (DBMS) are specialized databases designed to store, manage, and query data in the form of graphs. Unlike traditional relational databases that store data in rows and columns, graph databases represent data as nodes (entities), edges (relationships), and properties. </p> <p>In graph databases, data is represented as a graph. Nodes typically represent entities (like people, businesses, products), while edges represent the relationships between these entities. Both nodes and edges can have properties (key-value pairs) that store additional information.</p> <p>Graph databases are optimized for queries that involve traversing relationships, like finding the shortest path between two nodes or querying all nodes related to a specific node. They are highly efficient for complex queries that would require multiple joins in a relational database.</p> <p>They are particularly useful in scenarios where relationships are as important as the data itself. Common use cases include social networks (mapping relationships between people), recommendation systems, fraud detection, network and IT operations, and more.</p>"},{"location":"databases/green/","title":"Greenplum","text":"<p>Greenplum Database is an advanced, fully featured, open-source data warehouse. It provides powerful and rapid analytics on petabyte-scale data volumes. Originally developed by Greenplum Inc. and later acquired by Pivotal Software, it is now part of VMware. </p> <p>Greenplum is designed to manage large-scale data warehousing and business intelligence workloads. Greenplum uses MPP architecture, which allows it to process large datasets efficiently. The data is distributed across multiple nodes, and each node processes a portion of the entire data, enabling high-speed data analytics.</p> <p>Greenplum is based on [[PostgreSQL]], and it extends PostgreSQL with the capability to run and manage large-scale data warehousing operations. One of the strengths of Greenplum is its scalability. It can scale out to accommodate large data volumes and complex queries without a significant drop in performance.</p> <p>In Greenplum, data can be partitioned across different nodes in the cluster. This distribution enhances query performance and data management. Greenplum supports advanced analytics features, including in-database machine learning and AI functionalities.</p> <p>It offers a polymorphic storage system, which means that data can be stored in different formats (like row-based or column-based) depending on the use case, optimizing performance for various types of queries.</p> <p>Greenplum provides high availability features, including automatic failover and recovery mechanisms, to ensure continuous operation and minimize downtime. The database can integrate with various external data sources and frameworks, including [[Hadoop]], enabling comprehensive analytics across diverse data sets.</p>"},{"location":"databases/h2/","title":"H2","text":"<p>H2 is an open-source, lightweight, and fast [[relational database management system]] written in [[Java]]. It's known for its small memory footprint, high performance, and ease of use. H2 can be used in embedded mode or run in its own server mode and supports a browser-based console application.</p> <p>One of the key features of H2 is its ability to operate as an in-memory database, which means that data is stored in the main memory (RAM) rather than on disk. This leads to extremely fast data access and query performance.</p> <p>H2 can be embedded within Java applications, meaning that no separate server process is needed. It can also run in a server mode, similar to traditional [[Client-Server Architecture|client-server]] database systems.</p> <p>H2 is designed to be lightweight with a small footprint, making it an ideal choice for development, testing, and deployment in environments where resources are limited.</p> <p>The database supports [[ACID]]-compliant transactions, ensuring data integrity and consistency. H2 provides a web-based console for database management, which is convenient for managing and querying the database directly from a web browser.</p> <p>H2 can be accessed through the standard JDBC (Java Database Connectivity) API, making it compatible with a wide array of existing tools and frameworks.</p> <p>Besides in-memory storage, H2 also supports traditional disk-based storage, providing flexibility in how data is stored and managed. Being written in Java, H2 is platform-independent and can run on any system where Java is available.</p>"},{"location":"databases/hsqldb/","title":"HSQLDB","text":"<p>HSQLDB (HyperSQL DataBase) is an open-source [[relational database management system]] written in [[Java]]. It offers a small, fast, multithreaded and transactional database engine with in-memory and disk-based tables and supports embedded and server modes. HSQLDB is known for its compact size, high performance, and robust feature set.</p> <p>HSQLDB is lightweight, requiring minimal resources to run, which makes it an ideal choice for applications that need a small, embedded database system. Since it's written in Java, HSQLDB can be easily integrated into Java applications. It is often used for development, testing, and deployment of Java applications.</p> <p>One of HSQLDB's notable features is its ability to create in-memory databases, which reside entirely in the memory of the host application, offering very high query and update performance.</p> <p>Besides in-memory databases, HSQLDB also supports traditional disk-based databases, which are more suitable for larger data sets or when data persistence is required. HSQLDB can be run in an embedded mode, where the database engine runs in the same process as the application, or in a server mode, which supports multi-user connectivity.</p> <p>HSQLDB is highly [[Structured Query Language|SQL]]-compliant. It supports a large subset of SQL-92, SQL-99, and SQL-2008 standards along with SQL/MED extensions for Java functions and stored procedures.</p> <p>HSQLDB offers full ACID (Atomicity, Consistency, Isolation, Durability) compliance for transactional processing, ensuring the reliability and integrity of data. While primarily designed for lightweight applications, HSQLDB performs well with larger data sets and can be scaled for more demanding environments.</p> <p>HSQLDB provides tools for data export and import, allowing easy migration to and from other database systems. It is used in a variety of applications, from small web applications and desktop applications to large enterprise systems requiring a robust database backend.</p>"},{"location":"databases/ignite/","title":"Apache Ignite","text":"<p>Apache Ignite is an open-source distributed database, caching, and processing platform designed for high-performance, low-latency, and horizontally scalable computing. It's primarily used for in-memory computing but also supports disk-based storage.</p> <p>At its core, Apache Ignite is an in-memory computing platform. It stores data in RAM, dramatically speeding up data processing compared to disk-based databases.</p> <p>Ignite is designed as a distributed system. Data and computations are distributed across multiple nodes in a cluster, leading to high scalability and resilience. Apache Ignite supports [[Structured Query Language|SQL]] queries with a distributed joins feature, allowing it to run high-performance, complex queries over large datasets.</p> <p>Ignite functions as a key-value store but extends beyond this with SQL query support, transactions, and other database-like features. It can be used as a distributed cache, providing an intermediate layer where data is temporarily stored for fast access, reducing the load on underlying databases.</p> <p>Despite being an in-memory data grid, Apache Ignite supports [[ACID]] transactions, ensuring data integrity and consistency across all operations.</p> <p>Ignite maintains data redundancy and automatically handles node failures, ensuring that the system is fault-tolerant and data is not lost. Apart from data storage and caching, Ignite provides a compute grid that allows you to run computation tasks in the memory cluster, leading to efficient distributed computing.</p> <p>Ignite can be integrated with various [[Relational Database Management System|RDBMS]], [[Non-relational Database|NoSQL]], [[Hadoop]], and machine learning frameworks. It can also be deployed on top of Hadoop clusters to accelerate big data processing.</p>"},{"location":"databases/informix/","title":"Informix","text":"<p>Informix is a [[relational database management system]] (RDBMS) originally developed by Informix Corporation before being acquired by IBM. It's known for its robustness and scalability, and it's particularly well-suited for online transaction processing (OLTP) as well as for integrated solutions that involve extensive data analysis (Online Analytical Processing, OLAP). </p> <p>Informix is recognized for its high performance, especially in environments that require high throughput and minimal response times, making it suitable for mission-critical applications.</p> <p>The database is highly scalable, capable of handling large volumes of data and a significant number of concurrent users, which is essential for large enterprise applications.</p> <p>Informix offers features such as data replication and clustering, which contribute to high availability and disaster recovery, ensuring data is always accessible and secure. It is designed to be easy to manage, with features that reduce the complexity and time required for database administration.</p> <p>Informix includes support for time series data management, which is useful for applications that require efficient storage and querying of time-stamped data, such as [[IoT]] applications.</p> <p>Informix can be deployed in the cloud, offering flexibility for businesses moving towards cloud-based solutions.</p>"},{"location":"databases/inter/","title":"InterSystems Cache","text":"<p>InterSystems Cach\u00e9 is a high-performance [[Database Management Systems|database management system]] designed to facilitate rapid application development. Known for its speed and scalability, Cach\u00e9 is used in various industries, particularly where large volumes of data are processed, like in healthcare, finance, and government sectors.</p> <p>Cach\u00e9 is a multi-model (or multimodal) database, meaning it can store data in different formats. It supports object-oriented, relational, and key-value data models, allowing developers to choose the most appropriate model for their needs.</p> <p>One of Cach\u00e9\u2019s distinctive features is its object-oriented database model. It allows developers to store objects directly in the database without needing to convert them to a relational format, enhancing development speed and flexibility.</p> <p>Cach\u00e9 evolved from MUMPS (Massachusetts General Hospital Utility Multi-Programming System), a language and database originally designed for healthcare applications. It still supports MUMPS, now known as M, which is used in legacy applications, especially in healthcare.</p> <p>The system is designed for high performance, particularly in transactional environments. Its efficient use of memory and disk I/O allows it to handle large volumes of transactions and data.</p> <p>Cach\u00e9 can scale vertically and horizontally to accommodate growth in data and user numbers, making it suitable for enterprise applications. Despite its object-oriented architecture, Cach\u00e9 supports [[Structured Query Language|SQL]] queries, including JDBC and ODBC, allowing for straightforward integration with existing tools and systems that use SQL.</p> <p>Cach\u00e9\u2019s data storage system, known as globals, is highly efficient and allows for rapid data access, storage, and retrieval. It offers strong interoperability capabilities, making it easy to integrate with various applications, data formats, and protocols.</p> <p>Cach\u00e9 is particularly popular in the healthcare industry, where it\u2019s used for electronic medical records (EMR) systems, due to its robust data handling capabilities and MUMPS language support.</p>"},{"location":"databases/iris/","title":"IRIS","text":"<p>InterSystems IRIS is a data platform developed by InterSystems Corporation, designed to provide high-performance database management, integration, transaction processing, and analytics capabilities. </p> <p>It's an advanced data platform that supports high-volume transactional and analytical processing, aimed at facilitating the development and deployment of mission-critical applications.</p> <p>InterSystems IRIS is a multi-model database, supporting relational, object-oriented, and [[Non-relational Database|NoSQL]]models. This flexibility allows it to handle various data types and structures efficiently.</p> <p>The platform offers advanced analytics capabilities and full SQL support. It is optimized for high-performance analytical and transactional processing. InterSystems IRIS is designed for scalability and high availability. It can handle large volumes of data and high transaction rates, making it suitable for enterprise-level applications.</p> <p>A key feature of InterSystems IRIS is its strong interoperability and integration capabilities, allowing for seamless connection and data exchange with various systems and applications.</p> <p>The platform provides robust data management features, including [[ACID]]-compliant transactions, real-time data indexing, and efficient data storage mechanisms.</p> <p>InterSystems IRIS includes tools and capabilities for machine learning and AI, facilitating the development of intelligent applications. It offers flexibility in deployment, supporting both cloud-based and on-premises configurations.</p> <p>While it is a general-purpose data platform, InterSystems IRIS is particularly prominent in the healthcare sector for EMR systems, financial services, and other industries that require robust, scalable, and reliable data management.</p> <p>The platform includes comprehensive security features, ensuring the protection of sensitive data and compliance with regulatory requirements.</p>"},{"location":"databases/keyval/","title":"Key-Value Store Database Management Systems","text":"<p>Key-value store DBMS ([[Database Management Systems]]) is a type of [[Non-relational Database|NoSQL]] database that stores data as a collection of key-value pairs. In this system, each key is unique, and associated with exactly one value in the database. Key-value stores are known for their simplicity, high performance, and scalability.</p> <p>The model is straightforward \u2013 each item contains a key and a value. The key is used to uniquely identify and access the corresponding value. The value can be various data types, including strings, lists, or more complex objects. The nature of the value depends on the specific key-value store and its use case.</p> <p>Unlike [[Relational Database|relational databases]], key-value stores do not enforce a data schema, so the format and structure of the value are flexible and can vary from one item to another.</p>"},{"location":"databases/maria/","title":"MariaDB","text":"<p>MariaDB is a popular open-source [[relational database management system]] (RDBMS) that is a fork of [[MySQL (KB)]]. It was created by the original developers of MySQL after concerns over Oracle's acquisition of MySQL in 2010. </p> <p>MariaDB is designed to be highly compatible with MySQL, meaning that it follows the same schemas and structure and is essentially a drop-in replacement for MySQL. However, it includes new features, performance enhancements, and security improvements that are not present in MySQL.</p> <p>MariaDB is largely compatible with MySQL, both in terms of API and command line. This means that for most applications, MariaDB can be used as a direct replacement for MySQL with minimal changes.</p> <p>MariaDB includes several new features and extensions that are not available in MySQL, including new storage engines, optimizations for speed and reliability, and improved query execution. MariaDB supports a wide variety of storage engines, including some that are not available in MySQL, allowing for more flexibility in how data is stored and accessed.</p>"},{"location":"databases/maxdb/","title":"SAP MaxDB","text":"<p>SAP MaxDB is a [[relational database management system]] (RDBMS) developed and provided by SAP SE. It's designed for large-scale database environments and is particularly optimized for use with [[SAP applications]], but it can also be used independently.</p> <p>MaxDB is known for its high performance and scalability, making it suitable for managing large databases and handling high transaction volumes, which are typical in enterprise environments.</p> <p>It is capable of handling large amounts of data, with support for databases in the terabyte range. This makes it a good fit for data-intensive applications. While MaxDB can be used as a standalone database system, it is particularly optimized for integration with other SAP applications, such as [[Enterprise Resource Planning Applications|SAP ERP]] systems. This integration offers enhanced performance and data management capabilities for SAP environments.</p> <p>MaxDB supports SQL ([[Structured Query Language]]) for database queries, making it accessible to those familiar with SQL. While optimized for SAP applications, MaxDB can also be integrated into environments where multiple types of database systems are used.</p>"},{"location":"databases/mem/","title":"MemSQL","text":"<p>MemSQL, now known as SingleStore, is a distributed, in-memory, [[Structured Query Language|SQL]] [[database management systems|database management system]] known for its high performance and scalability. It is designed to handle both transactions and real-time analytics on large-scale datasets, making it suitable for various applications, including real-time analytics, operational analytics, artificial intelligence, and machine learning.</p> <p>MemSQL combines in-memory row-based and disk-based columnar storage, enabling fast data ingestion and high-speed query performance.</p> <p>Despite being a [[Non-relational Database|NoSQL]]-style distributed database system, MemSQL supports SQL, including complex joins and subqueries. This makes it compatible with a wide range of existing applications and tools that use standard SQL.</p> <p>One of the strengths of MemSQL is its capability to perform real-time analytics on streaming data, making it suitable for scenarios where immediate insights are critical. MemSQL is designed as a distributed system, which allows it to scale out horizontally by adding more nodes. This scalability is key for handling large volumes of data and high-concurrency workloads.</p> <p>MemSQL's architecture allows for high performance and high levels of concurrency, making it well-suited for both operational and analytical workloads in a single platform.</p> <p>It offers full [[ACID]] (Atomicity, Consistency, Isolation, Durability) compliance for transaction processing, ensuring data integrity and consistency. The combination of in-memory computing and efficient data storage techniques makes MemSQL very fast, which is particularly beneficial for applications that require rapid data processing.</p> <p>MemSQL can be deployed both in cloud environments and on-premises, offering flexibility depending on the needs of the business. Common use cases for MemSQL include real-time data warehousing, operational analytics, risk management and monitoring in financial services, [[IoT]] data analysis, and more.</p> <p>MemSQL rebranded itself as SingleStore, reflecting its expanded capabilities beyond memory-optimized databases to handle various workloads and data types in a single database.</p>"},{"location":"databases/mimer/","title":"MimerSQL","text":"<p>Mimer SQL is a high-performance, scalable, and robust [[relational database management system]] (RDBMS) known for its standards compliance and low maintenance requirements. Mimer SQL is designed to handle a wide range of applications, from embedded systems to enterprise-level databases.</p> <p>Mimer SQL is recognized for its strong compliance with SQL standards, including SQL-92, SQL-99, and SQL:2003, ensuring compatibility with standard SQL queries and procedures.</p> <p>The database is designed for high performance, even under heavy loads, and can be scaled to accommodate growth in data and user numbers. One of Mimer SQL's key selling points is its low maintenance requirement. It is designed to run with minimal administration, making it a cost-effective solution for many applications.</p> <p>Mimer SQL runs on a variety of platforms, including Windows, Linux, Unix, and various mobile and embedded systems, offering flexibility in deployment.</p> <p>The database includes robust security features, with support for encryption, comprehensive access controls, and secure communication protocols.</p> <p>Mimer SQL is suitable for a range of applications, from embedded systems in automotive and telecommunications to large-scale enterprise databases. It supports Unicode and has excellent capabilities for handling multilingual data, making it suitable for international applications.</p> <p>Mimer SQL's small footprint and efficiency make it ideal for embedded database solutions, where resources are limited and high reliability is required. The system follows a client/server architecture, ensuring efficient data management and access over networks.</p> <p>Mimer SQL is optimized for different environments, whether it\u2019s for resource-constrained devices or for high-end servers handling large volumes of transactions.</p>"},{"location":"databases/monet/","title":"MonetDB","text":"<p>MonetDB is an open-source, column-oriented [[Database Management Systems|database management system]] that is designed for high-performance applications in data warehousing, business intelligence, and database research. It's known for its pioneering role in column-store technology, which significantly improves the performance of complex queries on large datasets. </p> <p>Unlike traditional row-oriented databases, MonetDB stores data in columns. This columnar storage approach is particularly efficient for analytical queries that typically access only a subset of columns in a table, thereby reducing I/O operations and improving query performance.</p> <p>MonetDB is optimized for read-intensive queries, making it suitable for large-scale data analytics and business intelligence applications where quick query response times are crucial.</p> <p>While it primarily uses a columnar storage approach, MonetDB also leverages in-memory database techniques. It keeps frequently accessed data in memory, speeding up data access and query processing.</p> <p>The database is designed to handle large volumes of data and scales well on modern hardware, including multi-core processors and large memory configurations. MonetDB supports a broad subset of the standard [[Structured Query Language|SQL]]language, making it accessible to users and applications familiar with SQL.</p> <p>It provides [[ACID]] (Atomicity, Consistency, Isolation, Durability) transaction compliance, ensuring data integrity and consistency in database operations.</p> <p>MonetDB can be extended with additional modules for various data types and analytical functions, making it adaptable to different use cases. As an open-source project, MonetDB benefits from community-driven development and support. It provides a platform for research and innovation in database technologies.</p> <p>It is particularly effective for data warehousing, scientific databases, business intelligence, and large-scale OLAP (Online Analytical Processing) systems.</p> <p>MonetDB is optimized for complex read queries, which is a common requirement in analytical processing, but it may not be the best choice for transaction-heavy OLTP (Online Transaction Processing) systems.</p>"},{"location":"databases/mongo/","title":"MongoDB","text":"<p>MongoDB is a non-relational document database that provides support for\u00a0[[JavaScript Object Notation|JSON]]-like storage. The MongoDB database has a flexible data model that enables you to store unstructured data, and it provides full indexing support, and replication with rich and intuitive APIs.</p> <p>Instead of using tables and rows as in the traditional [[Relational Database|relational databases]], MongoDB makes use of collections and documents. Documents consist of key-value pairs which are the basic unit of data in MongoDB. </p> <p>Collections contain sets of documents and function which is the equivalent of relational database tables. </p>"},{"location":"databases/mysql/","title":"MySQL","text":"<p>MySQL is a freely available open source [[Relational Database Management System]] (RDBMS) that uses Structured Query Language (SQL). It stores that information in separate \u201ctables\u201d and connects it with \u201ckeys\u201d, which is why it\u2019s\u00a0relational.</p> <p>When your WordPress site needs to access that information, it sends a request to the MySQL database server using SQL (this is the\u00a0[[client]]-[[server]] model).</p> <p>Users can define, manipulate, control, and query data using [[Structured Query Language]], more commonly known as\u00a0SQL. </p>"},{"location":"databases/non/","title":"Non-Relational Database","text":"<p>Non-relational databases (often called\u00a0NoSQL databases) are different from traditional relational databases in that they store their data in a non-tabular form. Instead, non-relational databases might be based on data structures like documents. </p> <p>A document can be highly detailed while containing a range of different types of information in different formats. This ability to digest and organize various types of information side by side makes non-relational databases much more flexible than relational databases.</p> <p>Non-relational databases are often used\u00a0when large quantities of complex and diverse data need to be organized. </p> <p>For example, a large store might have a database in which each customer has their own document containing all of their information, from name and address to order history and credit card information. </p> <p>Despite their differing formats, each of these pieces of information can be stored in the same document.</p> <p>Non-relational databases often perform faster because a query doesn\u2019t have to view several tables in order to deliver an answer, as relational datasets often do. Non-relational databases are therefore ideal for\u00a0storing data\u00a0that may be changed frequently or for applications that handle many different kinds of data. </p> <p>They can support rapidly developing applications requiring a dynamic database able to change quickly and to accommodate large amounts of complex, unstructured data.</p>"},{"location":"databases/oracle/","title":"Oracle Database","text":"<p>An Oracle database, in simple terms, is a type of database management system developed and marketed by Oracle Corporation. It's a collection of data treated as a unit, designed to store and manage large amounts of information in a structured way. Here's a basic breakdown of what an Oracle database involves:</p> <ol> <li>Database Management System (DBMS): Oracle provides a DBMS, which is software that allows users to store, retrieve, modify, and manage data efficiently in a database.</li> <li>Relational Database: The Oracle database is primarily a relational database, which means it organizes data into tables. These tables are connected to each other through relationships, making data retrieval and management more systematic and efficient.</li> <li>SQL and PL/SQL: The database uses SQL (Structured Query Language) as its primary language for querying and manipulating data. Oracle also uses PL/SQL (Procedural Language/SQL), which is an extension of SQL designed specifically for the Oracle Database, adding procedural capabilities to the standard SQL.</li> <li>Scalability and Performance: Oracle databases are known for their capability to handle large volumes of data and concurrent users, making them suitable for enterprise-level applications and systems.</li> <li>Advanced Features: It includes advanced features like data partitioning, replication, and advanced security options, catering to complex business requirements and large-scale operations.</li> <li>Industry Use: Oracle databases are widely used in business environments for various applications like online transaction processing, data warehousing, and enterprise resource planning.</li> </ol>"},{"location":"databases/postgres/","title":"PostgreSQL","text":"<p>PostgreSQL is an open-source, highly stable [[Databases (KB)|database]] system that provides support to different functions of [[Structured Query Language|SQL]], like foreign keys, subqueries, triggers, and different user-defined types and functions. It further augments the SQL language proffering up several features that meticulously scale and reserve data workloads.</p> <p>It\u2019s primarily used to store data for many mobile, web, geospatial, and analytics applications.</p> <p>PostgreSQL supports\u00a0a wide range of\u00a0programming languages, including [[Python]], [[Java]], [[JavaScript]], [[Perl]], [[Ruby]], and Tcl making it versatile for various app development needs. </p> <p>It also offers an extensive selection of data types, including primitives (integer, numeric, string, boolean), structured types (date/time, array, range/multirange, UUID), document types ([[JavaScript Object Notation|JSON]], [[Extensible Markup Language|XML]]), geometry types (point, line, circle, polygon)</p>"},{"location":"databases/prepared/","title":"Prepared Statements","text":"<p>Prepared statements are a feature used in database programming to execute the same SQL statement repeatedly with high efficiency and to secure the database against [[SQL injection]] attacks. In the context of [[PHP]] and databases like [[MySQL]], prepared statements are particularly important. </p> <p>First, the SQL statement template is sent to the database server. This template contains placeholders (usually question marks ?) for parameters instead of actual values. </p> <p>For instance: INSERT INTO users (username, email) VALUES (?, ?).</p> <p>The database server parses, compiles, and performs query optimization on this SQL statement template, creating a prepared statement. At this point, the server understands what the query is meant to do and knows how to execute it efficiently, but it doesn't have the specific values for the placeholders yet.</p> <p>Next, the application supplies the actual values for these placeholders. This binding of parameters can be done separately from the statement preparation. Importantly, these values are treated as data only, not as part of the SQL command.</p> <p>The server then executes the prepared statement with the bound values. Since the SQL command structure is already known and optimized, the server can execute the statement more efficiently. If the same statement needs to be executed again, it can be done with new values without the need to recompile the SQL statement.</p> <p>The most significant advantage of prepared statements is increased security. Since parameter values are sent later and treated distinctly from the SQL command text, SQL injection attacks are largely mitigated. Attackers cannot manipulate the statement structure through the data input.</p> <p>An example of a prepared statement:</p> <pre><code>// Create a prepared statement\n$stmt = $mysqli-&gt;prepare(\"INSERT INTO users (username, email) VALUES (?, ?)\");\n\n// Bind parameters (s for string, i for integer, etc.)\n$stmt-&gt;bind_param(\"ss\", $username, $email);\n\n// Set parameters and execute\n$username = \"exampleUser\";\n$email = \"user@example.com\";\n$stmt-&gt;execute();\n\n// Repeat with different data\n$username = \"anotherUser\";\n$email = \"another@example.com\";\n$stmt-&gt;execute();\n\n$stmt-&gt;close();\n</code></pre>"},{"location":"databases/presto/","title":"Presto","text":"<p>Presto is an open-source distributed [[Structured Query Language|SQL]] query engine designed for running interactive analytic queries against data sources of all sizes, ranging from gigabytes to petabytes. Originally developed by Facebook to handle massive amounts of data, Presto is now part of the Linux Foundation's Presto Foundation.</p> <p>Presto is designed for high-speed, read-only data queries. It is particularly efficient in performing large-scale data analytics. Presto operates in a distributed system. It processes queries in parallel across multiple nodes, making it highly scalable and capable of providing rapid query responses.</p> <p>One of Presto's key features is its ability to query data from multiple sources, including traditional [[Relational Database|relational databases]] and [[Non-relational Database|NoSQL]] databases. It can query data stored in [[Hadoop]] Distributed File System (HDFS), Amazon S3, [[MySQL]], [[Apache Cassandra|Cassandra]], Kafka, and many others, without requiring data movement or transformation.</p> <p>Presto allows users to query data using standard ANSI SQL, which is familiar to many users and makes it accessible to a wide range of applications and tools. While Presto does not store any data itself (it's not a database), it processes data in-memory, which contributes to its fast query performance.</p> <p>It is optimized for interactive queries, enabling users to run analytical queries on large datasets and receive responses in real-time or near-real-time. Presto\u2019s distributed nature allows it to scale horizontally by adding more nodes to the cluster. This makes it suitable for large-scale data processing tasks.</p> <p>Presto has a strong and active community. It's used by numerous large companies and has a growing ecosystem of tools and integrations. Presto is widely used in data science, business intelligence, and data analytics to quickly run queries on large datasets. It's popular in environments where data is spread across multiple systems.</p>"},{"location":"databases/rdb/","title":"Relational Database","text":"<p>A relational [[Databases (KB)|database]] is a type of database that stores and provides access to data points that are related to one another. Relational\u00a0databases\u00a0are based on the relational model, an intuitive, straightforward way of representing data in tables. </p> <p>In a relational database, each row in the table is a record with a unique ID called the key. The columns of the table hold attributes of the data, and each record usually has a value for each attribute, making it easy to establish the relationships among data points. </p> <p>When a user needs to access specific information, they can use a key to access all the tables of data that have been pre-determined to be\u00a0related\u00a0to that key.</p> <p>Suppose you're working for a company that sells clothes online. Your organization uses a relational database to manage data related to shipping, customer information, inventory, and website traffic. You have a key to this database that accesses all tables related to shipping, and you need to find out if you have enough inventory to ship out last week's orders.</p> <p>Since the relational database recognizes that there's a relationship between shipping information and inventory, you can use your key to access inventory numbers and shipping requests to compare data. </p> <p>During this request, you won't access any information about website traffic because your key only accesses the tables of data that are related to shipping.</p>"},{"location":"databases/rdbms/","title":"Relational Database Management System","text":"<p>A Relational [[Database Management Systems]] (RDBMS) is a type of database management system (DBMS) that stores and provides access to data points that are related to one another.</p> <p>In an RDBMS, data is organized into tables (also known as relations), which consist of rows and columns. Each row represents a record, and each column represents a data field. Rows in different tables can be related based on common data fields.</p> <p>RDBMSs use [[Structured Query Language|SQL]] for querying and maintaining the database. SQL is a powerful and standardized language used to perform various operations like data insertion, querying, update, and deletion.</p> <p>RDBMSs provide data integrity and a way to maintain the accuracy and consistency of data. This is achieved through constraints, rules, and relationships defined in the database schema.</p> <p>Popular examples include [[MySQL (KB)]], [[Oracle Database]], [[Microsoft SQL Server|SQL Server]], [[PostgreSQL]], and [[SQLite]].</p>"},{"location":"databases/redis/","title":"Redis","text":"<p>Redis (Remote Dictionary Server) is an open-source, in-memory data structure store, used as a database, cache, and message broker. It stands out for its speed and efficiency, as it stores data in RAM. Redis supports various data structures such as strings, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, and geospatial indexes.</p> <p>Redis stores all data in the main memory, which provides extremely fast access compared to disk-based databases. This makes it ideal for scenarios where quick read and write access to data is required, such as caching.</p> <p>Unlike traditional [[Relational Database|relational databases]], Redis supports varied and complex data structures. This flexibility allows for specialized use cases and efficient data handling. Despite being an in-memory store, Redis offers options for data persistence, meaning it can save data to disk periodically. </p> <p>This is achieved through mechanisms like snapshots and append-only files (AOF), ensuring data durability.</p>"},{"location":"databases/redshift/","title":"Amazon Redshift","text":"<p>Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud, provided by Amazon Web Services ([[AWS]]). It's designed for large-scale data set storage and analysis. It is part of AWS's broad range of database services, catering to different needs like transactional processing, data warehousing, and in-memory caching.</p> <p>Amazon Redshift allows businesses to store and analyze vast amounts of data in the cloud, eliminating the need for on-premises data warehousing infrastructure.</p> <p>Redshift uses columnar storage, which improves query performance and reduces the amount of I/O needed for database operations. This makes it well-suited for data warehousing and analytics applications.</p> <p>Amazon Redshift uses MPP to execute complex queries quickly. It divides large queries into smaller parts and runs them in parallel across multiple nodes. Users can start with a small amount of data and scale up to petabytes. Redshift allows you to add or remove nodes to adjust performance and capacity, either manually or automatically.</p> <p>Redshift integrates seamlessly with other AWS services like Amazon S3 for data loading, Amazon Kinesis for real-time data streaming, and AWS Data Pipeline for data movement.</p> <p>Redshift offers a cost-effective solution for data warehousing. Its pricing is based on the amount of storage and the types of nodes you use. Users can also benefit from reserved instance pricing for long-term usage.</p> <p>Redshift is compatible with existing [[Structured Query Language|SQL]]-based clients and business intelligence tools, making it accessible for users familiar with SQL.</p> <p>Amazon Redshift provides robust security features, including encryption at rest and in transit, AWS Identity and Access Management (IAM) integration, and VPC support. Redshift automatically compresses data to reduce the size of your data warehouse, enhancing performance without requiring user intervention.</p>"},{"location":"databases/schema/","title":"Schema","text":"<p>In the context of [[Databases (KB)|databases]], a schema is a blueprint or an organizational framework that defines the structure and organization of data within a database. It serves as a formal description of how the database is constructed and is crucial for understanding and working with any database system.</p> <p>A schema defines the structure of the database in terms of tables, fields (columns), data types, indexes, and relationships between tables. It specifies how data is organized and how the relations among them are associated.</p> <p>A schema often includes constraints and rules to enforce data integrity. These might include primary keys, foreign keys, unique constraints, and check constraints to ensure the accuracy and consistency of data within the database.</p> <p>In addition to tables, a database schema can include other objects like views, stored procedures, functions, and triggers. These objects help in managing and accessing data efficiently. The process of designing a schema involves determining the tables, the fields in each table, and how these fields are related. </p> <p>This is an essential step in database design and can significantly impact the efficiency and functionality of the database system.</p> <p>While the concept of a schema is common across various database systems (like [[MySQL (KB)]], [[Microsoft SQL Server|SQL Server]], [[Oracle Database|Oracle]], [[PostgreSQL]]), the specific syntax and features for defining and manipulating schemas can vary.</p>"},{"location":"databases/sqlite/","title":"SQLite","text":"<p>SQLite is a lightweight, open-source, [[Serverless Architecture|serverless]], self-contained, and embedded [[relational database]] management system (RDBMS). It is designed for simplicity, speed, and ease of use, making it a popular choice for small to medium-sized applications and embedded systems where a full-fledged database server is not necessary.</p> <p>SQLite is a single, standalone library that can be linked with apps. It does not require a separate database server process or installation. Unlike [[MySQL (KB)]] or [[PostgreSQL]], SQLite operates without a separate client-server architecture.</p> <p>SQLite is a relational database management system and it supports tables with rows and columns, indexes, and [[Structured Query Language|SQL]] for data manipulation.</p> <p>SQLite database are stored as flat files on disk, making it portable and easy to manage.</p>"},{"location":"databases/sqls/","title":"Microsoft SQL Server","text":"<p>Microsoft SQL Server is a relational database management system developed by Microsoft. A Relational database is based on a Relational Model architecture. The data is organized in tables (relations), and the tables are related to each other. Each table has rows and columns (attributes). MS SQL Server is a software product used to administer the database and retrieve information. </p> <p>As a database server, it is a software product with the primary function of storing and retrieving data as requested by other software applications\u2014which may run either on the same computer or on another computer across a network (including the Internet).</p>"},{"location":"databases/sqlstate/","title":"SQL Statements","text":"<p>SQL ([[Structured Query Language]]) statements are the means by which users interact with a relational database to perform various operations. </p> <p>SQL is a domain-specific language used in programming and designed for managing and manipulating data held in a [[relational database management system]] (RDBMS). SQL statements are used to execute tasks such as updating data on a database or retrieving data from a database. There are several types of SQL statements, broadly categorized into the following groups:</p> <ol> <li>Data Definition Language (DDL): These statements define the database structure or schema. Some common DDL statements include:<ul> <li><code>CREATE</code>: Used to create a new table or database.</li> <li><code>ALTER</code>: Used to modify an existing database object, like adding a column to a table.</li> <li><code>DROP</code>: Used to delete an entire table or database.</li> <li><code>TRUNCATE</code>: Used to remove all records from a table, including all spaces allocated for the records.</li> </ul> </li> <li>Data Manipulation Language (DML): These statements are used for managing data within schema objects. Some common DML statements include:<ul> <li><code>SELECT</code>: Used to retrieve data from a database.</li> <li><code>INSERT</code>: Used to insert data into a table.</li> <li><code>UPDATE</code>: Used to update existing data within a table.</li> <li><code>DELETE</code>: Used to delete records from a database table.</li> </ul> </li> <li>Data Control Language (DCL): These statements are used to control access to data in the database. Common DCL statements include:<ul> <li><code>GRANT</code>: Used to give user access privileges to a database.</li> <li><code>REVOKE</code>: Used to withdraw access privileges given with the GRANT command.</li> </ul> </li> <li>Transaction Control Language (TCL): These statements are used to manage the changes made by DML statements. They allow transactions to be grouped together. Common TCL statements include:<ul> <li><code>COMMIT</code>: Used to save the work done.</li> <li><code>ROLLBACK</code>: Used to undo the work that has not been saved.</li> <li><code>SAVEPOINT</code>: Used to identify a point in a transaction to which you can later roll back.</li> </ul> </li> </ol>"},{"location":"databases/sybase/","title":"Sybase","text":"<p>Sybase, originally known as Sybase Inc., was a software company that specialized in [[database management systems]] (DBMS) and mobile software. Established in 1984, Sybase played a significant role in the development and evolution of relational databases.</p> <p>Sybase was one of the first companies to develop and commercialize a relational database with a client-server architecture, which was a significant innovation in the 1980s.</p> <p>Sybase SQL Server was their flagship product, a [[relational database management system]] (RDBMS), which became popular for its fast performance and scalability. It was particularly favored in the financial sector for trading systems and other high-volume applications.</p> <p>Sybase SQL Server was among the first RDBMS to implement a [[Client-Server Architecture|client-server architecture]]. This approach separated the database processing work (server) from the user interface application (client), greatly enhancing efficiency and scalability.</p> <p>Sybase developed [[Transact-SQL]], an extension of SQL, to include procedural programming and local variables. This language became widely adopted and was also used by [[Microsoft SQL Server]].</p>"},{"location":"databases/tidb/","title":"TiDB","text":"<p>TiDB is an open-source, distributed [[Structured Query Language|SQL]] database that is designed to support both online transactional processing (OLTP) and online analytical processing (OLAP) operations. TiDB aims to provide a scalable, [[MySQL (KB)|MySQL]]-compatible database solution that can handle hybrid workloads.</p> <p>One of the core features of TiDB is its ability to scale horizontally with ease. This means that you can add more nodes to the system to increase capacity and throughput without significant changes to the application or the database.</p> <p>TiDB is designed to be compatible with MySQL, which means that applications built for MySQL can usually run on TiDB without modification. This eases migration from MySQL and integration with existing MySQL-based applications.</p> <p>TiDB supports both OLTP and OLAP workloads, making it a hybrid transactional and analytical processing database. This capability allows businesses to perform real-time analytics on transactional data.</p> <p>The architecture of TiDB includes TiDB server (stateless SQL layer), TiKV (distributed transactional key-value storage), and PD (Placement Driver) servers that manage metadata and cluster coordination.</p> <p>TiDB provides high availability and strong consistency. It replicates data across multiple nodes, ensuring that the failure of a single node does not lead to data loss. TiDB supports real-time analytics by allowing complex SQL queries to be run directly on the transactional data without requiring ETL processes or a separate analytical database.</p> <p>TiDB is designed to run well in cloud environments. It supports deployment in public clouds, private clouds, and hybrid cloud environments. TiDB supports full ACID-compliant transactions, which is critical for applications that require strong data consistency and integrity.</p> <p>The database allows for the flexible addition or reduction of nodes, enabling it to adjust resource allocation dynamically based on workload demands. As an open-source project, TiDB has a growing community and ecosystem, with contributions from developers and adoption by various companies.</p>"},{"location":"databases/vertica/","title":"Vertica/Mckoi","text":"<p>Vertica and McKoi are two different database management systems, each with distinct features and use cases:</p> <p>Vertica:</p> <ol> <li>Type: Vertica is a column-oriented [[relational database management system]] (RDBMS) designed for data warehousing and analytics applications.</li> <li>Key Features:</li> <li>Columnar Storage: Vertica stores data in columns, which is efficient for analytical queries that typically read specific columns from large datasets.</li> <li>High Performance: Known for high-performance query processing, especially suitable for large-scale data analytics.</li> <li>Scalability: It scales horizontally, enabling the addition of more nodes to the system for increased data storage and query processing capacity.</li> <li>Advanced Analytics: Vertica supports advanced analytics capabilities, including machine learning and predictive analytics directly in the database.</li> <li>Compression and Partitioning: The columnar format allows for effective compression of data. Vertica also supports data partitioning for optimized query performance.</li> <li>Real-Time Querying: Offers near real-time querying capabilities, which is crucial for business intelligence and analytics.</li> <li>Use Cases: Vertica is widely used in industries like finance, telecommunications, e-commerce, and healthcare for data warehousing, big data analytics, and real-time data analysis.</li> </ol> <p>McKOI SQL database (McKoiDB):</p> <ol> <li>Type: McKoi SQL Database, also known as McKoiDB, is a [[relational database management system]] (RDBMS) with a focus on standards compliance and being lightweight.</li> <li>Key Features:</li> <li>Java-Based: It is written in [[Java]] and can be run on any platform that supports a Java Virtual Machine (JVM).</li> <li>ACID Properties: McKoiDB supports [[ACID]] (Atomicity, Consistency, Isolation, Durability) properties for reliable transaction processing.</li> <li>SQL Compliance: The database supports a significant subset of [[Structured Query Language|SQL]] standards.</li> <li>Lightweight Architecture: McKoiDB is designed to be lightweight and easy to manage, making it suitable for applications that do not require the extensive scalability of larger databases.</li> <li>Embedded Use: McKoiDB can be used as an embedded database in Java applications.</li> <li>Use Cases: McKoiDB is primarily used in smaller-scale applications, especially where an easy-to-deploy and manage database solution is needed, or in environments where Java integration is a priority.</li> </ol>"},{"location":"databases/wide/","title":"Wide-Column Databases","text":"<p>Wide-column [[Non-relational Database|NoSQL]] databases, also known as column-family stores, are a type of database that organizes data into columns, which are grouped together into column families. They are designed to efficiently store and access large volumes of data across distributed systems.</p> <p>Unlike [[Relational Database|relational databases]] that organize data in rows, wide-column stores are optimized for queries over large datasets and allow for high scalability and performance.</p> <p>Data is stored in tables, like in relational databases, but the focus is on columns rather than rows. Each row can have a different set of columns, and the column-oriented storage allows for efficient data storage and retrieval.</p> <p>Data is grouped into column families, which are the basic data containers. Each column family contains rows with a unique key, and each row can have any number of columns associated with it.</p> <p>Wide-column stores are schema-flexible, meaning that while the column families are defined, the columns within them can vary from row to row. This flexibility allows for efficient storage of semi-structured or unstructured data.</p> <p>These databases are designed to scale out horizontally, distributing data across many nodes. They can handle large volumes of data and high read/write throughput, making them suitable for big data applications.</p> <p>They are often used in big data analytics, time-series data, content management systems, and any application that requires large-scale data storage and high-speed access.</p>"},{"location":"frameworks/activex/","title":"ActiveX","text":"<p>ActiveX is a software framework from Microsoft that allows applications to share functionality and data with one another through web browsers, regardless of what programming language they're written in. ActiveX add-ons allowed early web browsers to embed multimedia files or deliver software updates to users.</p> <p>ActiveX controls are precoded software similar to web browser plug-ins. For example, a web page displaying a Flash file might require a user to download a Flash ActiveX control so the file can be played directly in-browser without opening a new application. </p> <p>ActiveX controls extend a browser's functionality, allowing the browser to perform tasks it otherwise could not execute innately. It's particularly useful for playing videos and other multimedia content, skipping the step of opening a separate media player.</p> <p>Danger</p> <p>ActiveX is still utilized in Internet Explorer 11, but is not supported by Microsoft's latest browser, Edge.23\u00a0Browsers such as Mozilla Firefox, Google Chrome, Apple's Safari, and Opera use other types of browser plug-ins, such as JavaScript, or similar cross-platform languages.</p> <p>ActiveX remains useful to Microsoft users and is included with Windows 10. This is because ActiveX still allows standalone software to receive updates, interface across programs, and enhance functionality. For example, ActiveX allows users to create more interactive documents in Word or create fillable forms in Excel.</p> <p>Microsoft warns ActiveX controls can sometimes malfunction or give users content they don't want. ActiveX controls can also be used to install\u00a0spyware, viruses, and malware, or damage the data on your computer.</p> <p>Partly because of widespread malicious use of ActiveX controls, many browsers either disable ActiveX controls by default or do not support them at all. For example, Google Chrome users must enable ActiveX in Chrome's security settings or download a Chrome extension.</p> <p>Info</p> <p>Even Microsoft seems to be turning away from ActiveX as Edge does not support ActiveX.</p>"},{"location":"frameworks/angularjs/","title":"AngularJS","text":"<p>AngularJS framework\u00a0is used for creating\u00a0dynamic web apps\u00a0with a structural architecture. This framework enables using HTML as the template language and facilitates the extension of HTML\u2019s syntax to express application components clearly and concisely.\u00a0</p> <p>Features such as Data binding and dependency injection reduce the code required. The whole process occurs solely within the browser, rendering it a suitable complement to any server technology.</p> <p>With this JavaScript MVC framework, you can effortlessly craft dynamic web applications packed with features and experience the multitude of benefits it offers, empowering developers to create web applications that are both user-friendly and engaging and captivating.</p> <p>Also, at the place where different JavaScript frameworks concentrate on extending the JavaScript capabilities itself, the true Angular JS meaning is to provide techniques for improving HTML. </p> <p>Therefore, the AngularJS framework helps to expand and enhance the HTML capabilities over being a plain and easy markup language. AngularJS also enables software developers to prevent the challenging workarounds that are usually essential when attempting to develop responsive applications with the help of HTML front-ends.</p>"},{"location":"frameworks/apache-cxf/","title":"Apache CXF","text":"<p>Apache CXF, which stands for \"CeltiXfire\", is an open-source services framework developed by the Apache Software Foundation. It is used to build and develop web services using standards-based protocols and formats, including SOAP (Simple Object Access Protocol), REST (Representational State Transfer), and XML - and JSON-based data formats.</p> <p>Apache CXF supports various web services standards such as SOAP, WSDL (Web Services Description Language), WS-* specifications, and RESTful web services.</p> <p>Its architecture is highly modular and configurable, making it adaptable to a wide range of use cases. Apache CXF is designed to be lightweight and integrates seamlessly with Spring Framework, which is often used to configure CXF components.</p> <p>CXF allows for the creation of both SOAP-based services (using WSDL) and RESTful services (using annotations or XML configuration). It supports the creation of clients and endpoints for these services.</p> <p>It can handle various data formats including XML, JSON, and others, and is equipped with data binding support for JAXB (Java Architecture for XML Binding). Apache CXF simplifies the development of web services through its straightforward APIs and annotations, reducing the boilerplate code typically associated with such tasks.</p> <p>It includes comprehensive support for web services security (WS-Security), including message encryption, decryption, and authentication. Being based on industry standards, services developed with Apache CXF are interoperable with other web services platforms and clients that adhere to the same standards.</p> <p>Apache CXF can be integrated with various Java Enterprise Edition (Java EE)|Java EE technologies, including Java Servlets, EJBs, JMS, and more. Developers can extend the functionality of Apache CXF through its plug-in architecture, allowing for custom features and extensions.</p>"},{"location":"frameworks/aspnet/","title":"ASP.NET","text":"<p>ASP.NET is an open-source web framework for building web apps on the\u00a0.NET framework. It is created by Microsoft and version 1.0 was released in 2002 to allow developers to build dynamic web apps, services, and sites. The framework is built to work with the standard HTTP protocol, which is the standard protocol used across all web applications.</p> <p>ASP.NET is the successor to the ASP (Active Server Pages) technology and was a significant upgrade in terms of flexibility and power. It is an extension of the .NET platform with additional tools and libraries specifically for building things on the web, including web apps and websites.</p> <p>The latest version of ASP.NET is the cross-platform version that was initially called ASP.NET Core, which was released in 2016. In November 2020, Microsoft simplified the name and removed \"Core\" from the name. </p> <p>ASP.NET is still supported and updated, but moving forward the focus for Microsoft is to develop the new cross-platform version.</p>"},{"location":"frameworks/bootstrap/","title":"Bootstrap","text":"<p>Bootstrap\u00a0is a free and open-source web development framework. It\u2019s designed to ease the web development process of responsive, mobile-first websites by providing a collection of syntax for template designs.</p> <p>In other words, Bootstrap helps web developers build websites faster as they don\u2019t need to worry about basic commands and functions. It consists of HTML, CSS and JS-based scripts for various web design-related functions and components.</p> <p>Bootstrap\u2019s primary objective is to create responsive, mobile-first websites. It ensures all interface elements of a website work optimally on all screen sizes.</p> <p>Bootstrap is available in two variants \u2012\u00a0precompiled\u00a0and\u00a0based on a source code version. Experienced developers prefer the latter since it lets them customize the styles to suit their projects.</p> <p>For example, the \u201csource code\u201d version of Bootstrap lets you access the\u00a0SASS port. This means it creates a custom stylesheet that imports Bootstrap, allowing you to modify and extend the tool as needed.</p> <p>Some of the most popular package managers include\u00a0npm,\u00a0Composer, and\u00a0Bower.\u00a0Npm\u00a0manages server-side dependencies, while\u00a0Composer\u00a0focuses on the front-end. If you work on PHP-based projects, consider using\u00a0Bower\u00a0instead.</p> <p>Due to its popularity, more and more Bootstrap communities emerge. These are great places for web developers and web designers to share knowledge and discuss the latest versions of Bootstrap patches.</p>"},{"location":"frameworks/bulma/","title":"Bulma","text":"<p>Bulma is a free class-based framework for CSS. It allows developers to implement CSS on web pages more efficiently than plain CSS. First released in 2016, Bulma has gained traction among front-end developers, enough to compete with other well-known CSS frameworks like Bootstrap.</p> <p>Bulma is built on\u00a0Flexbox, a CSS layout model that automatically adjusts the width of a page element based on the width of its container. Flexbox requires developers to write both HTML and CSS to create elements that adhere to this model. With Bulma, Flexbox behavior and most other things can be handled with HTML classes.</p>"},{"location":"frameworks/camel/","title":"Apache Camel","text":"<p>Apache Camel is an open-source integration framework that facilitates the integration of various systems, applications, and data across an enterprise. It provides a set of pre-built components and a rule-based routing engine to define and execute integration patterns. Apache Camel simplifies the development of complex integration solutions by offering a declarative and domain-specific language for expressing integration routes.</p> <p>Apache Camel supports a wide range of Enterprise Integration Patterns (EIP), which are common solutions to recurring integration challenges. These patterns include messaging, transformation, routing, and mediation. Camel is designed with a modular and extensible architecture. It offers a large number of components that connect to different systems and protocols. Examples include HTTP, JMS, FTP, JDBC, and many more. These components abstract the complexities of interacting with various technologies.</p> <p>Camel uses a rule-based routing engine to define how messages should be routed between different systems. The routing rules are expressed in a domain-specific language that is easy to understand and maintain. Camel provides support for data transformation using various data formats, including XML, JSON, and CSV. It allows developers to transform data as it moves through the integration process.</p> <p>Camel enables content-based routing, where messages are routed based on their content or attributes. This allows for flexible and dynamic routing decisions. The framework includes robust error-handling mechanisms, allowing developers to define error-handling strategies and specify how to handle exceptions during integration processes.</p> <p>Camel is highly extensible, allowing developers to create custom components, processors, and transformers. This extensibility ensures that the framework can be adapted to specific integration requirements. Camel supports a variety of communication protocols, making it suitable for integrating systems with diverse communication requirements. This includes support for messaging protocols, web services, and RESTful APIs.</p> <p>Camel integrates seamlessly with Apache ActiveMQ, a popular open-source message broker. This allows for reliable messaging and communication between different components. Camel offers tooling and integrations with popular IDEs (Integrated Development Environments) such as Eclipse and IntelliJ IDEA. This makes it easier for developers to design, test, and debug integration routes.</p> <p>Camel includes features such as transaction management, security, and monitoring, making it suitable for building enterprise-grade integration solutions.</p>"},{"location":"frameworks/dj/","title":"Django","text":"<p>Django is a\u00a0free and open-source web development framework written in Python. It is a\u00a0high-level framework,\u00a0with a pragmatic design that encourages fast and clean development. Django has a large collection of modules and features, allowing developers to focus on what really matters.</p> <p>Django provides the ability to\u00a0build websites quickly and to scale it with less effort.</p> <p>In general, a project developed with Django is broken down into small applications composed of a Django package that, in return, resolves specific domains of the application.</p> <p>Each of these small applications is based on the\u00a0MVT - or Model-View-Template -\u00a0pattern, the three aspects of a web application worked on by Django:</p> <ul> <li>Model:\u00a0the model is the structure that represents the data in this application. In other words, it has a direct connection to a database. This is the abstraction layer used to manipulate, include, or exclude data. Whenever a model is created, Django provides an API (also called ORM) for this manipulation;</li> <li>View: the view is a Python function designed to receive a request and send a response back. This is where the data is extracted, generating a response;</li> <li>Template:\u00a0this is the layer where the application template is produced through artifacts understood by the web browser. This is the part that concerns everything that the end user is able to view on their device.</li> </ul> <p></p>"},{"location":"frameworks/dotnetf/","title":".NET Framework","text":"<p>The .NET Framework is a software development framework created by Microsoft that provides a controlled programming environment where software can be developed, installed, and executed on Windows-based operating systems. It was first released in 2002 and has become a foundational technology for a wide range of Microsoft software and services.</p> <p>At the core of the .NET Framework is the CLR, which provides a runtime environment for executing .NET applications. It handles memory management, security, exception handling, and more.</p> <p>The .NET Framework includes a vast class library known as the Framework Class Library (FCL), offering an extensive range of reusable types, components, and services, which significantly simplifies the development process.</p> <p>The framework supports multiple programming languages, including C#, VB.NET, and F#. This interoperability allows for the integration of code written in different languages in the same project.</p> <p>The BCL is part of the FCL and includes classes that provide basic functionalities like file reading/writing, graphic rendering, database interaction, and XML document manipulation.</p> <p>For web development, the .NET Framework includes ASP.NET, a powerful platform for building dynamic websites, web applications, and web services.</p> <p>It provides tools and libraries for building desktop applications, notably Windows Forms for standard GUI applications and Windows Presentation Foundation (WPF) for more complex, rich UI applications.</p> <p>For data access, ADO.NET offers tools for working with databases and executing data operations. The .NET Framework compiles the source code into an intermediate language (IL) which is then compiled to native code by the CLR at runtime, a process known as Just-In-Time (JIT) compilation.</p>"},{"location":"frameworks/dropwz/","title":"Dropwizard","text":"<p>Dropwizard is an open-source Java framework for developing high-performance, RESTful web services and microservices. It is designed to be simple, fast, and easy to use, enabling developers to quickly bootstrap and deploy web applications.</p> <p>Dropwizard glues together several mature and stable Java libraries to provide a comprehensive and efficient platform for building RESTful web applications. Dropwizard focuses on being lightweight and providing just enough to get high-performance web services up and running with minimal effort.</p> <p>It comes with a set of pre-configured, high-quality libraries, including Jetty for HTTP, Jersey for RESTful services, Jackson for JSON processing, Metrics for monitoring, and JDBI or Hibernate for database access.</p> <p>One of the primary uses of Dropwizard is to develop RESTful web services. It simplifies this process with Jersey, which makes mapping Java objects to web resources a straightforward task. Dropwizard includes operational tools like Metrics, which provide powerful insights into the performance and health of the application.</p> <p>It uses a YAML file for external configuration, allowing for easy adjustment of settings and parameters without changing the code. The framework emphasizes convention over configuration, leading to rapid development and deployment of services.</p> <p>Dropwizard includes built-in support for sophisticated error handling and validation mechanisms. It provides support for basic authentication, OAuth, and other security mechanisms to protect web services. While Dropwizard is designed to be simple, it also allows for customization and extensions, enabling developers to add functionality as needed.</p>"},{"location":"frameworks/eap/","title":"EAP (Extensible Authentication Protocol)","text":"<p>EAP (Extensible Authentication Protocol) is a framework frequently used in network authentication. Initially developed for point-to-point connections, EAP has been extensively employed in wireless network and point-to-point authentication, particularly within the 802.1X standard for network access control.</p> <p>EAP itself is not a specific authentication mechanism but a framework that supports numerous authentication methods. These methods include token cards, Kerberos, One-Time Passwords (OTP), smart cards, Public Key Infrastructure (PKI), and more.</p> <p>The strength of EAP lies in its flexibility. It can support new authentication methods and can be used over various transport mechanisms like wireless, Point-to-Point Protocol (PPP), and Ethernet.</p> <p>EAP is widely used in wireless networks, particularly in IEEE 802.11 (Wi-Fi) through the 802.1X standard. It provides a means to securely authenticate devices and users to a wireless network.</p> <p>Some common EAP authentication types include EAP-TLS (Transport Layer Security), EAP-TTLS (Tunneled Transport Layer Security), PEAP (Protected EAP), and EAP-SIM (for SIM cards on mobile devices).</p> <p>EAP-TLS is one of the most secure EAP methods, using a full TLS handshake to provide mutual authentication between the client and server and generate encryption keys. It requires both a server-side and a client-side certificate.</p> <p>EAPoL is a version of EAP used over Ethernet (Local Area Networks (LANs)) networks. It's a key component of the 802.1X authentication protocol. In many network implementations, EAP authentication messages are encapsulated within RADIUS (Remote Authentication Dial-In User Service) messages and transported to an authentication server.</p> <p>The security of an EAP implementation depends on the specific authentication method being used. Some methods, like EAP-TLS, offer strong security, while others may have vulnerabilities. EAP is often used in combination with other protocols to control network access. It can enforce policies such as requiring encryption, updating antivirus software, or checking for system patches before granting access.</p> <p>EAP is also used in VPN (Virtual Private Network) configurations and remote access services to authenticate remote users connecting to a network.</p>"},{"location":"frameworks/ember/","title":"Ember.js","text":"<p>Ember.js is a JavaScript framework used for developing web applications. It provides a complete solution for building client-side JavaScript applications and is known for its convention over configuration and the \"don't repeat yourself\" principles.</p> <p>Ember.js follows the MVVM pattern, which facilitates the separation of concerns by dividing the application into models (data), views (presentation), and view models (logic that ties the two together). Ember.js emphasizes convention over configuration, meaning it provides standard ways to structure your application and expects certain patterns to be followed. This approach helps in reducing the amount of boilerplate code and decisions developers have to make.</p> <p>Ember.js includes a powerful routing system that makes it easy to manage URL state in your application. This is central to Ember\u2019s philosophy and is one of its standout features compared to other frameworks.</p> <p>The framework encourages the use of components - reusable, encapsulated elements that can manage their own layout and behavior. These are akin to custom, reusable HTML tags. Ember.js uses Handlebars, a simple templating language, to control how the view layer is rendered. Handlebars templates look like regular HTML, but also contain expressions that change the rendering based on the underlying data.</p> <p>Ember Data is a library that provides a consistent way of interacting with external APIs and managing application data. Ember.js has a strong community and ecosystem, offering a range of addons and extensions that can be easily integrated into Ember applications.</p> <p>Ember.js is particularly well-suited for ambitious web applications where there is a need for a rich single-page application (SPA) experience. It's used by many large-scale websites and applications due to its robustness and comprehensive feature set.</p>"},{"location":"frameworks/empire/","title":"Empire","text":"<p>Empire is a post-exploitation framework that is used primarily in penetration testing and red team operations. It provides a powerful platform for executing advanced post-exploitation tasks on compromised systems. Empire was originally developed as a Windows PowerShell tool, which later expanded to include Python for Linux and macOS environments.</p> <p>Empire is built around a modular framework, allowing users to execute a wide range of post-exploitation tasks through its various modules. Initially focused on PowerShell for Windows environments, Empire has evolved to support Python, extending its capabilities to Linux and macOS systems. It works by setting up agents on compromised systems. These agents communicate back to the Empire server, allowing for remote control and command execution.</p> <p>Empire can be used to establish command and control (C2) channels, facilitating long-term access to compromised systems. The framework includes capabilities for lateral movement, privilege escalation, reconnaissance, data exfiltration, and more. It can be integrated with other penetration testing and cybersecurity tools, enhancing its functionality in complex security assessments.</p> <p>In a typical penetration testing scenario, an attacker would use Empire to:</p> <ol> <li>Gain initial access to a system, possibly through phishing or exploiting a vulnerability.</li> <li>Deploy an Empire agent on the compromised system.</li> <li>Use the Empire console to execute modules for further exploitation, such as harvesting credentials, moving laterally across the network, and accessing sensitive data.</li> </ol>"},{"location":"frameworks/express/","title":"Express","text":"<p>Express.js is the most popular backend framework for Node.js, and it is an extensive part of the JavaScript ecosystem.</p> <p>It gives you the routing system and simplified features to extend the framework by developing more powerful components and parts depending on your application use cases. The framework provides a set of tools for web applications,\u00a0HTTP requests and responses, routing, and middleware for building and deploying large-scale, enterprise-ready applications.</p> <p>It also provides a command-line interface tool (CLI) called\u00a0Node Package Manager\u00a0(NPM), where developers can source for developed packages. It also forces developers to follow the Don\u2019t Repeat Yourself (DRY) principle.</p> <p>The DRY principle is aimed at reducing the repetition of software patterns, replacing it with abstractions, or using data normalizations to avoid redundancy.</p> <p>It is designed to build single-page, multi-page, and hybrid web applications, it has also become the standard for developing backend applications with Node.js, and it is the backend part of something known as the MEVN stack.</p> <p>The MEVN is a free and open-source JavaScript software stack for building dynamic websites and web applications that has the following components:</p> <ul> <li>MongoDB</li> <li>Express</li> <li>Vue.js</li> <li>NodeJS</li> </ul>"},{"location":"frameworks/flask/","title":"Flask","text":"<p>Flask is a micro web framework for Python, designed to make it easy to build web applications quickly and with minimal boilerplate code. It is considered \"micro\" because it provides the basic tools and components needed for web development, allowing developers to choose and integrate additional libraries and modules as needed, rather than including everything in the framework itself.</p> <p>Flask is known for its simplicity, flexibility, and ease of use, making it a popular choice among Python developers for building web applications and APIs.</p> <p>Flask provides just essentials for building web apps, such as routing, request handling, and response generation. Flask is also built on top of the Werkzeug WSGI toolkit, which handles HTTP request/response handling and integrates with the Jinja2 template engine.</p> <p>Flask also allows you to define URL routes using decorators, making it easy to map URLs to specific functions or views. It also supports various HTTP Verbs including GET, POST, PUT, DELETE and more, making it suitable for REST APIs.</p>"},{"location":"frameworks/found/","title":"Foundation","text":"<p>The Foundation framework is a front-end framework that integrates the classic Web design languages HTML and Cascading Style Sheets (CSS) with other tools and controls to provide a responsive environment for design. </p> <p>Essentially, Foundation is built on two languages called Sass (Syntactically Awesome Style Sheets) and SCSS (Sassy CSS). These languages are based on CSS, but offer different types of accessibility. The idea is that developers can use Foundation and other Sass/SCSS tools to do things more quickly or efficiently than if they were only using CS nbS as a Web design language.</p> <p>Foundation also includes rapid prototyping features, tools for responsive design for mobile projects, and a modular structure, as well as \u201cmixins,\u201d which is not offered by CSS. In general, Foundation offers an alternative way to construct Web projects in a complex design environment where developers have to address the needs of mobile device users and conventional computer users.</p>"},{"location":"frameworks/hadoop/","title":"Hadoop","text":"<p>Hadoop is an open-source software framework for storing and processing large datasets in a distributed computing environment. Developed by the Apache Software Foundation, Hadoop is designed to scale up from single servers to thousands of machines, each offering local computation and storage. It is a key technology in the field of big data analytics and cloud computing.</p> <p>Hadoop includes the Hadoop Distributed File System (HDFS), which allows it to store data across multiple machines, providing high aggregate bandwidth across the cluster.</p> <p>One of the core components of Hadoop is the MapReduce programming model, which enables it to process large datasets in parallel across a distributed cluster. MapReduce divides the task into smaller parts, processes them in parallel, and aggregates the results.</p> <p>Hadoop is highly scalable. You can start with a single machine and expand to thousands of machines. Each new machine adds more capacity to the Hadoop cluster. Hadoop is designed to handle failures at the application layer, so a high level of fault tolerance is achieved. It automatically replicates data across multiple nodes, ensuring that no data is lost if a node fails.</p> <p>Hadoop can handle various forms of structured and unstructured data, giving users the flexibility to collect, process, and analyze data in ways that were not previously feasible.</p> <p>Hadoop's ecosystem includes various tools and extensions to improve its functionality, including Apache Hive for SQL-like queries, Apache HBase for NoSQL data storage, Apache Pig for data processing, and Apache Spark for in-memory data processing.</p> <p>Since it runs on commodity hardware and is open-source, Hadoop provides a cost-effective solution for processing large datasets. Hadoop has a large and active community of contributors and users. Major technology companies have adopted and contributed to Hadoop, making it a robust and continually evolving platform.</p>"},{"location":"frameworks/jaxb/","title":"JAXB (Java Architecture for XML Binding)","text":"<p>JAXB (Java Architecture for XML Binding) is a Java framework that allows Java developers to map Java classes to XML representations. JAXB provides a convenient way to bind XML schemas and Java representations, making it easier to serialize Java objects into XML and deserialize XML back into Java objects. </p> <p>It's a part of the Java SE platform and is commonly used in web services and applications that require XML processing.</p> <p>JAXB simplifies the conversion process between Java objects and XML documents. This process is known as Object-XML mapping or OXM. The core operations of JAXB are marshalling (converting Java objects to XML) and unmarshalling (converting XML to Java objects).</p> <p>JAXB uses Java annotations to define how Java classes are mapped to XML. For example, <code>@XmlElement</code> and <code>@XmlAttribute</code> are used to map Java fields to XML elements and attributes, respectively.</p> <p>JAXB allows for the generation of Java classes from XML schemas (XSD) and vice versa, facilitating development in applications that rely on XML schemas. JAXB is often used in conjunction with JAX-RS (for RESTful web services) and JAX-WS (for SOAP web services) for data binding XML payloads.</p> <p>In web services, JAXB is used to bind request and response payloads, which are typically in XML format, to their corresponding Java objects. Being a part of standard Java API, JAXB provides a portable way to work with XML across different Java applications.</p> <p>Before JAXB, working with XML in Java was more complex, often involving low-level APIs like DOM (Document Object Model) or SAX (Simple API for XML). JAXB abstracts these complexities. While JAXB is part of Java SE, it is also widely used in Java EE applications, particularly those involving web services.</p> <p>Other libraries like Jackson or XStream can also be used for XML binding in Java, offering different features and configurations.</p>"},{"location":"frameworks/jersey/","title":"Jersey","text":"<p>Jersey is an open-source framework for developing RESTful Web Services in Java that provides support for JAX-RS (Java API for RESTful Web Services) APIs. It is a part of the Eclipse Foundation's Jakarta EE project. Jersey makes it easy for developers to build robust and scalable web services using the Java programming language.</p> <p>Jersey is a reference implementation of the JAX-RS specification. JAX-RS is a Java specification that provides a Java API for creating RESTful web services. Jersey simplifies the development of RESTful services by allowing developers to use annotations to define URIs, HTTP methods, and media type responses.</p> <p>Using annotations such as <code>@Path</code>, <code>@GET</code>, <code>@POST</code>, <code>@PUT</code>, <code>@DELETE</code>, and <code>@Produces</code>, developers can easily map Java methods to HTTP requests and responses. Jersey also includes a Client API, which simplifies the process of communicating with RESTful services. This is particularly useful for consuming REST services.</p> <p>It supports content negotiation using media type annotations, enabling services to produce and consume data in various formats like JSON, XML, and plain text. Jersey can be easily integrated with various web servers, servlet containers, and Java EE application servers. It also works well with other Java technologies like Spring, JSON processing libraries, and OAuth libraries.</p> <p>Jersey provides ways to map exceptions to HTTP responses, making error handling in web services more manageable. Jersey allows for the creation of filters and interceptors to modify the request and response objects in the server and client APIs.</p> <p>It supports asynchronous processing on both the server and client sides, allowing for more efficient processing of requests and responses. Jersey is extensible and allows developers to extend its capabilities through the use of custom providers, filters, and interceptors.</p>"},{"location":"frameworks/jpa/","title":"Java Persistence API (JPA)","text":"<p>The Java Persistence API (JPA) is a Java programming language framework that manages relational data in applications using Java Platform, Standard Edition and Java Platform, Enterprise Edition. Part of the Java EE and Java SE specifications, JPA provides an Object-Relational Mapping (ORM) approach to handle the relational data in a way that's more aligned with object-oriented programming practices.</p> <p>JPA is used for mapping Java objects to database tables and vice versa. This allows developers to work with data in a more object-oriented way, rather than using complex SQL queries. </p> <p>JPA is a standard API, which means it's not tied to any specific implementation. This allows developers to switch between different JPA providers, like Hibernate, EclipseLink, or Apache OpenJPA, without changing the application code.</p> <p>JPA uses annotations in the Java code or XML configuration files to define the relationship between Java classes and database tables, and how fields in a class correspond to columns in a table. The <code>EntityManager</code> interface is a key part of JPA, used for creating, reading, and removing data. It acts as a factory for query objects and manages the lifecycle of entities.</p> <p>JPQL is a query language, similar to SQL, but operates on Java objects rather than tables. It allows for database operations using object-oriented principles. JPA manages a set of entity instances in a persistence context, providing a cache of database data. This can improve application performance by reducing the number of database accesses.</p> <p>JPA supports transaction management to ensure data integrity and consistency. JPA simplifies data persistence in Java applications, especially those with complex database interactions. It abstracts the complexity of direct JDBC code, providing a more object-oriented programming model for database interaction.</p> <p>JPA is often used in conjunction with other Java EE technologies like Enterprise JavaBeans (EJB) and Java Transaction API (JTA). Because JPA is a standard API, applications written with JPA can be easily ported to different databases with minimal changes.</p>"},{"location":"frameworks/junit/","title":"JUnit","text":"<p>JUnit is a popular unit testing framework for the Java programming language. It plays a pivotal role in test-driven development (TDD) and agile methodologies, encouraging developers to write code that is more robust, reliable, and maintainable. JUnit is part of the family of unit testing frameworks collectively known as xUnit that originated with SUnit.</p> <p>JUnit provides a simple framework for writing and running tests, making it accessible even for those new to unit testing. It uses annotations (like <code>@Test</code>, <code>@Before</code>, <code>@After</code>, <code>@BeforeEach</code>, <code>@AfterEach</code>, <code>@BeforeClass</code>, <code>@AfterClass</code>) to indicate methods that perform tests or are to be run before/after tests.</p> <p>JUnit includes a set of assertion methods to test for certain conditions; these assertions form the basis of the test validations. JUnit provides test runners which can run tests and report test results. JUnit can be easily integrated into IDEs (like Eclipse, IntelliJ IDEA) and build tools (like Maven and Gradle).</p> <p>An example:</p> <pre><code>import org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\npublic class SimpleTest {\n\n    @Test\n    public void testAddition() {\n        assertEquals(4, 2 + 2, \"2 + 2 should equal 4\");\n    }\n}\n</code></pre> <p><code>SimpleTest</code> contains a single test (<code>testAddition</code>) which asserts that 2 + 2 equals 4. </p>"},{"location":"frameworks/laravel/","title":"Laravel","text":"<p>Laravel\u00a0is an open-source PHP framework designed to make developing web apps easier and faster through built-in features. These features are part of what makes Laravel so widely used by web developers:</p> <ul> <li>A modular packaging system with dependency management. This means you can easily add functionalities to your Laravel app without writing them from scratch. You can either create your own packages for code you routinely use or install ready-to-use packages through Composer.</li> <li>A complete authentication system</li> <li>Object-relational mapping. Eloquent ORM included with Laravel presents database tables as classes for easier data access and manipulation.</li> <li>A command-line interface (CLI) that comes with dozens of pre-built commands (Artisan).</li> <li>Automatic testing. Automated tests are provided as an integral part of Laravel.</li> <li>A portable, virtual development environment. Homestead provides developers with all the tools necessary to develop Laravel straight out of the box.</li> </ul>"},{"location":"frameworks/netnuke/","title":"DotNetNuke","text":"<p>DotNetNuke, also known as DNN, is a web content management system (CMS) and web application framework based on Microsoft's .NET technology. It's designed to enable businesses and developers to create and manage websites, applications, and online communities efficiently.</p> <p>DotNetNuke is a versatile and powerful CMS and application framework suited for creating and managing dynamic and interactive websites, particularly for businesses invested in Microsoft's technology ecosystem. It's praised for its modularity, customizability, and strong community support.</p> <p>It is built on the Microsoft .NET framework, making it a robust choice for organizations invested in Microsoft technologies. It allows the integration of .NET-based custom modules and functionalities. It also allows devs to modify and extend its core capabilities as it is open-source.</p> <p>DNN operates on a modular structure, enabling users to add or remove functionalities by installing or uninstalling modules.</p> <p>DNN operates what is known as a \"skinning\" system, allowing users to change the look and feel of their site by applying different skins without altering the content or layout. It also allows managing multiple websites from a single DNN installation. This feature is particularly useful for businesses and organizations that operate several sites.</p> <p>The platform is equipped with SEO-friendly features, helping websites to perform well in search engine rankings.</p>"},{"location":"frameworks/osgi/","title":"OSGi","text":"<p>OSGi (Open Service Gateway Initiative) is a Java framework for developing and deploying modular software programs and libraries. It provides specifications that define a system for modular architecture in Java, enabling components, known as bundles in OSGi terminology, to be dynamically installed, activated, updated, or removed at runtime.</p> <p>OSGi promotes strong modularity and encapsulation, which is a step beyond traditional Java classpath and JAR file mechanisms. Each OSGi bundle is a self-contained module that provides explicit details about its dependencies and services.</p> <p>Bundles are the primary components in OSGi; they are essentially JAR files with additional metadata. The metadata, defined in the <code>MANIFEST.MF</code> file, specifies information about the bundle, such as version, dependencies, and packages that it exports or imports.</p> <p>One of the key features of OSGi is the ability to manage components dynamically at runtime. Bundles can be installed, started, stopped, updated, or uninstalled on-the-fly without needing to restart the entire application.</p> <p>OSGi supports a form of Service-Oriented Architecture (SOA). Bundles can register services, which other bundles can discover and use, promoting loose coupling between different components. OSGi has a robust versioning and dependency resolution mechanism, allowing multiple versions of the same library to coexist and resolving dependencies based on specified version ranges.</p> <p>OSGi is used in various applications, from embedded devices and mobile applications to large-scale enterprise systems. Its dynamic module system makes it suitable for long-running applications where hot-deployment and updates are required.</p> <p>The Eclipse IDE is one of the most notable examples of an application built on OSGi, demonstrating the framework's capabilities in a complex, modular, and extensible desktop application.</p> <p>While OSGi provides many benefits in terms of modularity and flexibility, it also has a reputation for complexity, particularly in understanding the class loading model and debugging issues related to dynamic module interactions. OSGi can be used alongside other Java technologies and frameworks, although integration may require additional consideration due to its unique architectural model.</p> <p>OSGi is developed and maintained by the OSGi Alliance, a consortium of technology companies and is standardized, ensuring consistent and reliable behavior across different implementations.</p>"},{"location":"frameworks/phpunit/","title":"PHPUnit","text":"<p>PHPUnit is a widely-used testing framework for PHP, designed to support the practice of test-driven development (TDD) and to write and run unit tests for PHP applications. It is inspired by JUnit and has become an essential tool for PHP developers who aim to build robust and reliable software through systematic testing.</p> <p>PHPUnit automates the process of running tests on PHP code, making it easier to perform continuous testing during development. It focuses on unit testing, where individual components or functions of an application are tested in isolation to ensure they work as expected.</p> <p>Developers can organize tests into test cases and suites for better management and comprehensive testing coverage. PHPUnit provides a range of assertion methods to test expected outcomes of code execution, like asserting equality, truthiness, counts, and exceptions. </p> <p>It supports the creation of mock objects and stubs, which simulate the behavior of real objects to isolate and test code dependencies. PHPUnit integrates with various development and continuous integration tools, enhancing the development workflow.</p> <p>A simple PHPUnit test might look like this:</p> <pre><code>&lt;?php\nuse PHPUnit\\Framework\\TestCase;\n\nclass SampleTest extends TestCase\n{\n    public function testAddition()\n    {\n        $this-&gt;assertEquals(4, 2 + 2, \"Addition test\");\n    }\n}\n</code></pre> <p>Info</p> <p>The <code>SampleTest</code> class extends <code>TestCase</code> from PHPUnit. The <code>testAddition</code> method contains an assertion that checks if the addition of 2 and 2 equals 4.</p> <p>To run PHPUnit tests, you typically use the PHPUnit command-line tool, specifying the tests to run. PHPUnit then executes the tests and provides a report on their success or failure.</p>"},{"location":"frameworks/reactjs/","title":"ReactJS","text":"<p>React is a framework that employs Webpack to automatically compile React, JSX, and ES6 code while handling CSS file prefixes.\u00a0React is a\u00a0JavaScript-based UI development library. Although React is a library rather than a language, it is widely used in web development. </p> <p>React offers various extensions for entire application architectural support, such as Flux and React Native, beyond mere UI.</p> <p>In React, you develop your applications by creating reusable components that you can think of as independent Lego blocks. These components are individual pieces of a final interface, which, when assembled, form the application\u2019s entire user interface. \u00a0</p> <p>React\u2019s primary role in an application is to handle the view layer of that application just like the V in a model-view-controller (MVC) pattern by providing the best and most efficient rendering execution. </p> <p>Rather than dealing with the whole user interface as a single unit, React.js encourages developers to separate these complex UIs into individual reusable components that form the building blocks of the whole UI. </p> <p>In doing so, the ReactJS framework combines the speed and efficiency of JavaScript with a more efficient method of manipulating the DOM to render web pages faster and create highly dynamic and responsive web applications.</p>"},{"location":"frameworks/resteasy/","title":"RESTEasy","text":"<p>RESTEasy is a Java framework that provides support for developing RESTful Web Services. It is an implementation of the JAX-RS specification, which is the Java API for RESTful Web Services. RESTEasy is primarily used for creating and deploying RESTful services in Java, and it is known for its simplicity and ease of use.</p> <p>RESTEasy is an implementation of the JAX-RS (Java API for RESTful Web Services) specification. JAX-RS is a set of interfaces and annotations offered by Java for creating RESTful web services. The framework facilitates the development of services that use HTTP protocols to communicate and follow the REST (Representational State Transfer) architectural principles.</p> <p>RESTEasy can be easily integrated with various Java EE (Enterprise Edition) and Java SE (Standard Edition) applications. It's particularly well-suited for use with the Java EE ecosystem. Besides the standard JAX-RS features, RESTEasy includes additional features like JSON-P (JSON Processing), Asynchronous HTTP, Server-sent Events (SSE), and more.</p> <p>It supports pluggable providers to extend its capabilities. Providers can be used for things like MessageBodyReaders/Writers, ExceptionMappers, and ContextResolvers. RESTEasy includes a client API for accessing RESTful resources. The client API allows for easy interaction with RESTful web services.</p> <p>Being a JAX-RS implementation, RESTEasy applications are portable across any server container that supports JAX-RS. The framework supports various data formats including XML, JSON, YAML, and more for data exchange.</p> <p>It can be integrated with popular frameworks like Spring and can be run in servlet containers like Tomcat or application servers like WildFly.</p>"},{"location":"frameworks/spring/","title":"Spring Boot","text":"<p>Spring Boot is an open-source Java-based framework that simplifies the development of production-ready and stand-alone Spring-based applications. It provides a convention-over-configuration approach, reducing the need for extensive boilerplate code and configuration. Spring Boot is part of the larger Spring Framework ecosystem and is designed to streamline the process of building, deploying, and running Spring applications.</p> <p>Spring Boot follows the convention-over-configuration principle, minimizing the need for developers to specify a large amount of configuration. It comes with sensible defaults and auto-configuration options, allowing developers to focus on application logic.</p> <p>Spring Boot enables the creation of stand-alone, production-grade Spring-based applications with minimal effort. Applications can be packaged as executable JARs (Java Archive) or WARs (Web Application Archive) for deployment.</p> <p>Spring Boot includes support for embedded web servers such as Tomcat, Jetty, and [[Undertow]]. This eliminates the need for external web server deployment, simplifying the deployment process. Spring Boot includes a comprehensive set of default configurations for various components, including databases, messaging queues, and more. Auto-configuration automatically adapts to the libraries on the classpath, reducing manual configuration.</p> <p>Starters are pre-configured templates that provide a convenient way to add dependencies to your project. They simplify the process of including common libraries and configurations for specific tasks such as web development, data access, and messaging.</p> <p>Spring Boot is well-suited for building microservices-based architectures. It facilitates the development of individual microservices that can work together to form a larger application. Actuator is a set of production-ready features provided by Spring Boot for monitoring and managing applications. It includes endpoints for health checks, application metrics, environment properties, and more.</p> <p>DevTools provide features such as automatic application restarts, live reloading of changed resources, and enhanced development experience to boost developer productivity. The CLI allows developers to create, run, and test Spring Boot applications from the command line. It provides a concise syntax for creating applications quickly.</p> <p>While Spring Boot provides default configurations, it remains highly extensible. Developers can override defaults and customize configurations based on specific application requirements.</p>"},{"location":"frameworks/springframe/","title":"Spring Framework","text":"<p>The Spring Framework is an open-source application framework and inversion of control container for the Java platform. Developed by Pivotal Software, it has become one of the most popular frameworks for building Java applications, especially enterprise-level applications. Spring is known for its comprehensive infrastructure support for developing robust Java applications.</p> <p>At its core, Spring provides an IoC container that manages Java objects, known as beans, through dependency injection. This helps in promoting loose coupling between components. Spring supports aspect-oriented programming, allowing the separation of cross-cutting concerns (like logging and transaction management) from the business logic.</p> <p>Spring is modular, consisting of several modules that provide a range of services, including data access, transaction management, web application development, messaging, and more. For web applications, Spring offers the Spring MVC framework, a rich framework for building web applications following the Model-View-Controller design pattern.</p> <p>Spring simplifies interaction with databases through its JDBC abstraction layer and provides support for integrating with ORM frameworks like Hibernate, JPA, and JDO. Spring provides a consistent transaction management interface that can scale down to a local transaction and scale up to global transactions (JTA).</p> <p>Spring integrates well with other enterprise technologies, offering support for remoting, JMS, web services, and scheduling.</p>"},{"location":"frameworks/struts/","title":"Apache Struts","text":"<p>Apache Struts is an open-source web application framework used for developing Java-based enterprise web applications. It follows the Model-View-Controller (MVC) architectural pattern and is designed to simplify and streamline the development of web applications.</p> <p>MVC Architecture:</p> <ul> <li>Model: Represents the application's data and business logic.</li> <li>View: Deals with the presentation and user interface.</li> <li>Controller: Manages the flow of the application, handling user input and interacting with the model and view.</li> </ul> <p>Struts uses actions (Java classes) to process user requests, providing a clear separation of concerns. Struts includes custom JSP tag libraries to facilitate the creation of dynamic and interactive web pages. Used for encapsulating and validating user input. Allow developers to add functionality to the request processing workflow.</p> <p>Struts applications are typically configured using XML files, specifying mappings between URLs, actions, and resources. Struts provides a built-in validation framework that simplifies the validation of user input.</p> <p>Struts can be integrated with various technologies such as JavaServer Pages (JSP), JavaBeans, and custom tag libraries. Struts provides a set of tag libraries for creating forms, handling errors, and managing control flow.</p> <p>Struts supports internationalization (i18n) and localization (l10n), allowing applications to be adapted for different languages and regions. Struts includes features for managing security concerns, such as protection against common web application vulnerabilities.</p> <p>Struts 1 and Struts 2 are two major versions of the framework. Struts 2 is considered more modern and flexible, with improved features and a different architecture compared to Struts 1. Apache Struts is commonly used for building enterprise-level web applications in Java.</p>"},{"location":"frameworks/struts2/","title":"Apache Struts 2","text":"<p>Apache Struts 2 is an open-source web application framework for developing Java web applications. It is part of the Apache Struts project and is designed to simplify the development of web applications by providing an MVC (Model-View-Controller) architecture and various features for handling web requests and responses.</p> <p>MVC Architecture:</p> <ul> <li>Model: Represents the application's data and business logic.</li> <li>View: Displays the user interface and receives user input.</li> <li>Controller: Manages the flow of the application, handling requests, and interacting with the model and view.</li> </ul> <p>Struts 2 provides tag libraries for creating UI components, making it easier to develop dynamic and interactive web pages. Interceptors in Struts 2 allow developers to apply cross-cutting concerns, such as logging, validation, and security, to the application's actions. It includes a powerful validation framework for declarative validation of user input.</p> <p>Struts 2 integrates with various technologies and libraries, including JavaServer Pages (JSP), JavaBeans, and custom tag libraries. Struts 2 uses XML or annotation-based configuration, providing flexibility in defining actions, results, and interceptors. </p> <p>Struts 2 supports the development of RESTful web services by providing annotations and conventions for creating RESTful actions. Developers can extend Struts 2 functionality through plug-ins, allowing for customization and integration with other frameworks.</p> <p>Struts 2 includes features to address security concerns, such as protection against common web application vulnerabilities like Cross-Site Scripting (XSS) and Cross-Site Request Forgery (CSRF).</p> <p>While Apache Struts 2 offers powerful features for web application development, it's important for developers to follow best practices, especially regarding security, to prevent vulnerabilities such as OGNL injection, which has been a concern in the past. Regular updates and adherence to secure coding practices are recommended to ensure the robustness of applications built with Apache Struts 2.</p>"},{"location":"frameworks/symfony/","title":"Symfony","text":"<p>Symfony is a popular open-source PHP web application framework used to develop web applications and websites. It follows the Model-View-Controller (MVC) architectural pattern and provides a set of tools and components that streamline the development process, making it more efficient and maintainable.</p> <p>Symfony is highly modular, allowing developers to use only the components they need for a particular project. This modularity enhances code reuse and promotes a more flexible development process.</p> <p>Symfony provides a wide range of standalone and reusable components (such as routing, form handling, authentication, and more) that developers can use in their projects, even if they're not building a full-fledged Symfony application.</p> <p>Symfony follows the MVC architectural pattern, separating the application into three main components: Model (business logic and data handling), View (presentation and user interface), and Controller (handling user input and managing flow).</p> <p>Symfony integrates with Doctrine, an Object-Relational Mapping (ORM) system that facilitates database interactions by allowing developers to work with databases using object-oriented concepts. Symfony uses the Twig templating engine by default, providing a clean and efficient way to separate the presentation layer from the application logic.</p> <p>Symfony promotes the use of dependency injection, a design pattern that helps manage object dependencies and makes code more modular and testable. Symfony comes with various built-in tools for tasks such as testing, debugging, and profiling. The Symfony Console component allows developers to create command-line tools effortlessly.</p> <p>Symfony has a large and active community, which means that developers can find extensive documentation, tutorials, and community support. Additionally, there is an ecosystem of third-party bundles and extensions that can be easily integrated into Symfony applications.</p>"},{"location":"frameworks/tornado/","title":"Tornado","text":"<p>Tornado is an open-source web application framework and asynchronous networking library for Python. It is designed to handle asynchronous and non-blocking I/O operations, making it well-suited for building scalable and high-performance web applications.</p> <p>Tornado is built on an event-driven architecture, allowing it to handle a large number of simultaneous connections without the need for threads or processes. This makes it particularly suitable for building real-time web applications.</p> <p>Tornado has built-in support for WebSockets, enabling bidirectional communication between the client and the server. This is especially useful for building applications that require low-latency communication, such as chat applications and real-time collaboration tools.</p> <p>Tornado uses a handler-based architecture where developers define request handlers to process different types of HTTP requests. Each handler is responsible for handling a specific route or URL pattern.</p> <p>Tornado includes its own HTTP server implementation, allowing developers to deploy Tornado applications without the need for additional web servers like Apache or Nginx. It can also be integrated with other web servers if needed. </p> <p>Tornado includes a simple template engine for generating dynamic HTML content. Templates use a syntax similar to Python code and allow for embedding dynamic data. Tornado integrates well with other asynchronous libraries, including those for database access, allowing developers to build end-to-end asynchronous applications.</p> <p>Tornado provides mechanisms for handling user authentication and authorization, making it suitable for building secure web applications. Tornado has an active community, and there is documentation available to help developers get started with the framework. It is commonly used for building web applications, APIs, and services.</p> <p>A simple example of a Tornado application:</p> <pre><code>import tornado.ioloop\nimport tornado.web\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, Tornado!\")\n\ndef make_app():\n    return tornado.web.Application([\n        (r\"/\", MainHandler),\n    ])\n\nif __name__ == \"__main__\":\n    app = make_app()\n    app.listen(8888)\n    tornado.ioloop.IOLoop.current().start()\n</code></pre> <p>In this example, a basic Tornado application is defined with a single route (\"/\") that is handled by the <code>MainHandler</code> class. The application listens on port 8888.</p>"},{"location":"frameworks/uddi/","title":"Universal Description, Discovery and Integration (UDDI)","text":"<p>Universal Description, Discovery, and Integration (UDDI) is a platform-independent, open framework for describing services, discovering businesses, and integrating business services using the Internet. UDDI is an XML-based standard for distributing information about web services and enabling businesses to find and communicate with each other.</p> <p>UDDI can be thought of as a directory service for web services, where businesses can publish information about their services and search for other businesses' services.</p> <p>UDDI specifications include three main parts</p> <ul> <li>White Pages: Contain general information about the service provider, such as the company name, address, contact details, etc.</li> <li>Yellow Pages: Organize services into categories, based on standard taxonomies.</li> <li>Green Pages: Provide technical information about the services offered, including references to the actual services and their specifications (like WSDL documents).</li> </ul> <p>UDDI enables service consumers to discover web services that meet certain criteria, supporting the dynamic discovery of service endpoints and service descriptions. At its core, UDDI is a registry for businesses and their services, enabling businesses to list themselves on the Internet, similar to a digital 'phone book' of web services.</p> <p>UDDI uses SOAP (Simple Object Access Protocol) for communication, and services are typically described using WSDL (Web Services Description Language). It was designed to promote the integration of electronic business services and to facilitate interoperable and platform-independent web services.</p> <p>Initially, UDDI was anticipated as a crucial component of web services infrastructure. However, its adoption has been limited, and its importance has declined with the rise of other service discovery and integration methods.</p> <p>While public UDDI registries have not been widely adopted, the concept and technology are used in private registries within organizations and enterprises. UDDI was intended to play a significant role in Service-Oriented Architecture (SOA) by enabling dynamic binding of services, though in practice, many SOA implementations do not rely on it.</p> <p>UDDI has been criticized for its complexity and for not being as dynamic as originally envisioned. In many modern service architectures, simpler and more flexible discovery mechanisms are often preferred.</p>"},{"location":"frameworks/vue/","title":"Vue.js","text":"<p>Vue.js (or simply Vue) is a lightweight, JavaScript framework for building reactive web user interfaces. Vue extends standard HTML and CSS to create a suite of powerful tools for building the front end of interactive web applications.</p> <p>Operating within the model-view-viewmodel (MVVM) framework, the main library of Vue focuses on the viewmodel layer, providing reactive synchronization between the model and view layers via two-way data binding. This simplifies the creation of modern web apps based on the single-page application (SPA) model.</p> <p>Data binding allows Vue to dynamically update HTML elements that are \u201cbound\u201d to underlying Vue objects. This enables developers to create web applications that can run in a user\u2019s browser and provide an interactive experience that doesn\u2019t require refreshing the page.</p> <p>With the ability to update\u00a0HTML and CSS displayed in the browser in response to events in the underlying JavaScript, developers can use Vue to create everything from live chats to animated video games within a web browser.</p>"},{"location":"linux/absolutepaths/","title":"Absolute Paths","text":"<p>Absolute paths are a way of specifying the location of a file or directory in a file system, starting from the root directory.</p> <p>The root directory is the topmost directory in a file system hierarchy. In Unix and Unix-like systems, it is denoted by a single forward slash (<code>/</code>), while in Windows systems, it typically starts with a drive letter followed by a colon and a backslash (e.g., <code>C:\\</code>). An absolute path contains the complete address of a file or directory from the root directory. It doesn't depend on the current working directory of the user or application.</p> <p>In Unix/Linux, an absolute path might look like <code>/home/username/Documents/file.txt</code>, where <code>/</code> is the root, and each <code>/</code> thereafter separates different levels of directories. In Windows, an absolute path might be <code>C:\\Users\\username\\Documents\\file.txt</code>, where <code>C:\\</code> is the root drive, and each <code>\\</code> separates different levels of directories.</p> <p>Since absolute paths start from the root directory, they uniquely identify a file or directory's location in the file system, avoiding ambiguity. Absolute paths are particularly useful in scenarios where the relative position of files might change, or when a consistent and unchanging reference to a file is needed, like in system configuration or when linking libraries in programming.</p> <p>Relative Paths specify a location starting from the current directory. They are shorter but depend on the current directory's location, making them less consistent for some uses compared to absolute paths.</p> <p>Info</p> <p>For example, if your current directory is <code>/home/username</code>, a relative path to a file might be <code>Documents/file.txt</code>, which is relative to the current directory, whereas the absolute path would be <code>/home/username/Documents/file.txt</code>.</p>"},{"location":"linux/bash/","title":"BASH","text":"<p>In basic terms, Bash is a command line interpreter that typically runs in a text window where user can interpret commands to carry out various actions. The combination of these commands as a series within a file is known as a Shell Script. Bash can read and execute the commands from a Shell Script.</p> <p>Bash is the default login shell for most Linux distributions and Apple's mac OS. It is also accessible for Windows 10 with a version and default user shell in Solaris 11.</p>"},{"location":"linux/env/","title":"Linux Environment Variables","text":"<p>Linux environment variables are dynamic values that the operating system and other applications use to determine information specific to an environment, such as the location to store files, the current user name, and which directory to find executable files. </p> <p>These variables are part of the environment in which a process runs and are used to pass information into and out of programs running on the shell.</p> <p>Environment variables can be global (system-wide) or local (user-specific). System-wide variables apply to all users, whereas user-specific variables apply only to the particular user's environment. Some common variables include:</p> <ul> <li><code>PATH</code>: Specifies the directories where executable files are located. When a command is entered, the system searches these directories in the order listed in the <code>PATH</code> variable.</li> <li><code>HOME</code>: Indicates the current user's home directory.</li> <li><code>USER</code>: Contains the username of the current user.</li> <li><code>SHELL</code>: Specifies the path to the default shell.</li> <li><code>PWD</code>: Represents the current working directory.</li> <li><code>LANG</code>: Specifies the system language and locale.</li> <li><code>EDITOR</code>: Sets the default text editor.</li> <li><code>TZ</code>: Indicates the time zone.</li> </ul> <p>Environment variables are accessed in the shell using the <code>$</code> prefix. For example, <code>echo $HOME</code> prints the current user's home directory. It's common to modify the <code>PATH</code> variable to add new directories to the search path. This allows executables in those directories to be run from anywhere without specifying the full path.</p> <p>Child processes inherit the environment variables from their parent process. This behavior is essential for ensuring that system settings propagate correctly to all processes. Environment variables are widely used in shell scripts and applications to make them more flexible and adaptable to different system configurations.</p> <p>Care must be taken with environment variables, particularly when used in scripts and applications, as they can be exploited if not properly handled (e.g., in cases of Environment Variable Injection).</p>"},{"location":"linux/grep/","title":"Grep","text":"<p>The <code>grep</code> command in Unix and Unix-like operating systems is a powerful tool used for searching plain-text data for lines that match a given regular expression. Its name comes from the ed command <code>g/re/p</code> (globally search a regular expression and print). <code>grep</code> is widely used for searching in files, or combined with other commands in pipelines for various text-processing tasks.</p> <p>Some basic examples include:</p> <pre><code>grep \"search_string\" filename.txt\n</code></pre> <p>This command will search for <code>search_string</code> in <code>filename.txt</code> and print lines where the string is found.</p> <pre><code>grep -i \"search_string\" filename.txt\n</code></pre> <p>The -i option makes the search case-insensitive.</p> <pre><code>grep -c \"search_string\" filename.txt\n</code></pre> <p>The -c option will count the number of lines that match the search string.</p> <pre><code>grep -n \"search_string\" filename.txt\n</code></pre> <p>The <code>-n</code> option prints the line number before each matching line.</p> <pre><code>grep -r \"search_string\" /path/to/directory\n</code></pre> <p>The -r option tells grep to recursively search all files in the specified directory and its subdirectories.</p> <pre><code>grep -v \"search_string\" filename.txt\n</code></pre> <p>The -v option inverts the match, showing only the lines that do not contain the search string.</p> <pre><code>grep \"^[0-9]\" filename.txt\n</code></pre> <p>This searches for lines in filename.txt that start with a number. grep supports regular expressions for more complex pattern matching.</p> <pre><code>grep -A 2 \"search_string\" filename.txt  # Show 2 lines after the match\ngrep -B 2 \"search_string\" filename.txt  # Show 2 lines before the match\ngrep -C 2 \"search_string\" filename.txt  # Show 2 lines before and after the match\n</code></pre> <p>This displays lines before and after the matches.</p> <pre><code>grep -e \"string1\" -e \"string2\" filename.txt\n</code></pre> <p>The -e option allows you to specify multiple search patterns.</p> <pre><code>cat filename.txt | grep \"search_string\"\n</code></pre> <p>Here, <code>grep</code> is used to filter the output of another command (<code>cat</code> in this case).</p>"},{"location":"linux/ifsvar/","title":"$IFS Environment Varable","text":"<p>The \\$IFS environment variable in Linux stands for \"Internal Field Separator\". It is used by the shell to determine how to do word splitting, i.e., how to recognize word boundaries. In essence, $IFS defines a string of characters that the shell treats as delimiters between words or fields.</p> <p>By default, <code>$IFS</code> contains three characters: space, tab, and newline. This means that in its default state, the shell will split words or fields on spaces, tabs, and newlines. You can change the value of <code>$IFS</code> to alter the behavior of shell scripts or commands. For instance, if you set <code>IFS=,</code>, the shell will treat commas as the delimiter for splitting words.</p> <p>It's commonly used in shell scripts and command lines, especially when reading data from a file or processing input strings. For example, when parsing CSV files, setting <code>IFS</code> to a comma is useful. Modifying <code>$IFS</code> can significantly change the behavior of scripts and commands. It should be done cautiously, and typically, <code>IFS</code> is restored to its original state after its custom use in a script.</p> <p>Changes to <code>IFS</code> in a subshell do not affect the parent shell. So, scripts often modify <code>IFS</code> in a subshell to avoid side effects. It's also used in command-line arguments and in parsing file paths, where directories and filenames are separated by specific delimiters (like <code>/</code> in file paths).</p>"},{"location":"linux/relative/","title":"Relative Paths","text":"<p>Relative paths are a way of specifying the location of a file or directory in relation to the current working directory in a file system.</p> <p>A relative path is defined in relation to the current directory that the user or application is working in. This is known as the current working directory. Unlike Absolute Paths, which provide the complete path from the root of the file system, relative paths navigate from the current directory. They do not start with the root directory or a drive letter.</p> <p>In Unix/Linux, a relative path might look like <code>Documents/file.txt</code> or <code>../otherfolder/image.jpg</code>. The <code>.</code> denotes the current directory, and <code>..</code> denotes the parent directory. In Windows, similar to Unix/Linux but uses backslashes, like <code>Documents\\file.txt</code> or <code>..\\otherfolder\\image.jpg</code>.</p> <p>Relative paths are useful when the structure of a directory tree is consistent but the absolute position of the entire tree within the file system might change. For example, if a set of files is moved to a different folder or drive, relative paths inside this set will still be valid, whereas absolute paths would need updating.</p> <p>Relative paths are commonly used in programming and web development to link files (like libraries, images, or other resources) that are within the same directory tree, as they allow for more portability of the code or website. </p> <p>Absolute paths provide a complete path from the root directory to the target file or directory and remain constant, regardless of the current working directory. Relative paths, being dependent on the current directory, are more flexible but can sometimes lead to confusion if the current directory context is not clear.</p> <p>Info</p> <p>For example, if you are in the directory <code>/home/username/Documents</code>, and you want to refer to a file located at <code>/home/username/Pictures/image.jpg</code>, the relative path from your current directory would be <code>../Pictures/image.jpg</code>. This path means: go up one level to <code>/home/username/</code> (using <code>..</code>) and then down into <code>Pictures/image.jpg</code>.</p>"},{"location":"linux/sed/","title":"sed","text":"<p><code>sed</code>, short for \"stream editor,\" is a powerful text-processing utility in Unix and Unix-like operating systems, including Linux and macOS. It's used primarily for parsing and transforming text data, such as extracting, replacing, and modifying strings or file content. </p> <p><code>sed</code> is non-interactive, meaning it processes text without requiring user intervention, making it well-suited for scripting and batch processing.</p> <p><code>sed</code> reads input line by line, processes it according to provided commands, and outputs the result. It's particularly efficient for handling large text files. It uses regular expressions for pattern matching, which allows for complex text manipulations.</p> <p>It is capable of editing files in-place (with the <code>-i</code> option), modifying the original file with the changes. It is commonly used for its search and replace functionality, which allows for the substitution of text patterns. <code>sed</code> commands can be scripted, enabling complex text transformations in shell scripts.</p> <p>Some common uses for sed include:</p> <ul> <li>Text Replacement: Replacing words or patterns in a file. For example, to replace \"cat\" with \"dog\" in a file:</li> </ul> <pre><code>sed 's/cat/dog/' filename.txt\n</code></pre> <ul> <li>Data Extraction and Reporting: Extracting specific data from text files, such as logs or configuration files.</li> <li>File Formatting and Text Conversions: Modifying the format of text data, like converting dates or removing whitespace.</li> <li>Automating Text Edits in Scripts: Using within shell scripts or in combination with other Unix tools for batch processing.</li> </ul> <p>A simple example of Sed may be:</p> <pre><code>sed 's/foo/bar/g' input.txt &gt; output.txt\n</code></pre> <p>This command replaces every occurrence of \"foo\" with \"bar\" in input.txt and writes the result to output.txt. The s stands for substitute, and the g at the end signifies a global replacement (replace all occurrences, not just the first one).</p>"},{"location":"misc/activemq/","title":"Apache ActiveMQ","text":"<p>Apache ActiveMQ is an open-source message broker written in [[Java]]. It provides robust, scalable, and flexible messaging solutions. As a popular implementation of the [[Java Messaging Service (JMS)|Java Message Service (JMS)]] API, ActiveMQ facilitates the communication between different components of a distributed application by exchanging messages. It's widely used in enterprise systems for integrating various applications and services.</p> <p>ActiveMQ is a fully JMS-compliant message broker, supporting JMS 1.1 and 2.0. This allows applications to create, send, receive, and read messages. Like other message brokers, ActiveMQ enables asynchronous communication, allowing different parts of a system to communicate with each other without needing to respond immediately.</p> <p>It supports various messaging models, including point-to-point (queue-based) and publish-subscribe (topic-based) messaging. ActiveMQ can be integrated into numerous environments and frameworks, making it a versatile choice for enterprise application integration.</p> <p>It provides connectors for various protocols and technologies beyond JMS, including [[Advanced Message Queuing Protocol (AMQP)|AMQP]], [[MQTT|MQTT]], [[STOMP|STOMP]], and [[WebSockets]], enhancing its interoperability. ActiveMQ is designed for high performance and scalability. It supports clustering and load balancing, making it suitable for high-load and failover scenarios.</p> <p>Messages can be persisted to ensure they are not lost in case of broker failure, providing reliable message delivery. ActiveMQ includes features for securing message communication, including SSL/TLS support and the ability to integrate with various authentication and authorization mechanisms.</p>"},{"location":"misc/ansible/","title":"Ansible","text":"<p>Ansible is an open-source automation tool, or platform, used for tasks such as configuration management, application deployment, task automation, and IT orchestration. It aims to provide large productivity gains to a wide variety of automation challenges. </p> <p>Developed by Red Hat, Ansible is popular in the DevOps community and among system administrators for its ease of use, simplicity of its playbooks, and agentless architecture.</p> <p>Ansible uses a simple syntax written in [[YAML]] called playbooks. Playbooks describe the automation jobs in a human-readable format, making it easy for even those not familiar with the underlying technology to understand.</p> <p>Unlike other configuration management tools, Ansible does not require any agent software to be installed on the nodes it manages. Instead, it uses [[Secure Shell|SSH]] or [[Windows PowerShell|PowerShell]] to connect to the nodes, reducing the management overhead and potential security vulnerabilities.</p> <p>Ansible can be used to automate the configuration of systems, ensuring that they are all set up consistently and in compliance with specified requirements. It allows automated deployment of applications in a consistent manner across various environments, reducing human errors and speeding up the deployment process.</p> <p>Ansible works with Linux/Unix, Windows, and other platforms, making it versatile for managing a wide range of systems. Routine and repetitive tasks such as system updates, user management, and service monitoring can be automated, saving time and reducing the chance of errors.</p> <p>Ansible comes with a library of modules that can be executed directly on remote hosts or through playbooks. Users can also write their own modules and plugins. Ansible can define complex workflows to orchestrate the configuration, deployment, and update processes across multiple systems.</p> <p>It manages inventories in simple text files (though dynamic inventories are also supported), which list the nodes in the systems to be managed.</p>"},{"location":"misc/ant/","title":"Ant","text":"<p>Apache Ant is a Java-based build tool developed by the Apache Software Foundation. It is used primarily for automating the build processes in software development, especially for [[Java]] applications. Unlike traditional script-based build tools, Ant uses [[Extensible Markup Language|XML]] to describe the build process and its dependencies.</p> <p>Ant uses an XML file (commonly named <code>build.xml</code>) to define the build tasks and their dependencies. This XML-based configuration makes Ant builds easy to read and maintain. Being Java-based, Ant is platform-independent. It can run on any operating system where the [[Java Runtime Environment (JRE)]] is available.</p> <p>Ant includes a large number of built-in tasks that allow developers to compile code, copy files, delete directories, process [[Java Archive (JAR)|Java archives (JARs)]], and more. These tasks can be extended by writing custom tasks.</p> <p>Ant integrates well with popular Integrated Development Environments (IDEs) like Eclipse, IntelliJ IDEA, and NetBeans, making it easy to use within a developer's workflow. Developers can extend Ant's capabilities by writing their own tasks in Java. They can also use third-party libraries and tasks to augment Ant\u2019s core functionality.</p> <p>Common use cases for Ant include compiling Java code, packaging binary code into JAR files, running tests, generating documentation, and deploying applications. Ant scripts are highly customizable, and the tool is known for its flexibility and simplicity. It allows for complex builds with conditional logic, looping, and method calls.</p> <p>Ant predates tools like [[Apache Maven]] and [[Gradle]]. While it\u2019s less opinionated than Maven and doesn\u2019t have a convention-over-configuration approach, it may require more detailed setup for dependencies and project structure.</p> <p>While Ant itself doesn\u2019t provide advanced dependency management features like Maven or Gradle, it can be integrated with Apache Ivy for managing dependencies.</p>"},{"location":"misc/appexchange/","title":"AppExchange","text":"<p>AppExchange is Salesforce's online marketplace for third-party applications that integrate with the [[Salesforce]] platform. Launched in 2005, it allows Salesforce users to browse, download, and install applications and integrations developed by other companies and independent software vendors (ISVs) that extend the functionality of Salesforce.</p> <p>AppExchange hosts a diverse array of applications covering various business needs, including sales, customer service, marketing automation, analytics, and more. The applications on AppExchange can be used to customize and enhance the Salesforce experience, providing additional functionality and integration with other systems.</p> <p>Applications on AppExchange are typically vetted by Salesforce, ensuring a level of quality and security compliance. Users can review and rate applications, providing feedback and insights for other potential users.</p> <p>Businesses use AppExchange applications to augment their Salesforce capabilities, tailoring the platform to their specific processes and needs. Many applications offer automation tools for common tasks, improving efficiency. </p> <p>Specialized reporting and analytics tools are available to provide deeper insights into business operations. AppExchange includes solutions tailored to specific industries, offering customized tools and workflows.</p> <p>A real estate company might use Salesforce for customer relationship management. To enhance their capabilities, they could go to AppExchange and find an application specifically designed for real estate businesses, which adds features for property listing management, integration with real estate databases, and advanced analytics for market trends.</p> <p>Independent software vendors can develop and sell their applications to Salesforce users, reaching a wide audience. Developers can monetize their apps by offering them on AppExchange, either for free or as paid solutions.</p>"},{"location":"misc/ascii/","title":"ASCII","text":"<p>ASCII, which stands for American Standard Code for Information Interchange, is a character encoding standard for electronic communication. ASCII codes represent text in computers, telecommunications equipment, and other devices that use text.</p> <p>ASCII uses a 7-bit binary number to represent each character. This allows for 128 possible characters (2^7 = 128). These characters include:</p> <ul> <li>Uppercase and lowercase English letters (A-Z, a-z).</li> <li>Digits (0-9).</li> <li>Basic punctuation symbols.</li> <li>Control characters (like carriage return, line feed, tab).</li> </ul> <p>Apart from printable characters like letters and numbers, ASCII also includes control characters. These are non-printable characters that control the flow of data in transmission and display, such as the start and end of a transmission or a new line. The ASCII table maps each character to a numerical value. For example, the capital letter \"A\" is represented by the number 65.</p> <p>While ASCII has largely been superseded by [[Unicode]] (which can represent far more characters and supports multiple languages and scripts), it laid the foundation for modern character encoding. Many modern systems and protocols still use ASCII or an extended form of it.</p>"},{"location":"misc/base64/","title":"Base64","text":"<p>Base64 is a binary-to-text encoding scheme that is used to represent binary data in an [[ASCII]] string format. It's commonly used in various applications where data needs to be encoded to safely be transmitted over media that are designed to handle text.</p> <p>Base64 encoding takes binary data and divides it into groups of 6 bits. Since 6 bits can represent 64 different values (2^6 = 64), each 6-bit group is then mapped to a specific character from a set of 64 characters. The Base64 index table includes uppercase and lowercase letters (A-Z, a-z), digits (0-9), and a couple of special characters (+ and /).</p> <p>If the total number of bits in the binary data is not a multiple of 6, the last group will be padded with zeros to make it a full 6-bit group. Correspondingly, the Base64 output is padded with '=' characters to indicate that padding occurred.</p> <p>The standard Base64 character set includes:</p> <ul> <li>Uppercase letters</li> <li>Lowercase letters</li> <li>Digits</li> <li>Plus sign</li> <li>Slash</li> <li>Equals sign</li> </ul>"},{"location":"misc/bbp/","title":"Bug Bounty Program","text":"<p>A bug bounty program is an initiative offered by many websites, organizations, and software developers by which individuals can receive recognition and compensation for reporting bugs, especially those pertaining to security vulnerabilities and exploits.</p> <p>The primary focus is often on identifying security vulnerabilities in a software or system. These vulnerabilities could include issues like [[cross-site scripting]], [[SQL injection]], [[buffer overflows]], and more. Those who report vulnerabilities are usually rewarded. The rewards can vary greatly depending on the severity of the bug and the company's policy. They might range from small tokens of appreciation or merchandise to significant monetary rewards for major discoveries.</p> <p>Most bug bounty programs have specific guidelines. These guidelines define the scope of the program, what constitutes a valid bug, how to report it, and the rules of engagement to ensure ethical conduct (like not exploiting the bug for harm). Some companies run public bug bounty programs where anyone can participate, while others may have private programs, where participation is by invitation only.</p> <p>These programs are beneficial for both the organization and the security community. They allow organizations to harness the skills of a wide range of individuals to help secure their systems, and they offer an ethical outlet for security researchers and hackers to apply their skills. There are platforms like HackerOne or Bugcrowd that host and manage bug bounty programs for various companies. These platforms provide a framework and process for submission, evaluation, and reward of bug findings.</p>"},{"location":"misc/binj/","title":"Binary JSON","text":"<p>Binary JSON (BJSON) is a concept that typically refers to BSON, which stands for \"Binary JSON.\" BSON is a binary-encoded serialization of [[JavaScript Object Notation|JSON]]-like documents. It is designed to be more efficient in terms of space and speed when compared to JSON, especially in the context of certain types of data. </p> <p>BSON is used in several [[Non-relational Database|NoSQL]] databases, most notably [[MongoDB]].</p> <p>BSON's binary format allows for more efficient storage and faster access to data. This is particularly beneficial when working with large datasets or in environments where performance is critical.</p> <p>Unlike JSON, which primarily supports text, BSON supports a wider range of data types, including int, long, date, floating point, and decimal128. It also supports more complex types like byte arrays, making it suitable for storing binary data.</p> <p>BSON is essentially a binary representation of JSON data. It extends the JSON model to provide additional data types and to be efficient for encoding and decoding within different languages.</p> <p>BSON is widely used in NoSQL databases like MongoDB. In these databases, BSON allows for the storing and querying of documents in a way that is more space-efficient and faster than if the documents were stored in plain JSON format.</p>"},{"location":"misc/ble/","title":"Bluetooth Low Energy (BLE)","text":"<p>Bluetooth Low Energy (BLE), also known as Bluetooth Smart, is a wireless [[Personal Area Networks (PANs)|personal area network]] technology designed and marketed by the Bluetooth Special Interest Group (Bluetooth SIG) for novel applications in the healthcare, fitness, beacons, security, and home entertainment industries. It is distinct from the classic [[Bluetooth]] (Bluetooth Classic).</p> <p>The most significant feature of BLE is its extremely low power consumption. It is designed to consume a fraction of the power of Bluetooth Classic, making it ideal for battery-operated or energy-sensitive devices like wearables and [[IoT]] sensors.</p> <p>Unlike Bluetooth Classic, which maintains a continuous connection, BLE remains in sleep mode except when a connection is initiated. This 'connectionless' communication contributes to its lower power usage.</p> <p>BLE can communicate over similar distances to Bluetooth Classic, typically around 100 meters (330 feet) in open space, depending on the hardware. BLE is optimized for low data rate applications, with a maximum transfer rate of about 1 Mbps, which is less than Bluetooth Classic but sufficient for its intended uses.</p> <p>BLE is widely used in applications where periodic or infrequent data transfers are required over a long period, such as in fitness trackers, health monitoring devices, smart home devices, and location beacons. </p> <p>Most modern smartphones, tablets, and computers that support Bluetooth 4.0 or higher are compatible with both Bluetooth Classic and BLE. BLE supports various network topologies, including point-to-point, broadcast, and mesh networking, which allows for extensive IoT deployments.</p> <p>BLE enables easy pairing and wireless connectivity, often simplifying the connection process without the need for manual discovery and pairing as in Bluetooth Classic.</p> <p>BLE incorporates robust security features like [[Advanced Encryption Standard (AES)|AES-128]] encryption, but the security implementations can vary based on the application requirements.</p>"},{"location":"misc/blocking/","title":"Head-of-Line Blocking","text":"<p>Head-of-Line (HOL) blocking is a performance issue that occurs in networking and computer systems. In the context of HTTP/1.x, it refers to the problem where a line of requests must wait for the first request to be completed and responded to before the next can be processed. </p> <p>This happens because HTTP/1.x handles requests sequentially on each [[Transmission Control Protocol|TCP]] connection. With HOL blocking, even if subsequent requests are ready to be processed, they are blocked by the first request, leading to inefficiencies and increased latency. This issue is significantly mitigated in [[HTTP2|HTTP/2]] through the use of multiplexing, where multiple requests can be sent and responses received asynchronously over a single connection.</p>"},{"location":"misc/bt/","title":"Bluetooth","text":"<p>Bluetooth is a wireless technology standard used for exchanging data over short distances from fixed and mobile devices. It creates [[Personal Area Networks (PANs)]] with high levels of security. </p> <p>Bluetooth is designed for short-range communication, typically up to about 30 feet (10 meters), although newer versions can reach over 100 meters in ideal conditions. One of the defining features of Bluetooth is its low power consumption, making it ideal for mobile and battery-powered devices.</p> <p>It allows for the connection of multiple devices, enabling them to communicate wirelessly. This includes connecting peripherals like headsets, speakers, keyboards, and mice to computers or smartphones.</p> <p>There have been several versions of Bluetooth, each improving on speed, range, and energy efficiency. Newer devices are generally backward compatible with older Bluetooth versions.</p> <p>Bluetooth uses a variety of protocols and profiles to ensure that different types of devices can connect and communicate effectively. For example, the Headset Profile (HSP) for telephone headsets and the Advanced Audio Distribution Profile (A2DP) for sending stereo audio.</p> <p>Bluetooth includes security features such as encryption and authentication, which help to protect data as it is transferred between devices. Its applications are varied and include file transfer, audio streaming, real-time location systems, health monitoring, and connecting smart home devices.</p> <p>[[Bluetooth Low Energy (BLE)]]  is a power-conserving variant of Bluetooth, used in applications that do not require continuous data streaming, such as fitness trackers and smart home devices and [[IoT]] devices.</p>"},{"location":"misc/cc/","title":"Constant Contact","text":"<p>Constant Contact for WordPress refers to the integration of the Constant Contact email marketing platform with the [[WordPress]] [[content management system]]. This integration typically involves a plugin that enables WordPress users to easily connect their website with their Constant Contact account. The purpose of this integration is to streamline various email marketing tasks directly from the WordPress dashboard, enhancing the efficiency and effectiveness of digital marketing efforts for WordPress site owners.</p> <p>The integration allows you to create and add Constant Contact signup forms to your WordPress site. This helps in growing your email list by capturing the details of visitors to your site. You can manage your Constant Contact email lists directly from your WordPress dashboard, making it easier to segment and organize subscribers based on different criteria.</p> <p>When new users register on your WordPress site, or when forms are filled out, their information can be automatically synced to your Constant Contact account, saving time on manual entry. Access to Constant Contact's email templates and campaign tools from within WordPress, allowing for seamless creation and dispatch of email campaigns.</p> <p>If you're using an e-commerce platform on WordPress, such as WooCommerce, the integration can enhance your email marketing by targeting customers based on their purchasing behavior. Some integrations offer the ability to view basic reporting and analytics about your email campaigns directly in WordPress.</p> <p>When integrating email marketing tools like Constant Contact with WordPress, it's important to ensure that the integration complies with data protection and privacy laws (like GDPR, if applicable). Security is also a concern, so it's recommended to use plugins and integrations from reputable sources and keep them up to date.</p>"},{"location":"misc/cdi/","title":"CDI","text":"<p>Contexts and Dependency Injection (CDI) is a set of services and [[APIs]] that brings the concept of dependency injection to [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]]. It allows various components of a Java EE application, such as [[Enterprise JavaBeans (EJBs)|EJBs (Enterprise JavaBeans)]], [[Java Persistence API (JPA)|JPA (Java Persistence API)]] entities, and JSF (JavaServer Faces) managed beans, to interact with each other in a more decoupled manner. CDI is a part of the Java EE platform, but it can also be used in Java SE applications.</p> <p>CDI simplifies the process of connecting application components (beans), by allowing them to be injected at runtime, rather than being hard-coded or looked up manually. This makes the application easier to develop and maintain.</p> <p>CDI uses a type-safe approach for dependency injection, minimizing runtime errors and improving code readability. CDI manages the lifecycle of beans with defined scopes, such as <code>RequestScoped</code>, <code>ApplicationScoped</code>, <code>SessionScoped</code>, and <code>ConversationScoped</code>. This helps in managing the state of beans according to the lifecycle of the application or its components.</p> <p>CDI is designed to work seamlessly with various Java EE components, enhancing the capabilities of EJBs, JSF, JPA, and [[JAX-RS (Java API for RESTful Web Services)]]. CDI includes an event model that allows beans to produce and consume events, facilitating loose coupling and better separation of concerns.</p> <p>It supports interceptors and decorators, which can be used to modify or extend the behavior of beans, for example, adding logging or security checks. CDI allows for the creation of portable extensions that can integrate with the container\u2019s lifecycle, enabling customization and integration of third-party frameworks.</p> <p>CDI integrates with the Unified EL, allowing CDI beans to be used directly in the JSF user interface and other EL contexts. For some use cases, CDI provides a lighter alternative to EJB, offering many of the same features without the need for a full EJB container.</p> <p>CDI introduces the concept of stereotypes, which allow for encapsulating metadata about beans, making configuration more reusable and reducing boilerplate code.</p>"},{"location":"misc/chimp/","title":"Mailchimp","text":"<p>Mailchimp is a marketing automation platform and an email marketing service. Originally known for its email marketing tools, Mailchimp has expanded over the years to become an all-in-one marketing platform for small to medium-sized businesses. It offers a range of features to design, send, and track email campaigns, along with additional tools for advertising, analytics, and audience management.</p> <p>Users can create and send email newsletters, automated messages, and targeted campaigns. Mailchimp provides a variety of customizable templates and a drag-and-drop editor for designing emails. Features tools for managing contact lists, segmenting audiences based on behavior or preferences, and personalizing content for different segments.</p> <p>It also allows for the creation of automated email sequences, such as welcome series, birthday emails, or follow-up messages based on user actions. It also offers detailed reports on campaign performance, including open rates, click rates, and subscriber activity, which help in refining marketing strategies.</p> <p>It integrates with various e-commerce platforms, [[Customer Relationship Management (CRM) Software|CRM]] tools, and other software, allowing users to connect their email marketing with other aspects of their business. Users can create custom landing pages and sign-up forms to grow their mailing list and convert visitors into subscribers or customers.</p> <p>Mailchimp is widely used by businesses of all sizes, bloggers, non-profits, and various other entities to manage their email marketing campaigns and automate many of their marketing tasks. Its user-friendly interface makes it accessible to those without advanced technical skills, while its advanced features cater to the needs of more experienced marketers.</p> <p>Mailchimp takes data security and privacy seriously and provides features to help users comply with regulations like GDPR. It includes tools for managing subscriber consent, data processing agreements, and other compliance-related aspects of email marketing.</p>"},{"location":"misc/db2/","title":"IBM DB2","text":"<p>IBM DB2 is a family of data management products, including database servers, developed by IBM. It is known for its robust performance, scalability, and reliability, catering to various business needs.</p> <p>DB2 primarily functions as a [[Relational Database Management System|relational DBMS]] with support for object-oriented features and non-relational structures like [[JavaScript Object Notation|JSON]] and [[Extensible Markup Language|XML]].</p> <p>It's designed to operate on multiple platforms, including Linux, UNIX, and Windows, as well as IBM's mainframe systems. This cross-platform compatibility is a significant advantage for organizations with diverse IT environments.</p> <p>DB2 is well-regarded for its high performance, particularly in large enterprise environments. It can handle massive volumes of data and high transaction rates, making it suitable for big data applications and high-performance computing.</p> <p>DB2 includes features for data warehousing and analytics. It supports in-database analytics, allowing users to run complex queries and analytics operations directly on the database, which can significantly improve performance and reduce data movement.</p> <p>It offers robust security features, including advanced encryption capabilities, access control mechanisms, and compliance tools to help organizations meet various regulatory requirements.</p> <p>It offers compatibility with other [[Structured Query Language|SQL]] databases, providing tools and features to ease the migration process from other databases like [[Oracle Database|Oracle]] or [[Microsoft SQL Server|SQL Server]] to DB2.</p>"},{"location":"misc/docker/","title":"Docker","text":"<p>Docker is a tool that allows developers, sys-admins etc. to easily deploy their applications in a sandbox (called\u00a0[[Containers|containers]]) to run on the host operating system i.e. Linux. The key benefit of Docker is that it allows users to\u00a0package an application with all of its dependencies into a standardized unit\u00a0for software development. Unlike virtual machines, containers do not have high overhead and hence enable more efficient usage of the underlying system and resources.</p>"},{"location":"misc/dockercompose/","title":"Docker Compose","text":"<p>Docker Compose is a tool for defining and running multi-container [[Docker]] applications. With Compose, you use a [[YAML]] file to configure your application's services, networks, and volumes, and then create and start all the services from your configuration with a single command. It's a part of Docker, which is a platform for developing, shipping, and running applications inside lightweight containers.</p> <p>Docker Compose allows you to define your multi-container Docker application's configuration in a <code>docker-compose.yml</code> file, which makes the configuration easy to read, write, and maintain. It simplifies the setup of development environments where an application might require multiple services to run, such as a web server, a database, and a cache. All these services can be defined and run with a single command.</p> <p>In the <code>docker-compose.yml</code> file, you define a set of services, networks, and volumes. A service is a container based on a Docker image, and it defines how that container should run (what ports to use, what volumes to mount, etc.).</p> <p>Docker Compose provides a command-line interface (CLI) for managing the lifecycle of your application. Common commands include <code>docker-compose up</code> to start the application, <code>docker-compose down</code> to stop it, and <code>docker-compose restart</code> to restart all services.</p> <p>Compose sets up a network for your containers to communicate with each other and with the host machine. You can manage persistent data for your containers by defining volumes in the <code>docker-compose.yml</code> file.</p> <p>Compose supports the use of environment variables for configuring services, which is particularly useful for not exposing sensitive data. Compose works well with other Docker tools and services, providing a smooth workflow for developing, testing, and deploying applications.</p>"},{"location":"misc/dotnet/","title":".NET","text":"<p>.NET is an open-source platform for building desktop, web, and mobile applications that can run natively on any operating system. The .NET system includes tools, libraries, and languages that support modern, scalable, and high-performance software development. An active developer community maintains and supports the .NET platform.</p> <p>In simple terms, the .NET platform is a software that can do these tasks:</p> <ul> <li>Translate .NET programming language code into instructions that a computing device can process.</li> <li>Provide utilities for efficient software development. For example, it can find the current time or print text on the screen.</li> <li>Define a set of data types to store information like text, numbers, and dates on the computer.</li> </ul>"},{"location":"misc/dox/","title":"Doxygen","text":"<p>Doxygen is a documentation generator, a tool used for writing software documentation from annotated source code. It is one of the most popular tools of its kind and is particularly prevalent in [[C++]], [[C]], and [[CSharp|C#]] development, although it supports other programming languages like [[Java]], [[Objective-C]], [[Python]], [[PHP]], and more.</p> <p>Doxygen extracts documentation from source code comments. The comments are often written in a structured format that Doxygen understands, allowing it to generate well-formatted and organized documentation. While primarily used for C-like languages, Doxygen also supports other languages, making it versatile for multi-language projects.</p> <p>Doxygen can produce documentation in several formats, including [[HTML]], [[LaTeX]] (for printable PDFs), man pages, [[RTF]], and [[Extensible Markup Language|XML]]. It can generate class diagrams, inheritance diagrams, collaboration diagrams, and call graphs using Graphviz software.</p> <p>Doxygen provides functionalities to create cross-references in the documentation, making navigation easier. It can be configured to work with version control systems, ensuring that the documentation is always in sync with the source code.</p> <p>In a C++ project, a developer might annotate a class like this:</p> <pre><code>/**\n * @brief A brief description of the MyClass class.\n *\n * Detailed description of MyClass.\n */\nclass MyClass {\npublic:\n    /**\n     * @brief A brief description of the myMethod method.\n     * @param param1 Description of the first parameter.\n     * @return Description of the return value.\n     */\n    int myMethod(int param1);\n};\n</code></pre> <p>Doxygen would process these comments to generate comprehensive documentation for the <code>MyClass</code> class and its <code>myMethod</code> method, including descriptions of the method's purpose, its parameters, and its return value.</p> <p>Doxygen is typically run from the command line, where it reads a configuration file (Doxyfile) that specifies how the documentation should be generated. Users can customize a wide range of settings in the Doxyfile to tailor the output to their specific needs.</p>"},{"location":"misc/eip/","title":"Enterprise Integration Patterns (EIP)","text":"<p>Enterprise Integration Patterns (EIP) is a set of design patterns used to address common challenges in the integration of diverse software systems. These patterns provide a standardized and well-documented approach to designing, building, and implementing enterprise-level integration solutions.</p> <p>EIP offers a set of standardized solutions to common integration problems encountered in enterprise systems. These patterns help developers design integration solutions that are scalable, maintainable, and robust. EIP provides a pattern language for describing various integration scenarios and solutions. Each pattern represents a recurring design solution to a specific problem in the context of system integration.</p> <p>EIP abstracts complex integration challenges into a set of well-defined patterns, making it easier for architects and developers to communicate and collaborate on integration projects. Many EIP patterns focus on the use of messaging as a fundamental communication mechanism between different components or systems. This messaging-centric approach allows for loose coupling, scalability, and asynchronous communication.</p> <p>EIP emphasizes the benefits of asynchronous messaging for decoupling producers and consumers of information. Asynchronous communication allows systems to interact without requiring immediate responses, improving system responsiveness and scalability. EIP patterns address error handling and recovery strategies in integration solutions. This includes patterns for dealing with exceptions, retries, and compensating transactions.</p> <p>EIP includes patterns for data transformation and routing. These patterns help in converting data between different formats and routing messages to the appropriate destinations based on specific criteria. EIP introduces the concept of endpoint abstraction, allowing developers to design systems where components communicate through endpoints, which can represent various communication mechanisms such as message queues, web services, or direct method calls.</p> <p>EIP includes patterns for dynamic routing and content-based routing, enabling flexible and adaptive routing of messages based on their content or attributes. EIP addresses both stateful and stateless interactions between systems. Stateful interactions involve maintaining context or state information across multiple messages, while stateless interactions treat each message independently.</p> <p>EIP patterns are designed to facilitate the integration of new systems with existing ones. This is crucial in enterprise environments where legacy systems often coexist with modern applications.</p> <p>Some commonly used Enterprise Integration Patterns include:</p> <ul> <li>Message Channel</li> <li>Message Router</li> <li>Message Filter</li> <li>Message Translator</li> <li>Message Endpoint</li> <li>Publish-Subscribe Channel</li> <li>Content Enricher</li> <li>Aggregator</li> <li>Splitter</li> <li>Wire Tap</li> </ul>"},{"location":"misc/ejb/","title":"Enterprise JavaBeans (EJBs)","text":"<p>Enterprise JavaBeans (EJB) is a server-side software component architecture used in [[Java]] Platform, Enterprise Edition (Java EE) for building robust, scalable, transactional, and multi-user secure enterprise-level applications. EJBs are used to encapsulate business logic, which can then be reused without the need for developers to handle complex aspects like transaction management, multi-threading, connection pooling, and other low-level functionalities.</p> <p>Types of EJBs:</p> <ul> <li>Session Beans: Handle business logic. They come in two types:</li> <li>Stateless Session Beans: Do not maintain client state across method calls.</li> <li>Stateful Session Beans: Maintain client state across method calls.</li> <li>Message-Driven Beans (MDBs): Used for handling asynchronous messages from a queue or topic.</li> <li>Singleton Session Beans: Similar to stateless session beans but there's only one instance for the entire application, useful for shared states.</li> </ul> <p>EJBs run in an EJB container, which provides services like transaction management, security, remote access, concurrency control, and lifecycle management, relieving developers from handling these concerns explicitly.</p> <p>EJBs support both declarative and programmatic transaction management, ensuring data consistency and integrity. The EJB container can manage security, providing declarative role-based access control.</p> <p>EJBs can be accessed remotely or locally. Remote EJBs can be accessed by clients outside the EJB container, typically over a network, while local EJBs are accessed within the same application. While EJBs themselves are not responsible for data persistence, they can integrate with the [[Java Persistence API (JPA)]] for database access.</p> <p>EJBs support interceptors to allow for cross-cutting concerns like logging or auditing. EJBs are registered and looked up in the [[JNDI]] directory, which is a part of the Java EE platform. EJBs promote a component-based development approach, where business logic is modularized and encapsulated in enterprise beans.</p> <p>Despite their powerful features, EJBs have seen a decline in popularity due to their complexity and heavyweight nature. Modern Java EE and Jakarta EE platforms and frameworks like Spring and MicroProfile offer simpler and more flexible alternatives for many of the functionalities provided by EJBs.</p>"},{"location":"misc/elastic/","title":"ElasticSearch","text":"<p>Elasticsearch is a distributed search and analytics engine built on Apache Lucene. Since its release in 2010, Elasticsearch has quickly become the most popular search engine and is commonly used for log analytics, full-text search, security intelligence, business analytics, and operational intelligence use cases.</p> <p>You can send data in the form of [[JavaScript Object Notation|JSON]] documents to Elasticsearch using the API or ingestion tools such as\u00a0Logstash\u00a0and\u00a0Amazon Kinesis Data Firehose. Elasticsearch automatically stores the original document and adds a searchable reference to the document in the cluster\u2019s index.</p> <p>It\u2019s a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. Elasticsearch is primarily known for its simple [[REST APIs]], distributed nature, speed, and scalability, and it is the central component of the Elastic Stack.</p> <p>The ELK stack is a set of free and open tools for data ingestion, enrichment, storage, analysis, and visualization.</p> <p>Elasticsearch is scalable, offers many aggregations, and has a great visualization tool that is Kibana. It provides features to help you store, manage, and search time-series data, such as logs and metrics.</p> <p>Once in Elasticsearch, you can analyze and visualize your data using Kibana and other Elastic Stack features.</p> <p>Elasticsearch is typically used as the underlying search engine powering applications with simple/complex search features and requirements. Features include:</p> <ul> <li>Ability to Index, store, search and analyze large volumes of data quickly and in near real-time.</li> <li>Real-time search and analytics for structured, unstructured, numerical, or geospatial data.</li> <li>Efficiently stores and indexes data in a way to support fast searches.</li> </ul> <p>Elasticsearch uses OpenJDK, so there can be some performance differences compared to the Oracle version of Java.</p> <p>Elasticsearch has been around for a while and is used by large organizations such as CERN, Facebook, Walmart, Adobe, US Air Force, Shopify, Uber, Pfizer, Vimeo, eBay, Godaddy, and more.</p>"},{"location":"misc/erpapps/","title":"Enterprise Resource Planning Applications","text":"<p>SAP Enterprise Resource Planning (ERP) applications are integrated software solutions developed by SAP SE, designed to manage and streamline core business processes across various departments within an organization.</p> <p>These ERP applications play a crucial role in helping organizations maintain efficiency and competitiveness by providing real-time data and tools to manage operations.</p> <p>SAP ERP integrates various business processes, such as finance, human resources, sales, procurement, manufacturing, and services, into a unified system. This integration ensures consistency and efficiency throughout the organization.</p> <p>SAP ERP applications consist of several modules, each focused on different business areas. Notable modules include:</p> <ul> <li>Financial Accounting (FI): Manages a company's financial transactions and reports.</li> <li>Controlling (CO): Handles internal cost and profitability analysis.</li> <li>Sales and Distribution (SD): Manages sales, customer distribution, and billing.</li> <li>Material Management (MM): Covers procurement and inventory management.</li> <li>Human Capital Management (HCM): Manages employee information, payroll, and HR processes.</li> <li>Production Planning (PP): Handles production processes and manufacturing.</li> </ul> <p>SAP ERP systems are known for their ability to process data in real-time, enabling timely decision-making and responsiveness to changing business conditions. SAP ERP can be deployed on-premises, in the cloud, or through a hybrid model, offering flexibility depending on the organization's requirements.</p>"},{"location":"misc/esb/","title":"Enterprise Service Bus (ESB)","text":"<p>An Enterprise Service Bus (ESB) is a software architecture model used for designing and implementing the interaction and communication between mutually interacting software applications in a [[Service-Oriented Architecture (SOA)]].</p> <p>It functions as a core infrastructure that provides a set of rules and principles for integrating numerous applications over a bus-like infrastructure. ESB enables enterprises to integrate different applications by putting a communication bus between them and then enabling each application to talk to the bus.</p> <p>ESB facilitates the integration of various enterprise applications and services by providing a centralized, flexible, and scalable communication backbone. It routes messages between services, transforming and translating these messages as necessary so that they can be understood by the receiving services.</p> <p>By acting as an intermediary layer, ESB allows different systems to communicate without being directly connected, thereby decoupling systems and allowing them to evolve independently. ESB can modify or enrich the data within the message payloads, transforming them into formats that are consumable by different recipient systems.</p> <p>It supports various communication protocols and can convert messages from one protocol to another, enabling interoperability among disparate systems. ESB often includes a range of adapters that allow it to connect to different types of systems, such as databases, web services, message queues, and more.</p> <p>It offers error handling mechanisms and monitors data flows, ensuring message delivery and system health. ESB supports [[Load Balancer|load balancing]] and provides failover mechanisms to ensure high availability and reliability. ESBs can orchestrate complex business processes by coordinating interactions between different backend systems and services.</p> <p>Security features such as authentication, authorization, and encryption can be managed centrally in the ESB.</p>"},{"location":"misc/exim/","title":"Exim","text":"<p>Exim is an open-source [[Mail Transport Agent (MTA)]], which is a program responsible for routing, delivering, and receiving email messages. It's particularly known for its flexibility and configurability.</p> <p>Exim is designed to be highly configurable, allowing administrators to tailor it to a wide variety of email environments and needs. Its configuration is known for being more accessible and easier to understand than some other MTAs, like [[Sendmail]].</p> <p>One of Exim's strengths is its ability to handle different routing configurations and mail processing scenarios, making it suitable for both small and large installations. Security has been a focus in Exim's development, and it includes features to help safeguard against common email threats and vulnerabilities.</p> <p>Exim provides powerful mechanisms for mail filtering and routing, allowing for detailed control over how email is processed and delivered. Exim benefits from an active community of users and developers, which contributes to its continuous improvement and robust support resources.</p> <p>Exim is primarily used as an [[Simple Mail Transfer Protocol|SMTP]] server to route and deliver emails on the Internet and within organizations. Due to its flexibility, Exim is often used in environments where customized mail processing is required. Exim can be integrated with various spam and malware filtering tools, making it effective for managing and protecting against unwanted email.</p> <p>While similar in functionality to other MTAs like Sendmail and [[Postfix]], Exim is often praised for its balance of configurability and ease of use. It's considered more accessible than Sendmail and offers more flexibility in certain configurations compared to Postfix.</p> <p>Exim's main configuration file is typically located at <code>/etc/exim/exim.conf</code>, and it allows detailed control over all aspects of mail handling. The configuration syntax is designed to be readable and is well-documented, making it easier for system administrators to manage.</p>"},{"location":"misc/fish/","title":"GlassFish","text":"<p>GlassFish is an open-source application server project that implements the [[Java]] Platform, Enterprise Edition (Java EE) specification. GlassFish provides a server for developing and deploying Java-based web and enterprise applications.</p> <p>GlassFish is a fully Java EE-compliant application server, meaning it supports all the major Java EE technologies and [[APIs]], such as [[JavaServer Pages (JSP)|JSP]], [[JSF|JSF]], [[Java Persistence API (JPA)|JPA]], [[Java Messaging Service (JMS)|JMS]], [[Enterprise JavaBeans (EJBs)|EJB]], [[CDI]], and more. Initially created by Sun Microsystems and later acquired by Oracle Corporation, GlassFish is now an open-source project, allowing developers and organizations to use and contribute to it without cost.</p> <p>GlassFish provides an administration console (a web-based GUI) and a command-line interface (CLI) for configuring, managing, and monitoring server instances and applications. It is designed for high performance and scalability, making it suitable for large-scale enterprise applications.</p> <p>GlassFish uses a modular architecture based on the OSGi standard, which allows for dynamic loading and unloading of modules at runtime. GlassFish supports Eclipse MicroProfile, a set of specifications for building microservices-based applications.</p> <p>It offers a REST interface for administration, allowing remote and programmatic management of the server. GlassFish is integrated with various IDEs, like Eclipse and NetBeans, facilitating development, deployment, and debugging of Java EE applications. The server includes robust security features for authentication, authorization, web services security, and integration with security realms.</p> <p>[[Payara]] Server is a notable derivative of GlassFish, created to provide a fully-supported version with regular bug fixes and enhancements.</p>"},{"location":"misc/fo/","title":"XSL-FO (Formatting Objects)","text":"<p>XSL-FO (Extensible Stylesheet Language Formatting Objects) is a language for formatting [[Extensible Markup Language|XML]] data for output to screen, paper, or other media.</p> <p>It is part of the [[XSL (Extensible Stylesheet Language)]] specifications, which also include [[XPath]] and [[XSLT (Extensible Stylesheet Language Transformations)|XSLT]]. XSL-FO is primarily used for generating and formatting documents like reports, invoices, and other printed materials from XML data.</p> <p>XSL-FO is used to define the layout and formatting of pages in a document. This includes specifications for margins, headers, footers, page numbers, and other aspects of traditional page layout.</p> <p>One of the primary uses of XSL-FO is to transform XML data into PDF files or other print-ready formats. It provides a way to control the presentation of content when printed. XSL-FO is often used in conjunction with XSLT. The XSLT transforms XML data into an XSL-FO document, which is then rendered into a PDF or other printable format by an XSL-FO processor.</p> <p>The 'FO' in XSL-FO stands for Formatting Objects. These are XML elements that specify how the content is to be formatted. Examples include <code>fo:block</code> for blocks of text and <code>fo:table</code> for tables.</p> <p>XSL-FO allows for detailed control over document formatting, enabling precise placement and styling of text, graphics, and other document elements. It is suitable for creating complex documents with varying layouts, such as technical manuals, scientific papers, and detailed financial reports.</p> <p>Like [[CSS]] for [[HTML]], XSL-FO provides properties for styling elements, such as font size, color, alignment, and spacing. The output of XSL-FO is independent of the medium, meaning the same XSL-FO file can be used to generate output for different types of media.</p>"},{"location":"misc/gip/","title":"Google Identity Platform","text":"<p>Google Identity Platform is a suite of tools and services offered by Google that provides [[Identity and Access Management (IAM)]] solutions. It's designed to help developers and organizations manage user identities and access permissions across their applications and services.</p> <p>Firebase Authentication provides backend services, easy-to-use SDKs, and ready-made UI libraries to authenticate users to your app. It supports various authentication methods including passwords, phone numbers, popular federated identity providers like Google, Facebook, and Twitter, and more.</p> <p>Google Sign-In allows users to sign into apps and websites using their Google account. It simplifies the login process, enhances security, and leverages existing user credentials. Identity Toolkit is a set of [[APIs]] that allow developers to easily integrate sign-in, registration, and account management into their applications. It supports a range of authentication methods and is highly customizable.</p> <p>Smart Lock for Passwords on Android integrates with Google Save to help users automatically sign in to apps and websites. One Tap Sign-Up and Sign-In provides a streamlined user experience for signing up and signing in to apps and websites, reducing the friction associated with these processes.</p> <p>Cloud Identity is a more enterprise-focused solution that offers identity services for business users, including [[Single Sign-On (SSO)]], [[Multi-Factor Authentication (MFA)|multi-factor authentication]], and enterprise mobility management.</p>"},{"location":"misc/gradle/","title":"Gradle","text":"<p>\"Gradle\" is a powerful and flexible build automation tool that's used primarily for [[Java]] projects, but it also supports other programming languages like C/C++, [[Python]], and Swift. It combines the best features of [[Ant]] and [[Apache Maven|Maven]] and adds its own set of unique capabilities. </p> <p>Gradle is particularly known for its Groovy-based domain-specific language (DSL) for describing builds, which offers a more expressive and concise way to define custom build logic than [[Extensible Markup Language|XML]].</p> <p>Gradle build scripts are written in Groovy, a dynamic, object-oriented programming language for the Java platform, which makes the build scripts more flexible and easier to write compared to XML-based scripts used in Maven.</p> <p>Gradle features a daemon mode that makes builds much faster by reusing computations from previous builds. It also offers advanced caching and parallel execution strategies, resulting in significant performance improvements over other build tools.</p> <p>Like Maven, Gradle uses a central repository to manage project dependencies. It can import dependencies from Maven and Ivy repositories and can also publish artifacts to these repositories.</p> <p>Gradle allows for extensive customization to meet the specific needs of a project. It supports custom tasks and offers a rich API for extending the tool with custom plugins. Gradle is well-suited for managing multi-project builds, enabling modularization of large software projects with ease.</p> <p>Gradle is the official build tool for Android, making it a standard choice for [[Android]] app development. It brings powerful features for building, testing, and deploying Android applications. Gradle provides an innovative feature called build scans, which offers insights into build processes for performance optimization and troubleshooting.</p> <p>Gradle inherits the \u201cconvention over configuration\u201d principle from Maven but provides greater flexibility to override the conventions.</p>"},{"location":"misc/graphql/","title":"GraphQL","text":"<p>GraphQL is a specification for how to talk to an [[APIs|API]]. It's typically used over [[HTTP Protocol|HTTP]] where the key idea is to\u00a0POST\u00a0a \"query\" to an HTTP endpoint, instead of hitting different HTTP endpoints for different resources.</p> <p>GraphQL is designed for developers of web/mobile apps (HTTP clients) to be able to make API calls to fetch exactly the data they need from their backend APIs.</p> <p>GraphQL is a query language and server-side runtime for APIs that prioritizes giving clients\u00a0precisely the data they request and no more, unlike other API-building methods. For example, [[REST APIs|REST]] depends on endpoints, thus unable to fetch only the needed data.</p> <p></p> <p>Every GraphQL service defines a set of types that describe the possible data you can query on that service (that\u2019s the\u00a0schema). Then, when\u00a0queries and mutations\u00a0come in, they are validated and executed against that schema and processed using\u00a0resolvers.</p> <p>So a complete GraphQL implementation must have two parts:\u00a0schemas &amp; resolvers.</p> <p></p> <p>A GraphQL operation can either be</p> <ul> <li>Read\u00a0operation, known as\u00a0Query, is used to read or fetch values</li> <li>Write\u00a0operation, known as\u00a0Mutation, is used to write or delete values.</li> </ul> <p>In both cases, the operation is a simple string that a GraphQL server can parse and respond to with specifically formatted data. [[JavaScript Object Notation|JSON]] is usually the popular response format for mobile and web applications.</p>"},{"location":"misc/grpc/","title":"gRPC","text":"<p>gRPC (gRPC Remote Procedure Calls) is an open-source, high-performance RPC ([[Remote Procedure Call]]) framework initially developed by Google. </p> <p>It uses [[HTTP2|HTTP/2]] for transport, [[Protocol Buffers]] as the interface description language, and provides features like authentication, [[Load Balancer|load balancing]], and more. gRPC enables efficient communication between services in different languages by generating client and server code from .proto files. </p> <p>It's known for its efficiency in connecting services in microservices architectures, especially when low latency and high throughput are required. gRPC supports bi-directional streaming, providing advantages over traditional [[REST APIs]] in certain scenarios, particularly where real-time updates and high-performance communication are essential.</p>"},{"location":"misc/gssapi/","title":"Generic Security Services Application Programming Interface (GSSAPI)","text":"<p>The Generic Security Services Application Programming Interface (GSSAPI) is an application programming interface ([[APIs|API]]) that provides a standardized framework for secure communication and authentication in networked and distributed systems. </p> <p>GSSAPI is designed to enable secure interactions between applications and services across heterogeneous computing environments, ensuring that authentication and data protection are consistent and interoperable.</p> <p>GSSAPI provides a set of functions and mechanisms for applications to establish and verify the identity of communicating parties. This includes the negotiation of authentication methods, the exchange of security tokens, and the establishment of secure communication channels.</p> <p>GSSAPI supports a wide range of authentication mechanisms, allowing applications to choose the most appropriate one for their specific requirements. Common mechanisms include [[Kerberos Authentication|Kerberos]], [[NTLM]], [[Simple and Protected GSSAPI Negotiation Mechanism|SPNEGO]], and more.</p> <p>GSSAPI creates a security context between communicating parties, allowing them to exchange data securely. The security context encompasses authentication information, cryptographic keys, and other security parameters. GSSAPI is designed to be platform-independent and vendor-neutral. It enables applications running on different operating systems and platforms to communicate securely, making it a valuable tool for cross-platform compatibility.</p> <p>GSSAPI can be used to encrypt and protect data transmitted between applications, ensuring the confidentiality and integrity of the information being exchanged. GSSAPI can be used to implement [[Single Sign-On (SSO)|Single Sign-On]] solutions, allowing users to log in once and access multiple services or applications without re-entering their credentials.</p> <p>GSSAPI is typically available in multiple programming languages, including [[C]], [[C++]], [[Java]], and others, making it accessible for a wide range of application development. GSSAPI operates by exchanging security tokens between parties. These tokens are used to prove the identity of the communicating parties and establish trust.</p> <p>GSSAPI is based on industry standards and specifications, ensuring that implementations from different vendors can interoperate seamlessly. GSSAPI is commonly used in networked and distributed applications, including email clients, web browsers, [[secure shell]] (SSH) clients and servers, and various server-client interactions requiring secure authentication and data protection.</p>"},{"location":"misc/gw/","title":"Google Workspace","text":"<p>Google Workspace, formerly known as G Suite, is a cloud-based productivity and collaboration suite offered by Google. It provides a comprehensive set of applications and tools designed to help organizations, businesses, and individuals work more efficiently, communicate effectively, and collaborate seamlessly. Google Workspace includes a wide range of productivity and communication tools that are hosted in the cloud and accessible from various devices with an internet connection.</p> <p>Google Workspace offers Gmail for professional email communication, providing a custom email address using the organization's domain name. It includes features like spam filtering, labels, and powerful search capabilities.</p> <p>Google Drive is a cloud storage and file-sharing service that allows users to store documents, photos, videos, and other files. It includes Google Docs, Google Sheets, Google Slides, and Google Forms for creating and collaborating on documents, spreadsheets, presentations, and surveys.</p> <p>Google Calendar enables users to schedule appointments, meetings, and events. It supports sharing and collaboration, as well as integration with other Google Workspace applications. Google Meet is a video conferencing and online meeting platform that allows users to hold virtual meetings, webinars, and video conferences with colleagues and clients. It offers features like screen sharing and real-time captions.</p> <p>Google Chat is a messaging and collaboration platform that supports direct messaging, group chats, and threaded conversations. It integrates with other Google Workspace apps for seamless communication. Google Contacts helps users manage their contact lists, sync contacts across devices, and access contact information easily.</p> <p>Google Forms is a tool for creating surveys, questionnaires, and feedback forms. Responses can be collected and analyzed in Google Sheets. Google Sites allows users to create and customize websites for various purposes, such as team collaboration, project management, or information sharing.</p> <p>Google Vault is an archiving and eDiscovery solution that helps organizations retain, search, and export email and chat data for compliance and legal purposes. The Google Workspace Admin Console provides IT administrators with centralized control over user accounts, settings, security policies, and access controls.</p> <p>Google Workspace includes security features like [[Multi-Factor Authentication (MFA)|two-factor authentication (2FA)]], data loss prevention (DLP), and encryption to protect data and ensure compliance with privacy regulations.</p> <p>IT administrators can manage and secure mobile devices that access Google Workspace resources, including enforcing security policies and remote wipe capabilities.</p>"},{"location":"misc/hex/","title":"Hexadecimal","text":"<p>Hexadecimal (often shortened to \"hex\") is a base-16 number system used in mathematics and computing. It uses sixteen distinct symbols, 0-9 to represent values zero to nine, and A-F (or a-f) to represent values ten to fifteen. Each hex digit represents four binary digits (bits), which makes it a convenient way to represent binary data in a more compact and human-readable form.</p> <p>In the context of [[obfuscation]], hexadecimal encoding is used to disguise data, including code, to make it less readable and understandable to humans, thus adding a layer of complexity for anyone trying to analyze it.</p> <p>Textual data, such as strings in a script, can be encoded in hexadecimal. For example, the [[ASCII]] string \"hello\" can be represented in hex as 68 65 6c 6c 6f.</p> <p>In programming, especially in web technologies like [[JavaScript]], hexadecimal encoding can be used to hide the true purpose or logic of the code. For instance, instead of using plain strings or numbers, a developer might use their hex equivalents.</p> <p>Hexadecimal is used in character escaping where characters in strings are represented using hex values. This is commonly seen in [[URL encoding]], and the same principle can be applied to obfuscate code.</p> <p>Since hex is more compact than binary, it\u2019s often used to represent binary data in a more space-efficient manner. This can be part of a larger obfuscation strategy to make the binary data less recognizable.</p> <p>Hexadecimal encoding is usually combined with other obfuscation methods like [[Javascript minification|minification]], renaming variables, string concatenation, and encoding with other bases (like base64) to increase the obfuscation level.</p>"},{"location":"misc/hib/","title":"Hibernate","text":"<p>Hibernate is an open-source [[Object-Relational Mapping|Object-Relational Mapping (ORM)]] tool for [[Java]]. It provides a framework for mapping an object-oriented domain model to a traditional relational database, simplifying the development process by handling database interactions and abstracting the complexity of database operations.</p> <p>As an ORM tool, Hibernate maps Java classes to database tables and Java data types to [[Structured Query Language|SQL]] data types. This allows developers to work with objects in their Java code rather than dealing with SQL queries directly.</p> <p>Hibernate simplifies [[CRUD API|CRUD]] (Create, Read, Update, Delete) operations, as developers can perform these operations on objects without writing complex SQL queries. Hibernate provides its own query language known as [[HQL (Hibernate Query Language)]], which is object-oriented and similar to SQL. HQL allows writing database-independent queries, which Hibernate translates into SQL.</p> <p>Hibernate comes with an internal caching mechanism that can be configured to improve application performance by reducing the number of queries made to the database. It offers a powerful transaction management system, simplifying complex transaction operations and ensuring data integrity.</p> <p>Hibernate is database-independent. It can work with different databases like [[MySQL (KB)|MySQL]], [[Oracle Database|Oracle]], [[PostgreSQL]], and more, making it easier to switch databases if needed. Mapping entities to database tables can be done via annotations in the Java code or using [[Extensible Markup Language|XML]] configuration files.</p> <p>Hibernate supports lazy loading, meaning it fetches data only when it is needed, which can be a significant performance enhancement. It can be used in any Java environment, from standalone applications to [[Java Enterprise Edition (Java EE)|Java EE]] frameworks like [[Spring Framework|Spring]].</p> <p>Hibernate handles session management, providing an interface between the Java application and the database. With a large community of users and contributors, Hibernate is continually updated and maintained, and there's a wealth of resources and support available.</p>"},{"location":"misc/hmi/","title":"Human-Machine Interface (HMI)","text":"<p>Human-Machine Interface (HMI) refers to a user interface or dashboard that connects a person to a machine, system, or device. In industrial contexts, HMIs are crucial for interacting with and controlling complex machinery and processes in manufacturing plants, utility systems, and other industrial environments. They provide a graphical overview of the operational processes and allow operators to control and monitor these processes.</p> <p>Human-Machine Interfaces (HMIs) are integral components of various [[industrial control systems (ICS)]], including [[Distributed Control Systems (DCS)]], [[Programmable Logic Controllers (PLC)|Programmable Logic Controllers (PLCs)]], [[Remote Terminal Units (RTUs)]], and [[Supervisory Control and Data Acquisition (SCADA)]] systems. HMIs serve as the primary interface between human operators and these complex control systems. </p> <p>HMIs typically include a graphical display that shows real-time data, system statuses, and control options. This interface can range from basic text and numeric readouts to complex graphical representations of the system.</p> <p>HMIs allow operators to control the machinery or process system directly. This might include starting or stopping processes, adjusting settings, or manually overriding automatic controls. They often provide visualizations of the operational process, such as charts, graphs, and schematics, helping operators understand complex processes at a glance. </p> <p>HMIs can display alarms and notifications about system status, operational issues, or safety warnings, prompting timely human intervention when necessary. Modern HMIs are designed for ease of use, often featuring touch screens, intuitive interfaces, and customization options to suit different user preferences and requirements.</p> <p>In [[Supervisory Control and Data Acquisition (SCADA)|SCADA (Supervisory Control and Data Acquisition)]] systems, the HMI is the central component through which operators interact with the system, monitoring processes and making adjustments as needed.</p> <p>The effectiveness of an HMI greatly depends on its design and how well it meets the needs of its users. A well-designed HMI improves operational efficiency, reduces errors, and enhances safety. With the increasing connectivity of HMIs, especially in critical infrastructure, security is a major concern. HMIs need to be protected against unauthorized access and cyber threats.</p>"},{"location":"misc/hosts/","title":"Hosts","text":"<p>The hosts file is a simple text file used by the OS to map [[Hostname|hostnames]] to an [[IP Address]]. Before a device reaches out to the Internet to find the IP address of a website, it first checks the hosts file to see if there is an entry for that hostname.</p> <p>You can manually add entries to the hosts file. Each entry must contain an IP address and the corresponding hostname. An example entry is as follows:</p> <pre><code>127.0.0.1 login.fakedomain.com\n</code></pre> <p>Above, any request for login.fakedomain.com will be sent to 127.0.0.1 instead of looking it up via DNS. It's often used in local network environments, for testing websites, or for blocking access to websites.</p> <p>It is also often used in hacking to specify a manual entry for a website or subdomain that may not be accessible over the Internet, and therefore has no entry in a [[DNS]] server.</p>"},{"location":"misc/hpack/","title":"HPACK","text":"<p>HPACK is a header compression format used in [[HTTP2|HTTP/2]] for reducing the size of headers. It's designed to minimize both the size of each individual header and the overall size of header sets, addressing redundancy across multiple requests. </p> <p>HPACK works by employing a static table of common [[HTTP headers]] (which both client and server know) and a dynamic table (which gets built during the session). This approach reduces the need to send repeated header frames. </p> <p>The format also includes [[Huffman Coding]] for compressing header values. The combination of these techniques makes HPACK effective in reducing overhead, which is particularly beneficial for mobile environments and applications where network efficiency is crucial.</p>"},{"location":"misc/hql/","title":"HQL (Hibernate Query Language)","text":"<p>HQL, or Hibernate Query Language, is an object-oriented query language used by [[Hibernate]], a popular [[Object-Relational Mapping]] (ORM) framework in [[Java]]. HQL is similar to SQL ([[Structured Query Language]]) but operates on the domain model (objects) rather than directly on the database tables.</p> <p>HQL queries are written against the Hibernate entity objects and their properties, not against the database tables and columns. This aligns with object-oriented programming principles. Since HQL operates at the object level, it abstracts the underlying database specifics. Hibernate translates HQL queries into the appropriate SQL queries for the underlying database, providing database independence.</p> <p>The syntax of HQL is quite similar to SQL, making it familiar and easy to learn for developers who are already acquainted with SQL. HQL seamlessly handles relationships (like one-to-many, many-to-many) defined in the Hibernate domain model, allowing for easy querying across related entities.</p> <p>HQL supports a wide range of SQL-like operations, including joins, where clauses, group by, having, etc., along with Hibernate-specific features like fetching strategies and pagination. HQL supports parameter binding, which helps in preventing SQL injection attacks and makes the queries more dynamic.</p> <p>HQL works well with other features of Hibernate, such as caching, lazy loading, and transaction management. It can be used not only to retrieve complete entity objects but also to select individual attributes or a subset of an entity's attributes. Besides querying, HQL also supports [[Direct Manipulation Language (DML)]] style operations such as insert, update, and delete.</p> <p>HQL is commonly used in Java applications that utilize Hibernate for ORM, simplifying the task of writing complex queries involving objects and their relationships.</p>"},{"location":"misc/huff/","title":"Huffman Coding","text":"<p>Huffman coding is a widely used method of lossless data compression, developed by David A. Huffman. It's based on the frequency of occurrence of a data item (like a character in a file). The process involves creating a binary tree where each leaf node represents a data item, and the path from the root to the leaf represents the binary code of the item. </p> <p>Items that occur more frequently are given shorter codes, while less frequent items receive longer codes. This variable-length coding leads to a reduction in the overall size of the data. Huffman coding is efficient and optimal for a given set of probabilities, making it a common technique in compression algorithms like those used in ZIP files and JPEG image compression.</p> <p>Huffman coding is used in various applications for efficient data compression. Its most notable uses include:</p> <ol> <li>File Compression: In file compression algorithms like those in ZIP and RAR formats.</li> <li>Multimedia: Widely used in JPEG image compression and MP3 audio compression.</li> <li>Transmission: Huffman coding is employed in data transmission to reduce the amount of data sent.</li> <li>Error Correction Codes: It's used in creating more efficient error correction codes.</li> </ol>"},{"location":"misc/hvmanager/","title":"Hyper-V Manager","text":"<p>Hyper-V Manager is a management tool provided by Microsoft that allows administrators and users to create, manage, and operate [[virtual machines]] (VMs) on a [[Hyper-V]] host. It is a part of the Hyper-V role in Windows Server, and it's also available on Windows 10 and Windows 11 for desktop virtualization. Hyper-V Manager provides a graphical user interface (GUI) to interact with and manage Hyper-V environments.</p> <p>Hyper-V Manager enables the creation, configuration, and management of virtual machines. Users can set up various aspects of a VM, such as the amount of memory, number of processors, and storage options.</p> <p>It allows for the configuration and management of virtual networks that VMs can use to communicate with each other and with the outside network. Hyper-V Manager provides the capability to take snapshots (known as checkpoints in later versions) of VMs, allowing users to save the current state of a VM and revert back to it if needed.</p> <p>It offers basic performance monitoring tools to track the resource usage of VMs, such as CPU usage, memory usage, and network statistics. Users can import and export VMs, which is useful for moving VMs between different hosts or for backup and recovery purposes. It allows the addition of virtual hardware to VMs, like network adapters and virtual disks.</p> <p>Running Hyper-V requires a 64-bit processor with Second Level Address Translation (SLAT), VM Monitor Mode extensions, and hardware-assisted virtualization. For more complex or large-scale virtualization environments, Microsoft also offers [[System Center Virtual Machine Manager]] (SCVMM), which provides more advanced features.</p>"},{"location":"misc/hyperv/","title":"Hyper-V","text":"<p>Hyper-V is a virtualization platform developed by Microsoft. It allows users to create and manage [[Virtual Machines|virtual machines]] (VMs) on a Windows-based system. Originally released alongside Windows Server 2008, it's also available on Windows 10 and later versions, enabling both server and desktop users to utilize virtualization technologies.</p> <p>Hyper-V uses hardware virtualization to efficiently run multiple operating systems as VMs on a single physical server or computer. It supports various guest operating systems, including Windows, Linux, and others, allowing them to run concurrently on a single hardware platform. Each VM operates in isolation with its own resources (CPU, memory, storage, and networking), which can be adjusted based on workload requirements.</p> <p>Hyper-V provides the capability to take snapshots of VMs, allowing users to easily save the current state of a VM and revert back to it if needed. In a server environment, Hyper-V supports live migration of VMs from one host to another without downtime, enabling flexibility and improving fault tolerance.</p> <p>Hyper-V is tightly integrated with other Microsoft products and services, such as [[Azure]] for cloud-based scenarios, System Center for management, and Windows Admin Center. Hyper-V is designed to scale from small environments (like a local development setup) to large data centers, offering robust performance features.</p> <p>Hyper-V requires a 64-bit processor with Second Level Address Translation (SLAT). It also requires VM Monitor Mode extensions and hardware-assisted virtualization. Hyper-V can be managed using various tools, including [[Hyper-V Manager]] (a graphical tool), [[Windows PowerShell]] (for scripting), or [[System Center Virtual Machine Manager]] (for larger deployments).</p>"},{"location":"misc/ics/","title":"Industrial Control Systems (ICS)","text":"<p>Industrial Control Systems (ICS) are systems used to control industrial processes such as manufacturing, product handling, power generation, fabrication, and refining. They are designed to operate and manage machinery and processes in industrial settings, ensuring efficiency, reliability, and safety. </p> <p>ICS encompasses various types of control systems, including [[Supervisory Control and Data Acquisition (SCADA)]] systems, [[Distributed Control Systems (DCS)]], and [[Programmable Logic Controllers (PLC)]].</p> <p>Supervisory Control and Data Acquisition (SCADA) systems are used to monitor and control industrial, infrastructure, or facility-based processes. For example, a SCADA system might be used to monitor and regulate the water flow in a municipal water supply system, overseeing the various pumps and valves in the system, and ensuring the proper distribution of water.</p> <p>DCS are used in manufacturing processes that are continuous or batch-oriented. An example of DCS is in a chemical plant where the production process needs precise control and coordination across various parts of the plant.</p> <p>PLCs are used for the automation of industrial electromechanical processes. For instance, a PLC might be used in a car manufacturing plant to control the robotic arms used in the assembly line.</p> <p>ICS automate industrial processes, increasing efficiency and consistency in production. They enable real-time monitoring and control of industrial environments, improving the safety, performance, and reliability of these systems. ICS systems gather critical data from industrial environments, aiding in decision-making and process optimization.</p> <p>With the increasing connectivity of ICS to the internet and other networks for remote monitoring and control (part of the broader trend towards the [[Industrial IoT (IIoT)|Industrial Internet of Things]] or IIoT), these systems have become more vulnerable to cyberattacks. Such attacks can disrupt industrial operations, cause physical damage, or lead to safety hazards.</p> <p>Ensuring the cybersecurity of ICS is a growing concern and requires specialized knowledge of both cybersecurity and industrial processes.</p>"},{"location":"misc/iwa/","title":"Integrated Windows Authentication (IWA)","text":"<p>Integrated Windows Authentication (IWA) is a term used for a set of authentication protocols built into Microsoft Windows operating systems. It enables users to log in with their Windows credentials and gain access to network resources without being prompted to enter their credentials again. </p> <p>IWA uses the credentials of the user's current logon session to transparently authenticate the user to a network service or resource.</p> <p>IWA provides [[Single Sign-On (SSO)|SSO]] capabilities, allowing users to access multiple services or applications within a Windows domain without needing to repeatedly enter their login credentials. IWA primarily uses the [[Kerberos authentication]] protocol for security but can fall back to [[NTLM]] (NT LAN Manager) in environments where Kerberos cannot be used.</p> <p>By default, IWA encrypts the user's credentials and does not send them in plaintext across the network, reducing the risk of credential theft. IWA automatically authenticates users who are logged into a Windows domain when they access network resources, such as file shares or web applications, that support IWA.</p> <p>A common example is an employee accessing an internal company web portal. When the employee, who is logged into their Windows domain account, opens the portal in a browser, IWA automatically authenticates their identity with the web server using their current session's credentials. The employee gains access to the portal without having to enter their username and password again.</p>"},{"location":"misc/jack/","title":"Jackson","text":"<p>Jackson is a popular and highly efficient [[Java]] library used for serializing Java objects to JSON ([[Jackson]]) and deserializing JSON back into Java objects. It is widely used in Java applications for processing JSON data due to its performance, flexibility, and ease of use.</p> <p>Jackson excels at converting Java objects to JSON and vice versa, making it a go-to choice for Java applications that need to work with JSON, such as [[REST APIs|RESTful]] web services. </p> <p>While default serialization and deserialization often work out-of-the-box, Jackson allows for extensive customization via annotations. These annotations can be used to include, exclude, and alter the properties of Java objects being serialized.</p> <p>Jackson's Data Binding API provides a high-level facade over its streaming API, simplifying the task of converting between JSON and Java objects. Jackson provides a tree model for representing JSON as node trees. This is similar to [[Document Object Model|DOM]] for XML and is useful for flexible processing of JSON data.</p> <p>For high-performance applications, Jackson offers a streaming API that reads and writes JSON with minimal overhead. Although primarily known for JSON, Jackson can also handle other data formats such as XML, CSV, YAML, and more through various extensions.</p> <p>Jackson integrates seamlessly with many Java web frameworks like [[Spring Framework|Spring]], [[Dropwizard]], and [[RESTEasy]], making it a default choice for building RESTful web services in Java. It allows the creation of custom serializers and deserializers for complex data types that might need special handling.</p> <p>Jackson's widespread adoption and active development mean a wealth of documentation, tutorials, and community support is available. Jackson has a modular structure, allowing developers to use only parts they need, which helps in keeping the application lightweight.</p>"},{"location":"misc/jad/","title":"Java Application Descriptor (JAD)","text":"<p>The Java Application Descriptor (JAD) file is a text file commonly used in conjunction with [[Java ME (Micro Edition)]] applications, particularly MIDlets, which are Java programs designed to run on mobile devices. JAD files are used to describe the properties and attributes of a Java ME application or MIDlet suite.</p> <p>The JAD file contains information about the MIDlet suite, which is a collection of MIDlets packaged together. This information includes details about the MIDlet suite's configuration and its requirements.</p> <p>JAD files include metadata such as the name of the MIDlet suite, the vendor, version, size, and a description. They also contain configuration data, such as which MIDlets are included in the suite and their specific properties. The JAD file is used by the device or application store to determine how to install the MIDlet suite. It includes URLs pointing to the [[Java Archive (JAR)|JAR]] file (where the actual application bytecode resides) and other information necessary for downloading and installing the application.</p> <p>Common attributes in a JAD file include <code>MIDlet-Name</code>, <code>MIDlet-Version</code>, <code>MIDlet-Vendor</code>, <code>MIDlet-Jar-URL</code>, <code>MIDlet-Jar-Size</code>, and specific configuration properties for each MIDlet in the suite. The format of a JAD file is simple text with key-value pairs, making it easy to create and read. Each line in the file represents a property of the MIDlet suite.</p> <p>JAD files can also specify the security and permission requirements for the MIDlet suite, indicating what actions the application is allowed to perform on the mobile device. It can include information about device compatibility and dependencies, ensuring that the MIDlet suite is only installed on compatible devices.</p> <p>With the decline of Java ME in favor of more advanced mobile platforms like Android and iOS, the usage of JAD files has significantly decreased. In the context of Java ME, JAD files were often used for distributing MIDlet suites over the air (OTA) or through application stores.</p> <p>[!info] While JAD files are largely associated with legacy mobile applications, they were an important part of mobile application deployment in the era of feature phones and early smartphones.</p>"},{"location":"misc/jak/","title":"Jakarta EE","text":"<p>Jakarta EE, formerly known as [[Java]] Platform, Enterprise Edition ([[Java Enterprise Edition (Java EE)|Java EE]]), is a set of specifications that extend the [[Java SE (Standard Edition)]] with specifications for enterprise features such as distributed computing and web services. </p> <p>Jakarta EE provides APIs for developing and running scalable, multi-tiered, reliable, and secure network applications. It's now under the stewardship of the Eclipse Foundation. In 2017, Oracle announced the transfer of Java EE to the Eclipse Foundation, and it was rebranded as Jakarta EE. This transition marked a significant shift in the governance and evolution of these enterprise Java standards.</p> <p>Jakarta EE is used for developing enterprise-level applications, which typically require a large scale, distributed, and multi-tiered architecture. It includes specifications for various enterprise functionalities like web services, database access, messaging, transactions, and more.</p> <p>With the evolution of cloud computing and microservices, Jakarta EE has adapted to include support for these modern architectural patterns. Jakarta EE applications are built on top of Java SE. It leverages Java SE features and adds additional libraries and frameworks suitable for enterprise applications.</p> <p>Under the Eclipse Foundation, Jakarta EE\u2019s development is more community-driven, with an open and collaborative approach. Some of the key technologies under Jakarta EE include Jakarta Server Pages (JSP), Jakarta Servlets, Jakarta Messaging, Jakarta RESTful Web Services, and Jakarta Faces, among others.</p> <p>Jakarta EE applications are typically deployed on compatible application servers like [[Payara]], [[WildFly]] (formerly JBoss), [[TomEE]], and others. The newer versions of Jakarta EE focus on cloud-native development practices, enhancing the capabilities of Jakarta EE for modern cloud environments.</p>"},{"location":"misc/jar/","title":"Java Archive (JAR)","text":"<p>JAR files (Java Archive files) are archive files that bundle multiple files into a single compressed package, typically used in the Java programming environment. They are built on the ZIP file format and typically have a <code>.jar</code> file extension. JAR files are widely used for distributing Java applications or libraries.</p> <p>JAR files are used to package Java classes and associated metadata and resources (like text, images, etc.) into a single file. They are commonly used for distributing [[Java]] applications and libraries.</p> <p>A JAR file can contain Java class files, Java source files, image files, and other data files. It also contains a manifest file (<code>META-INF/MANIFEST.MF</code>) that specifies metadata about the archive, such as the main class with the <code>main</code> method for executable JARs.</p> <p>JAR files can be made executable, meaning they can be run as a standalone Java application. The manifest file specifies the entry point of the application, making it possible to run the JAR file by executing <code>java -jar filename.jar</code>.</p> <p>JAR files simplify the deployment and distribution of Java applications. They bundle all necessary components in a single file, making it easier to transport and use. They support compression, which reduces the size of the application and improves download time.</p> <p>JAR files are platform-independent, meaning they can be run on any device with a [[Java Runtime Environment (JRE)]]. JAR files can be digitally signed, allowing users to authenticate the source of the JAR and ensuring the integrity of its contents.</p> <p>In Java development, libraries are often distributed as JAR files. These can be included in the classpath of other Java projects to use the library's functionality. JAR files can be created and extracted using the <code>jar</code> command-line tool provided with the [[Java Development Kit (JDK)]], or with standard ZIP tools.</p>"},{"location":"misc/javadoc/","title":"Javadoc","text":"<p>JavaDoc is a documentation generator tool for the [[Java]] programming language provided by Oracle. It is used for generating API documentation in [[HTML]] format from Java source code, based on the JavaDoc comments. These comments are specially formatted multi-line comments that precede class, method, and field declarations.</p> <p>JavaDoc provides a standard format for documenting Java classes, interfaces, methods, variables, and packages. It generates HTML documentation from the source code, making it easy to browse and read. JavaDoc uses annotations (starting with <code>/**</code> and ending with <code>*/</code>) to identify documentation comments.</p> <p>Within these comments, tags such as <code>@param</code>, <code>@return</code>, <code>@throws</code>, <code>@see</code>, and <code>@author</code> provide additional information and structure.</p> <p>It is primarily used to document the public API of a Java class. This is crucial for both internal and external developers who use or maintain the code. JavaDoc comments are placed directly in the source code, making it easier to keep the documentation up-to-date with the code. IDEs like Eclipse or IntelliJ IDEA use JavaDoc comments to provide contextual help and documentation while coding.</p> <p>An example includes:</p> <pre><code>/**\n * This class represents a simple example.\n * @author John Doe\n */\npublic class Example {\n\n    /**\n     * Adds two integers.\n     * @param a the first integer\n     * @param b the second integer\n     * @return the sum of a and b\n     */\n    public int add(int a, int b) {\n        return a + b;\n    }\n}\n</code></pre> <p>Info</p> <p>The <code>Example</code> class and its method <code>add</code> have JavaDoc comments describing their purpose, parameters, and return values.</p> <p>JavaDoc is typically run from the command line or through an IDE. The JavaDoc tool processes the source files and generates [[HTML]] files that can be hosted or distributed for reference.</p>"},{"location":"misc/jaxrs/","title":"JAX-RS (Java API for RESTful Web Services)","text":"<p>JAX-RS, short for Java API for RESTful Web Services, is a [[Java]] programming language API spec that provides support in creating web services according to the Representational State Transfer ([[REST APIs|REST]]) architectural pattern. </p> <p>It is part of the [[Java Enterprise Edition (Java EE)]] platform and has been included as a standard for building RESTful web services in Java. JAX-RS uses annotations to simplify the development and deployment of web service clients and endpoints. </p> <p>JAX-RS is specifically designed for creating and consuming RESTful web services. REST is an architectural style that uses [[HTTP protocol]] for data communication, emphasizing scalability, stateless communication, and the use of standard HTTP methods like GET, POST, PUT, DELETE, etc.</p> <p>JAX-RS uses Java annotations to map HTTP requests to Java methods, define query and path parameters, and control response formats. This simplifies the process of developing RESTful web services. In JAX-RS, a web resource is a Java class annotated with <code>@Path</code> and contains methods annotated with HTTP verbs representing the resource's operations.</p> <p>Annotations such as <code>@GET</code>, <code>@POST</code>, <code>@PUT</code>, and <code>@DELETE</code> are used to specify the corresponding HTTP methods on Java methods. JAX-RS supports various data formats for request and response payloads, including XML, JSON, and plain text, through the use of annotations like <code>@Produces</code> and <code>@Consumes</code>.</p> <p>Annotations like <code>@PathParam</code>, <code>@QueryParam</code>, <code>@HeaderParam</code>, and <code>@FormParam</code> allow methods to accept different types of parameters from HTTP requests. JAX-RS also provides a client API for interacting with RESTful web services, allowing for the development of HTTP clients in a standardized way.</p> <p>JAX-RS allows developers to use and create providers that can add additional behavior to the service, such as message body readers and writers, exception mappers, and filters. JAX-RS can be integrated with other Java EE technologies like [[Enterprise JavaBeans (EJBs)|EJBs]], [[Java Persistence API (JPA)|JPA]], [[CDI]], and [[JSON-P]].</p> <p>Popular implementations of JAX-RS include [[Jersey]] (the reference implementation), [[RESTEasy]], and [[Apache CXF]].</p>"},{"location":"misc/jaxws/","title":"JAX-WS (for SOAP Web Services)","text":"<p>Java API for XML-Based Web Services (JAX-WS) is a set of APIs for building web services in [[Java]] using XML. It is part of the [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]] platform and provides a standard way to develop [[SOAP]] (Simple Object Access Protocol) web services.</p> <p>JAX-WS uses annotations to simplify the development of web services. Annotations are used to define the web service, its operations, and other aspects of the service. This reduces the amount of boilerplate code that developers need to write.</p> <p>JAX-WS relies on [[WSDL]] for describing the contract of the web service. WSDL is an [[Extensible Markup Language|XML]]-based language that defines the operations, input and output parameters, and communication details of a web service. JAX-WS generates WSDL automatically based on the annotated Java code.</p> <p>In JAX-WS, an endpoint is a Java class that contains methods annotated with <code>@WebMethod</code>. These methods represent the operations of the web service. The endpoint class is responsible for processing incoming requests and generating responses.</p> <p>JAX-WS provides client APIs for consuming SOAP web services. Clients can be generated dynamically or using tools like <code>wsimport</code> that generate client code based on the WSDL contract. JAX-WS supports SOAP as the messaging protocol for web services. SOAP is a protocol for exchanging structured information in web services and is based on XML.</p> <p>Handlers in JAX-WS allow developers to intercept the processing of inbound and outbound messages. Handlers can be used for tasks such as logging, security, or custom message processing. JAX-WS supports [[MTOM]] for efficient transmission of binary data in SOAP messages. MTOM allows large binary data, such as images or documents, to be transmitted as optimized binary attachments.</p> <p>JAX-WS supports asynchronous web services, allowing clients to send requests asynchronously and receive responses at a later time.</p> <p>A simple example of a JAX-WS annotated endpoint:</p> <pre><code>import javax.jws.WebMethod;\nimport javax.jws.WebService;\n\n@WebService\npublic class MyWebService {\n\n    @WebMethod\n    public String sayHello(String name) {\n        return \"Hello, \" + name + \"!\";\n    }\n}\n</code></pre> <p>The <code>MyWebService</code> class is a JAX-WS endpoint with a single method (<code>sayHello</code>) that is exposed as a web service operation. The <code>@WebService</code> and <code>@WebMethod</code> annotations define the web service and its operations.</p>"},{"location":"misc/jboss/","title":"JBoss Application Server","text":"<p>The JBoss Application Server (JBoss AS) is an open-source, [[Java]]-based application server developed by the JBoss community, now a division of Red Hat. JBoss AS is part of the larger JBoss Enterprise Middleware suite, providing a platform for deploying and managing [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]] applications.</p> <p>JBoss AS supports the Java EE specifications, providing a runtime environment for deploying enterprise-level Java applications. It includes implementations of various Java EE APIs, such as [[Java Servlets|servlets]], [[JSP]] (JavaServer Pages), [[Enterprise JavaBeans (EJBs)|EJB (Enterprise JavaBeans)]], [[Java Messaging Service (JMS)|JMS (Java Message Service)]], [[Java Transaction API (JTA)|JTA (Java Transaction API)]], and more.</p> <p>JBoss AS is known for its modular architecture. It uses a microkernel-based structure where services are deployed as independent modules. This modularity enhances flexibility, scalability, and ease of management. Depending on the version, JBoss AS is compatible with Java EE 6 or Java EE 7 specifications, offering support for the latest enterprise technologies and APIs.</p> <p>JBoss AS includes features essential for enterprise applications, such as clustering, high availability, load balancing, and distributed computing. These features contribute to the scalability and reliability of applications. JBoss AS provides a web-based administration console for managing and monitoring the application server. Administrators can use the console to deploy applications, configure server settings, and monitor performance.</p> <p>JBoss AS is designed to be developer-friendly, providing tools and features to simplify the development, testing, and debugging of Java EE applications. It supports hot deployment, allowing developers to make changes to their applications without restarting the server.</p> <p>JBoss AS has a large and active community of developers and users. Additionally, Red Hat offers commercial support for JBoss AS through its [[JBoss EAP (Enterprise Application Platform)]] product, which is a commercially supported and certified version of JBoss AS.</p> <p>JBoss AS is often used as part of a larger middleware stack, integrating with other Red Hat middleware products. This includes integration with [[JBoss ESB (Enterprise Service Bus)]], [[JBoss BPM (Business Process Management)]], and more.</p> <p>In later versions, the JBoss AS project evolved into [[WildFly]]. WildFly continues the tradition of providing a lightweight, modular, and fast Java EE application server. It is the community version, while JBoss EAP is the supported and certified version for enterprise use.</p>"},{"location":"misc/jbpm/","title":"JBoss BPM (Business Process Management)","text":"<p>JBoss BPM (Business Process Management) is a suite of business process management tools and technologies provided by Red Hat, specifically tailored for designing, executing, and monitoring business processes. JBoss BPM is part of the larger JBoss middleware portfolio and is designed to help organizations streamline their business operations and improve efficiency.</p> <p>JBoss BPM supports the BPMN (Business Process Model and Notation) 2.0 standard, which is a widely accepted standard for modeling business processes. BPMN provides a graphical notation for expressing business processes in a standardized and understandable way.</p> <p>JBoss BPM integrates with business rules engines, allowing organizations to define and manage business rules separately from the process logic. This integration ensures that business rules can be easily modified and updated without affecting the underlying processes.</p> <p>JBoss BPM includes a web-based process designer that enables business analysts and process stakeholders to visually model and design business processes. The designer supports drag-and-drop functionality for creating process diagrams using BPMN elements. The BPM suite includes a process execution engine that is capable of executing business processes based on the defined models. It manages the lifecycle of processes, including process instantiation, task assignment, and process completion.</p> <p>JBoss BPM provides capabilities for managing human tasks within business processes. This includes task assignment, notification, and tracking of tasks performed by human participants. Users can interact with tasks through a web-based user interface. JBoss BPM can be integrated with [[JBoss ESB (Enterprise Service Bus)]], allowing seamless communication and coordination between business processes and services in the enterprise.</p> <p>JBoss BPM supports flexible deployment options, allowing organizations to deploy their processes on-premises, in the cloud, or in a hybrid environment. This flexibility accommodates different organizational needs and IT infrastructures. The BPM suite includes tools for monitoring and analyzing the performance of business processes. Organizations can gain insights into process execution, identify bottlenecks, and make informed decisions for process optimization.</p> <p>JBoss BPM also supports DMN, a standard for decision modeling. This allows organizations to model and manage business decisions separately from the process, improving agility and maintainability.</p>"},{"location":"misc/jcp/","title":"Java Community Process (JCP)","text":"<p>The Java Community Process (JCP), established by Sun Microsystems in 1998, is the mechanism for developing standard technical specifications for [[Java]] technology. It is a formalized process that allows interested parties to contribute to the definition and evolution of Java specifications. </p> <p>The JCP involves the use of Java Specification Requests (JSRs) - the formal documents that describe proposed specifications and technologies to be added to the Java platform.</p> <p>The JCP is open to anyone interested in Java development, including individual developers, organizations, and companies. Participants can contribute by reviewing and providing feedback on JSRs, or by becoming a JCP member to submit and lead JSRs.</p> <p>A JSR is a formal document that describes a proposed specification or technology addition to the Java platform. Each JSR goes through several stages, including submission, review, and final approval or rejection. The process encourages community involvement and transparency, allowing the Java community to have a say in how the Java platform evolves.</p> <p>Each JSR has an Expert Group (EG) responsible for its content. The EG includes members from various backgrounds like Java developers, architects, and engineers, contributing their expertise and insights. JSRs are subject to public review, allowing anyone in the community to provide feedback and suggestions. This feedback is considered crucial for the development of robust and widely-accepted specifications.</p> <p>After passing through various review stages, a JSR goes to a Final Approval Ballot, where JCP members vote on whether to approve the JSR as a new standard or technology for Java. The JCP has been instrumental in the evolution of Java, ensuring that it remains a relevant and up-to-date technology. </p> <p>It has overseen numerous enhancements, including major releases of [[Java SE (Standard Edition)]], [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]], and [[Java ME (Micro Edition)]].</p>"},{"location":"misc/jdbc/","title":"JDBC","text":"<p>Java Database Connectivity (JDBC) is an [[APIs|API]] provided by [[Java]] that defines how a client may access a database. It provides methods for querying and updating data in a database and is oriented towards [[Relational Database|relational databases]]. JDBC plays a crucial role in Java applications that need to interact with databases for storing and retrieving data.</p> <p>JDBC allows Java applications to interact with relational databases by sending [[Structured Query Language|SQL]] queries and receiving results. It's a key technology in Java for database operations. JDBC uses JDBC drivers to connect with database servers. These drivers are typically provided by database vendors and are specific to a database. The JDBC DriverManager class manages these drivers.</p> <p>The <code>Connection</code> interface in JDBC is used for establishing a connection with the database. It includes methods for handling transactions like <code>commit</code>, <code>rollback</code>, and closing the connection. JDBC provides interfaces for creating and executing SQL statements. <code>Statement</code> is used for simple SQL queries, <code>PreparedStatement</code> for precompiled SQL queries, and <code>CallableStatement</code> for stored procedures.</p> <p>The <code>ResultSet</code> interface represents the result set of a query. It's used to navigate and read the data returned by a query. JDBC supports batch processing of SQL commands and transaction management to ensure data integrity.</p> <p>JDBC supports various data types used in SQL, mapping these to Java data types. JDBC provides a database-independent connectivity platform. This means the same code can generally be used with different databases with minimal changes, typically only changing the driver and connection details.</p> <p>Some frameworks and libraries extend JDBC functionality, simplifying database interaction and providing features like connection pooling, better transaction management, and data access abstractions.</p> <p>JDBC is widely used in enterprise applications, web applications, and standalone Java applications where interaction with relational databases is required.</p>"},{"location":"misc/jdbi/","title":"JDBI","text":"<p>JDBI (Java Database Connectivity Interface) is a [[Java]] library that provides a convenient, idiomatic approach to handle [[Structured Query Language|SQL]] databases in Java. It's designed to simplify database access by providing a more natural Java API for handling [[JDBC]] (Java Database Connectivity). </p> <p>JDBI streamlines the process of connecting to a database, executing SQL queries, and mapping results to Java objects. JDBI aims to offer a simpler alternative to traditional JDBC by reducing the boilerplate code required for database operations, making it more efficient and readable.</p> <p>One of the key features of JDBI is its SQL Object API, which allows developers to use annotations to define SQL queries and operations in interfaces, providing a declarative style of programming.</p> <p>JDBI makes it easy to map the results of SQL queries to Java objects. It can automatically handle the conversion of database rows to Java objects, reducing the manual effort required in JDBC. </p> <p>Alongside the SQL Object API, JDBI also offers a Fluent API that allows for building and executing SQL queries in a more dynamic and fluid manner. JDBI can be integrated with popular Java frameworks and libraries, making it a flexible choice for database operations in Java applications.</p> <p>It provides straightforward transaction management, making it easier to handle complex transaction scenarios with less risk of errors. JDBI supports customization and extension, allowing developers to plug in custom mappers, handlers, and other components as needed. JDBI supports a variety of SQL operations including queries, updates, batch operations, and more.</p> <p>It's designed to work easily with existing databases without the need to change the database schema or write a lot of additional code.</p>"},{"location":"misc/jdk/","title":"Java Development Kit (JDK)","text":"<p>The Java Development Kit (JDK) is a software development environment used for developing [[Java]] applications and applets. It is the essential toolkit for any Java developer and includes a complete set of tools and libraries necessary for Java development.</p> <ol> <li>Components of JDK:<ul> <li>Java Compiler (<code>javac</code>): Converts Java source code into bytecode.</li> <li>Java Virtual Machine (JVM): Executes the compiled Java bytecode. While the JVM is part of the Java Runtime Environment (JRE), it's also included in the JDK for testing purposes.</li> <li>Java Runtime Environment (JRE): Provides libraries, Java Virtual Machine (JVM), and other components to run applications written in Java.</li> <li>Archiver (<code>jar</code>): Packages related class libraries into a single JAR file.</li> <li>Documentation Generator (<code>javadoc</code>): Creates HTML format documentation from Java source code.</li> <li>Debugger (<code>jdb</code>): A tool for debugging Java code.</li> </ul> </li> </ol> <p>The JDK allows developers to create Java applications, which can then be executed by the JRE. It's essential for compiling, debugging, and testing Java applications. The JDK includes a set of standard class libraries that provide the core Java [[APIs]] (Application Programming Interfaces), including I/O, networking, GUI components, and data access.</p> <p>Java is known for its \"write once, run anywhere\" (WORA) capability. Java applications compiled on one platform can run on any platform that has a compatible JVM. The JDK has several versions, each offering different features. With each release, new features are introduced, and older ones may be deprecated.</p> <p>It is used by Java developers in various domains, from desktop application development to web and enterprise application development. The JDK is available as an open-source Oracle JDK and also in alternative distributions like OpenJDK, Amazon Corretto, AdoptOpenJDK, and others.</p>"},{"location":"misc/jdo/","title":"JDO","text":"<p>Java Data Objects (JDO) is an open standard developed by the [[Java Community Process (JCP)]] for persisting [[Java]] objects in a transactional data store. JDO provides a transparent persistence layer, which means that developers can focus on the business logic of their application without needing to deal with the underlying database specifics. </p> <p>This abstraction allows for the storage and retrieval of Java objects to and from various types of data stores, including relational databases, [[Non-relational Database|NoSQL]] databases, and file systems.</p> <p>JDO can be used as an ORM tool to map Java objects to relational database tables, similar to other ORM frameworks like [[Hibernate]] or [[Java Persistence API (JPA)|JPA]] (Java Persistence API). Unlike some ORM frameworks that are primarily focused on relational databases, JDO is designed to be datastore agnostic. It can work with various types of data stores, not limited to [[Structured Query Language|SQL]] databases.</p> <p>One of the key features of JDO is transparent persistence. This means that the Java objects don't need to be altered to be persisted. JDO handles the mapping to the data store without requiring specific persistence-related code in the domain objects. JDO includes its own query language ([[JDOQL]]), which allows for querying the data store using a syntax that is closely aligned with Java.</p> <p>As a standard (JCP), JDO provides a vendor-neutral approach to persistence, potentially offering higher portability of the application across different JDO implementations. JDO manages the lifecycle of persistent objects, including states such as transient, persistent, detached, and transactional.</p> <p>JDO uses a process called enhancement (bytecode modification) for persistent classes, which can be a build-time or load-time step in the development process. Despite its capabilities, JDO's popularity has waned compared to other persistence frameworks like JPA, which have gained more traction in the Java community, largely due to their direct support in [[Java Enterprise Edition (Java EE)|Java EE]].</p>"},{"location":"misc/jdoql/","title":"JDOQL","text":"<p>JDOQL, or Java Data Objects Query Language, is the query language for [[JDO|Java Data Objects (JDO)]]. It is used for querying data stored in a database, but unlike [[Structured Query Language|SQL]], which operates on tables and columns, JDOQL works on Java classes and objects. </p> <p>JDOQL is a part of the JDO specification, which provides a standard way for [[Java]] developers to interact with various data stores using object persistence. JDOQL allows developers to write queries in a way that is consistent with Java's object-oriented paradigm. Queries are written against Java classes and their fields, not directly against database tables.</p> <p>The syntax of JDOQL is similar to Java's expression syntax, which makes it familiar and easy to understand for Java developers. Since JDOQL operates at the object level, it aligns with JDO's principle of transparent persistence, allowing developers to focus on the object model rather than the underlying database schema.</p> <p>JDOQL queries can filter and order data based on the persistent fields of a class. These fields are defined in the JDO metadata. JDOQL can navigate and query across collections and relationships defined in the object model. JDOQL supports parameterized queries, enhancing query flexibility and security by separating the query logic from the data values.</p> <p>JDOQL queries are executed by JDO's PersistenceManager, which translates them into the query language of the underlying data store, whether it\u2019s a relational database or another type of data store. JDOQL is tightly integrated with the JDO API, allowing seamless interaction between querying and other persistence operations.</p> <p>While similar in purpose to SQL, JDOQL is more object-oriented, focusing on Java classes and objects, which can make it more intuitive for Java developers but less directly related to the structure of the underlying database. JDOQL is particularly useful in applications where the data model is heavily object-oriented and there is a need to abstract away from the specifics of the underlying database system.</p>"},{"location":"misc/jeap/","title":"JBoss EAP (Enterprise Application Platform)","text":"<p>JBoss EAP (Enterprise Application Platform) is an open-source, subscription-based platform developed by Red Hat. It provides a runtime environment for building, deploying, and managing enterprise [[Java]] applications. JBoss EAP is designed to support the development and deployment of [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]] applications, and it offers a range of features to enhance the performance, scalability, and reliability of enterprise applications.</p> <p>JBoss EAP is fully compatible with Java EE specifications. It supports the development of Java EE applications, which adhere to standardized APIs and frameworks for building enterprise-level software.</p> <p>JBoss EAP serves as a web and Java EE application server, providing the necessary runtime environment for deploying Java applications. It supports [[Java Servlets|servlets]], [[JSP|JSP (JavaServer Pages)]], [[Enterprise JavaBeans (EJBs)|EJB (Enterprise JavaBeans)]], [[Java Messaging Service (JMS)|JMS (Java Message Service)]], and other Java EE technologies.</p> <p>JBoss EAP features a modular architecture that allows developers to deploy applications in a modular and efficient manner. Applications can be deployed as independent modules, and the server can dynamically load and unload modules as needed. JBoss EAP includes features for achieving high availability and scalability. It supports clustering, allowing multiple instances of the application server to work together to distribute the workload and provide fault tolerance.</p> <p>JBoss EAP provides a web-based management console that allows administrators to configure, monitor, and manage the application server. This console simplifies the administration tasks related to deployment, resource configuration, and monitoring. The platform includes robust security features to protect applications and data. This includes support for authentication, authorization, role-based access control, and integration with enterprise security solutions.</p> <p>JBoss EAP is part of the Red Hat Middleware portfolio, and it integrates with other Red Hat middleware products. This integration allows organizations to build comprehensive and integrated solutions using Red Hat technologies. JBoss EAP undergoes certification for compatibility with Java EE specifications. This ensures that applications developed and deployed on the platform adhere to Java EE standards, promoting portability and interoperability.</p>"},{"location":"misc/jee/","title":"Java Enterprise Edition (Java EE)","text":"<p>Java Enterprise Edition (Java EE), formerly known as J2EE and currently known as Jakarta EE (under the Eclipse Foundation), is a set of specifications and an extended Java platform used for developing and running large-scale, multi-tiered, scalable, reliable, and secure network applications. </p> <p>Java EE extends the Java Standard Edition (Java SE) with specifications for enterprise features such as distributed computing and web services.</p> <p>Java EE provides a robust platform for enterprise-level services, including web services, component models, messaging services (JMS), and transaction management. It includes server-side technologies such as [[Java Servlets|servlets]], [[JavaServer Pages (JSP)]], and [[Enterprise JavaBeans (EJBs)]], which are essential for building enterprise applications.</p> <p>Java EE supports the creation of [[SOAP]] and [[REST APIs|RESTful]] web services, enabling applications to interact over the web. Java EE follows a component-based architecture, allowing developers to build modular applications with reusable components.</p> <p>It introduces the concept of \"containers\" which provide runtime support for Java EE components. Containers offer services like security, transaction management, and lifecycle management. Java EE includes the [[Java Persistence API (JPA)]] for database access, [[Object-Relational Mapping|object-relational mapping (ORM)]], and data persistence.</p> <p>With [[Java Messaging Service (JMS)|Java Message Service (JMS)]] and [[Java Transaction API (JTA)]], Java EE supports reliable messaging and transaction management. Java EE applications are typically deployed on application servers, such as [[WildFly]] (formerly JBoss), [[IBM WebSphere]], [[Oracle WebLogic]], [[Payara]], and [[GlassFish]].</p> <p>Contexts and Dependency Injection (CDI) in Java EE allows for loose coupling and easy integration of components. Java EE provides a robust security framework for authentication, authorization, and secure communication.</p>"},{"location":"misc/jesb/","title":"JBoss ESB (Enterprise Service Bus)","text":"<p>JBoss ESB (Enterprise Service Bus) is an open-source middleware platform developed by Red Hat. It provides an integration framework for connecting and coordinating services and applications within an enterprise environment. JBoss ESB facilitates the seamless exchange of data and messages among different systems, applications, and services.</p> <p>JBoss ESB allows organizations to integrate disparate services and applications by providing a standardized and extensible framework. This integration is essential for achieving interoperability and communication between different parts of an enterprise. The ESB includes advanced message routing capabilities, enabling the definition of routing rules and transformations for messages as they move through the system. This ensures that messages are directed to the appropriate destinations based on defined criteria.</p> <p>JBoss ESB supports data transformation and mediation between heterogeneous systems. It can handle different message formats and protocols, translating data to ensure compatibility between systems with varying requirements. JBoss ESB is designed to support [[Service-Oriented Architecture (SOA)|SOA]] principles, allowing organizations to build and expose services that can be easily discovered and consumed. This facilitates the creation of flexible and modular architectures.</p> <p>The ESB includes connectors and adapters for integrating with various systems, applications, and protocols. These adapters simplify the integration process and support connectivity to a wide range of technologies. JBoss ESB embraces an event-driven architecture, where events trigger actions or processes. This asynchronous and loosely coupled approach enhances flexibility and responsiveness in handling business events.</p> <p>The ESB provides transactional support, allowing organizations to coordinate and manage transactions across distributed systems. This ensures data consistency and reliability in complex integration scenarios. JBoss ESB includes tools for monitoring and managing the integration infrastructure. Administrators can track the flow of messages, monitor performance, and troubleshoot issues through a centralized management console.</p> <p>The ESB incorporates security features to protect data and ensure secure communication between integrated systems. This includes support for authentication, authorization, and encryption. JBoss ESB is designed to scale horizontally to handle increased workloads. It also supports high availability configurations to ensure continuous operation in mission-critical environments.</p> <p>JBoss ESB seamlessly integrates with other JBoss middleware components, such as [[JBoss Application Server]], to provide a comprehensive solution for building and deploying enterprise applications.</p>"},{"location":"misc/jetty/","title":"Jetty","text":"<p>Jetty is a widely used open-source [[Java]]-based web server and servlet container developed by the Eclipse Foundation. It provides a platform for hosting web applications and services, particularly in environments where lightweight and efficient solutions are desired. Jetty is known for its small footprint, scalability, flexibility, and ease of embedding in other applications.</p> <p>As a web server, Jetty can serve static content like [[HTML]], [[CSS]], and images. As a servlet container, it can host Java-based web applications using technologies like [[Java Servlets|servlets]] and [[JavaServer Pages (JSP)]].</p> <p>Jetty is designed to be lightweight and fast, which makes it an attractive choice for applications that require a smaller operational footprint and quick startup times. One of Jetty's standout features is its ability to be embedded into Java applications. This means Jetty can be instantiated and controlled programmatically within a Java application, making it ideal for microservices and standalone applications.</p> <p>It supports asynchronous processing, which allows it to handle a large number of concurrent requests with a relatively small number of threads. Jetty was one of the first servlet containers to support [[WebSockets]] natively for real-time communication and also supports HTTP/2. It provides robust security features, including [[SSL-TLS|SSL/TLS]] support, making it suitable for secure web applications.</p> <p>Jetty can be easily configured via [[Extensible Markup Language]] files, Java API, or command-line arguments. This flexibility makes it adaptable to various deployment scenarios. Jetty integrates well with various Java frameworks and technologies, such as [[Spring Framework|Spring]], [[OSGi]], [[JMX]], and [[JNDI]].</p> <p>Its lightweight nature and ease of embedding make Jetty a popular choice for testing web applications in development environments. Being an open-source project, Jetty has a strong community and is actively maintained, which ensures regular updates and availability of support.</p>"},{"location":"misc/jms/","title":"Java Messaging Service (JMS)","text":"<p>Java Messaging Service (JMS) is a [[Java]] API that allows applications to create, send, receive, and read messages. Designed by Sun Microsystems, JMS is a part of the Java Enterprise Edition (Java EE) and provides a standard way for Java applications to access messaging systems and perform asynchronous communication. </p> <p>It's widely used in enterprise application integration and supports various messaging patterns, primarily point-to-point and publish-subscribe models.</p> <p>JMS is used for communication between different parts of a distributed application. It allows loose coupling, reliability, and asynchronous communication between different components of the application. In this model, messages are sent to a specific queue and are consumed by one receiver. This is typically used for scenarios where a message must be processed by only one consumer.</p> <p>In the publish-subscribe model, messages are published to a topic. Multiple consumers can subscribe to the topic and receive messages. This is suitable for broadcasting information to multiple receivers.</p> <p>JMS enables asynchronous communication, which means the message sender does not need to wait for a response and can continue processing. The receiver can process the message and respond at its own pace.</p> <p>JMS is an [[APIs|API]] and requires a messaging system implementation, known as a JMS provider, to function. Examples include [[Apache ActiveMQ]], [[IBM MQ]], and [[Oracle WebLogic]] JMS. JMS supports various message types, including simple text messages, object messages (serialized Java objects), bytes messages (for byte streams), map messages (key-value pairs), and stream messages (a stream of primitive values).</p> <p>JMS provides different levels of reliability and quality of service, including guaranteed delivery, duplicate prevention, and message persistence. JMS is often used in conjunction with other Java EE technologies like [[Enterprise JavaBeans (EJBs)]], [[Java Persistence API (JPA)]], and [[Java Transaction API (JTA)]] to provide transactional support.</p> <p>JMS is commonly used in enterprise applications for scenarios like inventory management, order processing systems, and inter-service communication.</p>"},{"location":"misc/jms2/","title":"JMS","text":"<p>Java Message Service (JMS) is a [[Java]] [[APIs|API]] that allows applications to create, send, receive, and read messages. Designed by Sun Microsystems, JMS is a part of the [[Java Enterprise Edition (Java EE)]] and provides a standard way for Java applications to access messaging systems and perform asynchronous communication. It's widely used in enterprise application integration and supports various messaging patterns, primarily point-to-point and publish-subscribe models.</p> <p>JMS is used for communication between different parts of a distributed application. It allows loose coupling, reliability, and asynchronous communication between different components of the application.</p> <p>In this model, messages are sent to a specific queue and are consumed by one receiver. This is typically used for scenarios where a message must be processed by only one consumer. In the publish-subscribe model, messages are published to a topic. Multiple consumers can subscribe to the topic and receive messages. This is suitable for broadcasting information to multiple receivers.</p> <p>JMS enables asynchronous communication, which means the message sender does not need to wait for a response and can continue processing. The receiver can process the message and respond at its own pace.</p> <p>JMS is an API and requires a messaging system implementation, known as a JMS provider, to function. Examples include [[Apache ActiveMQ]], [[IBM MQ]], and [[Oracle WebLogic]] JMS. JMS supports various message types, including simple text messages, object messages (serialized Java objects), bytes messages (for byte streams), map messages (key-value pairs), and stream messages (a stream of primitive values).</p> <p>JMS provides different levels of reliability and quality of service, including guaranteed delivery, duplicate prevention, and message persistence. JMS is often used in conjunction with other Java EE technologies, like [[Enterprise JavaBeans (EJBs)]], [[Java Persistence API (JPA)]], and [[Java Transaction API (JTA)]].</p> <p>JMS is commonly used in enterprise applications for scenarios like inventory management, order processing systems, and inter-service communication. A JMS client is a Java application or component that produces and/or consumes messages.</p>"},{"location":"misc/jmx/","title":"JMX","text":"<p>JMX, which stands for Java Management Extensions, is a [[Java]] technology that provides a standard way to manage and monitor Java applications, system objects, devices, and service-oriented networks. It enables developers and administrators to instrument Java applications and services for monitoring, management, and control purposes. </p> <p>JMX defines a set of specifications, [[APIs]], and conventions for managing and monitoring Java applications in a distributed environment. </p> <p>MBeans are Java objects that expose management interfaces, attributes, and operations. They encapsulate the management aspects of a resource or application. MBeans can be registered with a management server, making their management interfaces accessible remotely. </p> <p>The MBeanServer is a central component that acts as a registry for MBeans. It provides the infrastructure for registering, locating, and managing MBeans. Multiple MBeanServers can coexist in a [[Java virtual machine (JVM)]], allowing for different management domains.</p> <p>JMX Agents are Java applications or services that act as intermediaries between managed resources (MBeans) and management tools. They host the MBeanServer and facilitate communication between the management tools and the MBeans.</p> <p>JConsole is a graphical monitoring tool provided by Java SE. It allows administrators and developers to connect to a Java application's MBeanServer and monitor its performance, memory usage, and other runtime attributes. JConsole provides a user-friendly interface for managing and monitoring Java applications.</p> <p>MXBeans are a specialized type of MBean designed for exposing read-only management attributes. They simplify the process of creating MBeans specifically for monitoring purposes. JMX supports a notification mechanism that allows MBeans to send notifications about specific events or changes in their state. This enables asynchronous communication between managed resources and management tools.</p> <p>JMX Remote enables remote management and monitoring of Java applications. It allows management tools to connect to a remote MBeanServer and interact with MBeans over a network.</p>"},{"location":"misc/jndi/","title":"JNDI","text":"<p>The Java Naming and Directory Interface (JNDI) is an Application Programming Interface ([[APIs|API]]) provided by Java for connecting a [[Java]] application to multiple naming and directory services. It is part of the Java Platform, Standard Edition (Java SE) and Java Platform, Enterprise Edition (Java EE). </p> <p>JNDI plays a crucial role in enterprise applications, where it's used for looking up data and resources, such as database connections, environment entries, and Java objects, in a way that's abstracted from the underlying implementation.</p> <p>JNDI provides a unified interface to multiple naming and directory services, allowing Java applications to access these services in a uniform way, regardless of the actual implementation of the service.</p> <p>It can be used with various directory and naming services like LDAP ([[Lightweight Directory Access Protocol]]), [[DNS]] (Domain Name System), RMI ([[Remote Method Invocation]]) registries, and more.</p> <p>In Java EE applications, JNDI is commonly used to look up resources like data sources (for database connections), [[Java Messaging Service (JMS)]] resources, [[Enterprise JavaBeans (EJBs)]], and environment variables defined in the deployment descriptor.</p> <p>JNDI has a pluggable architecture, allowing different service providers to be plugged in seamlessly. This makes it extensible and adaptable to various service types. The <code>Context</code> and <code>InitialContext</code> classes in JNDI are used to look up objects in a naming directory. The <code>InitialContext</code> acts as the starting point for a naming operation.</p> <p>By using JNDI, Java applications achieve portability across different environments, as they don't depend on a specific directory or naming service implementation. JNDI allows Java objects to be bound (assigned) to a name that can be later used for lookup. Similarly, objects can be unbound (removed) from names.</p> <p>JNDI is often used in conjunction with other Java EE technologies like [[Java Messaging Service (JMS)|JMS]], [[JDBC]], and [[Enterprise JavaBeans (EJBs)|EJB]], providing a mechanism to retrieve objects that are managed by the application server.</p>"},{"location":"misc/jpql/","title":"JPQL","text":"<p>Java Persistence Query Language (JPQL) is a query language used in the [[Java Persistence API (JPA)]] for making queries against entities stored in a relational database. JPQL is an object-oriented query language, similar in nature to SQL, but instead of operating on database tables and columns, it operates on Java classes and objects.</p> <p>JPQL queries are written against the entity objects and their fields rather than directly against database tables and columns. This allows developers to write database queries in an object-oriented fashion.</p> <p>While JPQL is designed to be familiar to those who know [[Structured Query Language|SQL]], it uses the entity model of the application instead of the actual database tables. For example, a JPQL query might look like <code>SELECT c FROM Customer c</code> where <code>Customer</code> is a Java entity.</p> <p>JPQL is part of the JPA specification and is used for querying the entities managed by JPA. It's a key component for retrieving entities based on various criteria. JPQL supports named parameters in queries, which enhances readability and maintainability. For example, <code>SELECT c FROM Customer c WHERE c.name = :name</code>.</p> <p>JPQL supports aggregate functions like <code>COUNT</code>, <code>MIN</code>, <code>MAX</code>, <code>SUM</code>, and <code>AVG</code>, similar to SQL. Since JPQL works with entities, it is database-independent. The same JPQL query can run across different database systems without modification.</p> <p>JPQL allows querying over relationships defined in the entity model. For example, you can easily join across various related entities (like fetching all orders for a customer). In a JPA application, JPQL queries are executed via the <code>EntityManager</code> interface, which provides methods like <code>createQuery</code> to create and execute JPQL queries.</p> <p>While powerful, JPQL has limitations compared to native SQL, especially in terms of database-specific features and optimizations. For more complex queries, sometimes native SQL queries might be preferable.</p> <p>JPA also provides the Criteria API as an alternative to JPQL for building queries programmatically. This is useful for constructing dynamic queries where the structure of the query depends on runtime conditions.</p>"},{"location":"misc/jre/","title":"Java Runtime Environment (JRE)","text":"<p>The Java Runtime Environment (JRE) is a part of the [[Java Development Kit (JDK)]], a set of software tools used for developing [[Java]] applications. It provides the libraries, the [[Java Virtual Machine (JVM)]], and other components to run applications written in Java.</p> <p>The JRE is specifically designed to provide an environment to execute Java applications. It cannot be used to develop applications, as it does not contain tools like compilers or debuggers.</p> <p>Components of the JRE:</p> <ul> <li>Java Virtual Machine (JVM): The core of the JRE, the JVM is an engine that provides a platform-independent way of executing Java code. It converts Java bytecode into machine language and executes it.</li> <li>Java Class Libraries: A set of dynamically loadable libraries that Java applications can call at runtime.</li> <li>User Interface Toolkits: Such as the Abstract Window Toolkit (AWT) and Swing.</li> <li>Integration Libraries: That enable database access, remote object invocation, and other networking mechanisms.</li> </ul> <p>One of the primary advantages of Java is its platform independence. Java applications compiled on one platform can run on any platform equipped with a compatible JRE. The JRE is a subset of the JDK. While the JDK is used for developing Java applications, the JRE is used for running them. The JDK includes the JRE along with compilers, debuggers, and other tools.</p> <p>Some web browsers require the JRE for running Java applets (though Java applets are largely obsolete now). For a user to run Java applications, their machine must have the JRE installed. Developers typically bundle the JRE with their software or instruct users on how to download it.</p> <p>Regular updates to the JRE are released to address security vulnerabilities and bugs, as well as to provide performance improvements.</p>"},{"location":"misc/jse/","title":"Java SE (Standard Edition)","text":"<p>Java SE (Standard Edition) is a computing platform for development and deployment of portable code for desktop and server environments. It forms the core foundation for the [[Java]] programming language and is used for a wide range of computing tasks, from small-scale applications on desktops to large-scale enterprise solutions.</p> <p>Java SE provides the basic components needed to develop and run Java applications. It includes the [[Java Runtime Environment (JRE)]], a set of libraries, the [[Java Virtual Machine (JVM)]], and other components necessary for Java application development. The JVM is a crucial part of Java SE, allowing Java programs to run on any platform without the need for recompilation, hence the famous slogan \u201cWrite Once, Run Anywhere.\u201d</p> <p>Java SE includes a comprehensive set of standard libraries ([[APIs]]) that provide functionality for various tasks such as I/O operations, networking, data structures, graphical user interface (GUI) development, and much more.</p> <p>It supports all the features of the Java language, including object-oriented programming, threads, lambda expressions (as of Java 8), and generics. Java SE comes with tools for developing and debugging Java applications, including the <code>javac</code> compiler, the <code>java</code> launcher, and other utilities.</p> <p>Through libraries such as AWT, Swing, and JavaFX, Java SE allows for the development of graphical desktop applications. While [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]] is specifically tailored for web and enterprise applications, Java SE also includes capabilities for developing server-side applications.</p> <p>Java SE provides strong security features, including a security manager, cryptographic libraries, and tools for securing Java applications. Applications written in Java SE are portable across many operating systems and platforms, maintaining compatibility across different Java SE versions.</p> <p>Java SE benefits from a large ecosystem and community, contributing to a vast array of libraries, frameworks, tools, and resources available for Java developers.</p>"},{"location":"misc/jsf/","title":"JSF","text":"<p>JavaServer Faces (JSF) is a [[Java]] specification for building component-based user interfaces for web applications. It is part of the [[Java Enterprise Edition (Java EE)]] platform. Developed by Oracle Corporation, JSF provides a framework for simplifying the development of user interfaces in Java web applications.</p> <p>JSF is a component-based MVC ([[Model-View-Controller (MVC)|Model-View-Controller]]) framework. It provides a set of reusable UI components that can be easily dragged and dropped in a web application. JSF supports event-driven programming. Components in a JSF page can generate events (like clicks or value changes) that are handled by server-side Java code.</p> <p>JSF integrates seamlessly with other Java EE technologies, such as [[Enterprise JavaBeans (EJBs)|Enterprise JavaBeans (EJB)]] for business logic and [[Java Persistence API (JPA)]] for database operations. In JSF, managed beans are used to define Java classes that contain business logic. These beans are managed by the JSF container in terms of their creation, lifecycle, and destruction.</p> <p>Facelets is a powerful templating engine used in JSF. It is the default view declaration language for defining JSF views using [[XHTML]]. JSF\u2019s architecture allows for easy customization of existing components and creation of new components.</p> <p>JSF supports [[Ajax]], enabling the creation of dynamic and rich internet applications with partial page updates. JSF provides built-in validation and data conversion features, simplifying the process of validating user input and converting it to application-specific data types.</p> <p>JSF includes a navigation model to control the sequence of screen navigation in a web application. It supports internationalization for building applications in multiple languages and also provides support for accessibility standards. JSF integrates with the Expression Language (EL), allowing the page to communicate with the managed beans.</p>"},{"location":"misc/json/","title":"JavaScript Object Notation (JSON)","text":"<p>JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on [[JavaScript]] object syntax. It is commonly used for transmitting data in web applications (e.g., sending some data from the server to the client, so it can be displayed on a web page, or vice versa). </p> <p>JSON is a text-based data format following JavaScript object syntax. Even though it closely resembles JavaScript object literal syntax, it can be used independently from JavaScript, and many programming environments feature the ability to read (parse) and generate JSON.</p> <p>JSON exists as a string \u2014 useful when you want to transmit data across a network. It needs to be converted to a native JavaScript object when you want to access the data. This is not a big issue \u2014 JavaScript provides a global\u00a0JSON\u00a0object that has methods available for converting between the two.</p> <p>You can include the same basic data types inside JSON as you can in a standard JavaScript object \u2014 strings, numbers, arrays, booleans, and other object literals. This allows you to construct a data hierarchy, like so:</p> <pre><code>{\n  \"squadName\": \"Super hero squad\",\n  \"homeTown\": \"Metro City\",\n  \"formed\": 2016,\n  \"secretBase\": \"Super tower\",\n  \"active\": true,\n  \"members\": [\n    {\n      \"name\": \"Molecule Man\",\n      \"age\": 29,\n      \"secretIdentity\": \"Dan Jukes\",\n      \"powers\": [\"Radiation resistance\", \"Turning tiny\", \"Radiation blast\"]\n    },\n    {\n      \"name\": \"Madame Uppercut\",\n      \"age\": 39,\n      \"secretIdentity\": \"Jane Wilson\",\n      \"powers\": [\n        \"Million tonne punch\",\n        \"Damage resistance\",\n        \"Superhuman reflexes\"\n      ]\n    },\n    {\n      \"name\": \"Eternal Flame\",\n      \"age\": 1000000,\n      \"secretIdentity\": \"Unknown\",\n      \"powers\": [\n        \"Immortality\",\n        \"Heat Immunity\",\n        \"Inferno\",\n        \"Teleportation\",\n        \"Interdimensional travel\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"misc/jsonp/","title":"JSON-P","text":"<p>JSON-P, short for JSON Processing, refers to the [[Java]] API for processing JSON ([[JavaScript Object Notation]]) data. This API, also known as <code>javax.json</code>, provides a portable standard library for parsing, generating, transforming, and querying JSON data in Java. </p> <p>JSON-P is a part of the [[Java Enterprise Edition (Java EE)]], but it can also be used in Java Standard Edition (Java SE) applications.</p> <p>JSON-P provides two models for processing JSON data: - The Object Model, which is a high-level API and uses a DOM ([[Document Object Model]]) like approach. - The Streaming Model, which is a low-level [[APIs|API]] and uses an event-driven approach.</p> <p>The Object Model API creates an in-memory tree representation of the JSON data. It allows reading, transforming, and writing JSON data. The API is similar to [[Extensible Markup Language|XML]] processing APIs and is useful for scenarios where random access to the parsed JSON structure is required.</p> <p>The Streaming API reads and writes JSON sequentially without loading the complete document into memory. This approach is more efficient in terms of memory usage and is faster for large JSON data sets.</p> <p>JSON-P provides builders to create JSON objects and arrays from scratch. It also offers parsers to read JSON data from input sources and write JSON data to output sources. The API allows for the transformation of JSON data by adding, removing, and modifying elements of the JSON structure.</p> <p>JSON-P doesn\u2019t directly support querying JSON data. However, it can be used in conjunction with other libraries like JSON-Path for querying. JSON-P integrates well with other Java technologies, such as [[JAX-RS (Java API for RESTful Web Services)|JAX-RS]] for building [[REST APIs|RESTful]] web services that consume and produce JSON data.</p> <p>As part of the Java EE platform, JSON-P provides a standardized way to handle JSON in Java, avoiding the need for third-party libraries. Being a standard Java API, JSON-P ensures portability across different Java environments.</p> <p>JSON-P is suitable for applications that need to parse, generate, or transform JSON data, like RESTful services, applications communicating with [[Non-relational Database|NoSQL databases]], and more.</p>"},{"location":"misc/jsonrpc/","title":"JSON-RPC","text":"<p>JSON-RPC is a remote procedure call protocol encoded in [[JavaScript Object Notation|JSON]]. It allows for sending messages, formatted as JSON, to a server that implements the JSON-RPC protocol. The server processes the request and returns a response, also in JSON format. This protocol is lightweight and stateless, making it suitable for various environments and applications, including [[web services]] and internal communications in distributed systems.</p> <p>A client can send a JSON object to request a specific method execution. For example:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"method\": \"addNumbers\",\n  \"params\": [5, 10],\n  \"id\": 1\n}\n</code></pre> <p>This request is asking to execute the <code>addNumbers</code> method with two parameters (5 and 10). The server, upon successfully executing the method, might respond with:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"result\": 15,\n  \"id\": 1\n}\n</code></pre> <p>This response indicates the result of the operation and correlates to the original request via the \"id\" field.</p> <p>JSON-RPC's simple and lightweight structure makes it a popular choice for internal [[APIs]] and services where extensive data modeling is not required. It is particularly useful in environments where bandwidth and performance are considerations.</p>"},{"location":"misc/jsp/","title":"JavaServer Pages (JSP)","text":"<p>JavaServer Pages (JSP) is a server-side technology used for creating dynamic, platform-independent web content. It's part of the Java technology family and provides a simplified, fast way to develop web applications. JSP allows you to write [[HTML]], [[Extensible Markup Language|XML]], or other types of documents, interspersed with [[Java]] code, for generating dynamic web content. </p> <p>JSP enables the creation of web pages that can dynamically generate content based on user requests, database queries, or other dynamic sources. </p> <p>Under the hood, JSP files are compiled into Java servlets by the server. While servlets embed HTML inside Java code, JSPs embed Java code in HTML. This makes JSPs more convenient to write and maintain, especially for those familiar with HTML.</p> <p>JSP uses Java-like tags and scriptlets that are embedded in HTML. A JSP tag is a special instruction that is interpreted on the server to generate dynamic content. For example, <code>&lt;%= expression %&gt;</code> is a JSP expression tag that outputs the result of the expression.</p> <p>JSP allows for a clear separation of presentation from business logic. Java code can be kept separate from the HTML, making the code cleaner and more maintainable. A JSP lifecycle includes several stages, from translation (converting JSP to a servlet), compilation (compiling the servlet into a class), initialization, request processing, and destruction.</p> <p>JSP is often used in conjunction with the Java Enterprise Edition (Java EE) platform and can be integrated with Java-based frameworks like Spring and Hibernate. JSP simplifies web development by allowing developers to embed Java code directly into HTML pages. It supports tag libraries, which are custom tags that encapsulate complex functionalities.</p> <p>JSP supports custom tag libraries, which abstract the Java code into more manageable and reusable components, known as custom tags. JSP supports session tracking, which is used to maintain state about a user as they navigate through a web application.</p>"},{"location":"misc/jta/","title":"Java Transaction API (JTA)","text":"<p>The Java Transaction API (JTA) is a [[Java Enterprise Edition (Java EE)]] API that allows applications to perform distributed transactions, which means transactions that span multiple resources like databases and messaging systems. JTA is part of the Java EE platform and is used for managing transactions in a consistent and reliable way across various data sources in an enterprise environment.</p> <p>JTA enables applications to handle distributed transactions, where a single transaction might involve multiple operations across various data sources, and all these operations need to be treated as a single unit of work.</p> <p>JTA transactions ensure [[ACID]] (Atomicity, Consistency, Isolation, Durability) properties. This means that all operations within a transaction are treated as a single atomic unit, which either completely succeed or completely fail.</p> <p>JTA typically uses a two-phase commit protocol to ensure all resources either commit or roll back changes in a coordinated manner. This is essential for maintaining data consistency across different systems.</p> <p>Key interfaces in JTA include <code>UserTransaction</code>, which is used for demarcating transaction boundaries, and <code>TransactionManager</code>, which is responsible for managing transactions across multiple resources. JTA is often used with other Java EE components like [[Enterprise JavaBeans (EJBs)]], [[Java Persistence API (JPA)]], and Java Message Service ([[JMS]]) to provide transactional support.</p> <p>Java EE application servers (like WildFly, IBM WebSphere, and Oracle WebLogic) provide support for JTA, allowing applications deployed on these servers to participate in transactions managed by JTA.</p> <p>JTA supports both declarative transaction management (using annotations or [[Extensible Markup Language|XML]] configuration) and programmatic transaction management (explicitly coding transaction boundaries). JTA is based on the X/Open XA standard for distributed transaction processing, which allows it to work with various XA-compliant resources, like relational databases and message-oriented middleware.</p> <p>JTA provides a unified and standardized way to handle complex transactions in enterprise applications, ensuring data integrity and consistency across different systems. JTA is particularly suitable for large-scale, enterprise-level applications where transactions involve multiple databases or other transactional resources.</p>"},{"location":"misc/jvm/","title":"Java Virtual Machine (JVM)","text":"<p>The Java Virtual Machine (JVM) is a crucial component of the [[Java Runtime Environment (JRE)]]. It is an abstract computing machine or virtual machine that enables a computer to run [[Java]] programs as well as programs written in other languages that are also compiled to Java bytecode. The JVM is platform-independent, meaning Java programs can run on any device or operating system that has a JVM installed.</p> <p>The primary function of the JVM is to execute Java bytecode, which is the intermediate representation of Java code compiled by the Java compiler from Java source files. \"Write Once, Run Anywhere\" (WORA) is a cornerstone of Java's architecture. Java applications are compiled into bytecode, which the JVM can execute on any platform, making Java applications platform-independent.</p> <p>The JVM comprises a class loader, a memory area, an execution engine, and a garbage collector.</p> <ul> <li>Class Loader: Loads Java classes into memory.</li> <li>Memory Area: Manages memory for Java objects, including the heap, stack, method area, and register set.</li> <li>Execution Engine: Executes instructions in the bytecode.</li> <li>Garbage Collector: Manages and optimizes memory by removing unused objects.</li> </ul> <p>JVMs often include a JIT compiler that improves the performance of Java applications by compiling bytecode into native machine code at runtime. The JVM provides a secure execution environment through various mechanisms like the bytecode verifier, which ensures that the code does not violate Java's security constraints.</p> <p>The JVM is a stack-based machine, where operations are performed using a stack rather than registers, as in most physical CPU architectures. While primarily known for Java, the JVM also supports other languages such as Scala, Kotlin, and Groovy, all of which compile to Java bytecode.</p> <p>In addition to bytecode execution, the JVM provides an environment for thread synchronization, exception handling, and other runtime functionalities essential for Java applications. There are various implementations of the JVM from different vendors, including Oracle's HotSpot, the open-source Eclipse OpenJ9, and others.</p>"},{"location":"misc/kube/","title":"Kubernetes","text":"<p>Kubernetes, often abbreviated as K8s, is an open-source container orchestration system for automating software deployment, scaling, and management. Originally designed by Google and now maintained by the Cloud Native Computing Foundation, Kubernetes has become a standard for deploying and managing containerized applications at scale. </p> <p>Kubernetes helps in managing containers (like [[Docker]] [[containers]]), which are lightweight, portable, and self-sufficient units for running applications. It automates the deployment, scaling, and operations of these containers.</p> <p>Kubernetes operates in a cluster environment. A cluster consists of at least one master node (which controls and manages the cluster) and multiple worker nodes (where the containers are run).</p> <p>The basic deployable units in Kubernetes are \"Pods.\" A Pod is a group of one or more containers, with shared storage/network resources, and a specification for how to run the containers.</p> <p>Kubernetes provides services that abstract pod IP addresses from consumers. This not only allows for load balancing traffic to the pods but also enables dynamic replacement of pods without disrupting the application.</p> <p>Kubernetes supports horizontal scaling automatically based on traffic or other metrics. It also ensures self-healing by restarting failed containers, replacing, and rescheduling containers when nodes die, and killing containers that don't respond to user-defined health checks.</p> <p>Kubernetes allows you to roll out changes to your application or its configuration, while monitoring the application's health to ensure it doesn't kill all your instances at the same time. If something goes wrong, Kubernetes can rollback the change for you.</p> <p>Kubernetes lets you store and manage sensitive information, such as passwords, OAuth tokens, and SSH keys. You can deploy and update secrets and application configuration without rebuilding your container images and without exposing secrets in your stack configuration.</p> <p>Kubernetes automatically mounts the storage system of your choice, whether from local storage, a public cloud provider, or a network storage system. Kubernetes has a large, rapidly growing ecosystem. Its services, support, and tools are widely available, making it a widely adopted platform in the cloud-native community.</p> <p>Kubernetes runs on various cloud providers, bare-metal servers, and even hybrid or multi-cloud environments, making it a versatile choice for different infrastructure needs.</p>"},{"location":"misc/latex/","title":"LaTeX","text":"<p>LaTeX (pronounced \"LAY-tech\" or \"LAH-tech\") is a typesetting system commonly used for the production of scientific and mathematical documents due to its powerful handling of formulas and bibliographic references. It is widely used in academia, especially in the fields of mathematics, computer science, engineering, physics, chemistry, economics, linguistics, and quantitative psychology.</p> <p>LaTeX is known for producing high-quality, professional-looking documents, particularly those containing mathematical symbols and notations. It allows for precise control over layout and content formatting, making it suitable for complex documents like academic papers, theses, and books. LaTeX separates content from layout, allowing authors to focus on writing without worrying about formatting details.</p> <p>LaTeX, in conjunction with tools like BibTeX, excels in managing bibliographies and citations, a vital feature for academic writing. A wide range of packages (extensions) are available for LaTeX, enabling additional functionalities like hyperlinks, PDF creation, complex graphics, and color support.</p> <p>LaTeX is not a word processor but a markup language. Users write their documents in plain text format with commands that describe its structure and presentation. LaTeX then processes this source text and commands to produce a formatted document.</p> <p>A simple LaTeX document might look like this:</p> <pre><code>\\documentclass{article}\n\\title{Introduction to LaTeX}\n\\author{John Doe}\n\\begin{document}\n\\maketitle\n\\section{Introduction}\nThis is a simple document in LaTeX.\n\\subsection{Mathematics}\nLaTeX is great for typesetting mathematics, like \\( E=mc^2 \\).\n\\end{document}\n</code></pre> <p>This code, when compiled with LaTeX, produces a document with a title, an author, sections, and a math formula.</p> <ul> <li>Writing: The user writes the document in LaTeX syntax.</li> <li>Compiling: The LaTeX engine processes the text and commands to create a formatted document, typically in PDF format.</li> </ul> <p>LaTeX is the de facto standard for many types of academic and scientific publications. Its plain text nature makes it ideal for collaborative writing and version control, which are essential in research environments.</p>"},{"location":"misc/logic/","title":"Logical Operators","text":"<p>Logical operators are fundamental elements in programming and logic used to combine or modify Boolean expressions. A Boolean expression is one that evaluates to either true or false. Logical operators are used to perform logical operations, and they are essential for controlling the flow of execution in a program based on certain conditions. </p> <p>The primary logical operators are:</p> <ul> <li>AND - operator returns true if both operands are true</li> <li>OR - returns true if at least one of the operands is true</li> <li>NOT - inverts the truth value of its operand</li> <li>NAND - combination of NOT and AND, returns false if both operands are true, otherwise true.</li> <li>NOR - combines NOT and OR, returns true only when all operands are false</li> <li>XOR - operators returns true if and only if exactly one of the operands is true</li> </ul> <p>Logical operators in [[Structured Query Language|SQL]] are used to combine or modify conditions in a SQL statement, particularly within the WHERE clause, which filters records based on specified criteria. </p> <p>These operators are crucial for formulating complex queries, allowing you to refine and target your data retrieval effectively.</p>"},{"location":"misc/lsa/","title":"LSA (Local Security Authority)","text":"<p>The Local Security Authority (LSA) is a critical component of the Microsoft Windows operating system responsible for enforcing the security policy on the system. It acts as a gatekeeper for controlling access to the system and managing security-related operations. </p> <p>LSA handles all local authentication processes. When a user logs on, the LSA is responsible for validating their credentials against the security policies and the user accounts database. It enforces various security policies and settings defined in Group Policy or the local security policy.</p> <p>After successful authentication, the LSA creates an access token, which contains the user's identity and security privileges. This token is used to grant access to resources and services on the system. LSA manages password changes, account lockouts, and similar security-related operations.</p> <p>In the context of hacking or penetration testing, the LSA is often targeted for several reasons:</p> <ol> <li>Extracting Credentials: Tools like [[Mimikatz]] exploit the LSA to extract credentials, such as plaintext passwords, hashed passwords, and [[Kerberos tickets]], from memory. These credentials can be used for further attacks like lateral movement within a network.</li> <li>[[Pass-the-Hash Attacks]]: Attackers may use the hashed credentials extracted from the LSA to perform pass-the-hash attacks, gaining unauthorized access to other systems on the network without needing the plaintext password.</li> <li>[[Privilege Escalation]]: Exploiting vulnerabilities in the LSA can lead to privilege escalation, allowing an attacker to gain higher-level access rights on the system.</li> <li>Security Policy Bypass: By manipulating the LSA, attackers can potentially bypass certain security policies or restrictions imposed by the system.</li> </ol>"},{"location":"misc/lsass/","title":"LSASS (Local Security Authority Subsytem Service)","text":"<p>LSASS (Local Security Authority Subsystem Service) is a critical process in Microsoft Windows operating systems that is responsible for enforcing the security policy on the system. It handles user logins, authentication, and creates security tokens. LSASS also writes to the Windows Security Log.</p> <p>LSASS verifies the validity of user logins to a PC or server. When a user logs into a Windows computer, LSASS generates the user's access token, which defines their privileges. LSASS is involved in changing passwords for user accounts. It enforces various security policies and acts as a gatekeeper for accessing sensitive information.</p> <p>LSASS is a target for attackers due to its critical role in handling authentication and storing credentials:</p> <ol> <li>Credential Dumping: Tools like [[Mimikatz]] exploit LSASS to extract passwords, [[NTLM]] hashes, and Kerberos tickets. This information can then be used for [[lateral movement]], [[privilege escalation]], or further penetration into the network.</li> <li>[[Pass-the-Hash Attacks|Pass-the-Hash (PtH) Attacks]]: Attackers can use NTLM hashes extracted from LSASS for PtH attacks, allowing them to authenticate to other systems without needing the plaintext password.</li> <li>Memory Dumping: Attackers may dump the LSASS process memory to extract sensitive information. This can be done by injecting code into the LSASS process or using debugging tools.</li> <li>Persistence and Evasion: Malware may inject itself into the LSASS process to hide its presence, as terminating LSASS can cause the system to crash, thus avoiding detection.</li> </ol>"},{"location":"misc/m365/","title":"Microsoft 365","text":"<p>Microsoft 365 is a subscription that includes the most collaborative, up-to-date features in one seamless, integrated experience. </p> <p>Microsoft 365 includes the robust Office desktop apps that you\u2019re familiar with, like Word, PowerPoint, and Excel, collectively known as [[Office 365]]. You also get extra online storage and cloud-connected features that let you collaborate on files in real time. </p>"},{"location":"misc/mac/","title":"Message Authentication Code (MAC)","text":"<p>A Message Authentication Code (MAC) is a short piece of information used to authenticate a message and to provide integrity and authenticity assurances on the message. A MAC function, like a cryptographic hash function, takes a secret key and an input (or message) and produces a MAC (sometimes known as a tag), which can be appended to the message and then sent to a receiver.</p> <p>MACs ensure that a message comes from the stated sender (authentication) and has not been changed in transit (integrity). Unlike a hash function, a MAC function requires a secret key in addition to the message. The same key is used to generate and to verify the MAC.</p> <p>Any change to the message or the MAC will make the verification fail at the receiver's end, which means any tampering with the message can be reliably detected. Common MAC algorithms include [[HMAC (Hash-based Message Authentication Code)]], [[CMAC (Cipher-based MAC)]], and [[GMAC (Galois Counter Mode MAC)]].</p> <p>The sender uses a MAC algorithm, a secret key, and the message to generate a MAC. The MAC is then sent along with the message. The receiver, who has the same secret key, uses it and the received message to generate a new MAC. The receiver compares this new MAC against the MAC sent with the message. If they match, the message is authenticated and considered untampered.</p> <p>MACs are used for integrity and authenticity between parties that share a secret key. They don't provide non-repudiation since both parties can generate the MAC. Digital Signatures provide integrity, authenticity, and non-repudiation, as they use public-key cryptography where the ability to generate a signature is not shared.</p>"},{"location":"misc/magic/","title":"Magic Bytes","text":"<p>Magic bytes are specific patterns at the beginning of a file used to indicate the file format, independent of file extensions. These patterns, typically a sequence of bytes, are unique to various file types and are used by software to determine the file's format and how to process it.</p> <p>Magic bytes are used to identify the format of a file, such as an image, document, audio, or video file. They serve as a signature for the file format. These bytes are usually located at the beginning of a file, known as the file header.</p> <ul> <li>For example, JPEG image files often start with the bytes <code>FF D8 FF</code>, and PNG image files begin with <code>89 50 4E 47 0D 0A 1A 0A</code>.</li> <li>PDF documents typically start with <code>%PDF-</code></li> </ul> <p>Operating systems and applications use magic bytes to determine how to handle a file. This is particularly useful when file extensions are missing or incorrect. Web servers and browsers often use magic bytes for [[MIME-Type|MIME type]] detection, influencing how a file is rendered or processed.</p> <p>Magic bytes are used in security to validate file types. For instance, an upload filter might check a file's magic bytes to ensure it matches its declared file type, helping to prevent certain types of malicious file uploads. In digital forensics, magic bytes can be used to identify and recover file types from disk images or fragments.</p> <p>While useful, magic bytes are not foolproof. Files can be crafted with misleading magic bytes for malicious purposes, like disguising an executable file as a benign file type.</p>"},{"location":"misc/masb/","title":"Microsoft Azure Service Bus","text":"<p>Microsoft Azure Service Bus is a fully managed messaging service provided by Microsoft [[Azure]]. It enables communication between applications and services, both within the Azure cloud and on-premises. Azure Service Bus supports different messaging patterns, including publish/subscribe, point-to-point, and request/response.</p> <p>Messaging Patterns:</p> <ul> <li>Publish/Subscribe (Topics and Subscriptions): Azure Service Bus Topics allow publishers to send messages to a topic, and subscribers can receive messages from specific subscriptions within that topic. This pattern enables one-to-many communication.</li> <li>Point-to-Point (Queues): Azure Service Bus Queues provide a one-to-one communication pattern. Messages sent to a queue are retrieved by a single receiver (consumer). This pattern ensures that each message is processed by only one consumer.</li> </ul> <p>Azure Service Bus ensures reliable message delivery by supporting features such as message durability, retries, and dead-lettering. Messages are stored persistently, and consumers can retrieve them even after temporary failures.</p> <p>Azure Service Bus supports message sessions, allowing related messages to be processed in a specific order. This is useful in scenarios where a group of related messages needs to be handled together. Messages can be automatically forwarded from one queue or topic/subscription to another. This feature is useful for routing messages to different destinations based on specific criteria.</p> <p>Messages that cannot be processed successfully after a certain number of retries are moved to a dead-letter queue. This allows for further analysis and handling of failed messages. Azure Service Bus can be integrated with Azure Relay to enable secure and hybrid communication between on-premises applications and those hosted in Azure.</p> <p>Topics and queues can be partitioned to improve scalability and throughput. Each partition operates independently, allowing for parallel processing of messages. Messages can be scheduled for future delivery, allowing for time-sensitive communication scenarios.</p> <p>Azure Service Bus uses namespaces to group related messaging entities. Access control is managed through shared access policies, allowing fine-grained control over who can send or receive messages. A tool called Azure Service Bus Explorer provides a graphical user interface for managing and interacting with Azure Service Bus entities. It simplifies tasks such as creating queues, topics, and subscriptions.</p> <p>Azure Service Bus provides SDKs and [[APIs]] for various programming languages, including [[Dotnet|.NET]], [[Java]], [[Python]], [[NodeJS|Node.js]], and more. This makes it easy for developers to integrate messaging capabilities into their applications.</p>"},{"location":"misc/maven/","title":"Apache Maven","text":"<p>Apache Maven is a powerful project management and comprehension tool used primarily for [[Java]] projects. It provides developers with a complete build lifecycle framework and is developed by the Apache Software Foundation. Maven uses a [[Project Object Model (POM)]] and a set of plugins to manage a project's build, reporting, and documentation.</p> <p>Maven is based on the POM (Project Object Model), which is defined in an [[Extensible Markup Language|XML]] file (<code>pom.xml</code>). This file describes the project, its dependencies, build order, external libraries needed, and other configurations.</p> <p>One of Maven's key features is its dependency management. It automatically downloads the libraries and plugins required for a project, which are defined in the <code>pom.xml</code>. Dependencies are retrieved from a central repository and stored in a local cache.</p> <p>Maven provides a standardized way to build projects. It uses a default build lifecycle that includes phases like <code>compile</code>, <code>test</code>, <code>package</code>, and <code>install</code>. The build process in Maven is extensible and can be customized with plugins. Each plugin can have one or more goals that are tied to different phases of the lifecycle.</p> <p>Maven follows a \"convention over configuration\" principle, meaning it provides default values for most project settings. This reduces the need for explicit configuration and makes project setup easier and more straightforward.</p> <p>Maven excels at handling multi-module projects, where an overall project is composed of several sub-projects, each with its own <code>pom.xml</code> file. Maven\u2019s build process includes several lifecycle phases, allowing developers to clean, validate, compile, test, package, verify, install, and deploy their code systematically.</p> <p>Maven can generate project structures using archetypes. An archetype is a project template, which is particularly useful for standardizing and simplifying the process of project setup.</p>"},{"location":"misc/mes/","title":"Microsoft Exchange Server","text":"<p>Microsoft Exchange Server is a mail server and calendaring server developed by Microsoft. It runs exclusively on Windows Server operating systems and is part of Microsoft's line of business server products. Exchange Server is widely used in businesses and organizations for its robust capabilities in email management, calendaring, tasks, and contacts.</p> <p>Exchange Server provides a platform for hosting enterprise-level email services, complete with features like email storage, forwarding, and filtering. It includes advanced calendaring features, allowing users to schedule meetings, share calendars, and coordinate events.</p> <p>Exchange Server includes integrated task management and contact management features, syncing this information across devices and users. It is designed to work seamlessly with Microsoft Outlook, a popular email client, providing a rich user interface for managing emails, calendars, contacts, and tasks.</p> <p>Exchange supports mobile access, including native synchronization with smartphones and tablets, using Microsoft's [[ActiveSync|ActiveSync protocol]]. The server includes built-in protections against spam and malware, along with compliance tools for archiving, eDiscovery, and data loss prevention. </p> <p>Some versions of Exchange include Unified Messaging features, integrating voicemails and faxes with the email system. Part of [[Microsoft 365]] (formerly Office 365), Exchange Online offers cloud-based email and calendaring services, eliminating the need for on-premises servers.</p>"},{"location":"misc/metrics/","title":"Metrics","text":"<p>Metrics, in the context of software development, usually refers to a library or tool designed to measure and monitor various aspects of application performance and health. One well-known library in this space is \"[[Dropwizard]] Metrics,\" a [[Java]] library for gathering and reporting various types of application metrics.</p> <p>Metrics libraries often provide various types of measurements, such as gauges (to measure values at a specific point in time), counters (to count occurrences of events), histograms (to measure the statistical distribution of values), timers (to measure durations of events), and meters (to measure the rate of events).</p> <p>Metrics are crucial for monitoring the performance of an application. This includes measuring response times, throughput, error rates, and other performance-related data. In addition to performance metrics, libraries like Dropwizard Metrics can be used to implement health checks, which provide insights into the health and operational status of an application.</p> <p>Metrics libraries often enable real-time monitoring of applications, allowing developers and operations teams to observe the behavior of a system as it runs and quickly identify any issues.</p> <p>Metrics data can be reported and visualized in various ways, often integrating with tools like Grafana, Prometheus, or other monitoring and alerting systems. By providing detailed insights into the application's operations, metrics can be an invaluable diagnostic tool, helping to pinpoint the causes of performance bottlenecks or failures.</p> <p>Metrics libraries typically offer customizable configurations, enabling developers to tailor the metrics to their specific needs and environment. Libraries like Dropwizard Metrics are designed to be easily integrated into application code, providing a seamless way to add metrics collection to existing applications.</p> <p>In microservices architectures and distributed systems, metrics are essential for understanding the behavior of individual services and the system as a whole. Using a metrics library can help standardize the way metrics are collected and reported across different parts of an application or across different applications within an organization.</p>"},{"location":"misc/mime/","title":"MIME-Type","text":"<p>MIME-Type, short for Multipurpose Internet Mail Extensions Type, is a standard that indicates the nature and format of a document, file, or assortment of bytes. It is used to specify the type of content that a file contains, which helps web browsers and other software to handle the file appropriately.</p> <p>MIME-Types are used to identify the format of files transmitted over the Internet (via email, web browsers, etc.) so that applications know how to process them. For example, when a web server sends a document, it also sends the MIME-Type in the [[HTTP Headers|HTTP header]] to inform the client about the type of data being sent.</p> <p>A MIME-Type is generally structured as a type and a subtype, separated by a slash. For example, <code>text/html</code> for [[HTML]] files, <code>image/jpeg</code> for JPEG images, and <code>application/json</code> for [[JavaScript Object Notation|JSON]] files.</p> <p>Common Types: - Text: Used for text-based files, like <code>text/plain</code>, <code>text/html</code>, <code>text/css</code>, <code>text/javascript</code>. - Image: Used for image files, like <code>image/png</code>, <code>image/jpeg</code>, <code>image/gif</code>. - Application: Used for various kinds of binary data and special files, like <code>application/json</code>, <code>application/xml</code>, <code>application/zip</code>, <code>application/pdf</code>.</p> <p>In web development, correctly setting the MIME-Type of content being sent to the browser is crucial for its correct rendering or processing. For instance, [[CSS]] files should be <code>text/css</code>, and ][[JavaScript]] files should be <code>text/javascript</code> or <code>application/javascript</code>.</p> <p>Incorrect or misleading MIME-Types can lead to security vulnerabilities. For example, if an executable file is served with an innocuous MIME-Type (like <code>text/plain</code>), it might bypass security checks.</p> <p>MIME-Types are also used in content negotiation, where the client and server exchange information about which formats they can understand and use. In emails, MIME-Types are used to indicate the type of attached files, ensuring the email client handles the attachments correctly.</p> <p>Browsers often use the MIME-Type, along with file extensions, to determine how to process a document. For example, they can render, download, or ask the user how to handle different types of files based on their MIME-Types.</p>"},{"location":"misc/monster/","title":"MonsterInsights","text":"<p>MonsterInsights is a powerful [[WordPress]] plugin designed for Google Analytics integration. It allows users to connect their WordPress websites with Google Analytics easily, enabling them to track and analyze their website traffic directly from the WordPress dashboard. </p> <p>MonsterInsights is widely used for its user-friendly interface and extensive features that make understanding website analytics more accessible, especially for users without technical expertise in analytics.</p> <p>MonsterInsights simplifies the process of integrating Google Analytics with a WordPress site. Users can set up analytics without having to edit code. It provides real-time statistics within the WordPress dashboard, allowing users to see how their site is performing at any moment. For e-commerce websites, MonsterInsights offers enhanced e-commerce tracking features that integrate with WooCommerce and other popular e-commerce platforms.</p> <p>Users can access reports on their audience demographics, including age, gender, interests, devices used, and more. The plugin tracks which pages and posts are the most popular, how long visitors stay on the site, and what they click on, helping users understand user behavior and content effectiveness.</p> <p>MonsterInsights shows where the website traffic is coming from, be it search engines, social media, referral sites, or direct visits. Users can set up custom dimensions to track additional metrics that are not tracked by default in Google Analytics. The plugin can track form views, submissions, and conversion rates if the website uses forms for lead generation or user input.</p> <p>As MonsterInsights deals with website data, security and privacy are important. The plugin itself is secure and follows standard WordPress security practices. However, users should ensure that their overall WordPress site is secure and comply with relevant data protection laws (like GDPR) when using analytics tools.</p>"},{"location":"misc/mq/","title":"IBM MQ","text":"<p>IBM MQ, formerly known as [[IBM WebSphere]] MQ, is a robust and secure messaging middleware by IBM. It enables applications to communicate and exchange data in a reliable and scalable way, regardless of the environment (mainframe, enterprise, or cloud). </p> <p>IBM MQ is designed to facilitate the assured, secure, and efficient transfer of information between applications, systems, services, and files. Here\u2019s an overview:</p> <p>IBM MQ is a message-oriented middleware (MOM) solution. It uses message queues to facilitate the exchange of information between distributed application systems across various platforms. By using message queues, IBM MQ allows for temporal and spatial decoupling of application components, meaning that the sender and receiver of the message do not need to be available at the same time or be directly connected.</p> <p>It enables asynchronous communication, where applications can put messages on a queue and not wait for a response to continue processing. IBM MQ ensures message delivery and integrity. Messages are not lost if a receiver, sender, or intermediary system is temporarily unavailable.</p> <p>The platform supports transactions, enabling the grouping of several actions into a single unit of work that either completely succeeds or fails, ensuring consistency in message processing. It provides robust security features, including encryption and authentication, to protect sensitive data and ensure that messages are not tampered with during transit.</p> <p>IBM MQ is highly scalable, capable of handling large volumes of messages and numerous concurrent applications. Used across multiple industries, including finance, healthcare, and retail, IBM MQ addresses complex messaging needs like banking transactions, inventory management, and order processing systems.</p> <p>IBM MQ supports various messaging patterns, including point-to-point, publish/subscribe, and file transfer.</p>"},{"location":"misc/mrpc/","title":"Microsoft Remote Procedure Call","text":"<p>Microsoft Remote Procedure Call, also known as a function call or a subroutine call, is a protocol that uses the [[client]]-[[server]] model in order to allow one program to request service from a program on another computer without having to understand the details of that computer's network. </p> <p>Depending on the host configuration, the RPC endpoint mapper can be accessed through [[Transmission Control Protocol|TCP]] and [[User Datagram Protocol|UDP]] port 135, via [[Server Message Block|SMB]] with a null or authenticated session (TCP 139 and 445), and as a web service listening on TCP port 593.</p> <p>The MSRPC process begins on the client side, with the client application calling a local stub procedure instead of code implementing the procedure. The client stub code retrieves the required parameters from the client address space and delivers them to the client runtime library, which then translates the parameters into a standard Network Data Representation format to transmit to the server.</p> <p>The client stub then calls functions in the RPC client runtime library to send the request and parameters to the server. If the server is located remotely, the runtime library specifies an appropriate transport protocol and engine and passes the RPC to the network stack for transport to the server.</p>"},{"location":"misc/msc/","title":"JBoss Modular Service Container (MSC)","text":"<p>The JBoss Modular Service Container (MSC) is a core component of the [[JBoss Application Server]], which is an open-source [[Java Enterprise Edition (Java EE)|Java EE (Enterprise Edition)]] application server. MSC is designed to provide a modular and dynamic framework for managing services within the JBoss server.</p> <p>MSC enables a modular architecture where services can be defined and managed independently. Each service is encapsulated within a module, allowing for better isolation and organization of functionality. MSC manages the lifecycle of services, including their instantiation, initialization, and eventual disposal. This includes handling dependencies between services, ensuring that services are started and stopped in the correct order.</p> <p>MSC supports dynamic updates to services, allowing for changes to be applied without requiring a full server restart. This dynamic behavior is essential for achieving high availability and minimizing downtime. Services in MSC can have dependencies on other services. MSC ensures that dependencies are satisfied before a service is started, creating a well-ordered and reliable system.</p> <p>MSC supports asynchronous execution of services, allowing certain operations to be performed concurrently. This is particularly useful for improving system responsiveness and resource utilization. MSC is designed to be extensible, allowing developers to add custom functionality or integrate with other frameworks. This extensibility is important for adapting the JBoss server to specific use cases and requirements.</p> <p>MSC manages resources associated with services, such as thread pools, database connections, and other critical resources. This helps in efficient resource utilization and prevents resource leaks. MSC provides runtime diagnostics and monitoring capabilities. Administrators can gain insights into the health and performance of the services running in the JBoss server.</p>"},{"location":"misc/mta/","title":"Mail Transport Agent (MTA)","text":"<p>A Mail Transport Agent (MTA), also known as a mail relay or mail server, is a software application that transports emails from one computer to another using the [[Simple Mail Transfer Protocol]] (SMTP). </p> <p>It is a critical component of the internet's email infrastructure, responsible for transferring email messages from the sender's to the recipient's mail server, and often to the recipient's local [[Mail User Agent (MUA)|mail user agent (MUA)]], which is the email client.</p> <p>MTAs determine the route and deliver emails across the internet or within an organization. They use SMTP to communicate with other MTAs and with MUAs. If an MTA cannot immediately deliver an email (e.g., if the recipient's server is down), it queues the email and periodically retries delivery.</p> <p>MTAs often process email by performing tasks like adding headers, filtering spam, or scanning for viruses. MTAs relay emails from one MTA to another until the email reaches its final destination.</p> <p>Some common MTA software applications include:</p> <ul> <li>[[Sendmail]]: One of the oldest and most widely used MTAs on Unix-like systems.</li> <li>[[Postfix]]: Known for its easy configuration and secure default settings, Postfix is widely used in Linux environments.</li> <li>[[Exim]]: Popular on Unix-like systems, Exim is known for its flexibility and configurability.</li> <li>[[Microsoft Exchange Server]]: Widely used in corporate environments, particularly in organizations using Microsoft infrastructure.</li> </ul> <p>When you send an email, your email client (MUA) submits the email to an MTA. This submission usually uses SMTP or submission protocols (like [[Simple Mail Transfer Protocol Secure (SMTPS)|SMTPS]] or SMTP over [[STARTTLS]]). The MTA then relays the email through potentially several other MTAs until it reaches the MTA responsible for the recipient's domain. Finally, that MTA delivers the email to the recipient's mailbox, where it can be accessed by their email client.</p>"},{"location":"misc/mtom/","title":"MTOM","text":"<p>MTOM (Message Transmission Optimization Mechanism) is a standard extension to the [[SOAP]] (Simple Object Access Protocol) messaging protocol. It is designed to optimize the transmission of binary data, such as images or documents, in SOAP messages. MTOM allows for more efficient handling of binary content by separating it from the [[Extensible Markup Language|XML]]-based SOAP message and transmitting it as optimized binary attachments.</p> <p>MTOM enables the efficient transmission of binary data by separating it from the XML payload of the SOAP message. Binary data is sent as separate [[MIME-Type|MIME]] attachments. Without MTOM, binary data in SOAP messages is often encoded using [[Base64]], which can increase the size of the message and add processing overhead. MTOM replaces Base64 encoding with a more efficient binary encoding.</p> <p>By sending binary data as separate attachments, MTOM reduces the overall size of the SOAP message. This is particularly beneficial for scenarios where large binary content needs to be transmitted. MTOM can improve the performance of SOAP-based web services, especially when dealing with large binary payloads. The optimized transmission of binary data can result in faster communication between service providers and consumers.</p> <p>MTOM is designed to be compatible with existing SOAP infrastructures. It does not introduce significant changes to the SOAP protocol but enhances its capabilities for handling binary content.</p> <p>In [[Java]], when using JAX-WS (Java API for XML-Based Web Services) to develop SOAP web services, MTOM can be enabled by annotating the service endpoint with <code>@MTOM</code>:</p> <pre><code>import javax.jws.WebMethod;\nimport javax.jws.WebService;\nimport javax.xml.ws.soap.MTOM;\n\n@WebService\n@MTOM\npublic class MyMtomWebService {\n\n    @WebMethod\n    public DataHandler getImage() {\n        // Code to retrieve and return binary data (e.g., image)\n    }\n}\n</code></pre> <p>The <code>@MTOM</code> annotation is used to enable MTOM for the web service. The <code>getImage</code> method returns a <code>DataHandler</code> object, which is a standard Java API for representing binary data. The use of <code>@MTOM</code> indicates that the binary data should be transmitted efficiently using MTOM.</p>"},{"location":"misc/mua/","title":"Mail User Agent (MUA)","text":"<p>A Mail User Agent (MUA), often referred to as an email client, is a software application used to access, manage, send, and receive email. It acts as the interface between the user and the email system, allowing users to interact with their email in a user-friendly way. The MUA connects to a mail server to send outgoing mail and to retrieve incoming mail.</p> <p>It allows users to write and send emails. The MUA formats the email according to internet email standards and then uses the [[Simple Mail Transfer Protocol]] (SMTP) to send the email to a [[Mail Transport Agent (MTA)|Mail Transfer Agent (MTA)]] for delivery.</p> <p>It retrieves email from a user's mailbox on the mail server. This is typically done using email retrieval protocols like the [[Post Office Protocol]] (POP) or the [[Internet Message Access Protocol]] (IMAP). It provides tools for organizing, searching, and managing emails. This includes creating folders, marking emails as read or important, flagging spam, and filtering.</p> <p>In the email communication process, the MUA plays a critical role in the user-facing side of email. While the MTA (Mail Transfer Agent) handles the routing and delivery of email between servers, the MUA is what the user interacts with to read and compose messages.</p> <p>Some examples of MUAs include:</p> <ul> <li>Desktop Email Clients: Applications like Microsoft Outlook, Mozilla Thunderbird, and Apple Mail are standalone programs installed on a user's computer.</li> <li>Web-Based Email Clients: Services like Gmail, Yahoo Mail, and Outlook.com are accessed through a web browser and provide MUA functionality.</li> <li>Mobile Email Apps: Applications designed for smartphones and tablets, such as the iOS Mail app and the Android Gmail app.</li> </ul>"},{"location":"misc/mvc/","title":"Model-View-Controller (MVC)","text":"<p>Model-View-Controller (MVC) is a software architectural pattern commonly used in the development of user interfaces. It divides an application into three interconnected components, each with distinct responsibilities, to separate internal representations of information from the ways that information is presented to and accepted from the user.</p> <p>The Model represents the data and the business logic of the application. It is responsible for managing the data, logic, and rules of the application. In an MVC application, the model directly manages the data, logic, and rules of the application, handling the retrieval, processing, and storage of data.</p> <p>The View is responsible for presenting data to the user. It displays the data that is contained in the model to the user and also sends user commands (e.g., button clicks, keyboard input) to the controller. The view is typically responsible for the layout, appearance, and user interface elements.</p> <p>The Controller acts as an interface between Model and View components. It receives user input and initiates a response by making calls to model objects. The controller interprets the input it receives from the view, then processes it (possibly updating the model), and returns the output display (view).</p> <p>MVC is widely used in web apps, with many [[Web Development Frameworks|web frameworks]] (like [[Django]], [[ASP.NET]] MVC) implementing the MVC pattern. It is also used in desktop apps and is integral to some development environments.</p>"},{"location":"misc/mvvm/","title":"MVVM","text":"<p>MVVM stands for Model-View-ViewModel. It's a software architectural pattern primarily used in building user interfaces. This pattern facilitates a clear separation of concerns, which makes it easier to manage complex user interfaces and enables more efficient code reuse and greater testability.</p> <ol> <li>Model: This represents the data and business logic of the application. It's where your data objects and business rules reside. The model notifies the ViewModel of any changes in data (usually through property notifications or observable patterns) so that the ViewModel can update the View accordingly.</li> <li>View: This is the user interface of the application. It displays the data (provided by the ViewModel) and delegates user inputs to the ViewModel. The View is usually a passive interface, waiting to be given instructions on what to display, rather than asking for data. It focuses purely on the visual elements, such as buttons, text fields, and graphics.</li> <li>ViewModel: Acting as an intermediary between the Model and the View, the ViewModel handles most of the view's logic. It receives user inputs from the View, processes them (which may involve querying or updating the Model), and then provides feedback to the View. The ViewModel transforms data from the Model in such a way that the data becomes easily manageable and presentable for the View.</li> </ol> <p>Info</p> <p>In essence, MVVM enhances the separation of the graphical user interface (the View) from the development of the business logic or back-end logic (the Model). This is particularly useful in web and mobile app development environments where the separation allows for more efficient development and testing processes, and better maintainability.</p> <p>Some of the key benefits of MVVM include:</p> <ul> <li>Improved testability: Since business logic is separated from UI code, it's easier to test the ViewModel without involving the View.</li> <li>Easier maintenance and extendability: Changes in the View do not directly affect the Model, and vice versa.</li> <li>Better support for two-way data binding: Changes in the backend data (Model) can automatically reflect in the UI (View) and user interactions with the UI can directly update the data model.</li> </ul>"},{"location":"misc/node/","title":"NodeJS","text":"<p>Node.js is an open-source, cross-platform [[JavaScript]] runtime environment that allows developers to run JavaScript on the server side. Node.js marked a significant shift in web development, enabling JavaScript to be used for server-side scripting, thereby allowing web pages to be dynamically generated on the server before being sent to the client.</p> <p>Node.js uses JavaScript for server-side scripting, unifying web application development around a single programming language, rather than different languages for server-side and client-side scripts.</p> <p>Node.js is an\u00a0open source, cross-platform runtime environment and library\u00a0that is used for running web applications outside the client\u2019s browser.</p> <p>It is used for\u00a0server-side programming, and primarily deployed for non-blocking, event-driven servers, such as traditional web sites and back-end API services, but was originally designed with real-time, push-based architectures in mind. Every browser has its own version of a JS engine, and node.js is built on Google Chrome\u2019s V8 JavaScript engine.</p> <p>In simple terms, what this means is that entire sites can be run using a unified \u2018stack\u2019, which makes development and maintenance quick and easy, allowing you to focus on meeting the business goals of the project.</p> <p>The fact that Node.js is open source means that it is free to use and constantly being tweaked and improved by a\u00a0global community of developers.</p> <p>An important thing to understand about Node.js is that it is actually neither a framework or a library - as with traditional application software -, but\u00a0JavaScript a runtime environment.</p> <p>A runtime environment (sometimes shortened to RTE) contains Web API\u2019s that a developer can access to build a code, and a JavaScript engine that parses that code. This makes it lightweight, flexible and easy to deploy, all features that will help to optimize and speed up your application project.</p> <p>Node.js operates on an asynchronous, non-blocking I/O model. This means that operations like reading files, network requests, or database operations do not block the execution of subsequent operations, making Node.js efficient and suitable for high-performance applications.</p> <p>Node.js runs on the V8 JavaScript engine, the same engine used in Google Chrome, which compiles JavaScript directly to native machine code for fast execution.</p> <p>Some common uses of NodeJS include:</p> <ul> <li>Web apps - particularly real-time apps like chat apps, online gaming and collaboration tools</li> <li>API development - ideal for building both [[REST APIs]] and [[GraphQL]] APIs</li> <li>Streaming services - its asynchronous nature makes it suitable for streaming data-intensive apps</li> <li>Microservices architecture - often used in microservice architectures due to its lightweight and modular structure</li> </ul>"},{"location":"misc/npm/","title":"npm","text":"<p>NPM, which stands for Node Package Manager, is a package manager for the [[JavaScript]] programming language and is the default package manager for the JavaScript runtime environment [[NodeJS|Node.js]]. It consists of a command-line client (<code>npm</code>), as well as an online database of public and paid-for private packages, called the npm registry.</p> <p>NPM allows developers to install, update, and manage software dependencies for their JavaScript projects. These dependencies are defined in a file called <code>package.json</code>. It provides access to hundreds of thousands of reusable packages. Developers can download packages needed for their projects and also publish their own packages to share with the community.</p> <p>NPM helps in managing different versions of packages and resolving version conflicts. <code>package.json</code> can be used to define scripts for automating various development tasks.</p> <p>Some example commands may be:</p> <pre><code>npm init\n</code></pre> <p>This command sets up a new Node.js project by creating a <code>package.json</code> file.</p> <pre><code>npm install express\n</code></pre> <p>This installs the [[express]] package, a popular Node.js framework.</p> <pre><code>npm install\n</code></pre> <p>In a project directory, this command installs all the dependencies listed in the project's <code>package.json</code> file.</p> <pre><code>npm update lodash\n</code></pre> <p>This updates the lodash package to its latest version.</p> <p>If <code>package.json</code> includes a script named <code>start</code>, it can be run with:</p> <pre><code>npm start\n</code></pre> <pre><code>npm install -g typescript\n</code></pre> <p>This installs the TypeScript compiler globally.</p> <p>In web development, NPM is used extensively for managing the multitude of libraries and frameworks that modern web applications depend on. It simplifies the process of sharing, updating, and using code across multiple projects.</p>"},{"location":"misc/o365/","title":"Office 365","text":"<p>The Microsoft Office 365 suite is a hosted, online version of the traditional installed version of Microsoft Office software. This online service is subscription-based and includes Office, Exchange Online, SharePoint Online, Lync Online and Microsoft Office Web Apps.</p> <p>The advantage of the Microsoft Office 365 suite is that the\u00a0[[Cloud Computing|cloud]] service\u00a0is provided by Microsoft and, thus, eliminates a company's IT maintenance tasks, such as patching and infrastructure support costs. For end users, the advantage is the ability to access Office 365 offerings using any device anywhere with an internet connection.</p> <p>IT administrators access the Microsoft Office 365 suite from a web-based portal to set up new user accounts, control access to features and see the status of all Office 365 services and tools.</p>"},{"location":"misc/oauth/","title":"OAuth","text":"<p>OAuth (Open Authorization) is an open standard for access delegation, commonly used to grant websites or applications access to user information on other websites without giving them the passwords. It provides a process for end-users to authorize third-party access to their server resources without sharing their credentials. </p> <p>Designed specifically for use with Hypertext Transfer Protocol ([[HTTP Protocol|HTTP]]), OAuth essentially allows an application to act on behalf of a user.</p> <p>There are two major versions \u2013 OAuth 1.0 and OAuth 2.0. OAuth 2.0, the most widely used version, is simpler and more secure than OAuth 1.0. OAuth uses \"access tokens\" granted by the resource owner (user) to the third-party application. These tokens provide restricted access to the user\u2019s resources hosted by the resource server without exposing the user's credentials.</p> <p>Roles in OAuth: - Resource Owner: The user who authorizes an application to access their account. - Client: The application that wants to access the user's account. - Authorization Server: The server that authenticates the resource owner and issues access tokens. - Resource Server: The server hosting user data and capable of accepting and responding to protected resource requests using access tokens.</p> <p>OAuth 2.0 defines several \"grant types\" (or \"flows\") for different use cases, like Authorization Code (for apps running on a web server), Implicit (for browser-based or mobile apps), Password Credentials, and Client Credentials.</p> <p>Common use cases include allowing users to log into an application using their Facebook or Google account, granting applications access to their data on another service, etc. OAuth provides a more secure alternative to the traditional practice of users sharing their credentials with an application. It also reduces the risk for service providers as they don\u2019t need to store user passwords.</p> <p>OAuth allows the resource owner to define the scope of access granted to the client, which can be limited to specific actions, data types, or resources. For long-term access, OAuth may provide a refresh token that allows clients to obtain a new access token without user interaction.</p>"},{"location":"misc/ognl/","title":"Object Graph Navigation Language","text":"<p>Object Graph Navigation Language (OGNL) is a powerful expression language used in Java-based applications, particularly associated with [[Apache Struts 2]] and other frameworks. OGNL provides a concise and flexible syntax for navigating and manipulating object graphs in [[Java]].</p> <p>OGNL serves as an expression language for evaluating expressions on object graphs. OGNL allows developers to navigate complex object structures, accessing and manipulating properties of objects within the graph.</p> <p>OGNL expressions are concise and resemble a combination of Java and [[XPath]] syntax. An example may be: <code>person.address.city</code>.</p> <p>OGNL supports various arithmetic and logical operations, enabling developers to perform calculations and make decisions within expressions. OGNL supports conditional expressions, allowing developers to create expressions with conditions like ternary operators.</p> <p>OGNL provides capabilities for working with collections, including iterating over lists and maps. OGNL is often integrated into frameworks like Apache Struts 2 for handling dynamic content and interactions in web applications. Developers can use OGNL expressions in configurations, form validations, and other aspects of a framework.</p> <p>In Apache Struts 2, OGNL is a key component for handling data binding, form submissions, and interactions between the view and the underlying Java code. Due to its powerful capabilities, OGNL usage should be carefully controlled to prevent security vulnerabilities, such as remote code execution.</p> <p>Developers can extend OGNL to support custom operations and functions, providing additional flexibility. OGNL supports null-safe navigation, allowing developers to safely navigate object graphs even when certain properties are null.</p>"},{"location":"misc/owa/","title":"Outlook Web Access","text":"<p>Outlook Web Access is a full-featured,\u00a0\u00a0email client with the look and feel of the Outlook client. With OWA, users can access their mailboxes from any Internet connection regardless of whether or not the computer is equipped with Outlook.</p> <p>OWA provides most of the same functionality found in Outlook, including the familiar, easy-to-use interface, and the essential tools needed to create a professional email (spell check, signatures, [[HTML]] support and more).</p> <p>In addition to email, OWA allows users to access their calendars, contacts, tasks and folders through a secure connection, just like they would in the office. Users can also search their old email, set up or edit out of office notifications, manage junk mail settings, and more.</p> <p>OWA also supports a wide range of file types including Word documents, Excel spreadsheets, PowerPoint slides, PDF files and more. With OWA, users can access these file types even if the program the file is derived from isn\u2019t installed on their computer.</p> <p>Intermedia hosted Exchange customers can access their mailbox through OWA by navigating to the unified login page, selecting webmail and entering their email address and password.</p> <p>OWA once applied exclusively to the online version of Outlook which came with\u00a0Microsoft Exchange Server. These days, Outlook on the web is more commonly accessed from a\u00a0[[Microsoft 365]]\u00a0or free Outlook.com account.</p>"},{"location":"misc/payara/","title":"Payara","text":"<p>Payara is an open-source application server derived from [[GlassFish]], the reference implementation of [[Java Enterprise Edition (Java EE)|Java EE]] (Java Platform, Enterprise Edition). It offers a robust, production-ready, and developer-friendly platform for building and running applications using the Java EE and [[Jakarta EE]] specifications.</p> <p>Payara Server is a fork of GlassFish, created to provide a more regularly updated and enhanced version of GlassFish, with additional enterprise-focused features and improved stability and performance. Payara supports Java EE and Jakarta EE web profile and full platform, making it suitable for running enterprise-grade Java applications.</p> <p>Payara Micro is a lightweight version of the Payara Server designed for microservices architectures and containerized environments like [[Docker]]. It\u2019s small, fast, and ideal for embedding directly in a [[Java]] application.</p> <p>Payara is optimized for cloud and container environments, offering compatibility with cloud providers and support for Docker and [[Kubernetes]]. It includes additional features for production use, such as monitoring, domain data grids, enhanced security, and clustering capabilities.</p> <p>Payara offers both a Community Edition, which is free and open source, and an Enterprise Edition, which includes additional features and support for commercial deployments. The Payara team provides regular releases and updates, ensuring that the platform stays current with bug fixes, security patches, and performance enhancements.</p> <p>Payara provides advanced monitoring and management capabilities, making it easier to manage, tune, and troubleshoot applications in production environments. Payara is designed to be developer-friendly, with easy setup, a robust administration console, and integration with popular development tools. Payara Server can be extended through its APIs and integration with other frameworks and technologies.</p>"},{"location":"misc/phar/","title":"PHP Archive (PHAR)","text":"<p>PHAR files, short for \"PHP Archive,\" are a way to package a complete [[PHP]] application or library into a single file. Introduced in PHP 5.3, PHAR files simplify the distribution and deployment of PHP applications by encapsulating entire PHP applications, including their libraries, data, and scripts, in a single archive.</p> <p>PHAR files allow bundling of all the PHP scripts, assets, and metadata needed for an application or library into a single file. This makes distribution and deployment easier and more streamlined. PHAR files can be executed directly by the PHP interpreter, similar to how [[Java Archive (JAR)|JAR]] files work in [[Java]]. This feature allows PHAR files to be used as standalone PHP applications.</p> <p>PHAR supports gzip and bzip2 compression, reducing the file size and making it more efficient for distribution. PHAR files can include a digital signature to verify the integrity of the contained files, adding a layer of security by preventing tampering. They can be used for various purposes, including as a distribution mechanism for PHP libraries, frameworks, and applications, as well as for creating self-contained command-line tools.</p> <p>PHAR files are often used to package entire PHP applications, so they can be easily distributed and run without the need for separate installation steps. Many PHP-based tools, such as [[PHPDocumentor]] or [[PHPUnit]], are distributed as PHAR files for ease of use and installation. Developers can package PHP libraries in PHAR format, allowing others to include the library in their projects without dealing with multiple files or directories.</p> <p>Creating a PHAR file involves bundling the PHP scripts and other resources, and optionally setting a stub (a small bootstrapping script) that directs the PHP interpreter on how to execute the PHAR. PHP provides a <code>Phar</code> class for creating and manipulating PHAR files programmatically.</p> <p>As with any executable file, care should be taken when running PHAR files from untrusted sources, as they can contain harmful code. Due to security implications, some server configurations might restrict the execution of PHAR files. Developers need to be aware of the deployment environment\u2019s constraints.</p>"},{"location":"misc/phpdocumentor/","title":"PHPDocumentor","text":"<p>PHPDocumentor, often styled as phpDocumentor, is a documentation generator for [[PHP]]. It is akin to [[Javadoc]] for [[Java]] or [[Doxygen]] for [[C++]], providing a way to create comprehensive documentation from the source code itself. PHPDocumentor analyzes PHP source code and generates human-readable documentation in various formats, including [[HTML]], PDF, and others.</p> <p>PHPDocumentor reads specially formatted docblocks (comments) in the PHP source code and generates documentation from these comments. This means that the documentation lives close to the code it describes. It understands and can parse different styles of docblocks, including those used by PHPDoc, Javadoc, and QtDoc.</p> <p>It automatically generates a complete API documentation of the classes, methods, functions, parameters, and more, in the PHP code. The output of the documentation can be customized using templates, allowing for flexibility in how the documentation is presented. PHPDocumentor supports a wide range of tags within docblocks, allowing developers to add structured information about parameters, return values, exceptions, and more.</p> <p>It is primarily used by PHP developers to document their code bases, making it easier for others (and themselves in the future) to understand how the code works and how to use it. For libraries and frameworks, PHPDocumentor can generate comprehensive API manuals that are useful for developers who use these libraries and frameworks.</p> <p>A PHP function with a docblock might look like this:</p> <pre><code>/**\n * Calculates the sum of two numbers.\n *\n * @param int $a The first number.\n * @param int $b The second number.\n * @return int The sum of the two numbers.\n */\nfunction sum($a, $b) {\n    return $a + $b;\n}\n</code></pre> <p>PHPDocumentor would read this docblock and generate documentation indicating that <code>sum</code> is a function that takes two integers as parameters and returns their sum, also an integer.</p>"},{"location":"misc/plc/","title":"Programmable Logic Controllers (PLC)","text":"<p>Programmable Logic Controllers (PLCs) are specialized, robust computers used in industrial automation and control systems. They play a critical role in managing the operations of machinery in manufacturing plants, assembly lines, and other industrial environments. PLCs are designed to perform a wide range of control functions in harsh industrial settings characterized by extreme temperatures, dust, and moisture.</p> <p>Programmable Logic Controllers (PLCs) are a fundamental component in various types of [[industrial control systems (ICS)]], including [[Distributed Control Systems (DCS)]] and [[Supervisory Control and Data Acquisition (SCADA)]] systems. Understanding the relationship between these systems helps in comprehending the overall structure of industrial automation and control.</p> <p>PLCs are designed to execute a series of control operations in real-time and with high reliability and precision. They can be programmed to perform a wide range of tasks, from simple control functions like turning on and off lights to complex sequential operations like controlling an automated assembly line.</p> <p>PLCs can read a variety of inputs from sensors and other devices, process them according to the programmed logic, and trigger outputs to control actuators or other machinery. Designed for industrial environments, PLCs are robust and can withstand harsh conditions, including vibration, high temperatures, and electromagnetic interference. Many PLCs are modular, allowing for the expansion of their capabilities by adding more input/output modules, communication modules, etc.</p> <p>The following is how they work:</p> <ul> <li>Input: PLCs receive data from connected sensors or input devices, like temperature sensors, limit switches, or button presses.</li> <li>Processing: The PLC processes this input data based on the pre-programmed logic or control program loaded into its memory.</li> <li>Output: Based on the processing results, the PLC sends commands to output devices like motors, pumps, valves, lights, and other actuators.</li> </ul> <p>An example of a PLC application is in a bottling plant. Sensors detect the presence of a bottle, and the PLC is programmed to fill the bottle with a precise amount of liquid, cap it, and then label it. The PLC coordinates the conveyor belts, filling mechanisms, capping machines, and labelling machines. It ensures that each bottle is processed accurately and efficiently, and can adapt the process if, for example, a bottle is missing or a fault is detected.</p> <p>The ability to reprogram PLCs for different tasks makes them highly flexible and adaptable to various industrial applications. PLCs are designed for long-term reliability, even in harsh industrial environments.</p> <p>They offer a cost-effective solution for automating complex industrial processes. PLCs often come with diagnostic capabilities, making it easier to identify and fix issues.</p>"},{"location":"misc/pom/","title":"Project Object Model (POM)","text":"<p>The Project Object Model (POM) is a fundamental concept in the [[Apache Maven]] software project management and comprehension tool. Defined in an [[Extensible Markup Language|XML]] file named <code>pom.xml</code> at the root of a Maven project, the POM includes information about the project and various configuration details used by Maven to build the project.</p> <p>The POM file specifies the project's configuration, including its dependencies, plugins, goals, version, and other settings necessary for Maven to build the project. Maven encourages a standard directory layout for projects, which can be customized in the POM file. This standardization facilitates understanding and maintaining the project.</p> <p>One of the key features of the POM is to define the dependencies required by the project. Maven automatically handles the downloading and updating of dependencies declared in the POM. The POM file configures plugins and defines specific goals to be achieved during the build process, such as compilation, testing, packaging, and deployment.</p> <p>It includes project information like the name, version, URL, developers, and contributors. This metadata can be useful for documentation and project reports. POM allows defining different build profiles for various development environments. For example, you can have separate profiles for development, testing, and production.</p> <p>In multi-module projects, a parent POM can manage common configurations for all sub-modules, promoting reusability and easier project management. The POM file defines how the project's build lifecycle is managed, including phases like <code>compile</code>, <code>test</code>, <code>package</code>, <code>install</code>, and <code>deploy</code>.</p> <p>Maven POM supports project versioning. Development versions are often marked as SNAPSHOTs, indicating that they are under active development. The POM can specify repositories from which to fetch dependencies or to which to deploy artifacts.</p>"},{"location":"misc/postfix/","title":"Postfix","text":"<p>Postfix is a popular [[Mail Transport Agent (MTA)]] used for routing and delivering email on the Internet. It is an open-source software application that serves as an alternative to [[Sendmail]], the traditional MTA for Unix-based systems.</p> <p>Postfix was designed with a strong emphasis on security, aiming to mitigate the vulnerabilities that were prevalent in other mail servers like Sendmail at the time. It uses a modular architecture where different components run with minimal privileges to reduce the impact of potential security breaches.</p> <p>Known for its performance, Postfix can handle a large volume of email efficiently, making it suitable for both small and large email systems. Compared to Sendmail, Postfix is easier to configure, with a simpler syntax in its configuration files. This accessibility makes it a preferred choice for system administrators.</p> <p>It is highly flexible and can be integrated with various databases, mail processing programs, and spam filtering solutions. Postfix is designed to be compatible with existing Sendmail configurations, allowing for easier migration from Sendmail to Postfix.</p> <p>It is primarily used as an [[Simple Mail Transfer Protocol|SMTP]] server in a variety of environments, from small-scale to large-scale email systems. Postfix routes and delivers email, handling tasks like queue management, policy implementation, and client requests.</p> <p>Postfix can be installed from the package repositories of most Unix-like operating systems. The configuration files are typically found in <code>/etc/postfix</code>. The main configuration file, <code>main.cf</code>, is well-documented and allows administrators to control various aspects of the MTA's operation.</p>"},{"location":"misc/proto/","title":"Google's Protocol Buffers (protobuf)","text":"<p>Google's Protocol Buffers (protobuf) is a method developed by Google for serializing structured data, similar to [[Extensible Markup Language|XML]] or [[JavaScript Object Notation|JSON]]. It is used for data interchange between services, applications, and systems, particularly in situations where efficiency and performance are critical. Protocol Buffers offer a compact and efficient way of encoding structured data.</p> <p>Protocol Buffers is a binary serialization format, which means it encodes data into a compact binary representation. This makes it more efficient in terms of size and speed of encoding/decoding than text-based formats like XML or JSON.</p> <p>Protocol Buffers use a language-neutral Interface Description Language (IDL) to define the schema of the data (called message types). This schema is written in <code>.proto</code> files, where you specify the data structure.</p> <p>The <code>.proto</code> files are compiled to generate code in supported languages like [[Java]], [[C++]], [[Python]], etc. This allows you to easily encode and decode structured data in a variety of programming environments.</p> <p>Protocol Buffers are used for storing and exchanging all kinds of structured information, such as in communication protocols, data storage, or API interfaces, particularly in microservices architectures.</p> <p>They are more efficient (both in terms of space and speed of encoding/decoding) than XML and JSON. They ensure forward and backward compatibility: the data structure can evolve over time while still supporting older versions of the message.</p> <p>The <code>.proto</code> files are compiled into source code using the Protocol Buffers compiler (<code>protoc</code>). This generated code provides simple accessors for each field and automatically handles the details of reading and writing the Protocol Buffers format.</p> <p>Protocol Buffers are designed to handle changes to the data schema. You can add new fields to your message formats without breaking backward compatibility with code written against the \"old\" format.</p> <p>Because of their small size and fast processing, protobuf is particularly suitable for communication between services in a distributed system, especially where bandwidth or processing speed is a concern.</p>"},{"location":"misc/qpid/","title":"Apache Qpid","text":"<p>Apache Qpid is an open-source messaging system that implements the [[Advanced Message Queuing Protocol (AMQP)]]. It provides a platform-agnostic framework for messaging between applications and services in distributed systems.</p> <p>Apache Qpid is designed to adhere to the AMQP standard, which is a messaging protocol that enables communication between applications in a reliable and interoperable manner. It defines the format of messages, the structure of the message broker, and the rules for message routing.</p> <p>Similar to RabbitMQ, Apache Qpid acts as a message broker, facilitating the exchange of messages between different components of a distributed system. It manages the storage and routing of messages between producers and consumers. Apache Qpid uses message queues to store and manage messages. Producers send messages to queues, and consumers retrieve messages from the queues. This decouples the communication between components, enabling asynchronous and scalable interactions.</p> <p>Apache Qpid supports different exchange types, including direct, fanout, topic, and headers exchanges. These exchanges determine how messages are routed to queues based on criteria such as routing keys. Messages in Apache Qpid are published with routing keys. These keys are used by exchanges to determine the destination queues for the messages.</p> <p>Apache Qpid allows the declaration of durable queues and exchanges. Durable entities survive broker restarts, ensuring that important messages are not lost. Messages in Apache Qpid can be marked as persistent, meaning they are stored on disk. This ensures that messages survive broker restarts or failures.</p> <p>Apache Qpid provides support for [[JMS]], a [[Java]]-based messaging API. This allows Java applications to interact with Qpid using the standard JMS interfaces. Apache Qpid can be integrated with [[Apache Camel]], a versatile open-source integration framework. This integration allows for the seamless exchange of messages between different systems and protocols.</p> <p>Apache Qpid supports clustering to achieve high availability. Clusters consist of multiple broker nodes, and if one node fails, others can continue processing messages. Apache Qpid provides tools for managing and monitoring the message broker. This includes features for configuring queues and exchanges, monitoring message flows, and tracking performance metrics.</p>"},{"location":"misc/rabbit/","title":"RabbitMQ","text":"<p>RabbitMQ is an open-source message broker software that facilitates communication between different components or applications. It implements the [[Advanced Message Queuing Protocol (AMQP)]] and provides a robust and scalable solution for handling messaging between distributed systems.</p> <p>RabbitMQ acts as a message broker, enabling communication between various components of a distributed system. It receives, stores, and forwards messages between producers (senders) and consumers (receivers). RabbitMQ uses message queues to store and manage messages. Producers send messages to a queue, and consumers retrieve messages from the queue. This decouples the producers and consumers, allowing for asynchronous communication.</p> <p>Exchanges receive messages from producers and route them to queues based on routing rules. RabbitMQ supports different types of exchanges, including direct, fanout, topic, and headers, allowing for flexible message routing. In RabbitMQ, messages are published to exchanges with a routing key. The routing key is used by exchanges to determine how to route the message to one or more queues.</p> <p>Bindings define the relationship between exchanges and queues. They specify which queues receive messages from a particular exchange based on routing keys. RabbitMQ follows the AMQP protocol, a standard for message-oriented middleware. This protocol defines the rules for message format, exchange types, and communication between clients and brokers.</p> <p>RabbitMQ supports a publish/subscribe messaging model. In this model, messages are sent to an exchange, and multiple queues (subscribers) can bind to that exchange to receive the messages. Consumers can acknowledge the receipt of messages to inform RabbitMQ that the message was successfully processed. This ensures reliable message delivery and processing.</p> <p>RabbitMQ allows the declaration of durable queues and exchanges. Durable queues and exchanges survive broker restarts, ensuring that important messages are not lost. Messages can be marked as persistent, meaning they are stored on disk. This ensures that messages survive broker restarts or failures.</p> <p>RabbitMQ supports clustering to achieve high availability. Clusters consist of multiple nodes, and if one node fails, others can continue processing messages. RabbitMQ can be extended with plugins to add functionality. It supports a variety of plugins, including those for authentication, authorization, and integration with other systems.</p> <p>RabbitMQ provides a web-based management interface that allows administrators to monitor and manage the broker. It includes features such as queue and exchange management, message tracing, and user management.</p>"},{"location":"misc/rdma/","title":"RDMA (Remote Direct Memory Access)","text":"<p>RDMA (Remote Direct Memory Access) is a technology that allows direct memory access from the memory of one computer to another without involving either one's operating system. This direct process enables high-throughput, low-latency networking, which is particularly beneficial in certain types of data transfer and communication scenarios.</p> <p>RDMA provides very high data transfer speeds with low latency because it bypasses the operating system's network stack, reducing CPU load and overhead. By allowing direct memory access, RDMA minimizes the time taken for data transfers, which is crucial for performance-sensitive applications. </p> <p>It facilitates efficient data movement with less CPU intervention, making it ideal for large data transfers and high-performance computing environments. RDMA offloads the work of data transfer to the network hardware (such as RDMA-capable network cards), freeing up CPU resources for other tasks.</p> <p>RDMA enables \"zero-copy\" networking, where data can be transferred from the storage of one computer directly into the memory of another without being copied between different layers of the OS.</p> <p>RDMA is widely used in HPC environments where large data sets are processed, and fast data transfer is crucial. In SANs, RDMA is used for fast data transfers between storage devices and servers. It is increasingly being adopted in cloud environments to enhance the efficiency and performance of cloud services.</p> <p>RDMA can significantly improve the performance of database operations and transaction processing systems. In network file sharing, particularly with protocols like [[SMB Direct]] and [[NFS over RDMA]], RDMA provides enhanced data transfer speeds and efficiency.</p> <p>SMB Direct is an implementation of the [[SMB 3|SMB 3.x]] protocol that utilizes RDMA for high-speed network transfers. This is particularly useful for applications like Microsoft [[Hyper-V]] and [[Microsoft SQL Server|SQL Server]], which can leverage SMB Direct for faster and more efficient access to network storage.</p> <p>RDMA requires network adapters that support RDMA, along with compatible switch infrastructure. Proper configuration and compatibility of hardware and software are necessary to fully realize the benefits of RDMA.</p>"},{"location":"misc/rfid/","title":"Radio-Frequency Identification (RFID)","text":"<p>Radio-Frequency Identification (RFID) is a technology used to identify and track tags attached to objects. It uses electromagnetic fields to automatically identify and track tags containing electronically stored information.</p> <p>An RFID system typically includes RFID tags, RFID readers, and an antenna. RFID tags contain an integrated circuit and an antenna to transmit data to the RFID reader. The reader then converts the radio waves to a more usable form of data.</p> <p>RFID tags can be either passive or active. Passive tags do not have their own power source; they receive energy from the reader's interrogating radio waves. Active tags have their own power source, usually a battery, and can transmit data over longer distances.</p> <p>RFID operates at several different frequencies, each with its own set of applications. Low-frequency (LF) RFID systems, high-frequency (HF) systems, including [[Near Field Communication (NFC)|NFC]] (Near Field Communication), and ultra-high-frequency (UHF) systems are the most common.</p> <p>RFID tags store data and transmit it to the reader. This data can include identification numbers, location information, or specifics about the product to which the tag is attached.</p> <p>RFID is used in a wide range of applications, including supply chain management, retail inventory tracking, access control (like keycards), identification (like pet microchips), and contactless payment systems.</p> <p>Unlike barcodes, RFID does not require line-of-sight to read tags. Multiple tags can be read simultaneously and from a greater distance, which significantly speeds up the scanning process.</p> <p>RFID poses unique security and privacy challenges, as tags can be read without the knowledge of the tag holder. Encryption and authentication methods are used to enhance security.</p> <p>RFID data can be integrated with other systems like [[Enterprise Resource Planning Applications|enterprise resource planning]] (ERP) systems for better data analysis and utilization.</p>"},{"location":"misc/rmi/","title":"Remote Method Invocation","text":"<p>Remote Method Invocation (RMI) is a [[Java]] API that allows an object running in one [[Java Virtual Machine (JVM)]] to invoke methods on an object running in another JVM. RMI is used primarily for building distributed applications, enabling objects to communicate directly across a network in a way that is largely indistinguishable from method calls on local objects.</p> <p>RMI allows a Java object located on one machine (the client) to invoke methods on an object (the server) located on another machine, as if the object were located on the client machine. It is used for distributed computing, where processing power and resources are spread across different networked computers.</p> <p>The architecture of RMI includes the client, the server, and the RMI registry. The registry is used for locating the remote objects. Each remote object is registered with the RMI registry using a unique name.</p> <p>In RMI, a 'stub' object on the client side represents the remote object. When a method is invoked on the stub, it forwards the request to the remote 'skeleton' object on the server side, which then invokes the method on the actual remote object. In more recent versions of Java (since Java 2), the skeleton is no longer used, but the term is sometimes still used to describe server-side RMI operations.</p> <p>RMI uses Java serialization to marshal and unmarshal parameters. The objects passed between the client and server must implement the <code>Serializable</code> interface. The RMI registry is a simple server-side naming service that allows clients to get a reference (stub) to a remote object.</p> <p>RMI includes support for [[SSL-TLS|SSL/TLS]] and can be configured to authenticate and encrypt RMI traffic. While RMI can be used in standalone applications, it also forms the basis for higher-level services provided in Java EE, such as [[Enterprise JavaBeans (EJBs)|Enterprise JavaBeans (EJB)]]. Methods invoked via RMI can throw <code>RemoteException</code> to indicate communication-related errors during the execution of a remote method call.</p> <p>RMI is suitable for distributed applications like remote monitoring and management systems, distributed data processing, and client-server applications where Java is the primary language.</p>"},{"location":"misc/rpc/","title":"Remote Procedure Call","text":"<p>Remote Procedure Call (RPC) is a protocol that one program can use to request a service from a program located on another computer in a network. RPC is used for communication between processes, typically across different machines. The main idea of RPC is to make a remote function call, which appears similar to a local function call, abstracting the details of network communication.</p> <p>RPC abstracts the complexity of network communication so that developers can focus on the logic rather than the details of the network operations. To the developer, the remote procedure call looks and behaves like a local procedure call.</p> <p>RPC typically follows a [[Client-Server Architecture|client-server]] model. The client sends a request to the server to execute a procedure, and the server returns the results of the executed procedure to the client.</p> <p>In RPC, 'stubs' are used on both the client and server sides. The client-side stub acts as if it were the server, receiving the calls, arguments, and handling the process of sending them to the server. The server-side stub receives this information, executes the procedure, and sends back the results.</p> <p>RPC involves marshalling (packing) parameters into a message format and unmarshalling (unpacking) them on the receiving side. This is necessary because the client and server might be using different architectures and data representations.</p> <p>RPC can be synchronous or asynchronous. In synchronous RPC, the client waits for the server to finish processing the call before continuing its execution. In asynchronous RPC, the client proceeds without waiting for the server response.</p> <p>RPC can be implemented over various transport protocols, such as [[TCP-IP|TCP/IP]] or [[User Datagram Protocol|UDP]], depending on the requirements like reliability and speed. Some RPC systems use an Interface Definition Language (IDL) to define the interface between the client and the server.</p> <p>RPC is used in distributed computing environments, client-server architectures, microservices architectures, and cloud computing services.</p> <p>There are various implementations and variants of RPC, including [[XML-RPC]] (where the procedure calls are made using [[Extensible Markup Language|XML]]), [[JSON-RPC]] (using [[JavaScript Object Notation|JSON]]), and gRPC (developed by Google, using Protocol Buffers and HTTP/2).</p> <p>Security is an important aspect of RPC, as data is transferred over networks. Implementations often include authentication, encryption, and other security mechanisms.</p>"},{"location":"misc/rtf/","title":"RTF","text":"<p>RTF, which stands for Rich Text Format, is a document file format developed by Microsoft. It is used for cross-platform document interchange, primarily between Microsoft products and other applications. RTF files can be read and written by most word processing software, making them useful for sharing formatted documents across different programs and operating systems.</p> <p>RTF supports various text formatting options, such as bold, italics, different fonts and sizes, text alignment, bullet points, and more. Since RTF is a common standard, it's supported by various word processors across different platforms, including Microsoft Word, WordPad, Apple Pages, LibreOffice Writer, and others.</p> <p>RTF can include embedded images and objects from other applications, though more complex objects may not always be rendered perfectly across different word processors. RTF files are fundamentally plain text, which makes them human-readable and editable with simple text editors. The formatting is encoded using special RTF commands.</p> <p>RTF is used when there's a need to share a document between different word processing programs or operating systems while preserving basic formatting. It's suitable for creating simple documents without the need for complex formatting and features available in more advanced word processing programs. RTF can serve as a fallback interchange format when more sophisticated formats like DOCX or ODT might not be supported or practical.</p> <p>An RTF file could contain a text like:</p> <pre><code>{\\rtf1\\ansi{\\fonttbl\\f0\\fswiss Helvetica;}\\f0\\pard\nThis is some {\\b bold} text.\\par\n}\n</code></pre> <p>Info</p> <p>This example shows RTF-encoded text where \"This is some bold text\" appears in a Helvetica font, with the word \"bold\" in boldface.</p> <p>Compared to more modern formats like DOCX, RTF is less feature-rich and might not support complex layouts, advanced styling, or certain types of embedded multimedia content. Like many document formats, RTF files can potentially contain harmful scripts or embedded objects, though modern word processors typically have security measures to handle such risks.</p>"},{"location":"misc/rtus/","title":"Remote Terminal Units (RTUs)","text":"<p>Remote Terminal Units (RTUs) are electronic devices used in [[industrial control systems (ICS)]] to connect various hardware in the field with the control system software in a central or master location. They are crucial components in [[Supervisory Control and Data Acquisition (SCADA)]] systems, playing a key role in monitoring and controlling equipment in remote or hard-to-reach areas.</p> <p>RTUs collect data from sensors and other field instruments, and control physical equipment via output signals, such as opening or closing valves or breakers. They communicate with a central SCADA system or other control systems, transmitting collected data and receiving control commands.</p> <p>RTUs are designed to operate reliably in harsh environmental conditions, such as extreme temperatures, humidity, or electromagnetic interference, common in remote industrial locations. They can perform some control functions autonomously, based on pre-programmed thresholds or conditions, even if communication with the central system is temporarily lost.</p> <p>The process of how they work is as follows:</p> <ul> <li>RTUs are installed at remote sites where they interface with sensors and actuators.</li> <li>They continuously collect data from these field devices, such as temperature, pressure, flow rate, or equipment status.</li> <li>This data is then processed, stored, and sent over a communication network (like radio, satellite, or cellular networks) to a central SCADA system.</li> <li>The SCADA system uses this data for overall monitoring and control, and it can send commands back to the RTU to control field devices.</li> </ul> <p>Remote Terminal Units (RTUs) are typically used for remote data acquisition and control in wide geographical areas, often where ruggedness and reliability over long distances and in challenging environments are required.</p> <p>[[Programmable Logic Controllers (PLC)|Programmable Logic Controllers (PLCs)]], on the other hand, are more commonly used for real-time control in industrial environments like manufacturing plants, where complex logic control is needed.</p>"},{"location":"misc/salesforce/","title":"Salesforce","text":"<p>Salesforce is a cloud-based software company that provides [[Customer Relationship Management (CRM) Software]] service and also offers a suite of enterprise applications focused on customer service, marketing automation, analytics, and application development. It's known for its flexibility and wide array of functionalities, including sales management, customer service, marketing automation, and business analytics.</p> <p>Salesforce offers a comprehensive suite of applications focused on enhancing business activities related to customer engagement and management.</p> <p>At its core, Salesforce provides CRM solutions that help businesses manage their interactions with current and potential customers. This includes tracking customer activity, market trends, customer complaints, and communications. Salesforce automates various sales and marketing processes, streamlining tasks like lead generation, sales forecasting, email campaigns, and customer journey mapping.</p> <p>The platform offers tools to improve customer support services, including automated case tracking, customer support ticketing, and a knowledge base for customer self-service. With Salesforce's platform, businesses can develop custom applications tailored to their specific needs using Salesforce's proprietary framework.</p> <p>Salesforce provides powerful analytics tools that allow businesses to track and analyze their performance metrics effectively. Being cloud-based, Salesforce offers the flexibility of remote access, ensuring that customer data and business operations can be managed from anywhere. Salesforce's [[AppExchange]] is a marketplace for third-party applications that integrate with the Salesforce platform, expanding its functionality.</p>"},{"location":"misc/saml/","title":"SAML (Security Assertion Markup Language)","text":"<p>SAML (Security Assertion Markup Language) is an open standard for exchanging authentication and authorization data between an [[Trusted Identity Provider (IdP)|identity provider (IdP)]] and a [[Service Provider (SP)]]. It is widely used for enabling [[Single Sign-On (SSO)]] for web applications, allowing users to log in once and gain access to multiple systems without needing to re-authenticate.</p> <p>SAML is based on [[Extensible Markup Language|XML]] for data exchange and is used primarily for web-based authentication. The XML-based framework allows different systems to communicate authentication and authorization information securely.</p> <p>Components of SAML:</p> <ul> <li>Assertion: This is the XML document that the identity provider sends to the service provider. It contains the authentication statement (proof of a user's identity), attributes (user information), and an optional authorization decision.</li> <li>Identity Provider (IdP): The system or service that authenticates the user and sends the SAML Assertion to the service provider.</li> <li>Service Provider (SP): The system or service that receives the SAML Assertion and provides access to the user based on the assertion.</li> </ul> <p>This is how SAML works:</p> <ul> <li>A user attempts to access a resource or service (the service provider).</li> <li>The service provider requests an authentication assertion from the identity provider.</li> <li>The identity provider authenticates the user and sends a SAML Assertion back to the service provider.</li> <li>The service provider validates the assertion and grants access to the user.</li> </ul> <p>SAML is commonly used to enable SSO, allowing users to log in with a single ID to gain access to a range of systems and applications, improving security and user experience. SAML supports various security measures, such as digital signatures and encryption, to ensure the integrity and confidentiality of the exchanged data.</p> <p>Being an open standard, SAML can be implemented by various vendors, ensuring interoperability between different systems and applications for authentication and authorization. SAML is key in identity federation, enabling organizations to share identity information across multiple domains securely.</p>"},{"location":"misc/sapa/","title":"SAP Applications","text":"<p>SAP applications refer to a range of software solutions developed by SAP SE, a German multinational software corporation. SAP is one of the world's leading providers of [[Enterprise Resource Planning Applications|enterprise resource planning]] (ERP) and related applications. </p> <p>These applications are used by businesses of all sizes to manage business operations and customer relations.</p> <ol> <li>Enterprise Resource Planning (ERP):<ul> <li>SAP ERP (formerly SAP R/3 and SAP ECC): A comprehensive ERP system that integrates all areas of business including finance, HR, manufacturing, supply chain, services, procurement, and others.</li> <li>SAP S/4HANA: The next-generation ERP suite designed for in-memory computing, providing enhanced performance and advanced analytics. It's available both in the cloud and on-premises.</li> </ul> </li> <li>Customer Relationship Management (CRM):<ul> <li>SAP C/4HANA (formerly SAP Hybris): A suite of solutions to improve customer experience, including marketing, sales, commerce, and customer service.</li> </ul> </li> <li>Supply Chain Management (SCM):<ul> <li>SAP Integrated Business Planning (IBP): For real-time supply chain planning.</li> <li>SAP Extended Warehouse Management (EWM): Advanced capabilities for warehouse management.</li> </ul> </li> <li>Human Capital Management (HCM):<ul> <li>SAP SuccessFactors: A cloud-based HCM suite for core HR processes, performance, recruitment, learning, and employee experience management.</li> </ul> </li> <li>Business Intelligence (BI):<ul> <li>SAP BusinessObjects: A suite of front-end applications that allow business users to view, sort, and analyze business intelligence data.</li> </ul> </li> <li>Data Management and Databases:<ul> <li>SAP HANA: An in-memory, column-oriented, relational database management system that integrates data processing and application platform capabilities.</li> <li>SAP ASE (Adaptive Server Enterprise), previously known as Sybase ASE, for high-performance transaction-based applications.</li> </ul> </li> <li>Product Lifecycle Management (PLM):<ul> <li>Solutions for managing product life cycles, from design to service.</li> </ul> </li> <li>Enterprise Performance Management (EPM):<ul> <li>Tools for budgeting, forecasting, and financial consolidation.</li> </ul> </li> <li>SAP Fiori: A design language and user experience approach for all SAP applications, providing a consistent, modern interface across devices.</li> <li>Cloud-Based Solutions:<ul> <li>SAP Cloud Platform: A platform-as-a-service (PaaS) for extending, integrating, and building applications in the cloud.</li> </ul> </li> </ol>"},{"location":"misc/sax/","title":"SAX (Simple API for XML)","text":"<p>SAX (Simple API for XML) is a popular, event-driven, stream-based [[APIs|API]] for processing [[Extensible Markup Language|XML]] documents in [[Java]]. Unlike the [[Document Object Model]] (DOM), SAX does not load the entire XML document into memory. Instead, it reads the document sequentially and triggers events (such as the start and end of elements) that can be handled by the application. This approach makes SAX highly efficient for parsing large XML files.</p> <p>SAX is based on an event-driven model where it triggers different events as it reads through the XML document. These events include the start and end of elements, character data, and processing instructions.</p> <p>Since SAX does not keep the entire XML document in memory, it is more memory-efficient than DOM, especially for large XML files. This makes it suitable for applications with memory constraints or for processing very large XML documents.</p> <p>SAX reads XML documents sequentially from start to end. It does not allow random access to elements in the XML document, which can be a limitation for certain use cases. A SAX parser invokes callback methods corresponding to the XML document events. Developers implement these methods in a handler class to process the XML data.</p> <p>SAX is generally faster than DOM for reading XML documents because it doesn\u2019t incur the overhead of building an in-memory tree representation of the XML document. Unlike DOM, SAX does not provide the capability to create or modify XML documents. It is a read-only API.</p> <p>SAX allows for robust error handling during parsing. The parser can report warnings, errors, and fatal errors encountered in the XML document. SAX is ideal for scenarios where you need to read and process large XML documents or streams without modifying them, such as data extraction and XML validation.</p> <p>Implementing a SAX parser can be more complex than using DOM because the developer must manage the application state and handle the parsing events appropriately. SAX is widely used in [[Java]] applications and is part of the standard Java API (in the <code>javax.xml.parsers</code> package).</p>"},{"location":"misc/saxon/","title":"Saxon","text":"<p>Saxon refers to two related software products developed by Saxonica:</p> <p>Saxon-HE (Home Edition): Saxon-HE is an open-source [[XSLT (Extensible Stylesheet Language Transformations)]] and [[XQuery]] processor. It is written in [[Java]] and provides implementations of the XSLT 2.0, XSLT 3.0, and XQuery 3.1 specifications. Saxon-HE is freely available for download and can be used in both commercial and non-commercial projects. It is widely used for transforming [[Extensible Markup Language|XML]] documents and querying XML data.</p> <p>Saxon-PE (Professional Edition) and Saxon-EE (Enterprise Edition): Saxon-PE and Saxon-EE are commercial versions of the Saxon processor that provide additional features and capabilities compared to the free Saxon-HE version. These editions include features such as schema-aware XSLT and XQuery processing, streaming transformations, and enhanced performance optimizations. Saxon-EE also supports XSLT 3.0 and XQuery 3.1 standards.</p> <p>Saxon is known for its high level of standards compliance, performance, and feature-rich implementation of XSLT and XQuery specifications. It is widely used in various industries and projects for XML processing tasks, including transforming XML documents into different formats, querying XML data, and applying stylesheets to achieve specific presentation or transformation requirements.</p>"},{"location":"misc/scada/","title":"Supervisory Control and Data Acquisition (SCADA)","text":"<p>Supervisory Control and Data Acquisition (SCADA) is a system used for controlling industrial processes and infrastructure systems. SCADA systems are crucial for managing large-scale, complex processes that require real-time monitoring and control, often spread over large geographical areas. These systems are widely used in utility management (like water and power distribution), manufacturing, and processing industries.</p> <p>SCADA (Supervisory Control and Data Acquisition) systems play a crucial role in the broader landscape of [[industrial control systems (ICS)]], interacting with and often complementing other systems like [[Distributed Control Systems (DCS)]] and Programmable Logic Controllers (PLC).</p> <p>Some key components include:</p> <ol> <li>[[Human-Machine Interface (HMI)]]: The interface through which human operators interact with the SCADA system, monitoring processes, and issuing commands.</li> <li>Supervisory Computers: These are the central processing units that communicate with the field devices and gather data. They also send control commands to the field.</li> <li>[[Remote Terminal Units (RTUs)]] and [[Programmable Logic Controllers (PLC)|Programmable Logic Controllers (PLCs)]]: RTUs and PLCs are located at remote sites and are responsible for interfacing with sensors and actuators, converting sensor signals to digital data, and sending control commands.</li> <li>Communication Network: This network facilitates data exchange between the supervisory computers and the field devices (RTUs/PLCs).</li> <li>Data Acquisition System: This system collects, processes, and stores the data for later use.</li> </ol> <p>The following is how SCADA works:</p> <ul> <li>Data Collection: RTUs and PLCs collect data from sensors in the field and send it to the central supervisory system.</li> <li>Data Processing: The supervisory system processes this data, which can then be displayed on the HMI, alerting operators to current conditions or issues.</li> <li>Control: Operators can issue control commands through the HMI, which are then relayed to the RTUs and PLCs to implement changes in the process or system.</li> <li>Automation: SCADA systems can also automate responses to certain conditions without human intervention, based on predefined parameters.</li> </ul> <p>SCADA systems provide comprehensive monitoring and control over large-scale processes, leading to increased efficiency. They improve safety by enabling the remote operation of dangerous processes and provide alarms and shutdown mechanisms in case of failures.</p> <p>SCADA systems collect vast amounts of data, which can be analyzed to improve operational efficiency and aid in predictive maintenance.</p>"},{"location":"misc/scvmm/","title":"System Center Virtual Machine Manager","text":"<p>System Center Virtual Machine Manager (SCVMM), part of Microsoft's System Center suite, is a comprehensive management solution for virtualized data center environments. It allows for efficient management of [[Virtual Machines|virtual machine]] (VM) infrastructure and resources across multiple virtualization hosts, including [[Hyper-V]], VMware, and Citrix XenServer environments.</p> <p>SCVMM provides a central platform to manage virtual machine infrastructure, streamlining tasks such as VM creation, deployment, and maintenance. It supports management of multiple virtualization platforms, including Microsoft Hyper-V, VMware vSphere, and Citrix XenServer, allowing for flexibility and interoperability in virtualized environments.</p> <p>SCVMM enables rapid deployment of VMs using templates, which can be pre-configured with specific settings, software, and policies. It offers advanced capabilities to manage and optimize virtual networks and storage associated with VMs, including features like dynamic optimization and storage migration.</p> <p>It facilitates the creation and management of private clouds, providing tools to pool and allocate resources efficiently while maintaining control and compliance. SCVMM integrates with [[Windows PowerShell]], allowing administrators to automate repetitive tasks and customize management operations through scripting.</p> <p>SCVMM is often used alongside other System Center products like System Center Operations Manager (SCOM) for monitoring, System Center Configuration Manager (SCCM) for configuration, and System Center Orchestrator for automation, providing a comprehensive management suite for enterprise IT environments.</p>"},{"location":"misc/sendmail/","title":"Sendmail","text":"<p>Sendmail is a widely used [[Mail Transport Agent (MTA)]] in Unix-based systems. It's a powerful, open-source software application that's responsible for routing and delivering email messages from one host to another, using the [[Simple Mail Transfer Protocol]] (SMTP).</p> <p>Sendmail transfers emails from the sending system to the recipient's mail server, handling decisions about routing based on various factors like domain names and network conditions. It is known for its highly configurable nature, allowing extensive control over how email is processed, routed, and delivered.</p> <p>The configuration of Sendmail can be quite complex, often requiring in-depth knowledge of system administration and the Sendmail configuration language. It can handle a large volume of email traffic and is capable of dealing with complex mail-processing operations, making it suitable for large organizations.</p> <p>Over the years, Sendmail has incorporated numerous security features to handle vulnerabilities and protect against threats like spamming and email relay abuse.</p> <p>Sendmail was widely adopted in the early days of email and is still in use, especially in legacy systems. However, its complexity and the rise of alternative MTAs (like [[Postfix]] and [[Exim]]) have led to a decrease in its popularity. It's often used in large-scale and complex email environments due to its robustness and extensive configurability.</p>"},{"location":"misc/seo/","title":"SEO","text":"<p>SEO stands for Search Engine Optimization. It's the practice of increasing the quantity and quality of traffic to a website through organic search engine results. The goal of SEO is to improve a site's visibility in the unpaid (organic) section of search engine results, making it more likely for the site to be visited by users.</p> <p>Some key elements include:</p> <ol> <li>Keywords: Identifying and using relevant keywords that users are searching for. These keywords should be integrated into the website's content.</li> <li>Content Quality: Creating high-quality, useful, and informative content that meets the needs of searchers. This includes articles, videos, and other forms of media.</li> <li>User Experience (UX): Designing a website that's easy to navigate and engaging for users.</li> <li>Site Speed and Performance: Ensuring the website loads quickly and performs well on different devices and browsers.</li> <li>Mobile Responsiveness: Optimizing the site for mobile devices, considering more users are browsing on smartphones and tablets.</li> <li>Backlinks: Acquiring high-quality links from other reputable websites.</li> <li>Social Signals: The presence and engagement on social media platforms can indirectly influence SEO.</li> <li>Local SEO: For businesses serving specific geographical areas, optimizing for local search is crucial.</li> </ol> <p>As an example, consider a local bakery that wants to attract more customers through its website. The bakery implements SEO by:</p> <ul> <li>Researching keywords that potential customers might use, like \u201cfreshly baked bread in [City Name]\u201d or \u201cbest chocolate cake near me\u201d.</li> <li>Updating its website with high-quality content, such as blog posts about different types of bread, recipes, and the benefits of fresh bakery items.</li> <li>Ensuring the website loads quickly and is easy to navigate.</li> <li>Creating a Google My Business profile to appear in local searches and maps.</li> <li>Encouraging satisfied customers to leave positive reviews on various online platforms.</li> </ul> <p>SEO intersects with cybersecurity in several ways:</p> <ol> <li>SEO Spam &amp; Malware: Hackers might inject malicious content or links into a website (often through outdated plugins/themes or weak passwords). This practice, known as SEO spam, can harm the site\u2019s ranking and reputation.</li> <li>Phishing and Scam Sites: Cybercriminals create websites optimized for SEO to appear legitimate and rank high in search results. They use these sites to conduct [[phishing]] attacks or scams.</li> <li>Negative SEO Attacks: Competitors or malicious actors might use SEO techniques to harm a site's ranking, like creating toxic backlinks or duplicating content.</li> <li>Search Engine Poisoning: Attackers manipulate SEO to promote malicious websites in search results, often to distribute malware or conduct phishing.</li> </ol>"},{"location":"misc/serial/","title":"Serialization","text":"<p>Serialization\u00a0is the process of converting complex data structures, such as objects and their fields, into a \"flatter\" format that can be sent and received as a sequential stream of bytes. Serializing data makes it much simpler to:</p> <ul> <li>Write complex data to inter-process memory, a file, or a database</li> <li>Send complex data, for example, over a network, between different components of an application, or in an [[APIs|API]] call</li> </ul> <p>Crucially, when serializing an object, its state is also persisted. In other words, the object's attributes are preserved, along with their assigned values.</p>"},{"location":"misc/serverless/","title":"Serverless Architecture","text":"<p>Serverless architecture is an approach to software design that allows developers to build and run services without having to manage the underlying infrastructure. Developers can write and deploy code, while a cloud provider provisions servers to run their applications, databases, and storage systems at any scale. </p> <p>Servers allow users to communicate with an application and access its business logic, but managing servers takes considerable time and resources. Teams have to maintain the server hardware, take care of software and security updates, and create backups in case of failure. </p> <p>By adopting serverless architecture, developers can offload these responsibilities to a third-party provider, enabling them to focus on writing application code.</p> <p>One of the most popular serverless architectures is Function as a Service (FaaS), where developers write their application code as a set of discrete functions. Each function will perform a specific task when triggered by an event, such as an incoming email or an [[HTTP Protocol|HTTP]] request. </p> <p>After the customary stages of testing, developers then deploy their functions, along with their triggers, to a cloud provider account. When a function is invoked, the cloud provider either executes the function on a running server, or, if there is no server currently running, it spins up a new server to execute the function. </p> <p>This execution process is abstracted away from the view of developers, who focus on writing and deploying the application code.</p>"},{"location":"misc/servlets/","title":"Java Servlets","text":"<p>Java Servlets are server-side [[Java]] programs that process and handle client requests and generate dynamic web content. They are a fundamental technology for Java-based web application development, providing a robust and scalable way to extend the capabilities of web servers.</p> <p>Servlets run on a web server or an application server, handling client requests received over [[HTTP Protocol|HTTP]] and generating responses sent back to the client. Unlike client-side Java applets, servlets do not run in a web browser.</p> <p>Servlets are used to create dynamic web content, such as [[HTML]], [[Extensible Markup Language|XML]], or [[JavaScript Object Notation|JSON]], in response to client requests. They can also forward requests to other server-side resources (like [[JavaServer Pages (JSP)|JSPs]] or other servlets) for processing.</p> <p>A servlet goes through specific lifecycle phases managed by the servlet container: initialization (<code>init</code> method), handling client requests (<code>service</code> method), and termination (<code>destroy</code> method).</p> <p>Servlets are managed by a component called a servlet container, which is part of a web server or an application server like [[Apache Tomcat]]. The container handles the lifecycle of servlets, network communication, and interaction with other web resources.</p> <p>Servlets offer a fast, efficient, and platform-independent way to build web applications. They can maintain state across multiple requests (session management), interact with databases, and integrate with other Java technologies.</p> <p>The Java Servlet API provides interfaces and classes for writing servlets. The <code>HttpServlet</code> class is commonly extended to create HTTP-specific servlets. Servlets are often used in conjunction with JavaServer Pages (JSP). While JSPs simplify writing HTML and other output, servlets handle more complex processing tasks.</p> <p>Servlets are deployed as part of a web application, usually packaged in a [[WAR (Web Application Archive)]] file, and deployed to a servlet container.</p>"},{"location":"misc/sgml/","title":"Standard Generalized Markup Language (SGML)","text":"<p>SGML, or Standard Generalized Markup Language, is a standard for defining generalized markup languages for documents. ISO 8879, which was first published in 1986, defines SGML. It's a meta-language in which one can define markup languages for documents. SGML is not a document language in itself but a description of how to specify document languages.</p> <p>SGML allows users to define their own markup languages for specific document types. This flexibility makes it suitable for a wide range of applications in different industries. SGML focuses on describing the structure and content of a document rather than its presentation. This approach separates the content from the formatting, enabling the same document to be presented in various ways.</p> <p>SGML is best known as the parent language of [[HTML]] (HyperText Markup Language) and XML ([[eXtensible Markup Language]]). Both HTML and XML are derived from SGML, inheriting its principles of markup and structure definition.</p> <p>SGML has been widely used in industries for technical documentation, where maintaining document structure and consistency is crucial. It's used in publishing for encoding and exchanging documents, especially where different document types and complex structures are involved. SGML has been used by government agencies and in defense systems for documentation purposes, given its ability to handle complex and structured documents.</p> <p>With the rise of the web, HTML (a simpler SGML application) and later XML became more popular for many of the purposes SGML was used for. XML offers many of the same advantages as SGML but in a simpler format, making it more suitable for web applications. However, SGML's legacy lives on through XML and HTML, which continue to play a fundamental role in the structure of the web and data interchange.</p> <p>First, an SGML declaration defines the rules for the markup language. Then, a [[Document Type Definition (DTD)]] specifies the structure of a particular type of document. Here's a hypothetical example:</p>"},{"location":"misc/sgml/#sgml-declaration","title":"SGML Declaration","text":"<p>This part is often predefined and specifies the syntax rules for the SGML application.</p> <pre><code>&lt;!SGML \"ISO 8879-1986\"&gt;\n</code></pre>"},{"location":"misc/sgml/#document-type-definition-dtd","title":"Document Type Definition (DTD)","text":"<p>Suppose we are defining a simple article type:</p> <pre><code>&lt;!DOCTYPE article [\n&lt;!ELEMENT article (title, body)&gt;\n&lt;!ELEMENT title (#PCDATA)&gt;\n&lt;!ELEMENT body (p+)&gt;\n&lt;!ELEMENT p (#PCDATA)&gt;\n]&gt;\n</code></pre> <p>In this DTD:</p> <ul> <li><code>article</code> is the root element, containing <code>title</code> and <code>body</code>.</li> <li><code>title</code> contains parsed character data (<code>#PCDATA</code>).</li> <li><code>body</code> consists of one or more paragraphs (<code>p</code>).</li> <li><code>p</code> represents a paragraph.</li> </ul>"},{"location":"misc/sgml/#sgml-document-example","title":"SGML Document Example","text":"<p>Based on the above DTD, an SGML document might look like this:</p> <pre><code>&lt;article&gt;\n    &lt;title&gt;Example Article&lt;/title&gt;\n    &lt;body&gt;\n        &lt;p&gt;This is the first paragraph of the example article.&lt;/p&gt;\n        &lt;p&gt;This is the second paragraph.&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/article&gt;\n</code></pre> <p>SGML itself is rarely used directly for documents; instead, it defines the rules for markup languages. The most famous application of SGML is HTML. SGML is highly flexible and can be used to define markup languages with complex structures, suitable for various industries and applications. The syntax and structure can become quite complex, especially for large DTDs in professional environments.</p>"},{"location":"misc/sharepoint/","title":"SharePoint","text":"<p>SharePoint is a web-based collaboration and document management platform developed by Microsoft. It's part of the Microsoft Office suite of products but is also available as a standalone product. SharePoint is designed to facilitate collaboration, information sharing, and document management within organizations, making it a popular choice for enterprise-level content management and intranet portals.</p> <p>SharePoint allows teams to create, store, and manage documents in a centralized location. It supports version control, document check-in/check-out, and sharing capabilities. Organizations use SharePoint to create internal portals where employees can access company news, announcements, shared resources, and collaborative tools.</p> <p>SharePoint can automate business processes with built-in workflow capabilities, streamlining tasks like document approvals, custom business processes, and task assignments. It integrates seamlessly with other Microsoft Office products, such as Word, Excel, and PowerPoint, enhancing productivity and collaboration.</p> <p>SharePoint can be customized to meet specific organizational needs. It supports custom development, allowing businesses to build tailored solutions on top of the SharePoint platform. It offers robust search features, making it easy to find documents, sites, and people within the organization.</p>"},{"location":"misc/shopify/","title":"Shopify","text":"<p>Shopify is an ecommerce platform you can use to build an online store. It allows you to sell both online with your own website and/or in person using a point-of-sale app. Shopify is easy for everyone to use, from beginner dropshippers to high-growth D2C brands.\u00a0</p> <p>Shopify works by unifying your online and retail sales on a single platform. With Shopify, you can bridge functions like inventory, marketing, payments, and shipping. This enables you to streamline your business and integrate any tools you need.</p> <p>Shopify is cloud-based software, meaning you can access it from any internet-enabled device. Plus, it\u2019s a fully hosted ecommerce solution, which means Shopify merchants do not have to worry about hosting their own website.</p>"},{"location":"misc/sid/","title":"Windows SID (Security Identifier)","text":"<p>A Windows Security Identifier (SID) is a unique value of variable length that is used to identify a security principal or security group in Windows operating systems. Security principals can be users, groups, and processes controlled by the operating system.</p> <p>Each account or group on a Windows system is assigned a unique SID when it is created, and this SID is used to control access to various resources, including files, folders, registry keys, and more.</p> <p>The SID is unique to each user or group, and is different even for accounts or groups with the same name on different systems. This uniqueness is crucial for maintaining security and access rights across the network. A SID is a string value that consists of several parts, including a revision level, an identifier authority value, and a set of subauthority values.</p> <p>The structure might look something like <code>S-1-5-21-1180699209-877415012-3182924384-1004</code>.</p> <p>SIDs are used in access control lists (ACLs) to define permissions on various objects within Windows, such as files, folders, and registry keys.</p> <p>There are certain SIDs that are predefined and used across Windows systems, such as <code>S-1-5-18</code> for the Local System account, <code>S-1-5-32-544</code> for the Administrators group, and others. These well-known SIDs are consistent across all versions of Windows.</p> <p>When setting permissions, the system translates account names into their corresponding SIDs. Access checks are performed against these SIDs. In security logs and audit trails, SIDs are recorded to track activities of users and groups. Understanding SIDs is important in penetration testing and hacking, as certain attacks may involve impersonating SIDs of privileged accounts or groups.</p>"},{"location":"misc/soa/","title":"Service-Oriented Architecture (SOA)","text":"<p>Service-Oriented Architecture (SOA) is an architectural pattern in software design where services are provided to other components by application components, through a communication protocol over a network. The basic principles of SOA are to allow easy cooperation of a large number of computers that are connected over a network.</p> <p>In SOA, a service is a well-defined, self-contained function that remains consistent and independent from the context or state of other services. Services in SOA are loosely coupled. This means that they interact with each other through simple, universal interfaces without needing to know a lot about each other.</p> <p>SOA facilitates different services to communicate with each other and share data and processes, regardless of the underlying technology or the programming language they are written in. This interoperability is often achieved through the use of web services. Services in SOA are designed to be reused, which reduces redundancy and allows for the efficient use of existing services to create new applications.</p> <p>Communication among services typically occurs over standard protocols, such as [[HTTP Protocol|HTTP]]/[[HTTPS Protocol|HTTPS]], allowing services to be accessible over the web. SOA enables the building of scalable and flexible software systems. Services can be added or modified independently without impacting other parts of the system.</p> <p>SOA aims to align business processes and goals with IT infrastructure, enabling more adaptive and agile business practices. SOA does not depend on any specific technology, which allows for integration of various technologies within a single architecture.</p> <p>Web services using [[SOAP]] (Simple Object Access Protocol) and [[REST APIs|REST]] (Representational State Transfer) are common implementations of SOA principles. In many SOA implementations, an [[Enterprise Service Bus (ESB)]] is used to facilitate communication and integration between different services.</p>"},{"location":"misc/soap/","title":"SOAP","text":"<p>Simple Object Access Protocol (SOAP) is a message specification for exchanging information between systems and applications. When it comes to application programming interfaces ([[APIs]]), a SOAP API is developed in a more structured and formalized way. </p> <p>Think of SOAP as being like the national postal service: It provides a reliable and trusted way to send and receive messages between systems (and within enterprise applications). It is older, established, and dependable\u2014but it can be slower than competing architectural styles like [[REST APIs|REST]].</p> <p>SOAP (also known as Simple Object Access Protocol) is a secure way to build APIs, and it works by encoding data in the [[Extensible Markup Language|XML]] format. REST (Representational State Transfer) APIs are more flexible, and they support data transfer in different formats, including XML, [[HTML]], [[Clear-Text|plain text]],\u00a0[[JavaScript Object Notation|JSON]]], and more. </p>"},{"location":"misc/soapaction/","title":"SOAPAction","text":"<p><code>SOAPAction</code> is a header in the [[SOAP|Simple Object Access Protocol (SOAP)]] used in web services. SOAP is a protocol for exchanging structured information in the implementation of web services in computer networks. It uses [[Extensible Markup Language|XML]] to format its messages, relies on application layer protocols, typically [[HTTP Protocol|HTTP]] or [[Simple Mail Transfer Protocol|SMTP]], for message negotiation and transmission, and offers a way to communicate between applications running on different operating systems.</p> <p>The <code>SOAPAction</code> HTTP header field is used to indicate the intent of the SOAP HTTP request. It is a mechanism to express the specific action to be performed by the SOAP message, often correlating to a particular operation or method in the web service.</p> <p>The <code>SOAPAction</code> header is part of the HTTP headers in a SOAP message. It is a URI (Uniform Resource Identifier) that identifies the intent of the SOAP message. The format typically looks like this:</p> <pre><code>SOAPAction: \"http://example.com/soap/actionUri\"\n</code></pre> <p>In SOAP-based web services, different operations provided by the service can be identified using the <code>SOAPAction</code> header. This helps the server to appropriately route the SOAP message to the correct service handler or operation. In SOAP 1.1, the <code>SOAPAction</code> header was mandatory, but in SOAP 1.2, it was made optional and its use is considered a best practice rather than a requirement. This change was due to the evolution of web services and the need for more flexibility in the way SOAP messages are processed.</p> <p>While <code>SOAPAction</code> is useful for routing and processing SOAP messages, it should be noted that the reliance on [[HTTP headers]] can have security implications. It's important for services to properly validate and handle <code>SOAPAction</code> headers to prevent issues like [[SOAPAction Spoofing]] or injection attacks.</p> <p>In a web service where multiple operations are available, the <code>SOAPAction</code> header can be used to distinguish which specific request or action the SOAP message is intended for, especially when multiple actions are available at the same endpoint URL. The <code>SOAPAction</code> header can also be important for interoperability purposes, ensuring that different software systems can effectively communicate and understand the purpose of each SOAP message.</p>"},{"location":"misc/sse/","title":"Server-Sent Events (SSE)","text":"<p>Server-sent Events (SSE) is a technology where a browser receives automatic updates from a server via [[HTTP Protocol|HTTP]] connection. SSE is used to push real-time updates from the server to the client over a single, long-held HTTP connection. It's a part of HTML5 and is a simple way to send unidirectional data from the server to the client.</p> <p>Unlike [[WebSockets]] which provide full-duplex communication, SSE is designed for unidirectional communication from the server to the client. This makes SSE simpler and more efficient for scenarios where only server-to-client communication is required.</p> <p>SSE is used for applications that require real-time data from the server, such as live news feeds, sports scores, social media updates, or any other form of real-time data streaming. Once established, the SSE connection remains open, allowing the server to send data to the client at any time without the client having to make a new request each time.</p> <p>SSE operates over standard HTTP and does not require a special protocol or server implementation. This makes it compatible with existing web infrastructure. SSE typically handles text-based data (like UTF-8) and sends messages in a simple, line-based format.</p> <p>In [[JavaScript]], the EventSource interface is used to handle SSE connections. This allows web pages to listen to server-sent events and react accordingly. If an SSE connection is dropped, the browser automatically tries to reconnect to the server, which is a useful feature for maintaining a persistent connection even in unstable network conditions.</p> <p>For use cases that only require server-to-client communication, SSE can be more efficient than WebSockets, as it's simpler and doesn't require a full protocol upgrade from HTTP. Implementing SSE on the server side involves setting the <code>Content-Type</code> of the response to <code>text/event-stream</code> and formatting the data according to the SSE specification.</p> <p>SSE is supported by most modern browsers, but it\u2019s important to check compatibility, especially with older browsers or certain mobile browsers.</p>"},{"location":"misc/subadd/","title":"Sub-Addressing","text":"<p>Sub-addressing in email, also known as \"plus addressing,\" is a feature that allows users to extend their email addresses using a '+' symbol followed by a tag or keyword. This extension creates variations of the main email address, which are all delivered to the same mailbox. Sub-addressing is particularly useful for organizing incoming mail and for identifying sources of spam.</p> <p>Suppose your primary email address is <code>user@example.com</code>. With sub-addressing, you can extend this address in the following way:</p> <ul> <li><code>user+shopping@example.com</code></li> <li><code>user+newsletters@example.com</code></li> <li><code>user+friends@example.com</code></li> </ul> <p>All emails sent to these addresses will be delivered to the inbox of <code>user@example.com</code>. However, the part after the '+' symbol allows for easy identification and management of incoming emails.</p> <p>By using different sub-addresses for different purposes or registrations (like online shopping, forums, newsletters), you can easily organize incoming emails into folders or apply specific rules based on the sub-address used. If you start receiving spam on a sub-address, it's easier to identify which service or registration may have compromised your email address or sold it to spammers.</p> <p>Sub-addressing can be used to quickly create \"disposable\" email addresses for one-time use without having to set up an actual new account.</p> <p>In the context of web application penetration testing, sub-addressing (or plus addressing) in emails can be used as a technique for testing and identifying security vulnerabilities, particularly in areas related to user account management, email validation, and information leakage.</p> <p>You can use sub-addressing to test how the web application handles email addresses with a '+' character. Check if the application accepts such emails and correctly sends messages to them. This can reveal how robust the application's input validation is.</p> <p>If the application requires unique emails for each account, sub-addressing can be used to create multiple accounts with what is essentially the same email address. For example, <code>user@example.com</code>, <code>user+test1@example.com</code>, and <code>user+test2@example.com</code> will all typically deliver to <code>user@example.com</code>.</p> <p>By registering with a sub-address, you can check if the application mishandles the part after the '+'. For instance, some applications might not properly parse the email address, leading to issues in email delivery or account verification.</p> <p>You can also potentially identify third-party sharing by registering on the application with a unique sub-address and monitor the inbox for emails sent to that address. If you start receiving emails (especially spam) not related to the original application, it could indicate that your email address has been shared with or leaked to third parties.</p> <p>While less common, you might test for injection vulnerabilities by including special characters or payloads in the sub-address part to see how the server handles and sanitizes these inputs. However, this is more of an edge case and less likely to yield significant results compared to other testing methods.</p> <p>Sub-addressing might be used in account enumeration testing. By using different sub-addresses and observing the application's responses, you might be able to infer the existence of certain user accounts.</p>"},{"location":"misc/suhosin/","title":"Suhosin","text":"<p>Suhosin is an advanced protection system for [[PHP]] installations. It was designed to protect servers and users from known and unknown flaws in PHP applications and the PHP core itself. Suhosin comes from the Korean word meaning \"guardian-angel.\" It was developed by Stefan Esser, a well-known expert in PHP security.</p> <p>Suhosin implements several security enhancements and protections to safeguard against potential vulnerabilities in PHP applications. These include protections against [[buffer overflows]], [[Format String Vulnerabilities]], and other low-level attacks.</p> <p>Suhosin adds advanced protection for global, request, and other variables by enforcing limits and ensuring that potentially harmful data is not passed into the application. It can transparently encrypt client-side [[cookies]] to protect sensitive data.</p> <p>Suhosin provides detailed logging of potential security issues, which is crucial for identifying and responding to attacks. It offers extensive configuration options, allowing system administrators to adjust the security settings according to their specific requirements.</p> <p>Suhosin consists of two parts: a patch for the PHP core and a PHP extension. The patch adds low-level protections to the PHP engine, while the extension implements additional protections that can be configured at runtime. It can be fine-tuned through a variety of configuration options set in the <code>php.ini</code> file, allowing administrators to enable or disable different features based on their security needs.</p> <p>Suhosin is mainly used by server administrators and is particularly beneficial for shared hosting environments where users may run untrusted PHP code. While Suhosin adds an extra layer of security, it's important to ensure that it's compatible with all PHP applications running on the server, as its restrictions might cause issues with some applications.</p>"},{"location":"misc/supply/","title":"Supply Chain Management","text":"<p>In the context of the [[Industrial IoT (IIoT)|Industrial Internet of Things (IIoT)]], Supply Chain Management (SCM) refers to the use of advanced [[IoT]] technologies to enhance and streamline supply chain and logistics operations. IIoT brings a new dimension of connectivity, automation, and data-driven insights into supply chain management.</p> <p>IIoT enables the real-time tracking of goods as they move through the supply chain. Smart sensors and [[Radio-Frequency Identification (RFID)|RFID]] tags can provide live updates on the location, condition, and progress of products, from manufacturing to delivery.</p> <p>By collecting and analyzing data from various points in the supply chain, IIoT facilitates predictive analytics. This can help in forecasting demand, managing inventory levels, and planning for transportation needs more effectively.</p> <p>Smart inventory management systems can automatically monitor stock levels, reducing the chances of overstocking or stockouts. This ensures optimal inventory levels are maintained, improving efficiency.</p> <p>IIoT devices can automate routine tasks, streamline operations, and improve overall supply chain efficiency. For instance, automated guided vehicles (AGVs) in warehouses can optimize picking and placing processes.</p> <p>Sensors can monitor the condition of goods, especially perishable products, in transit. Parameters like temperature, humidity, and vibration can be continually assessed to ensure product quality. Automation and advanced data capture techniques reduce human error, leading to more accurate order fulfillment and inventory records.</p> <p>By optimizing various aspects of the supply chain, IIoT can help reduce operational costs. This includes savings from improved inventory management, reduced energy usage, and efficient asset utilization.</p> <p>IIoT provides greater visibility into the entire supply chain. Decision-makers can have a comprehensive view of the supply chain, enabling them to identify issues and opportunities quickly.</p> <p>Enhanced data and analytics improve risk management by enabling companies to identify and mitigate potential supply chain disruptions more effectively. IIoT facilitates better collaboration and integration among different players in the supply chain, including suppliers, manufacturers, distributors, and retailers.</p>"},{"location":"misc/tomcat/","title":"Apache Tomcat","text":"<p>Apache Tomcat is a Java Servlet container, or web container, that provides the extended functionality to interact with Java Servlets, while also implementing several technical specifications of the Java platform: JavaServer Pages (JSP), Java Expression Language (Java EL) and WebSocket.</p> <p>A Java Servlet is software that enables a web server to handle dynamic Java-based web content using the [[HTTP protocol]]. JSP is a similar technology that allows developers to create dynamic content using [[HTML]] or [[Extensible Markup Language|XML]] documents. </p> <p>In terms of their ability to enable dynamic content, Java Servlets and JSP are broadly comparable to [[PHP]] or [[ASP.NET]], just based on the Java programming language.</p> <p>By bringing all these Java-based technologies together, Tomcat Apache offers a \u201cpure Java\u201d web server environment for running applications built on the Java programming language.</p>"},{"location":"misc/tomee/","title":"TomEE","text":"<p>Apache TomEE (pronounced \"Tommy\") is an open-source [[Java Enterprise Edition (Java EE)]] application server that combines the simplicity of Tomcat with the capabilities of Java EE. It is part of the [[Apache Tomcat]] project and aims to provide a lightweight, yet fully compliant, Java EE container.</p> <p>TomEE is designed to be a certified and compatible Java EE server. It implements the Java EE specifications, allowing developers to deploy enterprise applications that adhere to Java EE standards. </p> <p>TomEE is built on top of the Apache Tomcat servlet container. It extends Tomcat to provide support for Java EE features, such as [[Enterprise JavaBeans (EJBs)|EJB (Enterprise JavaBeans)]], [[Java Persistence API (JPA)|JPA (Java Persistence API)]], [[JMS|JMS (Java Message Service)]], and more.</p> <p>Similar to Tomcat, TomEE is known for its lightweight nature and ease of embedding. It is suitable for both development and production environments where a minimalistic and resource-efficient server is desired. TomEE supports different profiles that cater to different needs. These profiles include TomEE Web Profile, TomEE [[JAX-RS (Java API for RESTful Web Services)|JAX-RS]] (RESTful services), TomEE Plus (full profile with additional features), and more. Users can choose the profile that best fits their application requirements.</p> <p>TomEE includes support for [[CDI]], which is a powerful dependency injection framework in Java EE. CDI simplifies the development of enterprise applications by providing a standard way to manage beans and their dependencies.</p> <p>TomEE supports various enterprise features, including transaction management, security, messaging, and more. It allows developers to build robust and scalable enterprise applications. TomEE is part of the Apache Software Foundation and integrates well with other Apache projects. For example, it can be used in conjunction with [[Apache ActiveMQ]] for messaging and Apache OpenJPA for persistence.</p> <p>Apache TomEE is developed and maintained by a community of contributors. It benefits from the collaborative efforts of developers who work on enhancing its features, fixing bugs, and ensuring compatibility with the latest Java EE specifications.</p>"},{"location":"misc/trust/","title":"WS-Trust","text":"<p>WS-Trust is a specification that is part of the WS-Security framework, which establishes a standard for managing, issuing, and validating security tokens. Developed as an extension of WS-Security, WS-Trust provides additional protocols for secure message exchanges in web services and [[Service-Oriented Architecture (SOA)|SOA (Service-Oriented Architecture)]] environments.</p> <p>WS-Trust defines how security tokens can be issued, renewed, and validated. This includes exchanging and brokering tokens between different trust domains. It enhances the security of [[SOAP]] (Simple Object Access Protocol) messages by enabling the integration of various security token models, like [[SAML (Security Assertion Markup Language)]], with web services.</p> <p>WS-Trust supports federated identity scenarios where user credentials and identity information need to be securely shared across different security domains or services. It accommodates various types of security tokens, enabling flexibility in authentication and authorization mechanisms. The protocol defines a standard way for web services to establish and negotiate trust relationships, simplifying secure communications in distributed environments.</p> <p>In [[Single Sign-On (SSO)|SSO]] systems, WS-Trust can be used to manage and validate the tokens that represent users' authenticated sessions, allowing them to access multiple services with a single set of credentials. It is used in securing web services by providing mechanisms for issuing and validating tokens that assert the identity and permissions of message senders. In enterprise applications, WS-Trust is used to manage security tokens for internal and external communications, ensuring that only authorized entities can access services.</p> <p>A user wants to access a web service in a different organization, but the services require different types of security credentials. The user's home organization uses WS-Trust to issue a SAML token that the target web service can validate. This token encapsulates the user's identity and access rights, which the web service verifies to grant access. This process is integral to cross-domain federated access, enabling the user to securely access external services.</p>"},{"location":"misc/tsql/","title":"Transact-SQL","text":"<p>Transact-SQL, often abbreviated as T-SQL, is an extension of SQL ([[Structured Query Language]]) used in [[Microsoft SQL Server]] and [[Sybase]] ASE (Adaptive Server Enterprise). </p> <p>T-SQL expands upon the standard SQL language to include procedural programming, local variables, various support functions for string processing, date processing, mathematics, etc., and changes to the DELETE and UPDATE statements.</p> <p>T-SQL includes procedural programming features, such as the ability to declare variables, write IF...ELSE statements, and create loops. This allows for more complex and dynamic SQL scripts compared to standard SQL.</p> <p>It includes statements like BEGIN...END, WHILE, WAITFOR, and GOTO, which can control the flow of execution in a T-SQL script or stored procedure. T-SQL has a rich set of built-in functions for various operations like string manipulation, mathematical calculations, date processing, and system functions.</p> <p>Primarily used with Microsoft SQL Server and Sybase ASE, T-SQL scripts are specific to these environments and may not be fully compatible with other SQL-based database systems without modifications.</p>"},{"location":"misc/undertow/","title":"Undertow","text":"<p>Undertow is a high-performance, lightweight web server written in [[Java]]. It is designed to be embeddable within applications and frameworks, making it a popular choice for building microservices and standalone web applications.</p> <p>Undertow is designed to be easily embedded within Java applications. This makes it well-suited for microservices architectures, where lightweight and modular components are essential. Undertow is built with a focus on asynchronous and non-blocking I/O operations. This allows it to handle a large number of concurrent connections efficiently, making it suitable for high-performance scenarios.</p> <p>Undertow provides native support for [[WebSockets|WebSocket]] communication. This enables real-time, bidirectional communication between clients and servers, making it suitable for applications with interactive features.</p> <p>Undertow supports the HTTP/2 protocol, which is the latest version of the [[HTTP protocol]]. HTTP/2 introduces improvements in performance, multiplexing, and header compression over its predecessor, HTTP/1.1.</p> <p>Undertow supports the Servlet 4.0 specification, which includes features such as HTTP/2 support, server push, and more. Servlets are a standard Java technology for building web applications. Undertow is designed with a modular architecture, allowing developers to choose and include only the components they need. This results in a smaller footprint and improved performance.</p> <p>In addition to server-side WebSocket support, Undertow provides a WebSocket client API, allowing applications to initiate WebSocket connections to external services. Undertow is closely integrated with the JBoss ecosystem, and it is the default web server used by the WildFly application server. This integration provides seamless interoperability with other JBoss technologies.</p> <p>Undertow includes security features such as [[SSL-TLS|SSL/TLS]] support for secure communication, integration with security realms, and support for authentication and authorization mechanisms. Undertow can be deployed in various scenarios, including as a standalone web server, embedded within applications, or as part of a larger application server environment.</p>"},{"location":"misc/unicode/","title":"Unicode","text":"<p>Unicode is a comprehensive character encoding system designed to represent text for all the writing systems of the world, both modern and ancient. It goes far beyond the capabilities of earlier encoding systems like [[ASCII]].</p> <p>Unicode aims to include every character from every written language, along with technical symbols, mathematical symbols, and even emojis. This universal approach allows for the consistent encoding, representation, and handling of text in many languages and scripts.</p> <p>In Unicode, each character is assigned a unique code point, a number that identifies that character. Unicode defines more than a million code points, spread across 17 planes (each plane has 65,536 code points). These code points are typically represented in the format U+XXXX, where \"XXXX\" is a hexadecimal number.</p>"},{"location":"misc/uuidv1/","title":"UUIDv1","text":"<p>UUIDv1 is a version of the universally unique identifier (UUID) specified in RFC 4122. It is generated using a combination of the host computer's [[MAC address]] and the current timestamp. UUIDv1 uses the current time (down to 100-nanosecond intervals) since a specific epoch (15 October 1582) as part of the UUID. This ensures that UUIDs generated at different times are unique.</p> <p>The UUID includes the MAC address of the host computer's network card, which helps ensure uniqueness across different devices. Like other UUIDs, it is a 128-bit value formatted as a string of hexadecimal digits, typically displayed in 5 groups separated by hyphens.</p> <p>Since UUIDv1 contains the MAC address of the machine where it was generated, there is a potential privacy issue. The MAC address can be used to identify the machine or, in some cases, even track its location. The use of a timestamp makes UUIDv1 somewhat predictable, which might be a concern in certain applications where unpredictability is crucial (such as in cryptographic applications).</p> <p>UUIDv1 can be used in web applications as unique identifiers for objects, transactions, or records. It is particularly useful in distributed systems where coordination between different parts of the system to generate unique IDs is challenging. They are often used as primary keys in database tables. The time-based nature of UUIDv1 can offer better performance for insert operations in certain database systems compared to the random nature of [[UUIDv4]].</p> <p>They can also be used for generating unique session IDs in web applications.</p> <p>Given the privacy and predictability concerns with UUIDv1, many applications opt for [[UUIDv4]], which is randomly generated, or [[UUIDv5]], which uses [[SHA-1]] hashing. These versions do not disclose hardware-related information and offer less predictability.</p> <p>Identifying a UUID as being of version 1 (UUIDv1) can be done by examining its structure and specific components. A UUID is a 36-character string (including hyphens) composed of hexadecimal digits. It's structured into five groups, typically represented as 8-4-4-4-12 characters. The version and variant of a UUID are encoded in specific positions within the string.</p> <ol> <li>Version Digit: The version of the UUID is indicated by the first character of the 13th hexadecimal digit. For UUIDv1, this digit will be <code>1</code>.</li> <li>Timestamp: UUIDv1 is generated based on the current timestamp (time since 15 October 1582 in 100-nanosecond intervals). This timestamp forms the first part of the UUID.</li> <li>MAC Address: The last 12 hexadecimal digits of UUIDv1 represent the MAC address of the machine where it was generated.</li> </ol> <p>An example is:</p> <pre><code>6ba7b810-9dad-11d1-80b4-00c04fd430c8\n</code></pre> <ul> <li>The <code>1</code> at the start of the third group (<code>11d1</code>) indicates that this is a version 1 UUID.</li> <li>The <code>d</code> in <code>11d1</code> (specifically the most significant bits of this hexadecimal digit) indicates the UUID variant; in standard UUIDs, this is typically <code>8</code>, <code>9</code>, <code>a</code>, or <code>b</code>.</li> </ul>"},{"location":"misc/uuidv4/","title":"UUIDv4","text":"<p>UUIDv4 refers to a version 4 universally unique identifier (UUID), which is a type of UUID that is randomly generated. A UUID is a 128-bit number used to uniquely identify information in computer systems. The \"v4\" indicates that it's version 4, which is one of the several versions of UUIDs specified in RFC 4122.</p> <p>UUIDv4 is generated using random or pseudo-random numbers. The randomness feature ensures a very low probability of generating duplicate UUIDs. A UUIDv4 is composed of hexadecimal digits, displayed in 5 groups separated by hyphens, in a form such as 550e8400-e29b-41d4-a716-446655440000. The total number of characters is 36 (32 hexadecimal characters and 4 hyphens).</p> <p>In UUIDv4, the version number (4) is set in the 13th character, and the variant is set in the 17th character. The variant bits indicate the UUID layout; for UUIDv4, this is usually <code>8</code>, <code>9</code>, <code>A</code>, or <code>B</code>.</p> <p>The primary usage of UUIDv4 is when you need a unique identifier that you can generate without needing to coordinate with a central authority. This makes UUIDv4 ideal for distributed systems. UUIDv4 is often used as a unique key in databases, ensuring that each record can be uniquely identified across different tables, databases, or even different systems.</p> <p>UUIDv4 is used in software development for various purposes, such as transaction IDs, unique session identifiers, and any other scenario where a unique identifier is required.</p> <p>Due to its random nature, UUIDv4 has a very low probability of duplication, even when generated across different machines independently. UUIDv4 can be generated without needing a central authority to avoid duplicates, making it suitable for decentralized applications.</p> <p>Unlike [[UUIDv1]], which is time-based and sequential, UUIDv4 is random, offering better privacy (no embedded timestamps or [[MAC Address|MAC addresses]]). In database systems, the use of UUIDv4 as primary keys may have implications for storage and performance, as they are larger and not sequential compared to traditional integer IDs.</p>"},{"location":"misc/uuidv5/","title":"UUIDv5","text":"<p>UUIDv5 is a version of the universally unique identifier (UUID) that uses [[SHA-1]] hashing to generate a UUID from a namespace identifier and a name. It's specified in RFC 4122 and is designed to create deterministic and unique IDs.</p> <p>UUIDv5 uses the SHA-1 hashing algorithm on a namespace and a specific name to generate the UUID. The namespace is another UUID that acts as a domain or category identifier, ensuring uniqueness across different namespaces. Unlike [[UUIDv4]] which is randomly generated, UUIDv5 is deterministic. The same namespace and name combination will always generate the same UUID.</p> <p>Unlike [[UUIDv1]], UUIDv5 doesn't use the [[MAC address]] of the generating machine, thus avoiding the privacy issues associated with UUIDv1. The non-random, deterministic nature of UUIDv5 means it's predictable if the namespace and name are known. However, this predictability is by design and is not typically a vulnerability in the context of its intended use.</p> <p>UUIDv5 is useful in scenarios where you need a consistent identifier generated from a specific name within a known namespace. For example, generating a consistent ID for a user based on their username. It can be used in web [[APIs]] to generate unique identifiers for resources.</p> <p>Identifying a UUID as being of version 5 (UUIDv5) can be accomplished by examining its structure and specific components. Like other versions of UUIDs, UUIDv5 is a 128-bit number and is typically represented as a 36-character string (including hyphens) composed of hexadecimal digits. It's structured into five groups, represented as 8-4-4-4-12 characters.</p> <ol> <li>Version Digit: The version of the UUID is indicated by the first character of the 13th hexadecimal digit. For UUIDv5, this digit will be <code>5</code>.</li> <li>SHA-1 Hashing: UUIDv5 uses SHA-1 hashing of a namespace identifier and a name to generate the UUID. However, this hashing process is not evident from the UUID itself.</li> <li>Namespace: UUIDv5 is generated from a namespace, but the namespace used is not directly identifiable from the UUID.</li> </ol> <p>An example of a UUIDv5 string could look like this:</p> <pre><code>c6db45fb-8d5c-52b9-b7c0-1f6e8df6e5d6\n</code></pre> <p>The <code>5</code> at the start of the third group (<code>52b9</code>) indicates that this is a version 5 UUID.</p>"},{"location":"misc/vms/","title":"Virtual Machines","text":"<p>Virtual machines (VMs) are software emulations of physical computers. They provide the functionality of a physical computer, running an operating system and applications as if they were installed on a hardware system. Essentially, VMs are isolated software containers that can run their own operating systems and applications as if they were separate computers.</p> <p>Each VM is isolated from others and from the host system. This means the software within a VM can't interfere with the host or other VMs. This isolation provides a secure and stable environment for running different applications. VMs allow multiple operating systems to run concurrently on a single physical machine. For example, you could run Windows, Linux, and macOS on the same hardware.</p> <p>VMs share the physical resources of the host machine (such as CPU, memory, and storage), but these resources are allocated to each VM in a controlled manner. VMs can be easily moved, copied, and reassigned between host servers more easily than physical hardware, allowing for flexibility in managing computing resources.</p> <p>VMs can be snapshotted to capture their current state, and can be cloned to create exact replicas. This is particularly useful for backup, testing, and deployment scenarios.</p> <p>VMs provide developers and testers with isolated environments to run and test applications in different operating systems and configurations without affecting the host system. In data centers, VMs are used to optimize server utilization, allowing multiple virtual servers to run on a single physical server.</p> <p>VMs can be used for running different operating systems on a single physical workstation or for providing secure, isolated environments for running potentially risky applications. VMs provide a safe and controlled environment for educational purposes, allowing students to experiment with different operating systems and network configurations.</p> <p>Several technologies enable virtualization, including:</p> <ul> <li>VMware: Offers various products for virtualization, including VMware Workstation for desktops and VMware ESXi for servers.</li> <li>[[Hyper-V|Microsoft Hyper-V]]: A hypervisor-based virtualization platform integrated into Windows Server and also available on Windows 10/11 Pro and Enterprise editions.</li> <li>Oracle VirtualBox: A free and open-source virtualization tool that is suitable for desktop virtualization.</li> <li>KVM (Kernel-based Virtual Machine): A Linux-based virtualization solution.</li> </ul>"},{"location":"misc/vps/","title":"Virtual Private Server (VPS)","text":"<p>A Virtual Private Server (VPS) is a type of hosting service that provides users with a [[Virtual Machines|virtual machine]] running its own copy of an operating system (OS). This service gives customers superuser-level access to that operating system instance, allowing them to install almost any software that runs on that OS. Essentially, a VPS operates like a dedicated physical server but is actually a virtualized instance within a larger physical server.</p> <p>Each VPS is isolated from others on the same physical server, ensuring that the actions or traffic of one user do not affect others. Users have root or administrative access, allowing for extensive customization, software installations, and configuration adjustments. VPS hosting can typically be scaled to accommodate changing needs in resources like CPU, RAM, and disk space.</p> <p>VPS offers many of the benefits of a dedicated server at a lower cost, as the physical server's resources are shared among multiple users. Unlike shared hosting, a VPS provides dedicated portions of the server's resources, including CPU time, memory, and storage space.</p> <p>While VPS services are legitimate and widely used for hosting websites, running applications, and other IT needs, they can also be related to hacking in various ways:</p> <p>Malicious actors may use VPSs to host [[phishing]] sites, control panels for malware, or other illicit web services, taking advantage of the VPS's resources and relative anonymity. Ethical hackers and security researchers often use VPSs to legally conduct penetration testing or vulnerability assessments, providing a controlled and isolated environment for testing.</p> <p>Hackers may use VPSs, especially those located in different countries, to mask their location and identity, making it harder to trace malicious activities back to them. VPSs can be used to host [[Command and Control (C2)|command and control (C&amp;C)]] servers for botnets, benefiting from their stable internet connection, uptime, and processing power.</p> <p>Users are responsible for securing their VPS. This includes regular updates, firewall configuration, and other security measures to prevent unauthorized access. VPS providers typically monitor for and take action against abusive behavior on their networks, but the level of monitoring and enforcement can vary.</p>"},{"location":"misc/war/","title":"WAR (Web Application Archive)","text":"<p>WAR files (Web Application Archive files) are a type of [[Java Archive (JAR)]] file used to distribute and deploy web applications in the [[Java]] platform. The WAR file format is a standard packaging method for web applications that use servlets and [[JavaServer Pages (JSP)]].</p> <p>WAR files are used to package web applications so that they can be easily deployed on any Java EE (Enterprise Edition) compliant server, like [[Apache Tomcat]], [[IBM WebSphere]], [[Oracle WebLogic]], etc.</p> <p>A typical WAR file includes [[Java Servlets]], [[JavaServer Pages (JSP)|JSP files]], [[HTML]] pages, [[JavaScript]] files, [[CSS]] files, images, Java classes, [[Extensible Markup Language|XML]] configuration files, and any libraries required by the application (packaged as JAR files).</p> <p>WAR files have a specific directory structure. The root of the WAR file contains JSP files, HTML files, and other resources accessible directly by clients. There is a special directory named <code>WEB-INF</code> which contains:</p> <ul> <li><code>web.xml</code>: The deployment descriptor file that describes the servlets and other components of the application.</li> <li><code>classes</code>: A directory for compiled Java class files.</li> <li><code>lib</code>: A directory containing Java Archive (JAR) files that the web application depends on.</li> <li>Other configuration files and resources used by the application.</li> </ul> <p>To deploy a web application, you typically copy the WAR file into a specific directory on the application server (like the <code>webapps</code> directory in Apache Tomcat). The server then automatically deploys the web application based on the contents of the WAR file.</p> <p>WAR files simplify the deployment process, as they contain all the components of the web application in a single file. They provide a standard, server-agnostic way of packaging web applications, ensuring compatibility across different Java EE servers.</p> <p>WAR files can be created manually by organizing files into the required structure and using a zip tool, or automatically using build tools like [[Apache Maven]], [[Gradle]], or [[Ant]].</p>"},{"location":"misc/weber/","title":"AWeber","text":"<p>AWeber is a digital marketing platform specializing in email marketing services. Founded in 1998, it is one of the earlier email marketing platforms and has since grown to offer a variety of tools and features aimed primarily at small to medium-sized businesses. AWeber is designed to help businesses automate their email communications, manage subscribers, and craft effective email marketing campaigns.</p> <p>AWeber allows users to create and send newsletters, promotional emails, and automated email sequences. This is useful for keeping subscribers engaged and informed about products, services, or content. It offers a range of customizable email templates and a drag-and-drop email builder, making it easy to create visually appealing emails without needing coding skills.</p> <p>AWeber provides tools for managing email lists, including segmentation options to target specific subscriber groups based on their behaviors, preferences, or demographics. The platform offers autoresponder functionality, allowing users to set up automated email sequences that are triggered by specific actions, like signing up for a list or making a purchase.</p> <p>AWeber includes detailed reporting tools to track the performance of email campaigns, measuring metrics such as open rates, click-through rates, and conversions. It integrates with a variety of third-party applications and services, including [[Customer Relationship Management (CRM) Software|CRM]] systems, e-commerce platforms, and social media tools, to streamline workflow and data management.</p> <p>Users can create custom signup forms to embed on their websites or social media platforms, facilitating the growth of their mailing lists. AWeber is known for its customer support, offering assistance via email, live chat, and phone.</p> <p>AWeber is used by a wide range of businesses and individuals, including entrepreneurs, bloggers, online marketers, and non-profits, to manage their email marketing campaigns. Its ease of use and comprehensive feature set make it a popular choice for those looking to start with email marketing or enhance their existing efforts.</p> <p>As with any platform handling personal data, AWeber adheres to standard security protocols and compliance measures. This includes respecting privacy laws and regulations like GDPR, offering features for subscriber consent management, and ensuring the secure handling of subscriber data.</p>"},{"location":"misc/weblogic/","title":"Oracle WebLogic","text":"<p>Oracle WebLogic Server is a leading enterprise-level application server for developing and deploying multi-tier distributed [[Java]] EE applications. It's a part of Oracle's portfolio of middleware solutions and is known for its robustness, performance, and scalability. </p> <p>WebLogic Server is often used by large enterprises to build and run critical applications in various domains. </p> <p>Oracle WebLogic Server is fully compliant with the Java EE standards, supporting Java EE applications and components such as Enterprise JavaBeans (EJBs), [[Java Servlets]], [[JavaServer Pages (JSP)]], and more.</p> <p>WebLogic Server is designed for scalability and high performance, making it suitable for mission-critical applications that demand reliability and high throughput. It offers advanced clustering capabilities, allowing multiple WebLogic server instances to work together to ensure high availability and [[Load Balancer|load balancing]] of applications.</p> <p>WebLogic provides a comprehensive set of tools for administration and management, including a user-friendly console, command-line utilities, and scripting tools for automating administrative tasks.</p> <p>It offers strong integration capabilities with various databases, legacy systems, and other Oracle products, such as Oracle Database and Oracle Fusion Middleware. WebLogic includes robust security features, including [[SSL-TLS|SSL/TLS]] support, fine-grained access control, and integration with enterprise security systems.</p> <p>It supports a range of technologies and standards, including JMS (Java Message Service), JDBC (Java Database Connectivity), JMX (Java Management Extensions), and Web Services ([[SOAP]], [[REST APIs|REST]]).</p> <p>Oracle WebLogic is optimized for cloud environments and virtualized infrastructure, providing flexibility in deployment options. With tools and features designed to simplify application development, testing, and deployment processes, WebLogic aims to enhance developer productivity.</p>"},{"location":"misc/webs/","title":"IBM WebSphere","text":"<p>IBM WebSphere refers to a brand of IBM software products, primarily focused on creating and managing web and enterprise applications. WebSphere is known for its robust performance in business-critical and complex transactional environments. The brand includes a range of products, but the most recognized among them is the IBM WebSphere Application Server (WAS). </p> <p>WAS is a [[Java]]-based application server platform that allows businesses to build and run highly available, scalable, and secure applications. It supports Java EE (Enterprise Edition) and web services standards.</p> <p>WAS provides a runtime environment for enterprise applications and supports various services, including transaction management, messaging, clustering, workload management, and performance monitoring.</p> <p>WebSphere products are often used in middleware roles, facilitating communication and integration between different applications across diverse computing environments. IBM WebSphere also includes portal solutions, enabling the development of personalized web portals, which integrate applications and content into a single, user-friendly interface.</p> <p>WebSphere products support SOA, an architectural pattern in software design where services are provided to other components by application components, through a communication protocol over a network. Designed for enterprise environments, WebSphere offers high performance, scalability, and reliability for handling complex business transactions and processes.</p> <p>Security is a key aspect, with WebSphere providing robust authentication, authorization, and encryption capabilities. Formerly known as MQSeries, IBM WebSphere MQ is a messaging middleware product that allows independent and potentially non-concurrent applications on a distributed system to securely communicate with each other.</p> <p>WebSphere is typically used by large enterprises in industries like banking, finance, healthcare, and retail, where high-volume transactions and reliability are crucial.</p>"},{"location":"misc/wildfly/","title":"WildFly","text":"<p>WildFly is an open-source, lightweight, and modular [[Java]]-based application server. It is developed by the JBoss community, now part of Red Hat. WildFly is designed to be fast, lightweight, and feature-rich, making it suitable for a wide range of enterprise applications.</p> <p>WildFly is fully compatible with the [[Java Enterprise Edition (Java EE)|Java EE]] and [[Jakarta EE]] specifications, providing a runtime environment for enterprise Java applications. It is known for its fast startup times and low memory footprint, making it suitable for microservices architectures and cloud-native applications.</p> <p>WildFly adopts a modular architecture based on the [[JBoss Modular Service Container (MSC)]]. This allows for better modularity, reducing the overhead of unnecessary components. WildFly supports a wide range of Java EE and Jakarta EE standards, including [[Java Servlets|Servlets]], [[JSP|JSP]], [[CDI (Contexts and Dependency Injection)]], [[Java Persistence API (JPA)|JPA (Java Persistence API)]], and more. It also supports MicroProfile, a set of microservices specifications.</p> <p>WildFly can be used in embedded mode, allowing developers to embed it within their applications for testing and development purposes. WildFly provides features for clustering and high availability, enabling the deployment of applications in a distributed and scalable manner.</p> <p>WildFly includes a web-based management console that allows administrators to configure and monitor the server easily. It provides a user-friendly interface for managing deployments, data sources, and other server configurations. WildFly includes robust security features, including support for various authentication mechanisms, role-based access control, and encryption.</p> <p>WildFly has an active and vibrant community of developers and users. It benefits from ongoing contributions and support from the open-source community.</p>"},{"location":"misc/wmi/","title":"Windows Management Instrumentation (WMI)","text":"<p>Windows Management Instrumentation (WMI) is a core component of the Microsoft Windows operating system that provides a standardized way to access and manage Windows-based systems both locally and remotely. WMI is Microsoft's implementation of the Web-Based Enterprise Management (WBEM) and Common Information Model (CIM) standards defined by the Distributed Management Task Force (DMTF).</p> <p>WMI allows administrators and scripts to retrieve information about the status and configuration of computer systems and applications, including hardware details, operating system settings, network configuration, running services, and installed software. With WMI, administrators can perform operations on remote computers, making it an essential tool for managing large networks of Windows machines.</p> <p>WMI can monitor and notify about specific system events, such as changes in system configuration, file modifications, or system errors, enabling automated responses to these events. WMI is accessible via scripting languages like [[Windows PowerShell]] and [[VBScript]], allowing for the automation of administrative tasks and the creation of custom management tools and applications.</p> <p>WMI can be extended to include custom information and functions, providing flexibility to address specific management needs.</p> <p>In the context of hacking and cybersecurity:</p> <ul> <li>Attackers' Tool: Malicious actors can use WMI for [[persistence]], [[lateral movement]], and execution of payloads. WMI scripts can be difficult to detect, making them a stealthy option for attackers.</li> <li>Defense Strategies: Monitoring WMI activity can be an important part of a security strategy. Unusual WMI requests may indicate a compromise.</li> <li>Forensics and Incident Response: WMI logs can provide valuable information during cybersecurity investigations.</li> </ul>"},{"location":"misc/wsbpel/","title":"Web Services Business Process Execution Language (WS-BPEL)","text":"<p>WS-BPEL (Web Services Business Process Execution Language) is a standard for specifying business process behaviors based on [[Web Services]]. This [[Extensible Markup Language|XML]]-based language is used to define a business process model, which includes both the sequence of services to be invoked (the process flow) and the business logic that dictates the order of these service invocations.</p> <p>WS-BPEL enables the automation of business processes by integrating a series of discrete services (often web services) into an end-to-end process flow.</p> <p>This integration is crucial for enterprises that rely on diverse software systems, allowing them to orchestrate various services into coherent, automated business processes. BPEL is often used in [[Service-Oriented Architecture (SOA)|SOA (Service-Oriented Architecture)]] environments, where it helps in managing complex interactions among various web services.</p>"},{"location":"misc/wsdl/","title":"WSDL","text":"<p>WSDL, or Web Services Description Language, is an [[Extensible Markup Language|XML]]-based language used for describing the functionality offered by a web service. It provides a machine-readable description of how the service can be called, what parameters it expects, and what data structures it returns.</p> <p>WSDL is a key component in the web services stack and plays a critical role in [[SOAP]] (Simple Object Access Protocol) web services. WSDL is used to describe the details of a web service in a standard way. It defines how to access a web service and what operations it will perform.</p> <p>WSDL documents are written in XML, which makes them both human-readable and machine-processable. Although WSDL can be used with any web service, it is most commonly associated with SOAP web services. It specifies the SOAP actions and the data encoding method for HTTP-based SOAP services.</p> <p>A WSDL document typically contains definitions of:</p> <ul> <li>Types: Data types used by the web service.</li> <li>Message: Abstract, typed definitions of the data being communicated.</li> <li>Operation: An abstract description of an action supported by the service.</li> <li>Port Type: An abstract set of operations supported by one or more endpoints.</li> <li>Binding: A concrete protocol and data format specification for a particular port type.</li> <li>Service: A collection of related endpoints.</li> </ul> <p>WSDL helps in automating the details of web service discovery and integration, allowing for easier interoperation between different systems and platforms. WSDL is often used in conjunction with [[Universal Description, Discovery, and Integration (UDDI)]], an XML-based standard for describing, publishing, and finding web services.</p> <p>Many development tools can automatically generate client code (stubs) for calling a web service based on its WSDL description. While WSDL is commonly used with SOAP over [[HTTP Protocol|HTTP]], it also supports other underlying network protocols.</p> <p>WSDL 2.0, an updated version, adds additional features and addresses some limitations of WSDL 1.1, though 1.1 remains widely used. WSDL has been criticized for its complexity, and in some modern web service applications, it has been supplanted by more lightweight alternatives such as [[REST APIs|RESTful]] services, which often use simpler description formats.</p>"},{"location":"misc/xalan/","title":"Xalan","text":"<p>Xalan is an Apache Software Foundation project that provides an open-source implementation of the [[XSLT (Extensible Stylesheet Language Transformations)]] and [[XPath]] (XML Path Language) specifications. Xalan is written in [[Java]] and is designed to transform [[Extensible Markup Language|XML]] documents using XSLT stylesheets and perform XPath queries on XML data.</p> <p>The Xalan project consists of two main components:</p> <ol> <li>Xalan-Java (Xalan-J): This is the Java-based implementation of Xalan. It provides a set of libraries and tools for processing XML documents with XSLT and XPath. Xalan-J supports various versions of the XSLT and XPath specifications, offering developers the ability to transform and query XML data.</li> <li>Xalan-C++ (Xalan-C): In addition to the Java version, there is also a [[C++]] implementation of Xalan. Xalan-C++ provides similar functionality to Xalan-J but is written in C++ and can be used in C++ applications.</li> </ol> <p>Xalan allows developers to transform XML documents using XSLT stylesheets. XSLT is a language for transforming XML documents into different formats, such as [[HTML]], [[XHTML]], or other XML documents.</p> <p>Xalan supports XPath, a language for navigating XML documents and selecting nodes based on certain criteria. XPath is often used in conjunction with XSLT for specifying patterns and conditions during transformations.</p> <p>Xalan provides extension mechanisms, allowing developers to integrate custom Java or C++ extensions into their XSLT stylesheets. This can be useful for adding custom functions or accessing external resources during the transformation process. Xalan supports streaming and chunked processing, enabling the processing of large XML documents without loading the entire document into memory.</p>"},{"location":"misc/xinclude/","title":"XInclude","text":"<p>XInclude (XML Inclusions) is a part of the [[Extensible Markup Language|XML]] specification that defines a standard way to include external or internal content into an XML document. XInclude provides a mechanism for merging XML documents, or parts of documents, into a single composite document. This is particularly useful in situations where you want to assemble XML data from various sources or modularize XML documents.</p> <p>XInclude uses special XML elements to specify what content should be included and where. The most commonly used element is <code>&lt;xi:include&gt;</code>, which has attributes to specify the source of the content:</p> <ul> <li><code>href</code>: The URI of the document to include. This can be a local file or a URL.</li> <li><code>parse</code>: This attribute determines how the included content should be parsed. It can be set to \"xml\" if the content is XML or \"text\" for plain text.</li> <li><code>xpointer</code>: (optional) An [[XPointer]] expression that specifies a fragment of the document to include, allowing for partial document inclusion.</li> </ul> <p>A simple example could be:</p> <pre><code>&lt;document&gt;\n  &lt;title&gt;My Composite Document&lt;/title&gt;\n  &lt;content&gt;\n    &lt;xi:include href=\"content_section.xml\" parse=\"xml\" xmlns:xi=\"http://www.w3.org/2001/XInclude\"/&gt;\n  &lt;/content&gt;\n&lt;/document&gt;\n</code></pre> <p>In this example, the <code>&lt;xi:include&gt;</code> element is used to include the content of <code>content_section.xml</code> into the main document.</p> <p>XInclude can be exploited in [[XML External Entities (XXE)]] attacks, where an attacker could reference external entities or sensitive files in the <code>href</code> attribute. If the XML parser processes these inclusions, it could lead to data exposure, data exfiltration, or service disruption.</p>"},{"location":"misc/xmlschema/","title":"XML Schema","text":"<p>XML Schema, often referred to as XML Schema Definition (XSD), is a language used to define the structure, content, and semantics of [[Extensible Markup Language|XML]] documents. XML Schema provides a more powerful and rigorous alternative to [[DTD (Document Type Definition)]], the original XML document validation schema language.</p> <p>XML Schema is used to define the structure and data types of elements and attributes in an XML document. It specifies what elements are present, their order, and their data types. Unlike DTDs, XML Schema supports a wide range of data types, including string, integer, decimal, date, time, and more. It also allows for the creation of custom data types.</p> <p>Schemas are used to validate XML documents, ensuring they conform to a predefined structure and set of rules. This is crucial for data integrity and reliability in XML data interchange. XML Schema supports XML namespaces, allowing for the creation of fully-qualified names to avoid naming conflicts across XML documents.</p> <p>XML Schema can describe complex data structures, including nested and repeated elements, which is a limitation in DTDs. Elements defined in one XML Schema can be reused in other schemas, promoting modularity and reducing redundancy.</p> <p>When validating XML documents against an XML Schema, specific and detailed error messages can be generated, helping in troubleshooting and correcting structure or data issues. XML Schema is widely adopted in various industries for defining XML document structures, and there are many tools available for creating, editing, and validating XSDs.</p> <p>In the context of web services, especially [[SOAP|SOAP]]-based services, XML Schema plays a crucial role in defining the structure of request and response messages.</p> <p>XML Schema is often used in conjunction with other XML-based technologies, like [[XSLT (Extensible Stylesheet Language Transformations)|XSLT]] and [[XPath]], for comprehensive XML document processing.</p>"},{"location":"misc/xpath/","title":"XPath","text":"<p>XPath, which stands for [[Extensible Markup Language|XML]] Path Language, is a query language that allows for the selection of nodes from an XML document. It's a critical technology in the realm of XML data handling, enabling the extraction and manipulation of data from XML documents.</p> <p>XPath is primarily used to select nodes from an XML document. These nodes can be elements, attributes, text, and more. XPath expressions allow for navigating through elements and attributes in an XML document.</p> <p>XPath uses a path-like notation for navigating through the hierarchical structure of an XML document. For example, <code>/bookstore/book</code> selects all <code>book</code> elements that are children of <code>bookstore</code></p> <p>XPath is used in various XML-related technologies, including [[XSLT (Extensible Stylesheet Language Transformations)]], [[XQuery]], and [[XML Schema]].</p> <p>XPath supports conditional selections using predicates. For example, <code>/bookstore/book[price&gt;35.00]</code> selects all <code>book</code> elements in <code>bookstore</code> that have a <code>price</code> element with a value greater than 35.</p> <p>XPath includes functions for string values, numeric values, date and time comparison, node and QName manipulation, sequence manipulation, Boolean values, and more. XPath defines several data types such as node-set, string, number, and Boolean. XPath expressions evaluate to one of these data types.</p> <p>There are multiple versions of XPath; XPath 1.0 and XPath 2.0 are the most commonly used. XPath 2.0 is more powerful and includes additional functions and capabilities. XPath expressions are often used within XSLT for defining transformations and within XQuery for querying XML data.</p> <p>XPath supports XML namespaces. This is important for querying XML documents that use namespace prefixes.</p>"},{"location":"misc/xpointer/","title":"XPointer","text":"<p>XPointer, which stands for [[Extensible Markup Language|XML]] Pointer Language, is a system for addressing parts of an XML document. It extends the functionality of [[XPath]], a language used to select nodes in an XML document, by allowing more complex addressing that can include ranges of text and points between characters. XPointer is part of the XML family of technologies and is defined by the World Wide Web Consortium (W3C).</p> <p>XPointer allows for the identification of fragments within XML documents. It's used as a fragment identifier in a URI to point to specific parts of an XML document. While XPath is used for simple expressions to select nodes, XPointer can describe more specific locations in an XML document, such as ranges or specific points within the text.</p> <p>XPointer supports different schemes, such as the <code>xmlns</code> scheme for namespace handling, the <code>element()</code> scheme for element addressing, and the <code>xpointer()</code> scheme which uses XPath expressions.</p> <p>An XPointer expression could look like this:</p> <pre><code>http://example.com/document.xml#xpointer(id(\"Chapter2\"))\n</code></pre> <p>In this example:</p> <ul> <li>The URI points to an XML document named <code>document.xml</code>.</li> <li>The XPointer expression <code>#xpointer(id(\"Chapter2\"))</code> identifies a fragment in the XML document with an ID of <code>Chapter2</code>.</li> </ul> <p>XPointer can be used in web applications for deep linking directly to parts of XML-based documents like [[XHTML]], SVG, or XML databases. It's useful in XML processing applications where addressing specific parts of documents is required.</p> <p>The complexity of XPointer expressions can lead to potential performance issues if not properly implemented. Like with XPath, there is a potential for [[XML External Entities (XXE)|XXE]] vulnerabilities if XPointer is used with untrusted data in an XML context. Properly configuring XML parsers and validating input is crucial to mitigate this risk.</p>"},{"location":"misc/xquery/","title":"XQuery","text":"<p>XQuery, which stands for [[Extensible Markup Language|XML]] Query Language, is a powerful and versatile language designed for querying and manipulating XML data. XQuery provides functionalities to extract and manipulate data from XML documents, much like [[Structured Query Language|SQL]] does for [[Relational Database|relational databases]].</p> <p>XQuery is specifically designed to query XML data. It allows you to write queries that can traverse XML documents, filter elements, sort data, and extract specific information.</p> <p>XQuery is a functional programming language, meaning its design is based on and supports functional programming constructs like function composition, higher-order functions, and strong typing.</p> <p>A distinctive feature of XQuery is its FLWOR (pronounced \"flower\") expressions, which stand for \"For, Let, Where, Order by, Return\". These expressions are similar to SQL clauses and provide powerful ways to query and transform XML data.</p> <p>Beyond simple queries, XQuery can be used to transform XML data into other formats, such as HTML, text, or even new XML documents with different structures. XQuery leverages XPath expressions within its syntax, utilizing XPath\u2019s ability to navigate through XML documents effectively.</p> <p>XQuery is often supported by XML databases, which store data in XML format. These databases use XQuery as the primary language for querying and managing XML data. XQuery is particularly useful in scenarios where there is a need to work with complex XML data, such as in publishing, data interchange, web services, and content management systems.</p> <p>XQuery includes a rich set of functions for string manipulation and full-text search, making it effective for complex text-processing tasks. XQuery can be used in conjunction with other XML-based technologies, such as [[XSLT (Extensible Stylesheet Language Transformations)|XSLT]] and [[XSL-FO (Formatting Objects)|XSL-FO]], for comprehensive XML data processing and transformation solutions.</p>"},{"location":"misc/xsl/","title":"XSL (Extensible Stylesheet Language)","text":"<p>XSL (Extensible Stylesheet Language) is a family of languages used for transforming and rendering [[Extensible Markup Language|XML]] documents. XSL is made up of three parts: [[XSLT (Extensible Stylesheet Language Transformations)|XSLT (XSL Transformations)]], [[XPath]] (XML Path Language), and [[XSL-FO (Formatting Objects)|XSL-FO (XSL Formatting Objects)]].</p> <ol> <li>XSLT (XSL Transformations):</li> <li>XSLT is used for transforming XML documents into other XML documents or different formats like [[HTML]], plain text, or XSL-FO.</li> <li>It is the most widely used part of XSL and operates by matching template rules against XML nodes.</li> <li>XPath (XML Path Language):</li> <li>XPath is a language for navigating through elements and attributes in an XML document.</li> <li>It provides a way to select nodes in an XML document, which XSLT uses to define parts of the document that should be transformed.</li> <li>XSL-FO (XSL Formatting Objects): - XSL-FO is used for formatting XML data for output to screen, paper, or other media. It's a language for specifying the visual presentation of an XML document. - XSL-FO is often used for generating complex documents like reports, invoices, and other printed materials from XML data. -    XSLT allows developers to transform XML data into different formats, making it highly useful in web development, data interchange, and application integration. With XSL-FO, XML data can be styled for printing or display, similar to how [[CSS]] is used for HTML but with more capabilities for high-quality, paginated output.</li> </ol> <p>Being an XML-based technology, XSL can be used across different platforms and programming environments. XSL provides flexibility in how XML data is presented, enabling the same data to be rendered differently for various purposes or platforms.</p>"},{"location":"misc/xslt/","title":"XSLT (Extensible Stylesheet Language Transformations)","text":"<p>XSLT (Extensible Stylesheet Language Transformations) is a language for transforming [[Extensible Markup Language]] documents into other XML documents, or other formats such as [[HTML]] for web pages, plain text, or even [[XSL-FO (Formatting Objects)]] for PDF creation.</p> <p>It is part of the [[XSL (Extensible Stylesheet Language)]] family of technologies defined by the World Wide Web Consortium (W3C).</p> <p>XSLT is designed to transform the structure and appearance of XML data. It allows one XML document to be transformed into another XML document that has a different structure, or into a different format entirely.</p> <p>XSLT uses a template-based approach. An XSLT stylesheet consists of templates that match specific XML elements or attributes, and these templates define how the matched content should be transformed and formatted.</p> <p>The transformation is performed by an XSLT processor, which reads the XML and XSLT files, and then generates the output. This output can be another XML document, HTML, text, or other formats, depending on the transformation instructions.</p> <p>XSLT heavily relies on [[XPath]] (XML Path Language) for navigating XML documents and selecting nodes, which are pieces of data in the XML document that the XSLT transforms. Common use cases for XSLT include web page rendering from XML data, creating PDF documents from XML data, and converting XML data to different XML schemas.</p>"},{"location":"misc/xstream/","title":"XStream","text":"<p>XStream is a simple [[Java]] library used for serializing Java objects to [[Extensible Markup Language|XML]] and back again. It provides an easy and convenient way to convert objects to XML and to reconstruct them without the need for any additional mapping. XStream stands out for its simplicity and ease of use compared to more complex XML handling methods like [[JAXB (Java Architecture for XML Binding)|JAXB]] or [[SAX (Simple API for XML)|SAX]].</p> <p>XStream allows for direct serialization of Java objects to XML and vice versa with minimal configuration. This simplicity makes it popular for scenarios where quick and straightforward XML handling is needed.</p> <p>Unlike JAXB, XStream does not require the Java objects to be annotated with XML metadata. This can make it a good choice for cases where modifying the source code of the object classes is not feasible or desirable.</p> <p>XStream provides [[XStream]] to customize the XML output. It allows for changing element names, attributes, and adding custom converters to handle specific types.</p> <p>Its API is straightforward, often requiring only a few lines of code to serialize or deserialize objects, which makes it appealing for developers who need a quick solution without the complexity of other XML frameworks. XStream allows developers to define aliases for Java class names and field names, making the generated XML more readable and cleaner.</p> <p>It does not require an XML schema (XSD) to work. Objects are serialized and deserialized based on their runtime structure. XStream includes mechanisms to prevent security vulnerabilities related to object serialization, such as restricting the classes that can be serialized or deserialized.</p> <p>It is compatible with a wide range of Java versions and can be used in both Java SE and Java EE environments. XStream can be integrated with other libraries and frameworks, enhancing its functionality and adaptability. It is often used in applications that require quick and simple persistence of object graphs, configuration files, or in scenarios where XML is used for data interchange between systems.</p>"},{"location":"misc/yaml/","title":"YAML","text":"<p>YAML, which stands for \"YAML Ain't Markup Language\" (a recursive acronym), is a human-readable data serialization format. It is commonly used for configuration files and data exchange between languages with different data structures.</p> <p>YAML is broadly used in various programming environments and applications, particularly in scenarios where human readability and simplicity are important. YAML is designed to be easily readable by humans. Its syntax is straightforward, making it a preferred choice for writing configuration files.</p> <p>YAML can represent scalars (like strings, integers, floats), lists (arrays), and associative arrays (hashes or dictionaries). It uses indentation (spaces) to represent hierarchy, which helps in visually understanding the data structure.</p> <p>YAML is language-independent and can be used with any programming language that has a YAML parsing and emitting library, such as [[Python]], [[Ruby]], [[PHP]], [[Java]], [[JavaScript]], and others.</p> <p>YAML is extensively used in configuration files of systems and applications due to its simplicity and ease of use. It\u2019s notably used in [[Docker Compose]], [[Kubernetes]], [[Ansible]], and many other DevOps tools. YAML is a superset of [[JavaScript Object Notation|JSON]], meaning JSON files are also valid YAML. This makes it interoperable with systems that use JSON.</p> <p>Unlike JSON, YAML supports comments, making it more convenient for documenting the purpose or reason behind certain configurations. YAML can represent complex data structures, making it suitable for a wide range of applications beyond simple configuration, including data serialization and inter-process communication.</p> <p>While YAML is more readable than [[Extensible Markup Language|XML]] or JSON for complex data structures, it can be prone to errors due to its reliance on indentation and formatting, which needs careful handling.</p>"},{"location":"mobile/android/","title":"Android","text":"<p>Android is a widely-used operating system for mobile devices such as smartphones and tablets. Developed by Android Inc., which Google acquired in 2005, Android is based on a modified version of the Linux kernel and other open-source software. It was designed primarily for touchscreen mobile devices and has become one of the most popular operating systems globally. </p> <p>Android is an open-source platform, allowing manufacturers and developers to modify and customize the OS for various hardware platforms.</p> <p>Android versions are typically named in alphabetical order and have historically been named after sweets or desserts, like Android 8.0 Oreo, Android 9.0 Pie, etc., though Google announced a shift to numerical versioning starting with Android 10.</p> <p>Android devices typically come with pre-installed Google services, including the Google Play Store, which is the primary source for Android apps, games, movies, music, and books. Android's user interface is based on direct manipulation, using touch gestures that correspond to real-world actions, like swiping, tapping, and pinching, to manipulate on-screen objects.</p> <p>Android applications (apps) are primarily written in the [[Java]] language using the [[Android Software Development Kit (SDK)]]. Kotlin and C++ are also used. The Android architecture consists of several layers, including the Linux kernel (hardware abstraction), libraries, Android runtime (ART), and the application framework.</p> <p>Due to the wide variety of Android devices with different screen sizes, hardware specifications, and operating system versions, there's a notable issue of fragmentation in the Android ecosystem. </p> <p>Android includes various built-in security features such as app sandboxing, Google Play Protect for app scanning, and regular security updates. However, the openness of the platform can lead to security challenges.</p>"},{"location":"mobile/asdk/","title":"Android Software Development Kit (SDK)","text":"<p>The Android Software Development Kit (SDK) is a collection of tools, libraries, documentation, and samples that are used to develop [[Android]] applications. It provides the essential resources for developers to build apps for Android devices, including smartphones, tablets, and Android Wear devices.</p> <p>Tools such as the Android Studio Integrated Development Environment (IDE), the Android Debug Bridge (ADB), and the emulator for testing Android applications on different virtual devices. A set of pre-built code libraries, including the Android framework [[APIs]], which offer functionalities like UI elements, networking, media playback, database access, and more.</p> <p>Android Studio is the official IDE for Android development. It is based on IntelliJ IDEA and provides tools for coding, debugging, performance tuning, and version compatibility checking. The SDK includes an emulator (AVD) that allows developers to run and test their applications on different Android versions and screen sizes without needing physical devices.</p> <p>Android SDK is structured around API (Application Programming Interface) levels, which correspond to different versions of the Android platform. Developers can target specific API levels depending on the range of devices they aim to support.</p> <p>While [[Java]] was the primary language for Android development, Kotlin is now recommended by Google. The SDK also supports other languages like C and C++ for parts of the app that require high performance.</p> <p>Android uses [[Gradle]] as its build system, which automates the process of building the application package (APK or Android App Bundle) that is deployed to devices. The SDK includes frameworks for unit testing and UI testing, allowing developers to ensure their apps work correctly.</p>"},{"location":"networking/a/","title":"DNS A Records","text":"<p>An A record\u00a0maps a Fully Qualified Domain Name (FQDN) to the physical IP address of the computer hosting that domain. Internet traffic uses the A record to find the computer hosting your domain's DNS settings. The value of an A record is always an IP address, and multiple A records can be configured for one domain name.</p> <p>A records only hold IPv4 addresses. If a website has an IPv6 address, it will instead use an\u00a0DNS AAAA Record</p> <p>Here is an example of an A record:</p> example.com record type: value: TTL @ A 192.0.2.1 14400 <p>The \"@\" symbol in this example indicates that this is a record for the root domain, and the \"14400\" value is the\u00a0TTL (time to live), listed in seconds. The default TTL for A records is 14,400 seconds. This means that if an A record gets updated, it takes 240 minutes (14,400 seconds) to take effect.</p>"},{"location":"networking/aaaa/","title":"DNS AAAA Records","text":"<p>DNS AAAA records match a Fully Qualified Domain Name (FQDN) to an IPv6 address. DNS AAAA records are exactly like\u00a0DNS A Records, except that they store a\u00a0domain's IPv6 address instead of its IPv4 address.</p> <p>IOne of the important differences between IPv6 and IPv4 is that IPv6 addresses are longer than IPv4 addresses. The Internet is running out of IPv4 addresses, just as there are only so many possible phone numbers for a given area code. But IPv6 addresses offer exponentially more permutations and thus far more possible\u00a0IP addresses.</p> <p>Here is an example of an AAAA record:</p> example.com record type: value: TTL @ AAAA 2001:0db8:85a3:0000: 0000:8a2e:0370:7334 14400"},{"location":"networking/application/","title":"Application Layer","text":"<p>The application layer is the highest layer of the OSI Model and is used by end-user software such as web browsers and email clients. It provides protocols that allow software to send and receive information and present meaningful data to users.</p> <p>The layer is responsible for providing network services directly to user applications, enabling them to manage data, communications and collaboration over the network. This layer is crucial because it translates user requests into a format that can be understood and managed by the lower layers of the network.</p> <p>Some examples of application layer protocols are HTTP Protocol, File Transfer Protocol, Post Office Protocol, Simple Mail Transfer Protocol and DNS.</p> <p>This layer determines whether adequate resources exist for communication. It also manages communications between apps and directs data to the correct program. It is responsible for converting data into a format usable by applications and directing that data to the proper application window.</p> <p>If multiple instances of an application exist, this layer ensures that data is delivered to the correct instance.</p>"},{"location":"networking/arp/","title":"Address Resolution Protocol (ARP)","text":"<p>The Address Resolution Protocol (ARP) is a fundamental protocol used in the Internet Protocol Suite (TCP-IP) for finding the MAC Address of a device associated with a specific IP Address. It operates within the Data Link Layer of the Internet protocol suite and is used primarily in local area networks (LANs).</p> <p>ARP's primary function is to translate 32-bit IP addresses into 48-bit MAC addresses. This is necessary because while IP addresses are used to identify devices on a network at the logical (software) level, MAC addresses are used to identify devices at the physical (hardware) level.</p> <p>When a device (like a computer or router) on a LAN wants to communicate with another device, it needs to know the recipient's MAC address. If the sending device only knows the IP address of the target device, it broadcasts an ARP request onto the network. This request asks, \"Who has IP address X.X.X.X, and what is your MAC address?\" The device with that IP address responds with its MAC address. The requesting device then stores this mapping in its ARP cache for future reference and proceeds with communication.</p> <p>Each device on a network maintains a table known as the ARP cache, which stores IP-to-MAC address mappings for a certain period. This cache reduces the need to repeatedly broadcast ARP requests for the same IP addresses.</p> <p>ARP is essential in local area networking, particularly within Ethernet networks. ARP only works in the same broadcast domain or network segment. It is not routable, meaning it does not work across different networks.</p> <p>ARP does not include a mechanism for authenticating ARP responses. This can be exploited in ARP Poisoning (or ARP poisoning) attacks, where an attacker sends false ARP messages to the network. This can lead to traffic interception or network disruption.</p>"},{"location":"networking/caching/","title":"Caching Server","text":"<p>A caching server, also known as a cache server, is a type of server that stores copies of frequently accessed or requested data, known as cached content. The purpose of a caching server is to reduce latency, improve response times, and minimize the load on upstream servers by serving cached content instead of fetching it from the original source every time a request is made.</p> <p>Caching servers implement a caching mechanism to store copies of data, such as web pages, images, scripts, or other resources. Cached content is stored temporarily and can be quickly served to users upon subsequent requests.</p> <p>Caching servers prioritize caching frequently accessed content to optimize performance for users. Caching servers follow HTTP Protocol caching headers provided by web servers and applications to determine how long to store cached content and when to revalidate it. Common HTTP caching headers include Cache-Control, Expires, Last-Modified, and ETag.</p> <p>Types of Caching Servers:</p> <ul> <li>Web Proxy Caches: These caches are often deployed at the network edge, acting as intermediaries between clients and web servers. They store copies of content requested by clients and serve it locally.</li> <li>Content Delivery Network (CDN) Caches: Content Delivery Network consist of distributed caching servers strategically located around the globe. They cache and deliver static assets (e.g., images, stylesheets) to users based on their geographical location.</li> <li>Reverse Proxy Caches: Placed in front of web servers, reverse proxy caches store copies of dynamic content generated by web applications. They help offload server processing and improve response times.</li> <li>Browser Caches: While not traditional caching servers, web browsers maintain local caches on users' devices to store copies of recently visited web pages and resources.</li> </ul> <p>Caching servers implement cache invalidation mechanisms to ensure that stale or outdated content is periodically purged from the cache. Techniques for cache invalidation include time-based expiration, versioning, and cache purging.</p> <p>Some caching servers also function as Load Balancers, distributing incoming requests across multiple backend servers to optimize resource utilization.</p>"},{"location":"networking/cloudflare/","title":"Cloudflare","text":"<p>Cloudflare acts as an intermediary between a client and a server, using a reverse proxy to mirror and cache websites. By storing web content for delivery on the closest edge server, it is able to optimize loading times. That also allows it to modify content, such as images and rich text, for better performance.</p> <p>This intermediary design is also how Cloudflare offers a level of filtration for security. By sitting between the client and the hosting server, it can detect malicious traffic, intercept distributed denial-of-service attacks, deflect attacks from bots, remove bot traffic and limit spam.</p> <p>Cloudflare is a Content Delivery Network. CDNs are an increasingly popular model across the internet because they solve an important problem: latency. They, at least in Cloudflare\u2019s case, provide what\u2019s known as an edge network. In short, an edge network creates a much closer entry point for data, rather than bouncing it between servers across the globe.</p> <p>With 155 data centres around the world, Cloudflare works by caching a version of a customer\u2019s website and any static resources, then delivering it to visitors based on their location.</p> <p>That ensures the least amount of distance between a visitor and a website, which reduces latency, bandwidth and page load times. By moving the content and computational work closer, Cloudflare-powered websites can work faster.</p> <p>The company\u2019s DNS services use the same network of data centers. Cloudflare offers authoritative DNS and public DNS resolver services. Both are offered as privacy and speed-first alternatives to internet service provider DNS servers.</p> <p>In addition to content delivery and DNS services, Cloudflare provides security as a service with DDoS protection, email obfuscation, web application firewall access and threat blocking. By sitting between a client and host, it can also filter traffic, reducing bot traffic and spam.</p>"},{"location":"networking/cname/","title":"DNS CNAME Records","text":"<p>A \"canonical name\" (CNAME) record points from an alias domain to a \"canonical\" domain. A CNAME record is used in lieu of an\u00a0DNS A Records, when a\u00a0domain\u00a0or subdomain is an alias of another domain.</p> <p>All CNAME records must point to a domain, never to an\u00a0IP address. Imagine a scavenger hunt where each clue points to another clue, and the final clue points to the treasure.</p> <p>A domain with a CNAME record is like a clue that can point you to another clue (another domain with a CNAME record) or to the treasure (a domain with an A record).</p> <p>For example, suppose blog.example.com has a CNAME record with a value of \"example.com\" (without the \"blog\"). This means when a\u00a0DNS\u00a0server hits the\u00a0DNS records\u00a0for blog.example.com, it actually triggers another DNS lookup to example.com, returning example.com\u2019s IP address via its A record.</p> <p>In this case we would say that example.com is the canonical name (or true name) of blog.example.com.</p> <p>Oftentimes, when sites have subdomains such as blog.example.com or shop.example.com, those subdomains will have CNAME records that point to a root domain (example.com).</p> <p>This way if the IP address of the host changes, only the DNS A record for the root domain needs to be updated and all the CNAME records will follow along with whatever changes are made to the root.</p> <p>A frequent misconception is that a CNAME record must always resolve to the same website as the domain it points to, but this is not the case. The CNAME record only points the client to the same IP address as the root domain.</p> <p>Once the client hits that IP address, the web server will still handle the URL accordingly. So for instance, blog.example.com might have a CNAME that points to example.com, directing the client to example.com\u2019s IP address.</p> <p>But when the client actually connects to that IP address, the web server will look at the URL, see that it is blog.example.com, and deliver the blog page rather than the home page.</p> <p>Example of a CNAME record:</p> blog.example.com record type: value: TTL @ CNAME is an alias of example.com 32600"},{"location":"networking/datacenterbridging/","title":"Data Center Bridging","text":"<p>Data Center Bridging (DCB) is a suite of Institute of Electrical and Electronics Engineers (IEEE) standards that enhance traditional Ethernet networking to make it more suitable for data center environments.</p> <p>These enhancements are particularly focused on enabling Ethernet networks to carry mixed types of traffic, such as storage, data, and high-performance interconnects, with improved reliability, efficiency, and low latency. DCB is crucial for technologies like FCoE (Fibre Channel over Ethernet) and iSCSI, as well as RDMA over Converged Ethernet (RoCE).</p> <p>Some key components include:</p> <ol> <li>Priority-based Flow Control (PFC) - IEEE 802.1Qbb:</li> <li>Provides a link-level flow control mechanism that can prevent packet loss due to congestion. PFC allows for pause frames to be sent for specific classes of traffic, preventing packet drops without impacting other traffic.</li> <li>Enhanced Transmission Selection (ETS) - IEEE 802.1Qaz:</li> <li>Allows for the allocation of bandwidth on a network link to different traffic classes. It ensures that critical traffic gets the necessary bandwidth, improving network management and efficiency.</li> <li>Data Center Bridging Exchange (DCBX):</li> <li>A discovery and capability exchange protocol used for conveying configuration and capabilities of the DCB features between neighbors (such as switches and endpoints), ensuring consistent configuration across the network.</li> <li>Quantized Congestion Notification (QCN) - IEEE 802.1Qau:</li> <li>A mechanism to manage network congestion by providing feedback to the endpoints sending data, allowing them to adjust their transmission rate to alleviate congestion.</li> </ol> <p>DCB enables converged network environments where storage, LAN, and cluster traffic can coexist on the same Ethernet network, reducing the need for separate infrastructures. For storage traffic protocols like FCoE and iSCSI, DCB ensures lossless transmission, which is crucial for storage operations.</p> <p>By managing flow control and congestion, DCB supports low-latency operations, essential for high-performance computing and real-time applications. DCB provides a standardized way to implement these advanced features, ensuring compatibility and interoperability between different devices and vendors.</p>"},{"location":"networking/datalink/","title":"Data Link Layer","text":"<p>The Data Link layer defines how devices communicate over a network. It is responsible for managing physical addressing and switching on a network. Physical (MAC) addresses are handled here. Information traversing this layer is known as a \"frame\".</p> <p>It's responsible for node-to-node data transfer. It handles the physical addressing and error correction and control. It ensures data transfer is error-free from one node to another, over the Physical Layer.</p> <p>The major role is to ensure error-free transmission of information. It's also responsible for encoding, decode and organizing the outgoing and incoming data.</p> <p>Info</p> <p>This is considered the most complicated layer of the OSI model as it hides all the underlying complexities of the hardware from the other above layers.</p>"},{"location":"networking/defaultports/","title":"Default Ports","text":"<p>A default port is a port number that is configured by default to accept internet connections and packets from specific services, using protocols like User Datagram Protocol (UDP) or Transmission Control Protocol (TCP).</p> <p>For instance, to access web servers, port 80 is mostly open by default. Most devices enable HTTP Protocol communications between web servers and browsers over port 80 by default.</p> <p>Some common ports and services include:</p> Port Service \\ 21 File Transfer Protocol 22 Secure Shell 23 Telnet 25 Simple Mail Transfer Protocol 53 DNS 69 Trivial File Transfer Protocol 80 HTTP Protocol 88 Kerberos Authentication 110 Post Office Protocol 111 RPC Protocol 119 Network Time Protocol 135 Microsoft Remote Procedure Call 139/445 Server Message Block 143/993 Internet Message Access Protocol 161/162 Simple Network Management Protocol 389/636 Lightweight Directory Access Protocol 443 HTTPS Protocol 995 Post Office Protocol Secure 1433 Microsoft SQL Server 1521 Oracle Database 2049 Network File Share 3306 MySQL (KB) 3389 Remote Desktop Protocol 5900 Virtual Network Computing 8080 HTTP Protocol/Web Services"},{"location":"networking/dhcp/","title":"Dynamic Host Configuration Protocol (DHCP)","text":"<p>DHCP, which stands for Dynamic Host Configuration Protocol, is a network management protocol used on IP networks. It automates the process of configuring devices on the network with IP Address and other related configuration information.</p> <p>DHCP allows network administrators to automate the assignment of IP addresses to devices (known as clients) on the network. This saves the effort of manually assigning an IP address to each device.</p> <p>When a device connects to the network, it sends a broadcast request for configuration information. The DHCP server receives this request and assigns an IP address from a pool of available addresses (known as a DHCP pool). Along with the IP address, the DHCP server also provides other necessary configuration information such as the subnet mask, default gateway, and DNS server addresses.</p> <p>DHCP typically leases IP addresses to devices for a specified period. After the lease expires, the IP address is returned to the pool for reassignment. If the device remains connected, it can request to renew the lease.</p> <p>By automating IP address management, DHCP simplifies network setup and management, especially in environments where devices frequently join and leave the network, like in Wi-Fi networks.</p> <p>DHCP helps prevent IP conflicts, where two devices might otherwise be manually configured with the same IP address, leading to network communication issues. Administrators can configure DHCP settings according to the needs of their network, including the range of IP addresses in the DHCP pool, lease duration, and other options.</p> <p>DHCP operates on a Client-Server Architecture model. The DHCP client on the device requests network configuration details, and the DHCP server provides this information. It supports a wide range of devices, including computers, smartphones, and IoT devices, making it versatile for various network environments.</p>"},{"location":"networking/dns/","title":"DNS","text":"<p>DNS, or Domain Name System, is like the internet's phonebook. When you type a website address, like www.google.com into your browser, your computer doesn't understand the words. Instead, it needs a number called an IP Address to find the website.</p> <p>DNS is the system that converts the website name into this IP address. It's like looking up someone's name in a phonebook to find their telephone number. Without DNS, you'd have to remember complicated numbers for every website you want to visit. DNS makes it easy by letting us use simple, memorable names.</p> <p>Info</p> <p>These DNS requests are called \"queries\".</p>"},{"location":"networking/fcoe/","title":"FCoE (Fibre Channel over Ethernet)","text":"<p>FCoE (Fibre Channel over Ethernet) is a network technology that encapsulates Fibre Channel frames over Ethernet networks. This allows Fibre Channel to use 10 Gigabit Ethernet networks (or higher speeds) while preserving the Fibre Channel protocol. FCoE was developed to integrate the high-speed data transfer capabilities of Fibre Channel with the flexibility and ubiquity of Ethernet.</p> <p>FCoE enables the convergence of data and storage networking. This allows organizations to use a single network infrastructure for both SAN (Storage Area Naetwork) and Local Area Networks (LANs) traffic, reducing hardware, cabling, and management costs.</p> <p>FCoE preserves the Fibre Channel protocol, ensuring compatibility with existing Fibre Channel networks and devices. This allows for a seamless integration of new technology into existing data center infrastructures. It leverages high-speed Ethernet (10 Gbps or higher) for storage networking, which can provide improved bandwidth and reduced latency compared to traditional Fibre Channel.</p> <p>FCoE requires a lossless Ethernet environment to function correctly. This is typically achieved through Data Center Bridging capabilities, which add flow control and congestion notification features to standard Ethernet.</p> <p>FCoE is primarily used in data center environments where there is a need to consolidate network and storage infrastructure without sacrificing performance. In environments requiring high-speed data access and transfer, FCoE offers a way to combine high-speed networking with robust storage connectivity. FCoE is well-suited for virtualized data centers, offering flexibility and scalability in managing network and storage resources.</p>"},{"location":"networking/icmp/","title":"ICMP","text":"<p>ICMP, short for Internet Control Message Protocol, is a network layer protocol used by network devices, including routers, to send error messages and operational information indicating success or failure when communicating with another IP address. ICMP is an integral part of the Internet Protocol Suite, as defined in RFC 792.</p> <p>ICMP is used for diagnosing and reporting network errors and issues. For example, if a router cannot forward an IP packet due to a problem, it might send an ICMP message back to the sender indicating the issue.</p> <p>Tools like Ping and Traceroute use ICMP to test the reachability of network devices on an IP network.</p> <ol> <li>Types of Messages:</li> <li>Echo Request and Echo Reply: Used by the ping command to check network connectivity.</li> <li>Destination Unreachable: Indicates that a network destination is unreachable.</li> <li>Time Exceeded: Sent back to the source when a packet has expired (due to a TTL value reaching zero, indicating it has been in the network too long).</li> </ol> <p>Unlike Transmission Control Protocol or User Datagram Protocol|UDP, ICMP is not used for sending and receiving data between end systems. It doesn\u2019t carry application layer data but instead is used for control messaging.</p> <p>ICMP has a version for IPv6 called ICMPv6, which, in addition to providing similar functionalities as ICMP for IPv4, also handles IPv6-specific messages, like Neighbor Discovery.</p>"},{"location":"networking/infiniband/","title":"InfiniBand","text":"<p>InfiniBand is a high-performance, low-latency networking technology primarily used in high-performance computing (HPC), data centers, and enterprise storage. Developed by the InfiniBand Trade Association, it's known for its high throughput and low latency characteristics, making it well-suited for environments where speed and data transfer efficiency are critical.</p> <p>InfiniBand provides very high data transfer rates (up to several hundred gigabits per second) with low latency, significantly faster than traditional Ethernet or Fibre Channel networks. It is highly scalable, suitable for small clusters to large supercomputers with thousands of nodes.</p> <p>InfiniBand supports advanced QoS capabilities, ensuring reliable and consistent data delivery for various types of traffic. InfiniBand natively supports RDMA (Remote Direct Memory Access), allowing data to be transferred directly between the memory of two computers without CPU involvement. It includes features for error handling and failover, enhancing the reliability and stability of the network.</p> <p>While Ethernet is more common and versatile, used for a wide range of networking applications, InfiniBand is specialized for high-performance and data-intensive tasks. InfiniBand's low latency and high throughput make it ideal for HPC and data center environments, though its specialized nature means it's generally more expensive and less familiar than Ethernet.</p> <p>InfiniBand infrastructure, including switches and host channel adapters (HCAs), can be more expensive and complex to implement and manage than traditional Ethernet. InfiniBand is typically used in environments where all components are designed to support it, as it's not natively compatible with standard Ethernet networks. Effective use of InfiniBand requires software that is specifically designed or adapted to take advantage of its features.</p>"},{"location":"networking/ipa/","title":"IP Address","text":"<p>An IP address is a unique string of numbers separated by periods (IPv4) or colons (IPv6) that identifies each computer or device connected to the Internet or a local network.</p> <p>IP addresses are the identifier that allows information to be sent between devices on a network: they contain location information and make devices accessible for communication. The internet needs a way to differentiate between different computers, routers, and websites. IP addresses provide a way of doing so and form an essential part of how the internet works.</p> <p>There are two types of IP addresses:</p> <ul> <li>IPv4 - most common form. It uses a 32-bit address scheme allowing for a total of &gt;4 billion unique addresses (example address is 192.168.0.1)</li> <li>IPv6 - uses a 128-bit address scheme, significantly increasing the number of possible addresses (example address is 2001:0db8:85a3:0000:0000:8a2e:0370:7334).</li> </ul> <p>IP addresses can be static or dynamic:</p> <ul> <li>Static - do not change. They serve as a permanent Internet address and provide a simple, reliable way for computers to contact you.</li> <li>Dynamic - temporary and assigned each time a device accesses the Internet. They are borrowed from a pool of IP addresses that are shared among multiple computers.</li> </ul>"},{"location":"networking/iscsi/","title":"iSCSI","text":"<p>iSCSI (Internet Small Computer Systems Interface) is a network protocol standard that allows the use of the SCSI Protocol over TCP/IP networks. It enables the transfer of data over intranets and the management of storage over long distances.</p> <p>iSCSI is used to facilitate data transfers over Local Area Networks (LANs), Wide Area Network (WANs), or the internet, and can enable location-independent data storage and retrieval.</p> <p>iSCSI encapsulates SCSI commands into TCP/IP packets, which are then transmitted over LANs, WANs, or the internet. Unlike file-based storage (such as Network File Share or Server Message Block/CIFS), iSCSI works at the block level, allowing it to interact more closely with the storage devices, which is useful for tasks like disk partitioning.</p> <p>iSCSI can be implemented over existing network infrastructure, eliminating the need for expensive dedicated storage networks like Fibre Channel. iSCSI allows computers to boot from remote storage, which is useful for centralized management and for stateless computers or thin clients. It is commonly used in SANs for linking data storage facilities.</p> <p>This is how it works:</p> <ul> <li>iSCSI Initiator: A client, such as a server, that sends SCSI commands. This initiator communicates over the network with the iSCSI target.</li> <li>iSCSI Target: The storage resource, which could be a dedicated storage server or storage hardware, receives and responds to the commands from the initiator.</li> </ul> <p>Since iSCSI relies on network performance, its efficiency can be impacted by network congestion, latency, and reliability. When used over public networks, iSCSI traffic should be secured using techniques like Virtual Private Networks or IPsec to prevent unauthorized access. Proper configuration of network settings and iSCSI parameters is essential to ensure optimal performance and compatibility with various storage devices.</p>"},{"location":"networking/iwarp/","title":"iWARP","text":"<p>iWARP (Internet Wide Area RDMA Protocol) is a network protocol that enables Remote Direct Memory Access (RDMA) over standard TCP/IP networks. It extends the capabilities of RDMA, traditionally confined to high-speed InfiniBand networks, to Ethernet-based networks.</p> <p>iWARP allows for high-throughput, low-latency data transfers across network environments using the familiar and ubiquitous TCP/IP protocol stack.</p> <p>iWARP facilitates RDMA operations over standard Ethernet networks, which are more common and widespread than InfiniBand networks, especially in enterprise data centers. Since iWARP operates over TCP/IP, it can be deployed on existing Ethernet infrastructure without requiring specialized network switches. This makes it relatively easy to implement in many existing network environments.</p> <p>iWARP provides the low latency and high bandwidth benefits of RDMA, making it suitable for performance-critical applications like high-performance computing (HPC), storage area networks (SANs), and data center operations.</p> <p>By offloading data transfer operations from the CPU to the network interface card (NIC), iWARP reduces CPU usage and improves overall system performance. iWARP includes congestion management capabilities inherent in Transmission Control Protocol, making it robust in diverse network conditions, including in Wide Area Network (WANs).</p> <p>InfiniBand is another RDMA technology offering high performance but requires dedicated InfiniBand infrastructure. iWARP, on the other hand, operates over standard Ethernet.</p> <p>RDMA over Converged Ethernet (RoCE) also allows RDMA over Ethernet but requires a lossless Ethernet environment, which can involve additional configuration and equipment (like Data Center Bridging, DCB). iWARP, leveraging TCP/IP, can operate over standard Ethernet without these additional requirements.</p>"},{"location":"networking/lans/","title":"Local Area Networks (LANs)","text":"<p>A Local Area Network (LAN) is a computer network that interconnects computers within a limited area such as a residence, school, laboratory, office building, or closely positioned group of buildings. It is one of the most common types of networks used for data communications.</p> <p>LANs are designed for small geographical areas. They are typically confined to a single building or a group of closely situated buildings like a campus or business park. LANs offer high data transfer rates within the network, typically ranging from 100 Mbps to 10 Gbps or more, depending on the technology used.</p> <p>Devices commonly used in LANs include routers, switches, hubs, and network cables. In Wireless LANs (WLANs), Wi-Fi technology and wireless access points are used.</p> <p>LANs can be either wired, using Ethernet cables, or wireless, commonly using Wi-Fi technology. Wired LANs typically offer greater speed and security, while wireless LANs offer more flexibility and mobility.</p> <p>One of the primary purposes of a LAN is to enable the sharing of resources and files among multiple users. This includes sharing printers, file storage, and applications. LANs often provide internet access through a single shared connection. Devices on the LAN can connect to the internet using a router or modem.</p> <p>Security within a LAN includes firewall, network security protocols, and potentially Network Access Control (NAC) systems to protect sensitive data and prevent unauthorized access.</p> <p>While LANs are limited in size, they can be connected to other LANs over any distance via telephone lines and radio waves to form a Wide Area Network (WAN).</p>"},{"location":"networking/mac/","title":"MAC Address","text":"<p>A MAC (Media Access Control) address is a unique identifier assigned to network interfaces for communications on the physical network segment. It's a fundamental element in the architecture of networked devices and plays a critical role in network communications, particularly at the data link layer (Layer 2) of the OSI model.</p> <p>A MAC address is typically a 48-bit (6-byte) number. It's commonly written in hexadecimal format and separated by colons or hyphens, like <code>00:1A:2B:3C:4D:5E</code>. Each MAC address is meant to be globally unique. It's pre-assigned to a network interface card (NIC) or a similar device by the manufacturer.</p> <p>The MAC address is divided into two parts:</p> <ul> <li>Organizationally Unique Identifier (OUI): The first three bytes represent the OUI, which identifies the manufacturer or vendor of the device.</li> <li>Device Identifier: The remaining bytes are assigned by the manufacturer and serve to uniquely identify the network interface.</li> </ul> <p>In a Local Area Networks (LANs), devices use MAC addresses to identify and communicate with each other. MAC addresses operate at the data link layer of the OSI model, facilitating the transfer of data between physically connected network devices. MAC addresses are used in Ethernet and Wi-Fi networks. Each Ethernet or Wi-Fi interface in a computer, smartphone, router, or other network devices has a unique MAC address.</p> <p>Network switches use MAC addresses to forward data to the correct device on a LAN. The Address Resolution Protocol (ARP) maps IP addresses to MAC addresses, enabling proper routing of data in a network. MAC addresses are sometimes used in network access control and filtering, although they can be spoofed (falsely imitated).</p>"},{"location":"networking/mx/","title":"DNS MX Records","text":"<p>A DNS 'mail exchange' (MX) record directs email to a mail server. The MX record indicates how\u00a0email\u00a0messages should be routed in accordance with the Simple Mail Transfer Protocol (the standard protocol for all email). Like\u00a0DNS CNAME Records, an MX record must always point to another\u00a0domain.</p> <p>Example of an MX record:</p> example.com record type: priority: value: TTL @ MX 10 mailhost1.example.com 45000 @ MX 20 mailhost2.example.com 45000 <p>The 'priority' numbers before the domains for these MX records indicate preference; the lower 'priority' value is preferred. The server will always try mailhost1 first because 10 is lower than 20. In the result of a message send failure, the server will default to mailhost2.</p> <p>The email service could also configure this MX record so that both servers have equal priority and receive an equal amount of mail:</p> example.com record type: priority: value: TTL @ MX 10 mailhost1.example.com 45000 @ MX 10 mailhost2.example.com 45000 <p>This configuration enables the email provider to equally\u00a0balance the load\u00a0between the two servers.</p>"},{"location":"networking/nat/","title":"Network Address Translation (NAT)","text":"<p>NAT (Network Address Translation) is a method used in networking to modify network address information in IP packet headers while they are in transit across a traffic routing device. It is commonly used in routers and Firewall.</p> <p>One of the primary purposes of NAT is to conserve global IP Address by allowing multiple devices on a private network to be mapped to a single public IP address. This is particularly important given the limited number of IPv4 addresses available.</p> <p>Types of NAT:</p> <ul> <li>Static NAT: Maps an unregistered IP address to a registered IP address on a one-to-one basis.</li> <li>Dynamic NAT: Maps an unregistered IP address to a registered IP address from a group of available addresses.</li> <li>Port Address Translation (PAT): Also known as \"NAT overload\", PAT maps multiple unregistered IP addresses to a single registered IP address by using different ports.</li> </ul> <p>NAT is often used to enable 'IP masquerading', where all devices on a private network appear to the outside world to have the same IP address (the router\u2019s public IP address). This is commonly used in home and small business networks.</p> <p>By hiding internal IP addresses, NAT can add a layer of security to the network. External users see only the public IP address, making it more difficult to target specific devices within the local network.</p> <p>NAT is typically performed by routers, which are set up to translate the private IP addresses of devices within the network to a public address for internet communication. Some applications and protocols that require peer-to-peer connections, like VoIP and online gaming, can be disrupted by NAT, as it can prevent direct communication between devices.</p> <p>Various techniques, like UPnP (Universal Plug and Play) and STUN (Session Traversal Utilities for NAT), are used to overcome the limitations imposed by NAT, especially in peer-to-peer communications.</p> <p>NAT is predominantly a solution for IPv4 networks. IPv6, with its larger address space, reduces the need for NAT, though NAT for IPv6 does exist. Many Internet Service Providers (ISPs) use NAT to manage the limited number of IPv4 addresses available, especially as the world transitions more towards IPv6.</p>"},{"location":"networking/network/","title":"Network Layer","text":"<p>The Network Layer is responsible for logical addressing and routing on a network. Logical addressing methods include those defined by IPv4 and IPv6. The information traversing this layer is known as a \"packet\".</p> <p>This layer manages the delivery of packets, including routing through different routers in the network. It is responsible for packet forwarding and addressing. The main responsibility is to carry data packets from the source to the destination.</p> <p>Some examples of protocols used at this layer include:</p> <ul> <li>IP Address (IPv4)</li> <li>IP Address (IPv6)</li> <li>Open Shortest Path First (OSPF)</li> <li>Enhanced Interior Gateway Routing Protocol (EIGRP)</li> </ul>"},{"location":"networking/networkstack/","title":"Network Protocol Stack","text":"<p>A network protocol stack, often referred to as a protocol suite, is a set of network communication protocols layered atop one another to handle the complexities of data transmission across computer networks. Each layer in the stack has a specific function and communicates with the layers above and below it.</p> <p>The most commonly used and referenced stack is the OSI Model. Another model that is commonly used is the TCP/IP model</p>"},{"location":"networking/ns/","title":"DNS NS Records","text":"<p>NS stands for \u2018nameserver,\u2019 and the nameserver record indicates which DNS server is authoritative for that domain (i.e. which server contains the actual DNS records).</p> <p>Basically, NS records tell the Internet where to go to find out a domain's IP address. A domain often has multiple NS records which can indicate primary and secondary nameservers for that domain. Without properly configured NS records, users will be unable to load a website or application.</p> <p>Here is an example of an NS record:</p> example.com record type: value: TTL @ NS ns1.exampleserver.com 21600 <p>Info</p> <p>Note that NS records can never point to a DNS CNAME Records</p>"},{"location":"networking/osimodel/","title":"OSI Model","text":"<p>The OSI model is a seven-layer model used to visualize computer networks. Each of the seven layers goes up in increments of one as it gets closer to the human layer (Application Layer). The bottom layer (Physical Layer) is where the network receives and transmits raw data.</p> <p>The OSI model belongs to the International Organization for Standards (ISO) and is maintained by the Identification ISO/IEC 7498-1.</p> <p></p> <p>The seven layers are as follows:</p> <ul> <li>Application Layer</li> <li>Presentation Layer</li> <li>Session Layer</li> <li>Transport Layer</li> <li>Network Layer</li> <li>Data Link Layer</li> <li>Physical Layer</li> </ul>"},{"location":"networking/packet/","title":"Packet","text":"<p>A \"packet\" refers to a unit of data that is transmitted across a network. When information is sent over the Internet, it is broken down into smaller, manageable units known as packets. These packets contain not only the data being transmitted but also important control information such as:</p> <ol> <li>Source and Destination Addresses: These indicate where the packet is coming from and where it is going. This helps in routing the packet across the network to reach its intended destination.</li> <li>Sequence Information: This is used to reassemble the packets in the correct order when they reach their destination, as packets can arrive out of order.</li> <li>Error Checking Data: This is used to verify that the packet arrived intact and without corruption during the transit.</li> <li>Protocol Information: This indicates the type of protocol (like Transmission Control Protocol (TCP), User Datagram Protocol (UDP), etc.) used for communication, which dictates how data is treated.</li> </ol>"},{"location":"networking/pans/","title":"Personal Area Networks (PANs)","text":"<p>Personal Area Networks (PANs) are networks used for communication among computer devices, including telephones and personal digital assistants, within a range of a few meters or about 30 feet. The primary purpose of a PAN is to facilitate data transmission among devices close to a single user.</p> <p>PANs are designed to cover a small area, typically within the immediate vicinity of a user. They are not meant for large-scale network coverage like Local Area Networks (LANs) or Wide Area Network (WAN).</p> <p>They enable the interconnection of devices like smartphones, tablets, laptops, wearables (like smartwatches), and peripheral devices (like keyboards, mice, and printers). PANs can be wireless (WPANs) or wired. Wireless PANs are the most common, utilizing technologies like Bluetooth, Infrared, and Wi-Fi Direct. Wired PANs might use USB or FireWire connections.</p> <p>In wireless PANs, especially those using Bluetooth or Infrared, the emphasis is on low power consumption and short-range communication, suitable for personal device connectivity.</p> <p>Common uses include file transfers between devices, internet sharing from a phone to a laptop, wireless keyboards and mice connecting to computers, and fitness trackers syncing data with smartphones.</p> <p>Security in PANs is crucial, especially in wireless setups, to protect data during transmission. Technologies like Bluetooth incorporate security measures like encryption and authentication.</p> <p>Technologies like Bluetooth and Near Field Communication (NFC) are prevalent in establishing WPANs for quick and efficient device-to-device communication.</p>"},{"location":"networking/physical/","title":"Physical Layer","text":"<p>The Physical Layer defines how bits are passed over a medium. They can be passed electronically, mechanically, optically or by radio signals. It consists of various network components such as power plugs, connectors, receivers, cable types, etc. </p> <p>The physical layer sends data bits from one device(s) to another device(s). It also defines the types of encoding (that is how the 0\u2019s and 1\u2019s are encoded in a signal). This layer is responsible for the communication of the unstructured raw data streams over a physical medium.</p>"},{"location":"networking/port/","title":"Port","text":"<p>A port is a virtual point where network connections start and end. Ports are software-based and managed by a computer's operating system. Each port is associated with a specific process or service and there are default ports for common services.</p> <p>Ports allow computers to easily differentiate between different kinds of traffic: emails go to a different port than webpages, for instance, even though both reach a computer over the same Internet connection.</p> <p>Ports are standardized across all network-connected devices, with each port assigned a number. While\u00a0IP addresses enable messages to go to and from specific devices, port numbers allow targeting of specific services or applications within those devices.</p> <p>Ports are a transport layer concept. Only a transport protocol such as the Transmission Control Protocol or User Datagram Protocol can indicate which port a packet should go to.</p> <p>Info</p> <p>There are 65,535 possible port numbers, although not all are in common use</p>"},{"location":"networking/ppp/","title":"Point-to-Point Protocol (PPP)","text":"<p>The Point-to-Point Protocol (PPP) is a data link layer (Layer 2) communication protocol used to establish a direct connection between two nodes in a network. It enables the transmission of data packets over serial point-to-point links such as telephone lines, fiber optic links, or satellite transmission paths.</p> <p>PPP is widely used for establishing internet connections via dial-up modems, DSL, and other types of broadband connections.</p> <p>PPP is designed to encapsulate various network layer protocols (like IP) for transmission over a point-to-point link. It can dynamically assign or negotiate the IP address, netmask, and other necessary configuration parameters.</p> <p>LCP (Link Control Protocol) is a part of PPP that establishes, configures, and tests the data-link connection. It handles the initial setup of the link and its termination.</p> <p>After the LCP phase, PPP uses different NCPs to allow for the transmission of multiple network layer protocols simultaneously over the PPP link. Each network layer protocol (like IP, IPX, or AppleTalk) has its corresponding NCP.</p> <p>PPP supports various authentication protocols to ensure that the connection is being made with an authorized device. These include PAP (Password Authentication Protocol), CHAP (Challenge Handshake Authentication Protocol), and EAP (Extensible Authentication Protocol).</p> <p>PPP includes error detection mechanisms to check whether data has been transmitted accurately across the link. However, it does not attempt error correction; instead, it relies on higher-layer protocols for this purpose.</p> <p>PPP can operate over both asynchronous (like traditional phone lines) and synchronous (like ISDN) media, making it versatile for various types of point-to-point connections. PPP also supports a multilink feature where multiple physical links can be combined to act as a single logical link. This is useful for increasing bandwidth and reliability.</p> <p>PPP can negotiate and use compression protocols to increase the throughput of the PPP connection. In addition to its traditional use in direct point-to-point connections, PPP is also used in VPN (Virtual Private Network) scenarios, encapsulated within other protocols like L2TP (Layer 2 Tunneling Protocol).</p>"},{"location":"networking/presentation/","title":"Presentation Layer","text":"<p>The Presentation Layer is responsible for converting and representing the payload in different formats. For example, data-based, character-based, image-based, audio-based, video-based and so on.</p> <p>It formats and encrypts data to be sent across the network. It takes care that the data is sent in such a way that the receiver will understand the information and will be able to use the data efficiently and effectively.</p> <p>It ensures that data sent from the application layer of one system is readable by the application layer of another system. This includes data encryption, decryption, and compression. Some formats that can be used here are:</p> <ul> <li>Graphics Interchange Format (GIF)</li> <li>Joint Photographic Experts Group (JPEG)</li> <li>Motion Picture Experts Group (MPEG)</li> <li>QuickTime</li> </ul>"},{"location":"networking/ptr/","title":"DNS PTR Records","text":"<p>A DNS PTR (Pointer) record is a type of DNS record used for reverse DNS lookups. While most DNS records map domain names to IP addresses (forward DNS lookups), PTR records do the opposite; they map IP addresses to domain names (reverse DNS lookups).</p> <p>While DNS A records are stored under the given domain name, DNS PTR records are stored under the IP address \u2014 reversed, and with \".in-addr.arpa\" added. For example, the PTR record for the IP address 192.0.2.255 would be stored under \"255.2.0.192.in-addr.arpa\".</p> <p>\"in-addr.arpa\" has to be added because PTR records are stored within the .arpa top-level domain in the DNS. .arpa is a domain used mostly for managing network infrastructure, and it was\u00a0the first\u00a0top-level domain name defined for the Internet.</p> <p>in-addr.arpa is the namespace within .arpa for reverse DNS lookups in IPv4.</p>"},{"location":"networking/radius/","title":"RADIUS","text":"<p>RADIUS (Remote Authentication Dial-In User Service) is a networking protocol that provides centralized Authentication, Authorization, and Accounting (AAA) management for users who connect and use a network service. RADIUS is widely used in various network environments, including remote access to networks, wireless networks, and Internet service providers.</p> <p>RADIUS manages network access by authenticating users when they attempt to connect to the network. It verifies user credentials against a central database before granting access. After authentication, RADIUS determines what level of access and network privileges the user should have. This can include details like IP address assignment, network service access, and any other restrictions or permissions.</p> <p>RADIUS keeps track of users' network usage data, such as time logged in, amount of data transferred, and other usage statistics. This information is useful for billing, auditing, and monitoring purposes.</p> <p>RADIUS operates on a client-server model, where the RADIUS server is responsible for authentication, authorization, and accounting, and the client is typically network hardware like a router, switch, or wireless access point.</p> <p>RADIUS is commonly used by Internet Service Providers (ISPs) for managing access to internet services, as well as by enterprises for managing access to internal networks, especially for remote users.</p> <p>RADIUS supports a range of authentication methods, including username and password, tokens, and certificates. While RADIUS encrypts user passwords in transit, the rest of the RADIUS packet is not encrypted, which can be a security concern. Protocols like IPsec are sometimes used alongside RADIUS for enhanced security.</p> <p>RADIUS can be extended with vendor-specific attributes (VSAs), allowing vendors to include additional information in RADIUS messages that are specific to their equipment.</p> <p>RADIUS can integrate with various directory services like Lightweight Directory Access Protocol or Active Directory, allowing for centralized management of user credentials and policies.</p>"},{"location":"networking/roce/","title":"RDMA Over Converged Ethernet (RoCE)","text":"<p>RDMA over Converged Ethernet (RoCE) is a network protocol that allows Remote Direct Memory Access (RDMA) over an Ethernet network. RoCE leverages the high throughput and low latency capabilities of RDMA, enabling efficient data transfers between servers and storage systems in data centers. It's particularly beneficial in environments where performance and low CPU overhead are critical.</p> <p>RoCE allows data to be transferred directly between the memory of two machines over Ethernet, bypassing the operating system's network stack. This results in lower latency and higher throughput.</p> <p>Since data transfer operations are offloaded to the network hardware, RoCE reduces the CPU overhead that would typically be required for processing network packets. RoCE is suitable for high-performance computing (HPC), storage (like NVMe over Fabrics), and enterprise data center applications due to its efficiency and speed.</p> <p>There are two versions of RoCE:</p> <ul> <li>RoCE v1 operates over any standard Ethernet infrastructure.</li> <li>RoCE v2 is an extension of RoCE that operates over Layer 3 (IP-routed) networks, increasing deployment flexibility and scalability.</li> </ul> <p>RoCE requires a properly configured network that can support lossless Ethernet, typically with Priority Flow Control (PFC) and Enhanced Transmission Selection (ETS) as part of Data Center Bridging (DCB) extensions. RoCE requires network interface cards (NICs) and switches that support RDMA over Ethernet.</p> <p>RoCE v1 operates at Layer 2 (Data Link Layer), which may be simpler in configuration but is limited to a single Ethernet broadcast domain. RoCE v2 operates at Layer 3 (IP layer), allowing for routing over IP networks but may require more complex configuration.</p>"},{"location":"networking/routers/","title":"Routers","text":"<p>Routers are hardware devices or software programs in a computer network that direct data packets between different networks, ensuring that the data sent across the Internet or a local network reaches the correct destination. They play a crucial role in managing and directing internet traffic.</p> <p>Routers analyze the data packets sent across a network and determine their destination based on the packet's IP address. They then use information in their routing table to decide the best path for the packet to take.</p> <p>Routers are primarily used to connect multiple networks together. In home settings, they typically connect a local network to the Internet. In enterprise settings, they might connect various local area networks (LANs) to Wide Area Network (WAN).</p> <p>Many routers provide [Network Address Translation (NAT), which allows multiple devices on a local network to share a single public IP address for accessing the Internet. This helps in conserving the number of public IP addresses used and adds a layer of security by hiding internal IP addresses from external networks.</p> <p>Routers manage network traffic, helping to prevent congestion and ensuring data packets are efficiently routed. They can prioritize certain types of traffic over others, a concept known as Quality of Service (QoS).</p> <p>Many modern routers also function as wireless access points (WAPs), allowing Wi-Fi-enabled devices to connect to the network wirelessly. Routers often include firewall functions to block unwanted traffic from entering the network. They can also offer additional security features like [[Virtual Private Network|VPN]] support, traffic logging, and parental controls.</p> <p>Routers usually provide Dynamic Host Configuration Protocol (DHCP) services, assigning IP addresses to devices on the network automatically.</p>"},{"location":"networking/session/","title":"Session Layer","text":"<p>The Session Layer is responsible for establishing, maintaining and terminating data communications between applications or devices.</p> <p>Sessions are made up of requests and responses. It identifies the data as belonging to a particular session and ensures that the requests and responses are sent back and forth between the two parties.</p> <p>Some protocols that operate at this layer include:</p> <ul> <li>Password Authentication Protocol (PAP)</li> <li>Microsoft Remote Procedure Call (RPC)</li> </ul>"},{"location":"networking/shake/","title":"Handshake","text":"<p>A handshake refers to an automated process of negotation between two devices or systems, establishing a connection and communication parameters before they start exchanging data.</p> <p>In networking, a handshake often involves three steps, commonly known as the \"three-way handshake\". For instance, in the TCP/IP protocol, when a device wants to establish a connection with another device, it sends a message (SYN), the receiver acknowledges this request by sending back a message (SYN-ACK), and finally, the initiator acknowledges this acknowledgment (ACK).</p> <p>This process ensures that both ends are ready to communicate, agree on how they'll communicate (such as speed, data format), and that the connection is secure and reliable.</p> <p>In other scenarios, like in a secure HTTPS connection, a handshake also involves steps to establish a secure and encrypted communication channel, including the exchange of encryption keys and security certificates. This is crucial for safe data transfer on the internet, ensuring that data is unreadable to unauthorized parties.</p>"},{"location":"networking/soa/","title":"DNS SOA Records","text":"<p>The\u00a0DNS\u00a0\u2018start of authority\u2019 (SOA) record stores important information about a domain or\u00a0zone\u00a0such as the email address of the administrator, when the domain was last updated, and how long the server should wait between refreshes.</p> <p>All DNS zones need an SOA record in order to conform to IETF standards. SOA records are also important for zone transfers.</p> <p>Example of an SOA record:</p> name example.com record type SOA MNAME ns.primaryserver.com RNAME admin.example.com SERIAL 1111111111 REFRESH 86400 RETRY 7200 EXPIRE 4000000 TTL 11200 <p>The 'RNAME' value here represents the administrator's email address, which can be confusing because it is missing the \u2018@\u2019 sign, but in an SOA record admin.example.com is the equivalent of admin\\@example.com.</p>"},{"location":"networking/tcp/","title":"Transmission Control Protocol","text":"<p>TCP, or Transmission Control Protocol, is one of the main protocols of the Internet Protocol Suite. It is used to create a reliable, ordered, and error-checked connection between two systems on an IP network, ensuring the safe and complete transfer of data.</p> <p>TCP is fundamental to the operation of the internet, underpinning a wide variety of its applications, including web browsing, email, file transfers, and more.</p> <p>It is a connection-oriented protocol meaning before data is transmitted, TCP requires that a connection be established via a TCP three-way handshake. It also provides reliable transmission, ensuring that data packets are delivered to the recipient in the same order they were sent without errors.</p> <p>TCP also manages the rate of data transmission between a sender and receiver to ensure that the receiver is not overwhelmed by data it can't process quick enough. It also adjusts the rate of data transmission based on congestion. If congested, TCP reduces the rate of data transfer to alleviate the congestion.</p> <p>Every TCP packet also includes a checksum field to check for data integrity. The receiver uses this to verify that the packet has not been corrupted during transit.</p> <ol> <li>Establishing a Connection: The TCP three-way handshake is initiated. This involves the sender sending a SYN (synchronize) packet, the receiver responding with a SYN-ACK (synchronize-acknowledge) packet, and the sender finally sending an ACK (acknowledge) packet.</li> <li>Data Transfer: Once the connection is established, data packets are sent from the sender to the receiver. TCP numbers each packet and ensures they are delivered in the correct order.</li> <li>Ending a Connection: When the data transfer is complete, the connection is terminated using a process similar to the handshake - FIN (finish) packets are exchanged to gracefully close the connection.</li> </ol> <p>TCP is essentially the polar opposite of another transport layer protocol - User Datagram Protocol.</p>"},{"location":"networking/tcpip/","title":"TCP/IP","text":"<p>The TCP/IP model is a part of the network domain designed specifically for overseeing efficient and error-free transmission of data.</p> <p>The model works on a four-layered architecture model, where each layer implicit the required network protocols on the data to be transmitted, which remodels the data to the most optimum structure for efficient transmission over the network.</p> <p>It is an alternative to the OSI Model and has four different layers as opposed to the seven the OSI model have:</p> <ul> <li>Application layer - groups up the Application Layer, Presentation Layer and Session Layer under one group.</li> <li>Transport layer - equal to the OSI Model Transport Layer</li> <li>Internet layer - equal to the OSI Model Network Layer</li> <li>Network Access layer - groups up the Data Link Layer and Physical Layer</li> </ul>"},{"location":"networking/transport/","title":"Transport Layer","text":"<p>The Transport Layer is responsible for error-free delivery of information between devices. It is also responsible for flow control and sequencing. The information that traverses this layer is known as a \"segment\".</p> <p>It ensures end-to-end communication services for applications and provides reliable data transfer services to the upper layers via segmenting data, acknowledging data receipt and error-recovery.</p> <p>Some protocols that operate here are:</p> <ul> <li>User Datagram Protocol (UDP)</li> <li>Transmission Control Protocol(TCP)</li> </ul>"},{"location":"networking/tunneling/","title":"DNS Tunneling","text":"<p>DNS tunneling is a technique used to encode the data of other programs or protocols in DNS queries and responses. It leverages the DNS protocol, which is used to resolve domain names into IP addresses, as a carrier for data transmission, often to bypass network security measures that do not adequately monitor and filter DNS traffic.</p> <p>Data that needs to be transferred is broken down and encapsulated in DNS query packets. These packets are sent to a DNS server that is controlled by the attacker or penetration tester. The attacker's DNS server receives the query, decodes the data, processes it, and responds accordingly. The response itself can also be used to carry data back.</p> <p>Because DNS is a necessary and trusted protocol, many networks do not inspect DNS packets as closely as other types of traffic, making DNS tunneling an effective method for bypassing Firewall and network security systems.</p> <p>DNS tunneling can be used to:</p> <ol> <li>Simulate Exfiltration: Test the network's ability to detect and prevent data exfiltration. Penetration testers use DNS tunneling to demonstrate how an attacker could covertly move data in and out of the network.</li> <li>Bypass Network Segmentation: Test the effectiveness of network segmentation and firewall rules. Since DNS is often allowed through network perimeters, it can be used to communicate with external servers even from isolated network segments.</li> <li>Command and Control (C2) Communications: Simulate Command and Control (C2) channels that use DNS tunneling to control compromised systems without being detected by traditional security defenses.</li> </ol> <p>Some examples may include:</p> <ul> <li>Data Exfiltration: A penetration tester encodes sensitive data into DNS queries and sends it to an external server. The test checks if the network's security system detects the unusual amount of DNS traffic or the non-standard nature of the DNS requests.</li> <li>Remote Shell: Establishing a remote shell session where commands and outputs are encoded and transferred via DNS queries and responses, allowing control over a compromised system from outside the network.</li> </ul>"},{"location":"networking/txt/","title":"DNS TXT Records","text":"<p>The DNS \u2018text\u2019 (TXT) record lets a\u00a0domain\u00a0administrator enter text into the\u00a0Domain Name System (DNS). The TXT record was originally intended as a place for human-readable notes.</p> <p>However, now it is also possible to put some machine-readable data into TXT records. One domain can have many TXT records.</p> <p>Example of a TXT record:</p> example.com record type: value: TTL @ TXT This is an awesome domain! Definitely not spammy. 32600 <p>Today, two of the most important uses for DNS TXT records are email spam prevention and domain ownership verification, although TXT records were not designed for these uses originally.</p>"},{"location":"networking/udp/","title":"User Datagram Protocol","text":"<p>UDP, or User Datagram Protocol, is a communication protocol used across the Internet. It's part of the Internet Protocol Suite, commonly known as TCP/IP. Unlike its counterpart, TCP, UDP is known for its simplicity and speed in data transmission, but this comes at the cost of reliability and ordering.</p> <p>UDP is a connectionless protocol meaning that UDP does not establish a connection before sending data. Instead, it sends packets directly to the recipient without prior communications to set up special transmission channels or data paths.</p> <p>However, because there's no need to establish a connection, UDP is faster and more efficient for certain types of applications. It avoids the overhead of connection establishment, maintenance, and termination, which is characteristic of TCP.</p> <p>UDP does not offer error recovery. If a packet is lost, out of order, or corrupted, UDP does not resend it. This is unlike TCP, which provides extensive error checking and recovery.</p> <p>With UDP, there's no mechanism to manage the flow of data between sender and receiver. This means the sender can overwhelm the receiver with too much data too quickly.</p> <p>Finally, each UDP packet is independent of the other. This stateless nature means that if one packet encounters an issue in transmission, it does not affect any other packets.</p>"},{"location":"networking/wans/","title":"Wide Area Network (WAN)","text":"<p>A Wide Area Network (WAN) is a telecommunications network that extends over a large geographical area, typically to connect multiple Local Area Networks (LANs) or other types of networks. WANs are used to connect devices that are far apart, often in different cities or countries, making them essential for global business operations and communications.</p> <p>Unlike LANs, which cover a small area like a single building or campus, WANs can span cities, states, or even continents. This wide reach allows for long-distance communication and data sharing.</p> <p>WANs can be built using various types of connections, including leased lines, broadband (such as DSL), fiber optics, and satellite communications. The choice depends on factors like bandwidth requirements, cost, and geographic reach.</p> <p>WANs can be public (using shared or carrier-owned resources like the internet) or private (dedicated lines or Virtual Private Network that provide private, secure connections over public infrastructure).</p> <p>WANs use technologies like MPLS (Multiprotocol Label Switching), ATM (Asynchronous Transfer Mode), and Frame Relay for efficient data transfer.</p> <p>VPNs are often used over WANs to provide secure communication channels, especially when transmitting sensitive data over the public internet.</p> <p>Info</p> <p>The internet is the largest example of a WAN, connecting billions of devices worldwide.</p> <p>Many organizations use WANs to connect their various office locations, enabling efficient communication and resource sharing among different branches.</p> <p>Factors like latency, bandwidth, and packet loss are significant performance considerations in WANs, impacting the speed and reliability of data transmission.</p> <p>Building and maintaining a WAN, especially a private one, can be costly due to the required infrastructure and technologies. This has led to the popularity of cloud-based solutions and services.</p> <p>Techniques and technologies for WAN optimization are used to increase data transfer efficiencies across the network. This includes traffic shaping, data deduplication, and compression.</p>"},{"location":"networking/wlans/","title":"Wireless LANs (WLANs)","text":"<p>A Wireless Local Area Network (WLAN) is a type of local area network that uses wireless communication methods to connect devices within a limited area such as a home, school, office building, or campus. WLANs provide the same functionality as traditional Local Area Networks (LANs) but without the physical constraints of needing network cables.</p> <p>WLANs typically use Wi-Fi (Wireless Fidelity) technology to enable wireless communication. Wi-Fi is based on the IEEE 802.11 family of standards. The main components of a WLAN include a wireless router or access point and wireless-enabled devices like laptops, smartphones, tablets, and printers.</p> <p>In a WLAN, devices connect to the internet or exchange data with each other by linking to a wireless access point, which is in turn connected to a physical, wired network. WLANs are typically designed to cover a small geographical area like a home, office, or campus building. The range can be extended with additional access points or signal boosters.</p> <p>One of the primary advantages of WLANs is the mobility they offer. Users can move around within the coverage area and maintain network connectivity.</p> <p>WLANs are generally easier and less expensive to install and configure than traditional wired LANs, as they require no cabling between computers and network devices.</p> <p>Security is a critical concern in WLANs. Technologies like WPA (Wi-Fi Protected Access), WPA2, and WPA3 are used to secure wireless communications.</p> <p>While WLANs offer the convenience of wireless access, their speeds and bandwidth might be lower compared to wired LANs, especially in areas with signal interference.</p> <p>WLANs are widely used in homes, businesses, and public hotspots. They facilitate easy access to the internet and organizational resources for mobile users. WLANs can be affected by interference from other wireless devices and physical barriers. The reliability and quality of the wireless signal can be influenced by factors such as distance from the access point, building materials, and other electronic devices.</p>"},{"location":"networking/zonetransfers/","title":"DNS Zone Transfers","text":"<p>A DNS zone transfer is a process used in DNS to replicate DNS records across a network of DNS servers. It is a mechanism by which a DNS server can update its DNS records to match those of another DNS server.</p> <p>In a zone transfer, there are two types of servers involved:</p> <ul> <li>Primary DNS Server - known as master server, it holds the original read-write version of the zone file.</li> <li>Secondary DNS Server - known as slave server, it holds a read-only copy of the zone file. It receives updates from the primary through zone transfers.</li> </ul> <p>The secondary server periodically checks with the primary server to see if any changes have been made to the DNS records. If there have been changes, the secondary server requests a zone transfer. The primary server then sends a copy of the zone file.</p> <p>There are two main types of DNS zone transfers:</p> <ul> <li>AXFR (Full Zone Transfer) - complete transfer of the DNS zone file from the primary to the secondary server, used when the secondary server needs to sync its data from scratch.</li> <li>IXFR (Incremental Zone Transfer) - involves transferring only the changes made to the DNS records since the last successful transfer.</li> </ul> <p>Zone transfers can pose risks if not properly configured. Unauthorized access to DNS zone data can lead to DNS spoofing or other DNS-based attacks. Zone transfers are often restricted to specific, authorized secondary servers.</p> <p>The zone file contains various types of DNS records, such as DNS A Records, DNS MX Records, DNS NS Records and DNS CNAME Records.</p> <p>In the context of cybersecurity and penetration testing, testing for improperly configured DNS zone transfers is common, as it can reveal a wealth of information about internal network structures and systems.</p>"},{"location":"programming/add/","title":"add()","text":"<p>The jQuery add() function is used to add elements to a set of matched elements in a jQuery object. This method is useful for combining elements from different selectors or different parts of the document into a single jQuery collection, which can then be manipulated or iterated over in a unified way.</p> <p>The basic syntax of the add() function is:</p> <pre><code>$(selector).add(elements);\n</code></pre> <p>Where:</p> <ul> <li>selector - the initial jQuery selector</li> <li>elements - the elements to be added to the jQuery object. It can be a string representing a selector, a Document Object Model element, an HTML string or another jQuery object.</li> </ul> <p>The add() function is often used to combine elements from multiple selectors such as:</p> <pre><code>$(\"div\").add(\"p\");\n</code></pre> <p>This selects all &lt;div&gt; elements and then adds all &lt;p&gt; elements to the same jQuery object. If you need to apply the same style or event handlers to a group of elements that don't share the same parent or class, you can use add() to group them together:</p> <pre><code>$(\"#myDiv\").add(\".myClass\").css(\"background-color\", \"yellow\");\n</code></pre> <p>This will change the background color of both the element with id myDiv and all elements with the class myClass.</p> <p>If add() is used to handle user-supplied input or content from untrusted sources without proper validation and sanitization, there could be a risk of Cross-Site Scripting attacks. For example, if HTML content created based on user input is added to the DOM using add(), it could include malicious scripts.</p>"},{"location":"programming/addslashes/","title":"addslashes","text":"<p>The addslashes function in PHP is a built-in function used to escape certain characters in a string by prefixing them with a backslash. This function is typically used to prepare a string for insertion into a database, particularly when dealing with strings that may contain quotes or other special characters that need to be escaped.</p> <p>It escapes the following:</p> <ul> <li>Single quote (')</li> <li>Double quote (\")</li> <li>Backslash (\\)</li> <li>NULL (the NULL byte)</li> </ul> <p>An example usage may be:</p> <pre><code>$unescaped_str = \"O'Reilly &amp; Associates\";\n$escaped_str = addslashes($unescaped_str);\n\n// Output: O\\'Reilly &amp; Associates\necho $escaped_str;\n</code></pre> <p>In this example, the single quote in \"O'Reilly\" is prefixed with a backslash, making it safe for use in a SQL query, for instance.</p> <p>While addslashes can escape certain characters, it should not be solely relied upon for preventing SQL injection attacks. The use of prepared statements with parameterized queries is the recommended approach for database interaction in PHP to prevent SQL injection.</p> <p>The addslashes function in PHP is not suitable for preventing Cross-Site Scripting (XSS) attacks. While addslashes is designed to escape certain characters (like single quotes, double quotes, backslashes, and NULL) by adding backslashes before them, it does not address the core requirements for mitigating XSS vulnerabilities.</p>"},{"location":"programming/after/","title":"after()","text":"<p>The jQuery after() function is used to insert content after the selected elements in the Document Object Model (DOM). This method provides a convenient way to add new content or elements to your webpage dynamically.</p> <p>The after() function can take a string, HTML element, array of elements, or jQuery object as an argument. The provided content is then inserted right after each element in the set of matched elements:</p> <pre><code>$(selector).after(content);\n</code></pre> <p>Where:</p> <ul> <li>selector - jQuery selector that identifies the elements after which the new content will be inserted</li> <li>content - the content to be inserted, can be HTML strings, DOM objects or other jQuery objects</li> </ul> <p>An example could be:</p> <pre><code>$(\"p\").after(\"&lt;span&gt; New content&lt;/span&gt;\");\n</code></pre> <p>This will insert the &lt;span&gt;New content&lt;/span&gt; after every &lt;p&gt; element in the document. The after() method can also take multiple arguments to insert multiple elements in sequence:</p> <pre><code>$(\"p\").after(\"&lt;span&gt;First&lt;/span&gt;\", \"&lt;span&gt;Second&lt;/span&gt;\");\n</code></pre> <p>Be cautious when inserting content from untrusted sources to prevent Cross-Site Scripting (XSS) vulnerabilities. Always sanitize external input before including it in the DOM.</p>"},{"location":"programming/append/","title":"append()","text":"<p>The jQuery append() function is used to insert content at the end of the selected elements within the DOM (Document Object Model). It is a widely used method in jQuery for dynamically adding new content or elements to a webpage.</p> <p>The append() function can take a string of HTML, a DOM element, an array of elements, a jQuery object, or a function as an argument. The content specified in the argument is then inserted at the end of each element in the set of matched elements:</p> <pre><code>$(selector).append(content);\n</code></pre> <p>Where:</p> <ul> <li>selector - the jQuery selector identifying the elements to which the new content will be appended.</li> <li>content - the content to be appended, can be HTML strings, DOM elements, other jQuery objects or a function that returns content to append.</li> </ul> <p>An example could be:</p> <pre><code>$(\"#myDiv\").append(\"&lt;p&gt;New paragraph&lt;/p&gt;\");\n</code></pre> <p>This will add a new paragraph (&lt;p&gt;New paragraph&lt;/p&gt;) to the end of the element with the ID myDiv.</p> <p>The append() function can also take multiple arguments or a combination of different types of arguments to append multiple elements simultaneously. When appending content based on user input or external sources, be cautious of Cross-Site Scripting (XSS) vulnerabilities. Always sanitize external input to prevent the injection of malicious code.</p>"},{"location":"programming/arc/","title":"Automatic Reference Counting (ARC)","text":"<p>Automatic Reference Counting (ARC) is a memory management feature of Objective-C and Swift, the programming languages used for developing applications on Apple's macOS and iOS platforms. Introduced with Objective-C 2.0 and fully embraced in Swift, ARC automates the process of memory management, reducing the complexity of manual memory management and minimizing memory leaks.</p> <p>ARC automatically keeps track of the number of references to objects in memory. When an object's reference count drops to zero (meaning it's no longer referenced in the program), ARC automatically deallocates (frees) that object from memory.</p> <p>Each time you create a new reference to an object (for example, by assigning it to a variable or passing it in a method), ARC increments its reference count. Conversely, when the reference is no longer needed (like when the variable goes out of scope), ARC decrements the reference count. When an object\u2019s reference count reaches zero, indicating that it's no longer in use, ARC automatically deallocates the object, freeing up the memory it occupied.</p> <p>By automatically managing object lifecycles, ARC significantly reduces the chances of memory leaks\u2014a common problem in manual memory management. With ARC, developers don't need to write explicit memory management code (like <code>retain</code> and <code>release</code> in Objective-C), leading to cleaner and more maintainable code.</p> <p>Before ARC, Objective-C used manual retain/release for memory management. ARC was introduced as an option in Objective-C to simplify this process. Swift was designed with ARC integrated from the start. It handles memory management automatically for Swift objects, though manual memory management is still required when interacting with C APIs or for certain advanced tasks.</p> <p>In Swift, you simply create and use objects, and ARC takes care of the rest:</p> <pre><code>class MyClass {\n    var property: String\n    init(property: String) {\n        self.property = property\n        print(\"\\(property) initialized\")\n    }\n    deinit {\n        print(\"\\(property) deinitialized\")\n    }\n}\n\nvar example: MyClass? = MyClass(property: \"Example\")\nexample = nil // ARC decrements the reference count, triggering deinitialization\n</code></pre> <p>Info</p> <p>In this Swift example, when <code>example</code> is set to <code>nil</code>, ARC deallocates the <code>MyClass</code> instance, and its <code>deinit</code> block is called.</p> <p>ARC introduces the concept of strong and weak references to help manage memory, especially in situations where retaining cycles (two objects keeping each other alive) might occur. When dealing with Core Foundation objects in Objective-C, developers still need to manage memory manually, even with ARC enabled.</p>"},{"location":"programming/assembly/","title":"Assembly","text":"<p>Assembly language is a low-level programming language that has a strong correspondence between its instructions and the architecture's machine code instructions. It is specific to a particular computer architecture and is one level above machine code, which is directly executed by the CPU.</p> <p>Assembly language uses mnemonic codes or symbols (instead of binary code) to represent the fundamental instructions that the CPU can understand and execute. This makes it more readable for humans compared to raw machine code. Each type of CPU has its own specific assembly language. For example, the assembly language for an Intel processor is different from that of an ARM processor.</p> <p>It provides direct control over the hardware, allowing programmers to optimize operations for speed and efficiency, manipulate hardware directly, and write code for system bootstraps and device drivers. Assembly language consists of an instruction set, which includes operations like moving data, branching, and arithmetic/logic operations. Each instruction generally has an opcode (operation code) and operands (the data to be processed).</p> <p>A simple example of an assembly language program is as follows, which adds two numbers on an x86 processor:</p> <pre><code>section .data\n    num1 db 5          ; Define byte 'num1' with value 5\n    num2 db 3          ; Define byte 'num2' with value 3\n    result db 0        ; Define byte 'result' to store the result\n\nsection .text\n    global _start\n\n_start:\n    mov al, [num1]     ; Move the value of 'num1' into register AL\n    add al, [num2]     ; Add the value of 'num2' to the value in AL\n    mov [result], al   ; Move the result back into 'result'\n\n    ; Exit the program\n    mov eax, 1         ; System call number for 'exit'\n    mov ebx, 0         ; Exit code\n    int 0x80           ; Interrupt to signal the kernel\n</code></pre> <p>This program performs the following steps:</p> <ul> <li>Stores two numbers in memory (<code>num1</code> and <code>num2</code>).</li> <li>Loads the first number into a register (<code>AL</code>).</li> <li>Adds the second number to the register.</li> <li>Stores the result back in memory (<code>result</code>).</li> <li>Finally, it exits the program by making a system call.</li> </ul> <p>Assembly language allows for highly efficient and performance-optimized coding, ideal for time-critical and resource-limited systems. Writing and maintaining assembly code is more complex and time-consuming than using high-level languages. It requires a deep understanding of the specific hardware architecture.</p> <p>Today, it's often used in embedded systems, device drivers, real-time systems, and critical sections of code in larger applications where performance is paramount. Most software development, however, is done in higher-level languages due to their greater abstraction and portability.</p>"},{"location":"programming/basename/","title":"basename()","text":"<p>The <code>basename()</code> function is a commonly used function in various programming languages, including PHP and Unix/Linux shell scripting. Its primary purpose is to extract the filename from a given path.</p> <p>In PHP, <code>basename()</code> is used to return the filename from a specified path:</p> <pre><code>basename(string $path, string $suffix = \"\")\n</code></pre> <ul> <li><code>$path</code>: The path to be processed.</li> <li><code>$suffix</code> (Optional): If the filename ends in <code>suffix</code>, this will also be cut off.</li> </ul> <p>An example:</p> <pre><code>echo basename(\"/some/path/file.txt\"); // Outputs: file.txt\necho basename(\"/some/path/file.txt\", \".txt\"); // Outputs: file\n</code></pre> <p>In the first example, <code>basename()</code> returns <code>file.txt</code>, which is the filename. In the second example, it also removes the <code>.txt</code> suffix, returning just <code>file</code>.</p> <p><code>basename</code> in Unix/Linux shell scripting is a command used to strip the directory and suffix from filenames:</p> <pre><code>basename [path] [suffix]\n</code></pre> <p>An example:</p> <pre><code>basename /some/path/file.txt .txt\n</code></pre> <p>This command will output <code>file</code>, which is the filename without the path and the specified suffix.</p> <p>When using <code>basename()</code> in PHP, especially with user-supplied input, it's generally safe as it's designed to return the last component of a path. However, it's always good practice to validate and sanitize any user input and be cautious about how you use the resulting filename, particularly in file operations to prevent directory traversal or other path-related vulnerabilities.</p>"},{"location":"programming/before/","title":"before()","text":"<p>The jQuery before() function is used to insert content before the selected elements in the Document Object Model (DOM). This method is part of the jQuery library, which provides a powerful set of tools for HTML document traversal and manipulation.</p> <p>before() is used to insert specified content or elements immediately before each element in the set of matched elements. The syntax is:</p> <pre><code>$(selector).before(content)\n</code></pre> <ul> <li>selector - the jQuery selector that identifies the elements before which the new content is inserted</li> <li>content - content to be inserted, can be HTML strings, DOM elements, other jQuery objects or even functions that return content.</li> </ul> <p>An example may be inserting a text node:</p> <pre><code>$('#myDiv').before('New content');\n</code></pre> <p>This will insert the text 'New content' before the element with the ID myDiv. Another example may be inserting an HTML element:</p> <pre><code>$('#myDiv').before('&lt;p&gt;New Paragraph&lt;/p&gt;');\n</code></pre> <p>This will insert a new paragraph element before #myDiv.</p> <p>Similar to other jQuery methods, before() can handle script tags and event handlers in the content being added. However, this should be done with caution to avoid potential security risks like Cross-Site Scripting (XSS).</p>"},{"location":"programming/btoa/","title":"btoa()","text":"<p>The <code>btoa()</code> function in JavaScript is a built-in method used to encode a string in Base64 format. The name <code>btoa</code> stands for \"binary to ASCII.\" This function takes a string of characters and encodes it into a base-64 representation, which is a way of encoding binary data in a set of 64 printable characters in the ASCII character set.</p> <p><code>btoa()</code> takes a string and returns its base-64 encoded version. It's important to note that this function is designed to work with binary data represented as a string, so the input should be in a format that can be represented in 8-bit binary form. The basic syntax of <code>btoa()</code> is <code>btoa(string)</code>, where <code>string</code> is the input string to be encoded.</p> <p>In penetration testing (pentesting), <code>btoa()</code> can be used to encode data that needs to be included in URLs or HTTP requests in a format that is URL-safe. Base-64 encoding is often used to encode binary data or data that includes special characters that might otherwise cause issues in URLs or HTTP requests.</p> <p>Pentesters might use base-64 encoding as a simple form of obfuscation. While it's not secure by itself (as base-64 is easily decoded), it can be a part of a more complex obfuscation strategy to hide the true intent or content of the data being transmitted.</p> <p>In some cases, security systems might not properly handle base-64 encoded data. Pentesters might use <code>btoa()</code> to encode payloads or other data to bypass security filters that are not configured to decode and inspect base-64 encoded data.</p> <p>A usage example may be:</p> <pre><code>// Example string to encode\nvar originalString = \"Hello, pentesting world!\";\n\n// Using btoa() to encode the string\nvar encodedString = btoa(originalString);\n\n// Logging the results\nconsole.log(\"Original String: \" + originalString);\nconsole.log(\"Encoded String: \" + encodedString);\n</code></pre> <p>The explanation of this code is as follows:</p> <ol> <li>Define a String: We start with a string <code>originalString</code> that we want to encode. In this case, it's <code>\"Hello, pentesting world!\"</code>.</li> <li>Encode with <code>btoa()</code>: We use the <code>btoa()</code> function to encode <code>originalString</code>. The <code>encodedString</code> variable will hold the base-64 encoded version of the original string.</li> <li>Output: The <code>console.log</code> statements output both the original and the encoded strings to the console. This way, you can see the difference between the two.</li> </ol>"},{"location":"programming/c/","title":"C","text":"<p>The C programming language is a general-purpose, procedural computer programming language developed in the early 1970s by Dennis Ritchie at Bell Labs. C has had a profound influence on the development of other programming languages and computing in general.</p> <p>It's known for its efficiency, flexibility, and portability, making it popular for a wide range of applications, from operating systems to embedded systems.</p> <p>C is a procedural language, meaning it follows a set of instructions in a sequence. It supports structured programming and allows for greater control over the flow of the program. C provides a balance between low-level and high-level programming. It allows for close manipulation of computer hardware with a relatively clear programming syntax, making it efficient in terms of both memory and processing power.</p> <p>One of C's key features is its portability \u2013 C programs written for one operating system can typically be easily adapted for another with minimal changes. C is extensively used in system software development. It's the language behind many operating systems, including Unix, which has influenced many other popular operating systems.</p> <p>C comes with a standard library that includes a set of common functionalities such as I/O operations, string handling, mathematical functions, and utilities for memory management.</p> <p>The syntax of C has influenced many other programming languages, including C++, C#, Java, and JavaScript, among others.</p> <p>C supports low-level operations using pointers, bit manipulation, and direct memory access, which are essential in system programming. C supports modularity, allowing complex applications to be broken down into simpler modules, which can then be compiled separately.</p>"},{"location":"programming/callfunc/","title":"call_user_func_array()","text":"<p><code>call_user_func_array()</code> is a function in PHP, a widely-used server-side scripting language for web development. This function is used to call a callback (a function or a method) with an array of parameters. It's particularly useful when you need to call a function and you don't know beforehand how many arguments will be passed to it.</p> <p>The main purpose of <code>call_user_func_array()</code> is to call a user-defined function or a method of a class with a set of parameters that are passed in an array. The basic syntax of <code>call_user_func_array()</code> is as follows:</p> <pre><code>mixed call_user_func_array ( callable $callback , array $param_arr )\n</code></pre> <ul> <li><code>$callback</code>: The function or method to be called. This can be a string containing the function name, an array containing an object and method name, or an anonymous function.</li> <li><code>$param_arr</code>: An indexed array containing the parameters to be passed to the callback.</li> </ul> <p>It returns the result of the function call. If the callback is not callable, it will issue a warning and return <code>FALSE</code>.</p> <p>Here's an example to demonstrate how <code>call_user_func_array()</code> works:</p> <pre><code>function sum($a, $b, $c) {\n    return $a + $b + $c;\n}\n\n// Parameters to pass\n$params = [1, 2, 3];\n\n// Calling 'sum' function with parameters in '$params'\n$result = call_user_func_array('sum', $params);\n\necho $result; // Outputs 6\n</code></pre> <p>In this example, <code>call_user_func_array()</code> is used to call the function <code>sum</code> with the parameters stored in the array <code>$params</code>.</p> <p><code>call_user_func_array()</code> is often used in scenarios where the number of parameters is not known until runtime, or when implementing call forwarding or proxy patterns in object-oriented programming.</p> <p>While <code>call_user_func_array()</code> is a powerful and flexible function, it should be used with caution, especially when dealing with user input. If the <code>$callback</code> or parameters are influenced by user input, it could lead to security vulnerabilities, such as Remote Code Execution (RCE) or Function Injection attacks. It's crucial to validate and sanitize any user input that might affect the function call.</p>"},{"location":"programming/cfill/","title":"Conversion Filters","text":"<p>PHP does provide several functions and mechanisms for converting data types and formats, which might collectively be considered as tools for data conversion. These include:</p> <ol> <li>Type Casting: PHP allows for explicit type casting where you can convert one data type to another. For example, <code>(int)$variable</code> will convert <code>$variable</code> to an integer, and <code>(string)$variable</code> will convert it to a string.</li> <li>Conversion Functions: PHP has built-in functions for converting data types. Functions like <code>intval()</code>, <code>floatval()</code>, and <code>strval()</code> are used to convert values to integers, floats, and strings, respectively.</li> <li>Date and Time Conversion: Functions like <code>strtotime()</code> and <code>date()</code> are used to convert between timestamps and human-readable date/time formats.</li> <li>Serialization and Unserialization: PHP provides functions like <code>serialize()</code> and <code>unserialize()</code> for converting objects or array data to a storable string format and vice versa.</li> <li>JSON Conversion: Functions like <code>json_encode()</code> and <code>json_decode()</code> are used to convert arrays or objects to JSON format and to convert JSON formatted strings back into PHP arrays or objects.</li> <li>String Functions: Various string functions can be used to manipulate and convert strings, such as <code>strtoupper()</code>, <code>strtolower()</code>, <code>str_replace()</code>, etc.</li> <li>Array Functions: Functions like <code>array_map()</code> can be used to apply a callback to the elements of an array, effectively allowing for custom conversion logic.</li> </ol>"},{"location":"programming/compfil/","title":"Compression Filters","text":"<p>Compression filters in PHP are a feature that allows for on-the-fly compression and decompression of data streams using various compression algorithms. These filters can be applied to file operations, network communication, and any other data stream manipulation in PHP. The use of compression filters is particularly useful for reducing the size of data being stored or transmitted, which can lead to improved performance and reduced bandwidth usage.</p> <p>Some common ones include:</p> <ol> <li><code>zlib</code> Compression: The <code>zlib</code> compression filter is used for compressing data using the <code>gzip</code> algorithm. It can be applied to file operations or data streams to compress and decompress data on the fly.</li> <li><code>bzip2</code> Compression: This filter uses the <code>bzip2</code> algorithm for compression and decompression. It's more efficient in terms of the compression ratio compared to <code>zlib</code> but can be more CPU-intensive.</li> </ol> <p>Compression filters in PHP are typically used with stream contexts. You can create a stream context using <code>stream_context_create()</code> and then pass this context to functions like file_get_contents() or fopen(). You can use compression filters for file operations, such as reading from or writing to compressed files directly. These filters can also be used for data streams, such as output buffering or processing data received over the network.</p> <p>An example could be using zlib:</p> <pre><code>// Compressing data\n$compressedData = file_get_contents('php://filter/write=zlib.deflate/resource=data.txt', false, $context);\n\n// Decompressing data\n$decompressedData = file_get_contents('php://filter/read=zlib.inflate/resource=data.gz', false, $context);\n</code></pre> <p>Or using bzip2:</p> <pre><code>// Compressing data\n$compressedData = file_get_contents('php://filter/write=bzip2.compress/resource=data.txt', false, $context);\n\n// Decompressing data\n$decompressedData = file_get_contents('php://filter/read=bzip2.decompress/resource=data.bz2', false, $context);\n</code></pre> <p>Compressing data reduces its size, which can lead to faster file operations and reduced bandwidth usage during data transmission. They can help in managing disk space more efficiently, especially when dealing with large amounts of data. PHP's stream filter interface makes it straightforward to apply compression without the need for complex coding.</p>"},{"location":"programming/cpp/","title":"C++","text":"<p>C++ is a high-level, general-purpose programming language created by Bjarne Stroustrup as an extension of the C programming language, or \"C with Classes\". It was first introduced in 1985 and has since become one of the most widely used programming languages.</p> <p>C++ is particularly known for its performance and efficiency, as well as its support for Object-Oriented Programming, making it a popular choice for software development in various domains.</p> <p>C++ supports object-oriented programming (OOP), a paradigm that uses \"objects\" \u2013 data structures consisting of data fields and methods together with their interactions \u2013 to design applications and computer programs.</p> <p>Known for its high performance and efficiency, C++ is widely used in software that requires high execution speed or tight resource management, such as game development, real-time systems, embedded systems, and high-performance computing.</p> <p>C++ provides features for low-level memory manipulation, which is beneficial for programs that need direct interaction with the hardware or need to manage memory explicitly.</p> <p>The language comes with a rich standard library known as the Standard Template Library (STL). STL provides a collection of classes and functions for data structures, algorithms, iterators, and other useful constructs.</p> <p>C++ is used in developing a variety of applications, from operating systems, GUI-based applications, and 3D graphics engines to medical and engineering applications. Besides supporting OOP, C++ is also a multi-paradigm language, offering support for procedural, functional, and generic programming.</p> <p>C++ can be used to develop applications that can be run on a variety of platforms, such as Windows, Mac, Linux, and various embedded systems. C++ is compatible with C, allowing most C code to be compiled with a C++ compiler, which has made the transition from C to C++ relatively smooth for many developers.</p>"},{"location":"programming/csharp/","title":"C#","text":"<p>C# (pronounced \"C Sharp\") is a modern, Object-Oriented Programming language developed by Microsoft as part of its .NET initiative. C# has evolved to become one of the most widely used programming languages. It is used for a variety of software applications ranging from web development to desktop and mobile applications, and even game development.</p> <p>C# is fundamentally object-oriented, meaning it supports concepts like classes, inheritance, polymorphism, encapsulation, and abstraction. Initially designed for the .NET Framework, C# is now also a primary language for .NET Core, a cross-platform, open-source framework. It allows C# applications to run on Windows, MacOS, and Linux.</p> <p>C# is a strongly typed language, enforcing strict type-checking at compile time. This helps to catch errors early in the development process and enhances code quality and maintainability. The syntax of C# is similar to other C-style languages such as Java and C++. It was influenced by these languages but includes many unique features.</p> <p>C# comes with a vast standard library, .NET class library, which provides rich functionalities and helps in building robust applications quickly. C# is often used in conjunction with Visual Studio, a powerful IDE from Microsoft, which provides a comprehensive environment for development, debugging, and testing.</p> <p>C# is used for developing a wide range of applications including web applications (using ASP.NET), Windows desktop applications, mobile applications (via Xamarin), and even games (using Unity).</p> <p>C# benefits from a large developer community and a wide ecosystem of libraries, frameworks, and tools. It is continuously updated and maintained by Microsoft. C# manages memory automatically through a garbage collector, which frees up memory used by objects that are no longer in use.</p>"},{"location":"programming/css/","title":"CSS","text":"<p>CSS (Cascading Style Sheets) is a language used for describing the presentation of a document written in HTML or XML. CSS makes websites look good. It is used to style and layout web pages - i.e. change font, colour, size, spacing, add columns, animations and many more.</p> <p>It can control the layout of multiple web pages all at once. CSS can either be in the same HTML file or they can be stored externally in other CSS files.</p>"},{"location":"programming/ddomain/","title":"document.domain","text":"<p>document.domain is a property in JavaScript that gets or sets the domain of the current document. This property is part of the Document Object Model (DOM) and is used primarily in the context of the Same Origin Policy, which is a critical security concept in web development.</p> <p>Web browsers implement the Same-Origin Policy to prevent potentially malicious scripts on one page from accessing data or code on another page with a different origin. An origin is defined by the scheme (protocol), host (domain), and port of a URL.</p> <p>For two pages to interact with each other's content via JavaScript, they need to have the same origin.</p> <p>By setting document.domain to a specific value, you can loosen the restrictions imposed by the Same-Origin Policy. This is particularly useful when you have two different subdomains that need to interact with each other.</p> <p>An example to get the domain may be:</p> <pre><code>var domain = document.domain;\n</code></pre> <p>An example of setting the domain may be:</p> <pre><code>document.domain = \"example.com\";\n</code></pre> <p>Modifying document.domain can have security implications. Reducing the restrictions of the Same-Origin Policy should be done carefully as it can potentially expose your website to certain types of attacks, such as Cross-Site Scripting (XSS).</p> <p>Modern web development practices often favour more secure alternatives for cross-origin communication, such as Cross-Origin Resource Sharing (CORS) and postMessage API. These methods provide more controlled and secure ways to handle cross-origin interactions.</p>"},{"location":"programming/doctrine/","title":"Doctrine","text":"<p>Doctrine is an Object-Relational Mapping (ORM) system for PHP. It is a set of PHP libraries and tools that provide an abstraction layer for database interactions, allowing developers to work with databases using object-oriented principles rather than SQL queries. Doctrine aims to simplify database access and manipulation, improve code maintainability, and enhance the overall development process.</p> <p>Doctrine allows developers to define the mapping between PHP objects (entities) and database tables. This is done through annotations, YAML, or Extensible Markup Language configuration files. The mapping describes how the properties of an entity correspond to columns in a database table.</p> <p>ORM is the core concept of Doctrine. It enables developers to interact with the database using PHP objects, eliminating the need to write raw SQL queries. Entities represent database records, and changes to these objects are automatically synchronized with the underlying database.</p> <p>Doctrine provides a database abstraction layer that supports multiple database management systems (DBMS), such as MySQL, PostgreSQL, SQLite, and others. This allows developers to switch between different database backends with minimal code changes.</p> <p>Doctrine Query Language (DQL) is a powerful SQL-like language specifically designed for querying object-oriented data. DQL allows developers to express queries in terms of their PHP entities and avoids the need for direct SQL queries in many cases.</p> <p>Doctrine can generate database schemas based on the entity mappings, and it provides tools for database schema migration. This helps manage database changes over time, making it easier to evolve the database schema without losing data.</p> <p>Doctrine supports various caching mechanisms to improve performance. It can cache metadata, query results, and other elements to reduce the need for repeated database queries. Doctrine includes an events system that allows developers to hook into specific points in the object lifecycle, enabling them to execute custom logic during certain operations (e.g., before or after an entity is persisted or removed).</p>"},{"location":"programming/dql/","title":"Doctrine Query Language (DQL)","text":"<p>Doctrine Query Language (DQL) is a powerful query language used in the Doctrine ORM (Object-Relational Mapping) system for PHP. DQL is designed to allow developers to interact with their database using a syntax that is similar to SQL but is tailored for working with object-oriented entities rather than raw database tables.</p> <p>DQL operates on the entities and their associations defined in the ORM mapping. Instead of dealing with database tables and columns directly, developers write queries in terms of their PHP entities and their relationships.</p> <p>In DQL, entities are identified by their fully-qualified class names. This helps in navigating through associations and properties using the object-oriented syntax. While DQL has its unique syntax, it shares similarities with SQL, making it easier for developers familiar with SQL to transition. DQL queries often resemble SQL queries, but they are focused on working with objects and their associations.</p> <p>DQL supports various types of joins and associations between entities, allowing developers to navigate through relationships and retrieve related data. DQL supports parameter binding, allowing developers to write parameterized queries. This helps prevent SQL injection and makes queries more flexible.</p> <p>Like SQL, DQL supports aggregate functions (e.g., COUNT, MAX, MIN, AVG, SUM) for performing calculations on grouped data. A simple query may be:</p> <pre><code>&lt;?php\n// DQL query to retrieve all users whose age is greater than 25\n$dql = \"SELECT u FROM User u WHERE u.age &gt; :age\";\n\n// Create a Doctrine Query object\n$query = $entityManager-&gt;createQuery($dql);\n\n// Set a parameter value\n$query-&gt;setParameter('age', 25);\n\n// Execute the query and get the result\n$users = $query-&gt;getResult();\n</code></pre> <p>In this example, <code>User</code> is a mapped entity, and the DQL query retrieves users whose age is greater than 25. The <code>:age</code> is a parameter that can be bound to a specific value when executing the query.</p>"},{"location":"programming/dwln/","title":"document.writeln()","text":"<p>document.writeln() is a JavaScript method used to write a string of text to the document stream, followed by a newline character. It's part of the Document Object Model (DOM) and is closely related to the document.write() method.</p> <p>The primary difference is that writeln adds a newline character at the end of the string, which results in a line break in the rendered HTML.</p> <p>The syntax of document.writeln() is similiar to document.write() - it takes one or more strings as arguments and writes them to the HTML document, adding a newline character at the end:</p> <pre><code>document.writeln(string1, string2, ..., stringN);\n</code></pre> <p>A usage example would be:</p> <pre><code>document.writeln(\"Hello, world!\");\ndocument.writeln(\"This is on a new line.\");\n</code></pre> <p>This script will write \"Hello, world!\" to the document, then start a new line and write \"This is on a new line.\".</p> <p>Just like document.write(), document.writeln() can pose security risks if used with untrusted data. It can be a vector for Cross-Site Scripting (XSS) attacks if the written data is not properly sanitized.</p>"},{"location":"programming/dwrite/","title":"document.write()","text":"<p>document.write() is a JavaScript method used to write content directly to the HTML document. When called, it writes a string of text to the position in the document where the document.write() call is made. This method is often used to dynamically generate HTML content on a webpage.</p> <p>document.write() is a method in JavaScript used to write a string of text directly to the HTML document where the script is being processed. It's part of the Document Object Model (DOM) and provides a way to dynamically generate and add content to a webpage.</p> <p>The method is typically called with a string argument, which is inserted into the HTML document at the point where the document.write() call appears:</p> <pre><code>document.write(\"&lt;h1&gt;Hello, World!&lt;/h1&gt;\");\n</code></pre> <p>This would write a heading element (&lt;h1&gt;) with the text \"Hello, World!\" into the HTML document.</p> <p>The primary security concern with document.write() is its potential use in Cross-Site Scripting (XSS) attacks. If document.write() is used to write unfiltered, user-supplied data to the document, it can lead to the execution of malicious scripts.</p> <p>For instance, if a web application uses document.write() to display data from a URL parameter or user input without proper sanitization, an attacker could inject a script into this data.</p>"},{"location":"programming/el/","title":"Expression Language (EL)","text":"<p>Expression Language (EL) is a scripting language used in web applications, particularly in Java-based technologies like JSF, JavaServer Pages (JSP), and other Java Enterprise Edition (Java EE) frameworks. EL provides a way to dynamically access and manipulate data within the application, making it a powerful tool for developing dynamic and data-driven web pages.</p> <p>EL allows developers to access and manipulate data stored in Java objects dynamically. This includes retrieving values from Enterprise JavaBeans (EJBs), arrays, lists, and other data structures. EL is often embedded within the markup of web pages, enabling developers to seamlessly mix static content with dynamic data. It simplifies the process of displaying data retrieved from the backend.</p> <p>EL expressions are enclosed in <code>${}</code>. For example, <code>${user.name}</code> might retrieve the \"name\" property of a user object.</p> <p>Common Use Cases:</p> <ul> <li>Displaying dynamic content on web pages.</li> <li>Accessing and presenting data from backend Java objects.</li> <li>Evaluating conditions and controlling the flow of the user interface.</li> </ul> <p>Suppose you have a JSP page with a user object stored in the request scope:</p> <pre><code>&lt;%@ page import=\"com.example.User\" %&gt;\n&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;User Profile&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Welcome, ${user.name}!&lt;/h1&gt;\n    &lt;p&gt;Email: ${user.email}&lt;/p&gt;\n    &lt;!-- Other dynamic content --&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>In this example, the EL expressions <code>${user.name}</code> and <code>${user.email}</code> retrieve and display the name and email properties of the user object.</p>"},{"location":"programming/encf/","title":"Encryption Filters","text":"<p>PHP does provide various functions and libraries for handling encryption and cryptographic operations. These are not implemented as \"filters\" in the same sense as PHP's data validation and sanitization filters, but they serve the purpose of encrypting and decrypting data.</p> <ol> <li>penSSL Functions: PHP's OpenSSL extension offers a comprehensive set of functions for encryption and decryption, as well as for other cryptographic operations like generating certificates, signing data, etc. Functions like <code>openssl_encrypt()</code> and <code>openssl_decrypt()</code> are used for encrypting and decrypting data respectively.</li> <li>Sodium Library: Introduced in PHP 7.2, the Sodium library is a modern and easy-to-use cryptographic library that provides a higher level of security. It offers various encryption functions, including public-key and symmetric-key encryption.</li> <li>Mcrypt Functions: Although it was deprecated in PHP 7.1 and removed in PHP 7.2, the Mcrypt extension was previously widely used for encryption. It's not recommended for use in newer PHP versions, but it's worth mentioning for legacy applications.</li> <li>Hash Functions: While not encryption per se, PHP provides functions like <code>hash()</code> and <code>password_hash()</code> for generating cryptographic hashes of data, which is essential for securely storing passwords and other sensitive information.</li> <li>Custom Encryption/Decryption Functions: PHP allows you to create custom encryption and decryption mechanisms using the available cryptographic libraries and functions, tailored to the specific needs of your application.</li> </ol> <p>Some examples include using OpenSSL for encryption:</p> <pre><code>$data = \"Secret Data\";\n$encryption_key = openssl_random_pseudo_bytes(32);\n$iv = openssl_random_pseudo_bytes(openssl_cipher_iv_length('aes-256-cbc'));\n$encrypted = openssl_encrypt($data, 'aes-256-cbc', $encryption_key, 0, $iv);\n$decrypted = openssl_decrypt($encrypted, 'aes-256-cbc', $encryption_key, 0, $iv);\n</code></pre> <p>Or using Sodium for encryption:</p> <pre><code>$key = sodium_crypto_secretbox_keygen();\n$nonce = random_bytes(SODIUM_CRYPTO_SECRETBOX_NONCEBYTES);\n$cipher = sodium_crypto_secretbox('Sensitive data', $nonce, $key);\n$original = sodium_crypto_secretbox_open($cipher, $nonce, $key);\n</code></pre>"},{"location":"programming/escapestring/","title":"pg_escape_string()","text":"<p>The pg_escape_string() function is a part of the PostgreSQL (PgSQL) extension in PHP. It is used to escape string literals for safe use in SQL queries when working with PostgreSQL databases. The primary purpose of this function is to prevent SQL injection, a common web security vulnerability that allows attackers to interfere with the queries that an application makes to its database.</p> <p>It escapes special characters in a string for use in an SQL query. Escaping a string involves prefixing certain characters with a backslash (). These characters typically include single quotes ('), double quotes (\"), and others that might otherwise be interpreted in a harmful way by the SQL parser.</p> <p>The function can be used in two ways:</p> <ul> <li>As <code>pg_escape_string(string $data)</code>, which escapes a string for safe use in an SQL query.</li> <li>As <code>pg_escape_string(resource $connection, string $data)</code>, which takes an additional argument \u2013 a connection resource to the PostgreSQL database. This is useful when multiple connections are present, and you need to specify which connection's encoding should be considered while escaping the string.</li> </ul> <p>An example usage may be:</p> <pre><code>$dbconn = pg_connect(\"host=localhost dbname=mydb user=myuser password=mypass\")\n    or die('Could not connect: ' . pg_last_error());\n\n// Unsafe data\n$data = \"O'Reilly\";\n\n// Escaping string\n$escapedData = pg_escape_string($dbconn, $data);\n\n// Safe SQL query\n$query = \"SELECT * FROM authors WHERE name = '$escapedData'\";\n$result = pg_query($query) or die('Query failed: ' . pg_last_error());\n</code></pre>"},{"location":"programming/exec/","title":"exec","text":"<p>The <code>exec</code> function in PHP is used to execute an external program or a shell command from within a PHP script. It provides a powerful way to interact with the underlying operating system. However, this capability comes with significant security risks if not used carefully.</p> <p><code>exec</code> allows a PHP script to run shell commands or external programs and optionally collect the last line of the output.</p> <p>The primary security concern with <code>exec</code> is the risk of command injection attacks. If user input is not properly sanitized, an attacker can inject malicious commands to be executed by the server, leading to severe vulnerabilities like remote code execution.</p> <p>If the use of <code>exec</code> is not tightly controlled, it can allow attackers to execute arbitrary commands on the server, potentially gaining unauthorized access to the system, modifying files, or accessing sensitive data.</p> <p>PHP provides other functions to execute shell commands, like shell_exec, system, and passthru, each with slightly different behavior. However, these functions have similar security risks and must be used with caution.</p>"},{"location":"programming/expect/","title":"Expect Wrapper","text":"<p>The <code>expect://</code> wrapper in PHP is a part of the Expect extension, which allows a script to interact with processes that are typically interactive. It's used to automate interactions with programs that require user input, such as shell scripts, command-line tools, or any other interactive application.</p> <p>The wrapper is primarily used for automating scripts and applications that usually require manual interaction. It allows for the execution of a command and then interaction with the process, by sending strings to the process and reading its output. The Expect extension can simulate a user's input, like responding to prompts, which is useful in automating tasks in scripts that are not originally designed for non-interactive environments.</p> <p>The <code>expect://</code> wrapper is used with PHP's fopen() function to open a process for reading and writing. After opening a process, you can send commands or data to it and read the response, simulating an interactive session. To use the <code>expect://</code> wrapper, you need to have the Expect PECL extension installed and enabled in your PHP environment.</p> <p>A conceptual example of how the <code>expect://</code> wrapper might be used in PHP:</p> <pre><code>&lt;?php\n// Open a process with the expect wrapper\n$process = fopen('expect://ls', 'r+');\n\nif ($process) {\n    // Send a command to the process\n    fwrite($process, \"some command\\n\");\n\n    // Read the output of the process\n    $output = fread($process, 4096);\n\n    // Close the process\n    fclose($process);\n\n    // Output the response\n    echo $output;\n}\n?&gt;\n</code></pre> <p>Info</p> <p>A command <code>ls</code> (to list directory contents in Unix/Linux) is executed, and the script interacts with it as if a user is typing commands in a terminal. The script could send additional commands based on the output, read the responses, and process them as needed.</p> <p>The <code>expect://</code> wrapper in PHP is not inherently vulnerable. However, like any tool that interacts with system processes or executes commands, it can be involved in security vulnerabilities if used improperly, especially when handling untrusted input. The primary security concerns with the <code>expect://</code> wrapper arise from how it's used to execute and interact with external processes.</p> <p>If the commands executed by the <code>expect://</code> wrapper include user-supplied input without proper sanitization, it could lead to command injection vulnerabilities. An attacker could potentially inject malicious commands to be executed on the server. If the script using the <code>expect://</code> wrapper is running with elevated privileges, executing untrusted commands or scripts could lead to a privilege escalation attack.</p> <p>Consider a PHP script that uses the <code>expect://</code> wrapper to execute a command based on user input:</p> <pre><code>&lt;?php\n$userInput = $_GET['cmd'];  // User-supplied input from a query parameter\n\n// Dangerous use of user input in expect\n$process = fopen(\"expect://$userInput\", 'r+');\n\n// Rest of the script to interact with the process\n// ...\n?&gt;\n</code></pre> <p>In this example, an attacker could manipulate the <code>cmd</code> query parameter to execute arbitrary commands on the server. For instance, by setting <code>cmd</code> to a malicious command, they could exploit this script to perform actions like modifying files, accessing sensitive data, or compromising the server.</p>"},{"location":"programming/fetch/","title":"fetch()","text":"<p>The <code>fetch()</code> function in JavaScript is a modern, versatile method used for making network requests. It's part of the Fetch API, which provides a more powerful and flexible feature set compared to older methods like XMLHttpRequest. <code>fetch()</code> returns a Promise, which resolves to the Response object representing the response to the request. This makes it well-suited for asynchronous operations.</p> <p>The basic syntax is <code>fetch(url)</code>, where <code>url</code> is the path to the resource you want to fetch. It returns a Promise, allowing you to use <code>.then()</code> and <code>.catch()</code> methods for handling the response and errors, respectively. <code>fetch()</code> deals with Request and Response objects, making it easier to manage and manipulate various aspects of requests and responses.</p> <p>You can configure requests with custom headers, different HTTP methods (like GET, POST), and other settings. <code>fetch()</code> supports streaming responses, which is useful for handling large data sets.</p> <p>A simple example of using fetch() may be:</p> <pre><code>fetch('https://api.example.com/data')\n  .then(response =&gt; response.json())\n  .then(data =&gt; console.log(data))\n  .catch(error =&gt; console.error('Error:', error));\n</code></pre> <p>Info</p> <p>This code fetches data from the provided URL and prints it to the console. The response is first converted to JSON, which is a common use case.</p>"},{"location":"programming/fgc/","title":"file_get_contents()","text":"<p>The <code>file_get_contents()</code> function in PHP is a simple and convenient way to read the entire contents of a file into a string. It's widely used due to its ease of use and efficiency for reading files, especially when dealing with text files or the contents of a URL.</p> <p>It can be used to read local files from the file system. The function reads the entire file and returns its contents as a string. If the PHP configuration allows, <code>file_get_contents()</code> can also be used to read content from a URL, effectively fetching data from the web.</p> <p>It supports the use of a context resource created with <code>stream_context_create()</code> to modify the behavior of the request (like setting HTTP headers when fetching a URL).  If the function fails to read a file (e.g., due to permissions issues or the file not existing), it returns <code>FALSE</code>.</p> <p>The syntax is:</p> <pre><code>$content = file_get_contents(string $filename, bool $use_include_path = false, resource $context = null, int $offset = 0, int $length = null): string|false\n</code></pre> <ul> <li><code>$filename</code>: Path to the file or URL.</li> <li><code>$use_include_path</code>: Whether to search for the file in the include_path (optional).</li> <li><code>$context</code>: A context resource created with <code>stream_context_create()</code> to specify options like headers, proxy settings, etc. (optional).</li> <li><code>$offset</code>: Offset where reading starts on the original stream (optional).</li> <li><code>$length</code>: Maximum length of data read (optional).</li> </ul> <p>Some examples include reading a local file:</p> <pre><code>$content = file_get_contents('/path/to/file.txt');\necho $content;\n</code></pre> <p>And reading from a URL:</p> <pre><code>$content = file_get_contents('http://example.com');\necho $content;\n</code></pre> <p>When using <code>file_get_contents()</code> with user-provided data (e.g., file paths or URLs), it's crucial to validate and sanitize the input to prevent security vulnerabilities, such as Local File Inclusion (LFI) or Remote File Inclusion (RFI). Additionally, when reading from external URLs, be aware of the risks of fetching untrusted content, which could include malicious data or code.</p> <p>An example of vulnerable code is:</p> <pre><code>&lt;?php\n// A vulnerable script where the file name is taken from user input\n$filePath = $_GET['file'];\n\n// Using file_get_contents() with user-controlled input\n$content = file_get_contents($filePath);\n\necho $content;\n?&gt;\n</code></pre> <p>Danger</p> <p>In this example, an attacker could manipulate the query string in the URL to access sensitive files. For instance:</p> <pre><code>http://example.com/script.php?file=../../etc/passwd\n</code></pre> <p>This URL attempts to access the Unix/Linux system file <code>/etc/passwd</code>, which contains user information and could be sensitive.</p>"},{"location":"programming/file/","title":"file()","text":"<p>The <code>file()</code> function in PHP is used to read the entire content of a file into an array. Each element of the array corresponds to a line in the file, with newline characters still attached. This function is particularly useful for reading and processing files line by line.</p> <pre><code>file(string $filename, int $flags = 0, resource $context = null): array|false\n</code></pre> <ul> <li><code>$filename</code>: Path to the file.</li> <li><code>$flags</code> (Optional): A bitmask of flags for handling the file. Common flags include <code>FILE_IGNORE_NEW_LINES</code> (which omits newline characters from each element of the array) and <code>FILE_SKIP_EMPTY_LINES</code> (which skips empty lines).</li> <li><code>$context</code> (Optional): A context resource created with <code>stream_context_create()</code> to specify options like headers, proxy settings, etc.</li> </ul> <p>An example can be reading a file into an array:</p> <pre><code>$lines = file('path/to/file.txt');\n\nif ($lines === false) {\n    echo \"Error reading the file\";\n} else {\n    foreach ($lines as $line) {\n        // Process each line\n        echo $line;\n    }\n}\n</code></pre> <p>In this example, <code>file()</code> reads each line of <code>file.txt</code> into the array <code>$lines</code>. The script then iterates over each line for processing.</p> <p>It can also be with flags:</p> <pre><code>$lines = file('path/to/file.txt', FILE_IGNORE_NEW_LINES | FILE_SKIP_EMPTY_LINES);\n\nif ($lines === false) {\n    echo \"Error reading the file\";\n} else {\n    foreach ($lines as $line) {\n        // Process each line without newline characters and skipping empty lines\n        echo $line;\n    }\n}\n</code></pre> <p>In this version, <code>FILE_IGNORE_NEW_LINES</code> removes the newline characters at the end of each array element, and <code>FILE_SKIP_EMPTY_LINES</code> excludes empty lines from the array.</p> <p>When using <code>file()</code> with user-supplied data, such as file paths, it's important to validate and sanitize the input to prevent security vulnerabilities like Directory Traversal. Additionally, be aware of the file permissions and the server's configuration when reading files to avoid unauthorized access or disclosure of sensitive information.</p> <p>An example of a vulnerable implementation:</p> <pre><code>// A simple script where the file path is taken from user input\n$filePath = $_GET['filePath'];\n\n// Using file() with user-controlled input\n$lines = file($filePath);\n\nif ($lines === false) {\n    echo \"Error reading the file\";\n} else {\n    foreach ($lines as $line) {\n        // Output each line of the file\n        echo htmlspecialchars($line);\n    }\n}\n</code></pre> <p>Danger</p> <p>In this example, the script takes a file path from a query parameter (<code>filePath</code>) and reads its contents. An attacker could exploit this by manipulating the query string to access sensitive files. For instance, using a URL like:</p> <pre><code>http://example.com/script.php?filePath=../../etc/passwd\n</code></pre> <p>This URL could potentially give the attacker access to the <code>/etc/passwd</code> file on a Unix-like system, which contains user account information.</p>"},{"location":"programming/filtervar/","title":"filter_var()","text":"<p>filter_var() is a function in PHP used for filtering and validating data. It's a part of PHP's filter extension, which provides a range of functionalities for validating and sanitizing data, such as email addresses, URLs, IP addresses, and more. </p> <p>This function is particularly useful for ensuring that data conforms to specific formats or ranges, making it a valuable tool for data validation in PHP applications.</p> <p>The syntax is:</p> <pre><code>filter_var(value, filter, options)\n</code></pre> <ul> <li>value: The variable you want to check or filter.</li> <li>filter: The type of check to use. PHP provides many predefined filters for various purposes, like <code>FILTER_VALIDATE_EMAIL</code>, <code>FILTER_SANITIZE_STRING</code>, etc.</li> <li>options: An associative array of options or bitwise disjunction of flags. The available options and flags depend on the chosen filter.</li> </ul> <p>Some common uses are validating user input from forms, such as email addresses, URLs, and numbers. Another use is sanitizing data before it is used in a query or output to prevent security issues like SQL injection or Cross-Site Scripting (XSS) attacks.</p> <p>Some examples may be validating an email:</p> <pre><code>$email = \"test@example.com\";\nif (filter_var($email, FILTER_VALIDATE_EMAIL)) {\n    echo \"This is a valid email address.\";\n} else {\n    echo \"This is not a valid email address.\";\n}\n</code></pre> <p>Or validating/sanitizing a string:</p> <pre><code>$string = \"&lt;script&gt;alert('Hi!');&lt;/script&gt;\";\n$sanitizedString = filter_var($string, FILTER_SANITIZE_STRING);\necho $sanitizedString;\n// Outputs: alert('Hi!');\n</code></pre> <p>Using filter_var() is a good practice for enhancing the security of your application by preventing the use of invalid or malicious data.</p>"},{"location":"programming/fopen/","title":"fopen()","text":"<p>The <code>fopen()</code> function in PHP is used to open a file or a URL and initialize a new file pointer to it. It's a fundamental function for file handling in PHP, allowing you to read from or write to files.</p> <p>The syntax is:</p> <pre><code>fopen(string $filename, string $mode, bool $use_include_path = false, resource $context = null): resource|false\n</code></pre> <ul> <li><code>$filename</code>: Path to the file or a URL.</li> <li><code>$mode</code>: The mode in which to open the file. This determines how the file will be used (e.g., read-only, write-only, read/write).</li> <li><code>$use_include_path</code> (Optional): Whether to search for the file in the include path.</li> <li><code>$context</code> (Optional): A context resource created with <code>stream_context_create()</code> to specify options like headers, proxy settings, etc.</li> </ul> <p>There are various file modes including:</p> <ul> <li><code>'r'</code>: Open for reading only; place the file pointer at the beginning of the file.</li> <li><code>'w'</code>: Open for writing only; place the file pointer at the beginning of the file and truncate the file to zero length. If the file does not exist, attempt to create it.</li> <li><code>'a'</code>: Open for writing only; place the file pointer at the end of the file. If the file does not exist, attempt to create it.</li> <li><code>'x'</code>: Create and open for writing only; place the file pointer at the beginning of the file. If the file already exists, the <code>fopen()</code> call will fail</li> </ul> <p>There are other modes as well, including combinations and modes for binary files (e.g., <code>'rb'</code>, <code>'wb'</code>, <code>'ab'</code>, etc.).</p> <p>An example such as opening a file for reading:</p> <pre><code>$handle = fopen(\"test.txt\", \"r\");\nif ($handle === false) {\n    echo \"Error opening the file\";\n} else {\n    // Process the file\n    fclose($handle);\n}\n</code></pre> <p>Or opening a file for writing:</p> <pre><code>$handle = fopen(\"newfile.txt\", \"w\");\nif ($handle === false) {\n    echo \"Error opening the file\";\n} else {\n    fwrite($handle, \"Writing this to newfile.txt\");\n    fclose($handle);\n}\n</code></pre> <p><code>fopen()</code> returns a file pointer resource on success, or <code>false</code> on error. It's essential to check the return value of <code>fopen()</code> for <code>false</code> to handle errors, such as permissions issues or the file not being found.</p> <p>The <code>fopen()</code> function in PHP itself is not inherently vulnerable, but it can become a source of security vulnerabilities if used improperly, particularly when handling user-supplied input. The primary security concerns associated with <code>fopen()</code> are Directory Traversal and Remote File Inclusion.</p> <p>An example of vulnerable code is:</p> <pre><code>// A simple script that opens a file specified by the user\n$filePath = $_GET['file']; // User-supplied input\n\n// Open the file for reading\n$handle = fopen($filePath, \"r\");\n\nif ($handle === false) {\n    echo \"Error opening the file\";\n} else {\n    // Read and output the file content\n    echo fread($handle, filesize($filePath));\n    fclose($handle);\n}\n</code></pre> <p>Danger</p> <p>In this example, the script uses a query parameter (file) to open a file. An attacker could manipulate the query string to access sensitive files. For instance, using a URL like:</p> <pre><code>http://example.com/script.php?file=../../etc/passwd\n</code></pre> <p>This could allow an attacker to read the contents of the /etc/passwd file on a Unix-like system, which can be a severe security breach.</p>"},{"location":"programming/fprintf/","title":"fprintf","text":"<p><code>fprintf</code> is a function in the C standard library used for formatted output to a stream. It is similar to printf, but instead of writing output to the standard output (typically the screen), <code>fprintf</code> writes the output to the specified file stream. The function prototype is:</p> <pre><code>int fprintf(FILE *stream, const char *format, ...);\n</code></pre> <p><code>fprintf</code> takes a file stream (like a file pointer returned by <code>fopen</code>) and a format string followed by an unspecified number of additional arguments. The vulnerabilities in <code>fprintf</code> are generally related to the format string. If an attacker can control the format string, they might exploit it in a way similar to Format String Vulnerabilities in <code>printf</code>.</p> <p>If the format string is not properly specified and user input is passed directly as a format string, it can lead to a format string vulnerability. An attacker might provide a format string that causes <code>fprintf</code> to perform unauthorized operations like reading from or writing to arbitrary memory locations. If <code>fprintf</code> is used to write more data to a buffer than it can hold, it can lead to buffer overflow vulnerabilities.</p> <p>Consider a program that uses <code>fprintf</code> to write user input to a file:</p> <pre><code>FILE *fp;\nchar user_input[100];\n\nfp = fopen(\"log.txt\", \"w\");\nscanf(\"%99s\", user_input);  // Read user input\nfprintf(fp, user_input);   // Vulnerable\nfclose(fp);\n</code></pre> <p>In this example, <code>user_input</code> is directly used in <code>fprintf</code> as a format string. An attacker could input a string like <code>%x %x %x</code> to potentially leak memory contents into the <code>log.txt</code> file. More maliciously, they could use <code>%n</code> to write values to memory, leading to code execution vulnerabilities.</p>"},{"location":"programming/fread/","title":"fread()","text":"<p><code>fread()</code> is a built-in function in PHP used to read data from a file or a file-like resource. This function is commonly used for file handling operations in PHP, where it reads a specified number of bytes from a file pointer.</p> <p>The syntax is:</p> <pre><code>fread(resource $handle, int $length): string|false\n</code></pre> <ul> <li><code>$handle</code>: A file system pointer resource that is typically created using fopen().</li> <li><code>$length</code>: The number of bytes to read from the file or resource.</li> </ul> <p><code>fread()</code> returns the read string of up to <code>$length</code> bytes on success, or <code>false</code> on failure. A simple example showing how to open a file, read its contents and close the file is as follows:</p> <pre><code>&lt;?php\n$filename = \"example.txt\";\n\n// Open the file for reading\n$handle = fopen($filename, \"r\");\n\nif ($handle) {\n    // Read the entire file\n    // filesize() gets the size of the file for the length parameter\n    $contents = fread($handle, filesize($filename));\n\n    // Close the file handle\n    fclose($handle);\n\n    // Print the contents of the file\n    echo $contents;\n} else {\n    echo \"Error: Unable to open the file.\";\n}\n?&gt;\n</code></pre> <p>In this example, <code>fopen()</code> is used to open the file named <code>example.txt</code> in read mode (<code>\"r\"</code>). The <code>fread()</code> function then reads the entire file by using <code>filesize($filename)</code> to determine the length of the file in bytes. After reading, the file is closed using <code>fclose($handle)</code>.</p> <p><code>fread()</code> itself in PHP is not inherently vulnerable, but like any file operation function, it can become part of a vulnerability if used improperly, particularly in scenarios where the file being read is determined by user input. The main security concern with <code>fread()</code> is not the function itself, but how the file paths and data are handled.</p> <p>If the file path provided to <code>fread()</code> comes from an untrusted source (like user input) without proper validation and sanitization, it can lead to a security vulnerability known as Directory Traversal or Path Traversal.</p> <p>An example of a vulnerable scenario is:</p> <pre><code>&lt;?php\n// Example of a vulnerable use of fread()\n\n$userFile = $_GET['file'];  // File name comes from user input\n$filePath = \"uploads/\" . $userFile;\n\n$handle = fopen($filePath, \"r\");\nif ($handle) {\n    $contents = fread($handle, filesize($filePath));\n    fclose($handle);\n    echo $contents;\n}\n?&gt;\n</code></pre> <p>In this example, a file name is taken directly from user input via <code>$_GET['file']</code>. If the application doesn't validate or sanitize this input, an attacker could potentially read arbitrary files from the server by supplying a relative path (like <code>../../etc/passwd</code>).</p>"},{"location":"programming/fsharp/","title":"F#","text":"<p>F# (pronounced \"F sharp\") is a functional-first programming language that also supports imperative and Object-Oriented Programming paradigms. It is a .NET language, meaning it runs on the Microsoft .NET Framework and .NET Core, and it was developed by Microsoft Research and later made open source. </p> <p>F# is known for its concise syntax, strong type system, and focus on functional programming.</p> <p>F# is designed with a focus on functional programming techniques. It encourages immutable data, first-class functions, and expression-oriented programming, which can lead to more predictable and less error-prone code.</p> <p>F# uses type inference to deduce the types of values and expressions without explicit type annotations. This leads to cleaner, more concise code while still providing the benefits of a strong static type system.</p> <p>The syntax of F# is succinct and expressive, allowing developers to write less code compared to many other languages, without sacrificing readability or functionality. </p> <p>As a .NET language, F# can easily interoperate with other .NET languages like C# and VB.NET. It can use the extensive .NET libraries and frameworks, and F# code can be used in other .NET applications.</p> <p>F# has strong support for asynchronous programming and parallel computations, making it well-suited for tasks involving I/O operations, computations on multicore processors, and cloud computing.</p>"},{"location":"programming/fsrf/","title":"fs.readFile()","text":"<p>The <code>fs.readFile()</code> function is a part of the File System (<code>fs</code>) module in Node.js, used for reading the contents of a file in an asynchronous manner. This function is essential for handling file operations in Node.js applications and allows you to read files from the file system without blocking the execution of your program.</p> <p>It reads files in a non-blocking way, meaning that Node.js can perform other operations while the file is being read. It requires a callback function that is called when the file reading is complete or an error occurs. By default, the content is read into a <code>Buffer</code> object. However, if an encoding is specified, the content is returned as a string in the specified encoding. The first argument to the callback function is an error object, which will be <code>null</code> if no error occurred.</p> <p>The syntax is:</p> <pre><code>fs.readFile(path[, options], callback)\n</code></pre> <ul> <li><code>path</code>: A string that specifies the path to the file.</li> <li><code>options</code> (Optional): An object or string that specifies the encoding or other options. Commonly used to specify the file encoding, like <code>'utf8'</code>.</li> <li><code>callback</code>: A function that is called with two arguments <code>(err, data)</code> when the file read operation is complete. <code>err</code> will contain an error object if an error occurred, and <code>data</code> will contain the file contents.</li> </ul> <p>For example, reading a file into a string:</p> <pre><code>const fs = require('fs');\n\nfs.readFile('/path/to/file.txt', 'utf8', (err, data) =&gt; {\n    if (err) {\n        console.error('Error reading the file:', err);\n        return;\n    }\n    console.log(data); // Output the file content as a string\n});\n</code></pre> <p>In this example, <code>fs.readFile()</code> is used to read the contents of <code>'file.txt'</code> into a string. The encoding <code>'utf8'</code> is specified so that the content is returned as a string rather than a buffer.</p> <p>Or reading a file into a buffer:</p> <pre><code>const fs = require('fs');\n\nfs.readFile('/path/to/file.txt', (err, data) =&gt; {\n    if (err) {\n        console.error('Error reading the file:', err);\n        return;\n    }\n    // data is a Buffer object\n    console.log(data.toString('utf8')); // Convert the buffer to a string\n});\n</code></pre> <p>The <code>fs.readFile()</code> function in Node.js itself is not inherently vulnerable. However, when used improperly, particularly with unvalidated user input, it can lead to security vulnerabilities, most notably Path Traversal (or Directory Traversal) attacks.</p> <p>An example of vulnerable code:</p> <pre><code>const fs = require('fs');\nconst http = require('http');\n\nhttp.createServer((req, res) =&gt; {\n    // Extracting the file path from the query parameter\n    // This is dangerous if not properly validated\n    const filePath = req.url.slice(1);\n\n    fs.readFile(filePath, 'utf8', (err, data) =&gt; {\n        if (err) {\n            res.writeHead(404);\n            res.end('File not found');\n        } else {\n            res.writeHead(200, {'Content-Type': 'text/plain'});\n            res.end(data);\n        }\n    });\n}).listen(3000);\n</code></pre> <p>Danger</p> <p>In this example, the server reads a file based on the user's input from the URL and returns its content. An attacker could exploit this by manipulating the URL to access sensitive files. For instance:</p> <pre><code>http://localhost:3000/../../etc/passwd\n</code></pre> <p>This URL could potentially give the attacker access to the /etc/passwd file on a Unix-like system, containing sensitive user information.</p>"},{"location":"programming/fssf/","title":"fs.sendFile()","text":"<p>The <code>res.sendFile()</code> function is a method of the response object (<code>res</code>) in Express.js, a web application framework for Node.js. This method is used to send a file as an HTTP response to the client. It's particularly useful for tasks like serving static files (e.g., images, PDFs, HTML files) in response to client requests.</p> <p>The syntax is:</p> <pre><code>res.sendFile(path [, options] [, callback])\n</code></pre> <ul> <li><code>path</code>: The absolute or relative path to the file.</li> <li><code>options</code> (Optional): An object to specify options like root directory, headers, etc.</li> <li><code>callback</code> (Optional): A callback function that is called after the file is sent or if there's an error.</li> </ul> <p>A usage example:</p> <pre><code>const express = require('express');\nconst path = require('path');\nconst app = express();\n\napp.get('/download-report', (req, res) =&gt; {\n    const filePath = path.join(__dirname, 'public', 'report.pdf');\n    res.sendFile(filePath, (err) =&gt; {\n        if (err) {\n            console.log(err);\n            res.status(500).send('Error occurred while sending file.');\n        }\n    });\n});\n\napp.listen(3000, () =&gt; {\n    console.log('Server is running on port 3000');\n});\n</code></pre> <p>Info</p> <p>In this example, a PDF report is sent to the client when they access the <code>/download-report</code> endpoint. The <code>sendFile()</code> method is used to send <code>report.pdf</code> as the response.</p> <p>The <code>res.sendFile()</code> function in Express.js itself is not inherently vulnerable. However, like many other functions that involve file handling and user input, it can become a source of security vulnerabilities if not used properly. The primary concern with <code>res.sendFile()</code> is related to Directory Traversal attacks when user input is used to determine the file path.</p> <p>A vulnerable example:</p> <pre><code>const express = require('express');\nconst app = express();\nconst path = require('path');\n\napp.get('/file', (req, res) =&gt; {\n    // User input is taken directly from the query parameter\n    let fileName = req.query.fileName;\n\n    // This usage of res.sendFile() is vulnerable to Path Traversal\n    res.sendFile(fileName, { root: path.join(__dirname, 'public') }, (err) =&gt; {\n        if (err) {\n            res.status(500).send('Error occurred while sending file.');\n        }\n    });\n});\n\napp.listen(3000, () =&gt; console.log('Server running on port 3000'));\n</code></pre> <p>Danger</p> <p>In this example, the server sends a file based on the <code>fileName</code> query parameter. An attacker could exploit this by manipulating the <code>fileName</code> parameter to access files outside the <code>public</code> directory. For example:</p> <pre><code>http://example.com/file?fileName=../../etc/passwd\n</code></pre> <p>This URL could potentially give the attacker access to the /etc/passwd file on a Unix-like system.</p>"},{"location":"programming/fwrite/","title":"fwrite()","text":"<p>In PHP, the <code>fwrite()</code> function is used to write data to a file or a stream. It's commonly used in conjunction with fopen() to handle file operations. fwrite() is an essential function for file handling in PHP, allowing for both text and binary data writing.</p> <p>The syntax is:</p> <pre><code>fwrite(resource $handle, string $string, int $length = ?): int|false\n</code></pre> <ul> <li><code>$handle</code>: The file resource pointer that points to the file to be written to. This handle is typically created using <code>fopen()</code>.</li> <li><code>$string</code>: The string of data that you want to write.</li> <li><code>$length</code> (optional): The maximum number of bytes to write. If this parameter is omitted, <code>fwrite()</code> will write all of the <code>$string</code> to the file.</li> </ul> <p><code>fwrite()</code> returns the number of bytes written to the file on success, or <code>false</code> on failure.</p> <p>A simple example showing how to open a file, write content to it and close the file is:</p> <pre><code>&lt;?php\n$filename = \"example.txt\";\n$content = \"Hello, World!\";\n\n// Open the file for writing\n$handle = fopen($filename, \"w\");\n\nif ($handle) {\n    // Write content to the file\n    fwrite($handle, $content);\n\n    // Close the file handle\n    fclose($handle);\n} else {\n    echo \"Error: Unable to open the file.\";\n}\n?&gt;\n</code></pre> <p>The file named <code>example.txt</code> is opened in write mode (<code>\"w\"</code>). The string <code>Hello, World!</code> is then written to the file using <code>fwrite()</code>. After writing, the file is closed using <code>fclose($handle)</code>.</p> <p><code>fwrite()</code> in PHP, as a file writing function, is not inherently vulnerable by itself. However, it can be involved in security vulnerabilities if used improperly, especially in scenarios involving unvalidated user input. The primary concern with <code>fwrite()</code> is how it's used to handle data and file operations. Improper use can lead to security issues such as unauthorized file access, file inclusion vulnerabilities, or data leakage.</p> <p>Consider a web application that allows users to write content to a file on the server, and the filename or content is taken from user input without proper validation or sanitization:</p> <pre><code>&lt;?php\n// Example of a potentially vulnerable use of fwrite()\n\n$filename = $_GET['filename']; // Filename from user input\n$content = $_GET['content'];   // Content from user input\n\n$handle = fopen($filename, \"w\");\nif ($handle) {\n    fwrite($handle, $content);\n    fclose($handle);\n} else {\n    echo \"Error: Unable to open the file.\";\n}\n?&gt;\n</code></pre> <p>In this example, an attacker could potentially:</p> <ol> <li>Write to Sensitive Files: If the server permissions allow, the attacker might overwrite important system files or configuration files by providing their paths in the <code>filename</code> parameter.</li> <li>Execute Arbitrary Scripts: If the server is configured to execute scripts in the directory where files are being written, an attacker could write a PHP script and then execute it by accessing its URL, leading to remote code execution.</li> </ol>"},{"location":"programming/go/","title":"Go","text":"<p>The Go programming language, often referred to as Golang, is an open-source programming language developed by Google. It's known for its simplicity, efficiency, and strong support for concurrency and networking. Go is statically typed and compiles to machine code, which contributes to its performance benefits.</p> <p>An example program:</p> <pre><code>package main\nimport \"fmt\"\n\nfunc main() {\n    fmt.Println(\"Hello, World!\")\n}\n</code></pre> <p>Info</p> <p>This example demonstrates a basic Go program that prints \"Hello, World!\" to the console. It uses the <code>fmt</code> package for formatted I/O operations.</p> <p>Additionally, here is an example of concurrent HTTP requests:</p> <pre><code>package main\nimport (\n    \"fmt\"\n    \"net/http\"\n)\n\nfunc fetch(url string) {\n    _, err := http.Get(url)\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    fmt.Println(\"Fetched:\", url)\n}\n\nfunc main() {\n    urls := []string{\n        \"https://www.google.com\",\n        \"https://www.example.com\",\n    }\n    for _, url := range urls {\n        go fetch(url)\n    }\n}\n</code></pre> <p>This snippet shows how Go can handle concurrent operations, like making multiple HTTP requests simultaneously. The <code>go</code> keyword is used to start a new goroutine, Go's lightweight thread, for each HTTP request.</p> <p>Go's simplicity in syntax and powerful built-in features for handling concurrency make it a popular choice for server-side applications, cloud and network services, and command-line tools.</p>"},{"location":"programming/hsc/","title":"htmlspecialchars","text":"<p>In PHP, the htmlspecialchars function is used to convert special characters to their corresponding HTML entities. This function is particularly important in web development for preventing Cross-Site Scripting (XSS) attacks by escaping characters that could otherwise be interpreted and executed as HTML or JavaScript.</p> <p>htmlspecialchars specifically targets characters that have special significance in HTML such as:</p> <ul> <li>Ampersand (&amp;)</li> <li>Double quote (\")</li> <li>Single quote (')</li> <li>Less than (&lt;)</li> <li>Greater than (&gt;)</li> </ul> <p>The basic syntax is:</p> <pre><code>string htmlspecialchars(string $string, int $flags = ENT_COMPAT, string $encoding = 'UTF-8', bool $double_encode = true)\n</code></pre> <ul> <li>$string: The string to be converted.</li> <li>$flags (optional): A bitmask that controls the behavior. Common flags include ENT_COMPAT (default, converts double quotes), ENT_QUOTES (converts both double and single quotes), and ENT_NOQUOTES (does not convert any quotes).</li> <li>$encoding (optional): Defines the character encoding. If not specified, the default is 'UTF-8'.</li> <li>$double_encode (optional): When set to true (default), it will convert existing HTML entities to their entity-encoded versions. If set to false, it will leave existing HTML entities as-is.</li> </ul> <p>An example may be:</p> <pre><code>$input = \"&lt;script&gt;alert('XSS');&lt;/script&gt;\";\n$escapedInput = htmlspecialchars($input, ENT_QUOTES, 'UTF-8');\necho $escapedInput; // Outputs: &amp;lt;script&amp;gt;alert(&amp;#039;XSS&amp;#039;);&amp;lt;/script&amp;gt;\n</code></pre> <p>In this example, htmlspecialchars converts the special characters in $input to HTML entities, rendering the script harmless if echoed to a web page.</p>"},{"location":"programming/htmlent/","title":"htmlentities","text":"<p>html-entities in NodeJS is a package that provides similar functionality to the htmlentities() function in PHP. It's used for encoding and decoding HTML entities. This is especially important in web development to ensure that text is safely rendered in web browsers, preventing issues like cross-site scripting (XSS) attacks.</p> <p>It allows you to encode and decode HTML entities. For example, characters like &lt;, &gt;, and &amp; can be encoded to &lt;, &gt;, and &amp; respectively, and vice versa.</p> <p>The package supports various types of entities, including HTML4, HTML5, XML, and more. It can handle a wide range of character sets and is capable of encoding or decoding all HTML entities defined in the named character references in HTML 4 and 5.</p> <p>By encoding user input or other insecure data sources, it helps in preventing XSS attacks in web applications.</p> <p>A basic example of how to use html-entities in a Node.js application:</p> <pre><code>// First, install the package using npm\n// npm install html-entities\n\nconst { Html5Entities } = require('html-entities');\n\nconst html5Entities = new Html5Entities();\n\nconst encoded = html5Entities.encode('&lt;script&gt;alert(\"xss\")&lt;/script&gt;');\nconsole.log(encoded); // Outputs: &amp;lt;script&amp;gt;alert(&amp;quot;xss&amp;quot;)&amp;lt;/script&amp;gt;\n\nconst decoded = html5Entities.decode(encoded);\nconsole.log(decoded); // Outputs: &lt;script&gt;alert(\"xss\")&lt;/script&gt;\n</code></pre> <p>In this example, html-entities is used to encode a string that could be potentially harmful if rendered directly in a web browser, and then it is decoded back to its original form. This package is quite versatile and useful for handling HTML entities in Node.js applications.</p>"},{"location":"programming/htmlentities/","title":"html-entities","text":"<p>html-entities in NodeJS is a package that provides similar functionality to the htmlentities() function in PHP. It's used for encoding and decoding HTML entities. This is especially important in web development to ensure that text is safely rendered in web browsers, preventing issues like cross-site scripting (XSS) attacks.</p> <p>It allows you to encode and decode HTML entities. For example, characters like &lt;, &gt;, and &amp; can be encoded to &lt;, &gt;, and &amp; respectively, and vice versa.</p> <p>The package supports various types of entities, including HTML4, HTML5, XML, and more. It can handle a wide range of character sets and is capable of encoding or decoding all HTML entities defined in the named character references in HTML 4 and 5.</p> <p>By encoding user input or other insecure data sources, it helps in preventing XSS attacks in web applications.</p> <p>A basic example of how to use html-entities in a Node.js application:</p> <pre><code>// First, install the package using npm\n// npm install html-entities\n\nconst { Html5Entities } = require(\"html-entities\");\n\nconst html5Entities = new Html5Entities();\n\nconst encoded = html5Entities.encode('&lt;script&gt;alert(\"xss\")&lt;/script&gt;');\nconsole.log(encoded); // Outputs: &amp;lt;script&amp;gt;alert(&amp;quot;xss&amp;quot;)&amp;lt;/script&amp;gt;\n\nconst decoded = html5Entities.decode(encoded);\nconsole.log(decoded); // Outputs: &lt;script&gt;alert(\"xss\")&lt;/script&gt;\n</code></pre> <p>In this example, html-entities is used to encode a string that could be potentially harmful if rendered directly in a web browser, and then it is decoded back to its original form. This package is quite versatile and useful for handling HTML entities in Node.js applications.</p>"},{"location":"programming/htmlfunc/","title":"html()","text":"<p>The jQuery html() function is used to get or set the HTML content of an element. It's a versatile and widely-used function in jQuery, a popular JavaScript library, for DOM manipulation.</p> <p>When used without any arguments, html() gets the HTML content of the first element in the set of matched elements:</p> <pre><code>var content = $(selector).html();\n</code></pre> <p>An example:</p> <pre><code>var content = $('#myDiv').html();\n</code></pre> <p>This retrieves the inner HTML content of the element with the ID myDiv. When a string is passed as an argument to html(), it sets the HTML content of each element in the set of matched elements to the specified string:</p> <pre><code>$(selector).html(htmlString);\n</code></pre> <p>An example:</p> <pre><code>$('#myDiv').html('&lt;p&gt;New content&lt;/p&gt;');\n</code></pre> <p>This example sets the inner HTML of the element with the ID myDiv to \\<p>New content\\</p>.</p> <p>If you use html() with user-supplied data or content from an untrusted source, it poses a risk of XSS attacks. You should always sanitize input to ensure it's safe before using it with html().</p>"},{"location":"programming/htmlpartial/","title":"@Html.Partial()","text":"<p>The <code>@Html.Partial()</code> function is used in ASP.NET MVC (Model-View-Controller (MVC)) framework, which is a part of ASP.NET for building web applications. It's a method defined in the <code>HtmlHelper</code> class and is used to render a specified partial view within a view. This method helps in modularizing and reusing views by allowing the inclusion of reusable components (partial views) within other views.</p> <p>It helps in breaking down complex views into smaller, reusable components (partial views) and enables the reuse of views across different parts of the application. It also improves the maintainability of the code by keeping views organized and avoiding repetition.</p> <p>The syntax is:</p> <pre><code>@Html.Partial(string partialViewName)\n@Html.Partial(string partialViewName, object model)\n</code></pre> <ul> <li><code>partialViewName</code>: The name of the partial view to render.</li> <li><code>model</code> (Optional): The model that should be passed to the partial view.</li> </ul> <p>Some usage examples include rendering a partial view without a passing model:</p> <pre><code>@Html.Partial(\"PartialViewName\")\n</code></pre> <p>And with passing a model:</p> <pre><code>@Html.Partial(\"PartialViewName\", Model)\n</code></pre> <p>As an example, assume you have a partial view named <code>_UserInfo.cshtml</code> that renders user information. In your main view, you can render this partial view as follows:</p> <pre><code>@Html.Partial(\"_UserInfo\", Model.UserInfo)\n</code></pre> <p>The partial view is rendered inline and its output is included in the parent view's output. The <code>@Html.Partial()</code> method can be called with just the name of the partial view or with both the name and the model to be passed to the partial view.</p> <p>Partial views are generally stored in the <code>Views/Shared</code> folder if they are to be shared across multiple views or in the same folder as the calling view if they are specific to that view. ASP.NET MVC also offers other similar methods like <code>@Html.RenderPartial()</code>, which has slight differences in usage and performance characteristics. </p> <p><code>RenderPartial</code> writes directly to the response stream, offering better performance for larger content, whereas <code>Html.Partial</code> returns a string that can be stored, manipulated, or displayed in different ways.</p>"},{"location":"programming/include/","title":"include()","text":"<p>The <code>include()</code> function in PHP is a widely-used construct that allows a PHP file to insert and execute the content of another file into the current file. This is particularly useful for reusing code, such as headers, footers, or user-defined functions, across multiple pages of a website.</p> <p>The <code>include()</code> function can be a security risk if not properly handled, especially in scenarios where the file to be included is determined by user input. This risk arises from a vulnerability known as \"Local File Inclusion\" (LFI) or, in some cases, \"Remote File Inclusion\" (RFI):</p> <ol> <li>Local File Inclusion (LFI): This occurs when a script allows user-controlled input to dictate which files are included. An attacker could exploit this to include files that are already on the server, such as configuration files containing sensitive information.</li> <li>Remote File Inclusion (RFI): This is possible if the <code>include()</code> function is configured to allow the inclusion of remote files (files located on a different server). An attacker can use this to include malicious files from a remote server, leading to various attacks such as code execution, data theft, or server compromise.</li> </ol> <p>A basic example may be:</p> <pre><code>// This will include 'header.php' in the current file.\ninclude('header.php');\n\n// Rest of the page content goes here\n\n// This will include 'footer.php' in the current file.\ninclude('footer.php');\n</code></pre> <p>Whereas a vulnerable example may be:</p> <pre><code>// A more secure approach using whitelisting\n$allowed_pages = ['home', 'contact', 'about'];\n$page = $_GET['page'];\n\nif (in_array($page, $allowed_pages)) {\n    include($page . '.php');\n} else {\n    echo 'Page not found.';\n}\n</code></pre> <p>Danger</p> <p>In this example, if a user can control the value of <code>$_GET['page']</code>, they might be able to include files like <code>config.php</code> by accessing the URL <code>http://example.com/?page=../config</code>.</p> <p>A more secure example may be:</p> <pre><code>// A more secure approach using whitelisting\n$allowed_pages = ['home', 'contact', 'about'];\n$page = $_GET['page'];\n\nif (in_array($page, $allowed_pages)) {\n    include($page . '.php');\n} else {\n    echo 'Page not found.';\n}\n</code></pre> <p>In this secure example, the <code>include()</code> only happens if the user input matches one of the predefined and allowed pages, significantly reducing the risk of LFI attacks.</p>"},{"location":"programming/innerh/","title":"DOM.innerHTML","text":"<p>DOM.innerHTML is a property in the Document Object Model (DOM) of web development that is used to get or set the HTML content of an element. It's a powerful feature that allows developers to dynamically manipulate web page content, but it also needs to be used with caution due to security implications.</p> <p>When innerHTML is used to get the content of an element, it returns all the HTML inside that element as a string. This includes tags, text, and other elements:</p> <pre><code>let content = document.getElementById(\"myDiv\").innerHTML;\n</code></pre> <p>Above, \"content\" will contain the HTML markup within the element with the ID \"myDiv\".</p> <p>When used to set the content of an element, innerHTML replaces the existing content of the element with the provided HTML string:</p> <pre><code>document.getElementById(\"myDiv\").innerHTML = \"&lt;p&gt;New content&lt;/p&gt;\";\n</code></pre> <p>This will replace whatever is inside myDiv with &lt;p&gt;New content&lt;/p&gt;.</p> <p>The primary security concern with innerHTML is its susceptibility to XSS attacks. If innerHTML is used to set content based on user input or other untrusted sources without proper sanitization, it can lead to the execution of malicious scripts.</p> <p>For example, if user-provided data is directly inserted using innerHTML, and that data contains a &lt;script&gt; tag with malicious JavaScript, the script will be executed when the HTML is rendered.</p>"},{"location":"programming/insertafter/","title":"insertAfter()","text":"<p>The jQuery insertAfter() function is used to insert elements after a specified target in the Document Object Model (DOM). This method is part of the jQuery library, which provides a rich set of tools for manipulating HTML documents.</p> <p>insertAfter() is used to insert specified elements or HTML content after a given target element within the DOM. The syntax is:</p> <pre><code>$(content).insertAfter(target)\n</code></pre> <ul> <li>content - the content or elements to be inserted, can be a string containing HTML, a jQuery object or a DOM element.</li> <li>target - the target element after which the content will be inserted, typically expressed as a jQuery selector.</li> </ul> <p>A usage example may be:</p> <pre><code>$('&lt;p&gt;New paragraph&lt;/p&gt;').insertAfter('#myDiv');\n</code></pre> <p>In this example, a new paragraph element (&lt;p&gt;New paragraph&lt;/p&gt;) is inserted after the element with the ID myDiv.</p> <p>If insertAfter() is used to insert content that includes user-supplied data, there is a risk of [[Cross-Site Scripting]] attacks. This can happen if the data is not properly sanitized or escaped before being inserted into the DOM. </p> <p>For example, if an attacker is able to inject a &lt;script&gt; tag into the content being inserted, they could execute malicious JavaScript on the client's browser. An example may be:</p> <pre><code>var userInput = \"&lt;script&gt;maliciousCode();&lt;/script&gt;\";\n$(userInput).insertAfter(\"#someElement\");\n</code></pre> <p>In this example, if userInput comes from an untrusted source and contains malicious scripts, it will lead to an XSS vulnerability.</p>"},{"location":"programming/insertbefore/","title":"insertBefore()","text":"<p>The jQuery insertBefore() function is used to insert elements before a specified target in the Document Object Model (DOM). This method is part of the jQuery library, which simplifies HTML document traversal, manipulation, event handling, and animation.</p> <p>insertBefore() moves the selected elements and inserts them before the specified target element(s) in the DOM. The syntax is:</p> <pre><code>$(content).insertBefore(target)\n</code></pre> <ul> <li>content - content or elements to be inserted, can be a string containing HTML, a jQuery object, or a DOM element</li> <li>target - target element before which the content will be inserted, typically expressed as a jQuery selector.</li> </ul> <p>A usage example may be:</p> <pre><code>$('&lt;p&gt;New Paragraph&lt;/p&gt;').insertBefore('#myDiv');\n</code></pre> <p>In this example, a new paragraph element (&lt;p&gt;New Paragraph&lt;/p&gt;) is inserted before the element with the ID myDiv.</p> <p>If insertBefore() is used to insert content derived from user input or external sources without proper sanitization, it can lead to Cross-Site Scripting vulnerabilities. For example, if an attacker can influence the content being inserted and includes malicious scripts, they can execute arbitrary JavaScript in the context of the user's browser.</p>"},{"location":"programming/inwrap/","title":"Input Wrapper","text":"<p>In PHP, the <code>php://input</code> stream allows you to read raw POST data. It is less memory intensive than <code>$HTTP_RAW_POST_DATA</code> and does not need any special <code>php.ini</code> directives. <code>php://input</code> is not available with <code>enctype=\"multipart/form-data\"</code>.</p> <p>It provides access to raw POST data, which is useful when you need to process the body of a POST request directly, such as with JSON or XML payloads. It's a read-only stream that can only be read once, as it does not support seek operations. However, as of PHP 5.6, it can be reopened and read multiple times.</p> <p>Unlike <code>$_POST</code>, which is affected by certain <code>php.ini</code> settings (like <code>post_max_size</code>), <code>php://input</code> allows access to the raw POST data without processing.</p> <p>The <code>php://input</code> stream is often used for reading JSON or XML POST data, which is common in REST APIs and web services:</p> <pre><code>&lt;?php\n// Example - Reading JSON POST data\n\n// Get the raw POST data\n$rawData = file_get_contents(\"php://input\");\n\n// Decode the JSON data\n$jsonData = json_decode($rawData);\n\n// Use the JSON data\nif ($jsonData) {\n    // Process the JSON data\n    echo \"Received: \" . print_r($jsonData, true);\n} else {\n    echo \"No valid JSON data received\";\n}\n?&gt;\n</code></pre> <p>Info</p> <p>In this example, <code>file_get_contents(\"php://input\")</code> is used to read the raw POST data. This is particularly useful for content types that are not automatically parsed by PHP, like JSON or XML.</p> <p><code>php://input</code> is an essential feature for modern PHP applications, particularly those that interact with APIs or rely on AJAX requests. It provides a more straightforward and efficient way of accessing raw POST data compared to older methods.</p> <p>The <code>php://input</code> stream itself in PHP is not inherently vulnerable. However, like any data input in web applications, its use can introduce security vulnerabilities if the data is not properly handled. The security risk primarily arises from how the input data is processed and used within the application, rather than from the <code>php://input</code> stream itself.</p> <p>If the data read from <code>php://input</code> is not properly sanitized, it can lead to various security issues like SQL Injection, Cross-Site Scripting (XSS), or XML External Entity (XXE) Injection, depending on how the data is used. Reading large amounts of data from <code>php://input</code> without proper size checks can lead to buffer overflow or resource exhaustion issues.</p> <p>Consider a PHP script that reads JSON data from <code>php://input</code> and uses it in a database query without proper validation or sanitization:</p> <pre><code>&lt;?php\n// Example of a potentially vulnerable use of php://input\n\n// Get the raw POST data\n$rawData = file_get_contents(\"php://input\");\n$data = json_decode($rawData, true);\n\n// Unsafe database query\n$query = \"SELECT * FROM users WHERE id = \" . $data['id'];\n$result = mysqli_query($connection, $query);\n?&gt;\n</code></pre> <p>In this example, if the <code>id</code> parameter from the input data is not properly sanitized, it could be exploited for SQL Injection attacks. An attacker could potentially manipulate the <code>id</code> parameter in the raw POST data to alter the SQL query, leading to unauthorized database access or manipulation.</p>"},{"location":"programming/ionce/","title":"include_once()","text":"<p>The <code>include_once()</code> function in PHP is similar to the include_once() function, but with a key difference: it checks if the specified file has already been included, and if so, it does not include it again. </p> <p>This behavior is particularly useful in situations where the same file might be included multiple times due to complex scripting or nested includes. By using <code>include_once()</code>, you can prevent issues like function redefinitions, variable redeclarations, and performance overhead from redundant inclusions.</p> <p>The syntax is:</p> <pre><code>include_once 'path/to/file.php';\n</code></pre> <p>If a file containing functions is included multiple times, PHP will generate an error because it does not allow function redefinitions. Using <code>include_once()</code> ensures that the file is included only once, avoiding such errors. It's common to use <code>include_once()</code> for including configuration files. Since these files usually set up environment variables, database connections, or other critical settings, they should not be included more than once.</p> <p>When dealing with object-oriented programming in PHP, <code>include_once()</code> is often used to include class definitions. This ensures that a class is not declared more than once, which would result in a fatal error.</p> <p>An example includes:</p> <pre><code>// Include a configuration file - it will only be included once, \n// even if this line appears multiple times in the script or in different scripts\n// that are included in the execution flow.\ninclude_once 'config.php';\n\n// Further code that might also include 'config.php' directly or indirectly\n</code></pre> <p>While <code>include_once()</code> and require_once() serve similar purposes, the key difference lies in their behavior when the specified file cannot be found or loaded:</p> <ul> <li><code>include_once()</code> will emit a warning (E_WARNING) and the script will continue to execute.</li> <li><code>require_once()</code> will emit a fatal error (E_COMPILE_ERROR) and halt script execution.</li> </ul> <p>The primary risks are similar to those with <code>include()</code>, notably Local File Inclusion (LFI) and Remote File Inclusion (RFI) vulnerabilities. However, the <code>include_once()</code> function's unique behavior does not inherently mitigate these risks.</p> <p>A vulnerable example may be:</p> <pre><code>&lt;?php\n// A vulnerable script where the file name is taken directly from user input\n$page = $_GET['page'];\n\n// Using include_once with user-controlled input\ninclude_once($page . '.php');\n?&gt;\n</code></pre> <p>Danger</p> <p>In this script, the <code>$page</code> variable is directly taken from the user input (<code>$_GET['page']</code>). An attacker could manipulate the URL to include files that are not intended to be accessible. For example, if the script is located at <code>http://example.com/script.php</code>, an attacker could access the following URL to potentially include sensitive files:</p> <pre><code>http://example.com/script.php?page=../../etc/passwd\n</code></pre> <p>This URL attempts to traverse the directory structure (using <code>../</code> for going up a directory) and include the Unix/Linux system file <code>/etc/passwd</code>, which contains user information and could be sensitive.</p> <p>An example of safe implementation includes:</p> <pre><code>$allowed_pages = ['home', 'contact', 'about'];\n$page = $_GET['page'];\n\nif (in_array($page, $allowed_pages)) {\n    include_once($page . '.php');\n} else {\n    echo 'Page not found.';\n}\n</code></pre> <p>Success</p> <p>In this example, even though <code>include_once()</code> is used, the script ensures that only files from a predefined list are included, thus significantly reducing the risk of LFI attacks.</p>"},{"location":"programming/java/","title":"Java","text":"<p>Java is a widely-used programming language for coding web applications. It has been a popular choice among developers for over two decades, with millions of Java applications in use today. </p> <p>Java is a multi-platform, object-oriented, and network-centric language that can be used as a platform in itself. It is a fast, secure, reliable programming language for coding everything from mobile apps and enterprise software to big data applications and server-side technologies.</p> <p>Java is a very popular programming language you can use to create a variety of software applications. It's an object-oriented language that was made to be simple to read, write, and learn.</p>"},{"location":"programming/javame/","title":"Java ME (Micro Edition)","text":"<p>Java ME (Micro Edition) is a subset of the Java programming language specifically designed for embedded systems and consumer devices such as mobile phones, PDAs (Personal Digital Assistants), TV set-top boxes, and printers. </p> <p>Java ME provides a robust, flexible environment for applications running on embedded and mobile devices, with limited resources such as processing power and memory.</p> <p>Java ME is optimized for devices with limited processing power, storage, and memory. It's a lightweight platform compared to Java SE (Standard Edition) and Java EE (Enterprise Edition).</p> <p>Java ME is composed of configurations, profiles, and optional packages. Configurations (like CLDC - Connected Limited Device Configuration) provide a basic set of libraries and VM capabilities. Profiles (like MIDP - Mobile Information Device Profile) are built on configurations and add more specific functionalities.</p> <p>Java ME was historically popular for mobile application development before the rise of smartphones and platforms like Android and iOS. It was used to develop applications (MIDlets) for feature phones. Applications written for Java ME are called MIDlets. They are packaged in JAR files and use the Java Application Descriptor (JAD) files to describe the MIDlet\u2019s properties.</p> <p>Java ME runs on a scaled-down version of the JVM, which is tailored for devices with limited resources. It includes an API for user interface development, which, while less sophisticated than typical desktop APIs, is designed for the constraints of mobile devices. Java ME supports both networked applications and applications that can run offline.</p> <p>Like other Java platforms, Java ME applications are written once and can run on any device that supports the Java ME platform, though specific device capabilities and limitations must be considered. With the advent of modern smartphone platforms like Android and iOS, the popularity of Java ME has significantly declined for mobile application development.</p>"},{"location":"programming/jquery/","title":"jQuery","text":"<p>jQuery is a fast and concise JavaScript library that simplifies HTML document traversing, event handling, animating, and Ajax interactions for rapid web development. In simpler terms, jQuery is a collection of JS code that you can use in websites.</p> <p>jQuery allows easy finding and changing of elements in the HTML document. It also makes it easier to handle user actions like clicks, mouse movements, key presses and so on.</p> <p>jQuery also includes built-in effects and animations, allowing developers to add visual interest to the web page. It also simplifies the process of sending and receiving data asynchronously without interfering with the display and behaviour of the existing page.</p> <p>Finally, jQuery can handle a lot of the headaches in cross-browser capability. It smooths over the differences in how different browsers respond to JavaScript code, so you do not have to write different code for different browsers.</p>"},{"location":"programming/js/","title":"JavaScript","text":"<p>JavaScript is a dynamic programming language commonly used in websites. It was originally used to make web pages more interactive but is now a core technology of the World Wide Web. It enables you to create dynamically updating content, control multimedia, animate images, and pretty much everything else. It adds a bunch of features including:</p> <ul> <li>Client-Side Scripting - started as a way to add interactivity to web pages, things like button clicks, updating content dynamically, animating page elements and more.</li> <li>Server-Side Deployment - JS expanded into server-side allowing developers to build entire web apps using just JS.</li> <li>Event-Driven and Asynchronous - it can respond to events like mouse clicks or key presses. It also supports asynchronous operations enabling tasks like fetching data from a server without reloading the entire page.</li> <li>Dynamic - dynamically typed language, which means variable types are determined at runtime. This makes it flexible but also requires careful programming to avoid type-related bugs.</li> <li>Frameworks/Libraries - numerous JavaScript frameworks and libraries that provide pre-written JavaScript code to help developers build applications quickly and efficiently.</li> </ul>"},{"location":"programming/libx/","title":"libxml_disable_entity_loader","text":"<p>libxml_disable_entity_loader is a function in PHP used to disable the ability to load external entities in libxml, which is the library PHP uses for parsing XML. This function is particularly relevant for preventing XML External Entities (XXE) attacks in PHP applications.</p> <p>The main purpose of <code>libxml_disable_entity_loader</code> is to prevent libxml from loading external entities, which is a common attack vector in XXE attacks. By default, libxml in PHP may load external entities specified in an XML document, which can lead to security vulnerabilities.</p> <p>A basic example of using it may be:</p> <pre><code>// Disable the ability to load external entities\nlibxml_disable_entity_loader(true);\n\n// Load an XML document (without loading any external entities)\n$xml = simplexml_load_string($xmlString);\n\n// Re-enable the ability to load external entities if needed\nlibxml_disable_entity_loader(false);\n</code></pre> <p>Before loading an XML string with <code>simplexml_load_string</code>, the loading of external entities is disabled to prevent XXE attacks.</p> <p>When <code>libxml_disable_entity_loader</code> is set to <code>true</code>, it effectively mitigates the risk of XXE attacks, which can lead to information disclosure, data exfiltration, or server-side request forgery. In PHP 8.0 and newer, <code>libxml_disable_entity_loader</code> has been deprecated, as it no longer affects libxml's entity loader behavior, which is now safe by default. In PHP 7.3 and earlier, where the function isn\u2019t deprecated, it's crucial to use it to secure XML processing.</p> <p>While <code>libxml_disable_entity_loader</code> helps secure XML processing against XXE attacks, it's also important to ensure that all user-supplied XML data is properly validated and sanitized.</p>"},{"location":"programming/libxslt/","title":"LibXSLT","text":"<p>Libxslt is the C library for XSLT (Extensible Stylesheet Language Transformations) processing developed by the GNOME project. It is part of the larger libxml2 library, which is a widely-used Extensible Markup Language C parser and toolkit. Libxslt provides functionality for applying XSLT stylesheets to XML documents, transforming them into different structures or formats.</p> <p>Libxslt allows developers to perform XSLT transformations on XML documents using XSLT stylesheets. XSLT is a language for defining the transformation rules to convert one XML document into another.</p> <p>Libxslt includes an implementation of XPath, which is used within XSLT stylesheets to navigate and query XML documents. XPath is a powerful language for addressing parts of an XML document. Libxslt adheres to the XSLT 1.0 and XPath 1.0 specifications, making it suitable for processing documents that conform to these standards.</p> <p>Libxslt is designed to be portable and can be compiled and run on various platforms, including Unix-like systems, Windows, and others. Libxslt provides mechanisms for incorporating custom extensions into XSLT stylesheets, allowing developers to extend the functionality of the transformation process.</p> <p>The library is optimized for performance, and it supports features like streaming and incremental processing to efficiently handle large XML documents. Libxslt is often used in conjunction with the libxml2 library, which provides XML parsing and manipulation capabilities. Together, they form a powerful toolkit for working with XML and XSLT in C-based applications.</p>"},{"location":"programming/loadl/","title":"LoadLibrary","text":"<p><code>LoadLibrary</code> is a function in the Windows API that loads a Dynamic Link Library (DLL) into the calling process's address space. The function is widely used in legitimate software development to dynamically load libraries at runtime. However, in the context of hacking and DLL Hijacking(), <code>LoadLibrary</code> can be exploited for malicious purposes.</p> <p>In a DLL injection attack, <code>LoadLibrary</code> is used to load a malicious DLL into a target process's memory. This is often achieved by first allocating memory in the target process (using functions like <code>VirtualAllocEx</code>) and then writing the path of the malicious DLL into this allocated space. </p> <p>A remote thread is created within the target process using <code>CreateRemoteThread</code>, with <code>LoadLibrary</code> as the start routine, pointing to the memory location where the DLL path is written. This causes the target process to load and execute the malicious DLL.</p> <p>As an example, an attacker injects a DLL into a process running with higher privileges. The DLL is loaded using <code>LoadLibrary</code>, granting the attacker the same privileges as the target process.</p> <p>If an application does not specify a full path for a required DLL, Windows searches for the DLL in a predefined set of directories. An attacker can place a malicious DLL with the same name as the expected DLL in one of these directories. When the application uses <code>LoadLibrary</code> to load the DLL, it inadvertently loads the attacker's malicious DLL.</p> <p>As an example, a legitimate application attempts to load a commonly used DLL, but due to the search order, it ends up loading a malicious DLL placed by the attacker in a directory that is searched before the legitimate one.</p>"},{"location":"programming/location/","title":"window.location()","text":"<p><code>window.location</code> in JavaScript is an object that contains information about the current URL and provides methods to change it. It's part of the <code>window</code> object, which represents the browser window or tab.</p> <p>The <code>window.location</code> object includes properties like <code>href</code> (the full URL), <code>hostname</code> (domain name), <code>pathname</code> (the path after the domain name), <code>protocol</code> (such as 'http:' or 'https:'), and <code>search</code> (the query string).</p> <p>You can also use <code>window.location</code> to redirect the user to another page by setting <code>window.location.href</code> to a new URL. For instance, <code>window.location.href = 'https://www.example.com'</code> would redirect the user to 'https://www.example.com'. This object is widely used in web development for tasks related to navigation and URL manipulation.</p>"},{"location":"programming/mcrypt/","title":"Mcrypt","text":"<p>Mcrypt is a library for encrypting and decrypting data, which was previously a popular choice in many PHP applications. It provided a range of encryption algorithms and modes, allowing developers to implement data encryption in their projects. However, it's important to note the current status and historical context of Mcrypt in PHP and general cryptographic practices.</p> <p>Mcrypt supported a variety of encryption algorithms, including DES, TripleDES, Blowfish, Twofish, and RIJNDAEL (which is the basis for AES). It offered several modes of operation for encryption, such as CBC (Cipher Block Chaining), CFB (Cipher Feedback), and OFB (Output Feedback). Mcrypt functions were straightforward to use, offering a procedural interface for encryption and decryption tasks.</p> <p>Mcrypt was widely used in PHP applications for many years due to its ease of use and the wide range of algorithms it supported. As of PHP 7.1, Mcrypt was deprecated, and it was removed entirely in PHP 7.2. This decision was made due to several factors:</p> <ul> <li>The library had not been actively maintained for years.</li> <li>Newer, more robust, and actively maintained cryptographic libraries like OpenSSL and Sodium (included in PHP 7.2 and later) became available.</li> <li>Concerns about the security and modern cryptographic standards of Mcrypt.</li> </ul> <p>Due to its deprecation and removal, Mcrypt should not be used in new PHP projects. Instead, it's recommended to use modern and actively supported libraries like OpenSSL or Sodium. For legacy projects that still use Mcrypt, it's advisable to plan for migration to a more current and supported encryption library.</p> <p>An example of its use:</p> <pre><code>$key = 'your-secret-key';\n$input = 'Sensitive data';\n\n$td = mcrypt_module_open('rijndael-256', '', 'cbc', '');\n$iv = mcrypt_create_iv(mcrypt_enc_get_iv_size($td), MCRYPT_RAND);\nmcrypt_generic_init($td, $key, $iv);\n\n$encrypted_data = mcrypt_generic($td, $input);\nmcrypt_generic_deinit($td);\nmcrypt_module_close($td);\n</code></pre>"},{"location":"programming/mres/","title":"mysqli_real_escape_string()","text":"<p>The mysqli_real_escape_string() function is a part of the MySQLi (\"MySQL Improved\") extension in PHP. This function is used to escape special characters in a string for use in an SQL query, considering the current character set of the connection. </p> <p>The primary purpose of this function is to prevent SQL injection attacks, which can occur when unescaped special characters in SQL statements are interpreted as command parts.</p> <p>It escapes certain characters like single quotes (<code>'</code>), double quotes (<code>\"</code>), backslash (<code>\\</code>), and NULL (the NULL byte), among others. This is important because these characters can be used maliciously in SQL commands by attackers.</p> <p>The function is aware of the character set used by the MySQL connection, ensuring that the escaping is done correctly according to the specific encoding. To use this function, you first need to establish a connection to a MySQL database using MySQLi. The mysqli_real_escape_string() function then takes two arguments: the MySQLi database connection and the string to be escaped.</p> <p>An example is:</p> <pre><code>$connection = mysqli_connect(\"localhost\", \"username\", \"password\", \"database\");\n$unsafe_variable = $_POST['user_input'];\n$safe_variable = mysqli_real_escape_string($connection, $unsafe_variable);\n$sql = \"SELECT * FROM table WHERE column = '$safe_variable'\";\n</code></pre>"},{"location":"programming/mtrand/","title":"mt_rand()","text":"<p>The <code>mt_rand()</code> function in PHP is a pseudorandom number generator (PRNG) based on the Mersenne Twister algorithm. It is used to generate seemingly random numbers more efficiently and with a better statistical distribution than the older <code>rand()</code> function. </p> <p>However, despite these improvements, <code>mt_rand()</code> is not suitable for cryptographic purposes due to its predictability under certain conditions.</p> <p>The main issue with <code>mt_rand()</code> is that it is deterministic. This means if an attacker knows or can guess the state of the PRNG (which is set by the seed), they can predict future outputs. The Mersenne Twister algorithm, while excellent for simulations and general-purpose random number generation, reveals its internal state after observing a relatively small number of outputs.</p> <p>Given its predictability, <code>mt_rand()</code> should not be used for cryptographic purposes, such as generating tokens, cryptographic keys, or passwords. An attacker with some knowledge of the generated values and the algorithm could potentially predict or reproduce other values, leading to security vulnerabilities.</p> <p>The level of entropy (randomness) is not sufficient for security-critical applications. The seeding mechanism of <code>mt_rand()</code>, especially in older PHP versions, could be relatively weak, further exacerbating the predictability issue.</p> <p>For applications where security is a concern, particularly those involving cryptography, it is recommended to use more secure random number generation functions that are designed for cryptographic purposes, such as:</p> <ul> <li><code>random_int()</code>: Generates cryptographically secure pseudo-random integers.</li> <li><code>random_bytes()</code>: Generates cryptographically secure pseudo-random bytes, useful for creating tokens or salts.</li> </ul>"},{"location":"programming/mysqli/","title":"MySQL Improved","text":"<p>The MySQL Improved (MySQLi) extension is a relational database driver used in the PHP programming language to provide an interface with MySQL databases. It is specifically designed to work with MySQL versions 4.1 and above. </p> <p>The MySQLi extension offers various benefits and improvements over the older PHP MySQL extension, making it a better choice for new applications and development.</p> <p>In addition to the standard procedural interface, MySQLi provides an object-oriented interface. This allows for more sophisticated, robust, and object-oriented database interactions. MySQLi supports prepared statements, which provide a more secure way to execute SQL queries. Prepared statements prevent SQL injection attacks by separating SQL logic from the data being inputted.</p> <p>MySQLi allows the execution of multiple SQL statements in a single function call, which can enhance performance by reducing the amount of round-trip communication between the PHP application and the MySQL server.</p> <p>To use MySQLi, you must have PHP and MySQL installed on your server. The MySQLi extension is enabled by default on most PHP installations since PHP 5.0. A simple example is:</p> <pre><code>$mysqli = new mysqli(\"localhost\", \"username\", \"password\", \"database\");\n\nif ($mysqli-&gt;connect_error) {\n    die(\"Connection failed: \" . $mysqli-&gt;connect_error);\n}\n\n$result = $mysqli-&gt;query(\"SELECT * FROM table\");\nwhile($row = $result-&gt;fetch_assoc()) {\n    echo $row[\"column1\"]. \" - \" . $row[\"column2\"]. \"&lt;br&gt;\";\n}\n\n$mysqli-&gt;close();\n</code></pre>"},{"location":"programming/objectc/","title":"Objective C","text":"<p>Objective-C is a programming language primarily used for developing software for Apple's macOS and iOS operating systems. It was developed in the 1980s and combines C language efficiency with the object-oriented capabilities of Smalltalk. Before the introduction of Swift by Apple in 2014, Objective-C was the primary language used for developing applications in the Apple ecosystem.</p> <p>Objective-C is an object-oriented language, which means it allows developers to define classes, create objects, and implement inheritance, encapsulation, and Polymorphism. As a superset of C, Objective-C includes all functionalities of C and adds object-oriented features. This means any valid C code is also valid in Objective-C.</p> <p>The language supports dynamic typing, allowing the type of an object to be determined at runtime, which can enhance flexibility and extensibility. One of the unique aspects of Objective-C is its use of message passing for invoking methods, which is different from function calling in traditional C.</p> <p>Before the introduction of Automatic Reference Counting (ARC), Objective-C used a manual reference counting system, but it now largely automates memory management.</p> <p>Objective-C was the main language used for developing applications for Apple's desktop and mobile operating systems until the introduction of Swift. These are key Apple frameworks for macOS and iOS development, respectively, and were traditionally based on Objective-C.</p> <p>An example:</p> <pre><code>#import &lt;Foundation/Foundation.h&gt;\n\n@interface MyClass : NSObject\n- (void)myMethod;\n@end\n\n@implementation MyClass\n- (void)myMethod {\n    NSLog(@\"Hello, World!\");\n}\n@end\n\nint main() {\n    MyClass *myObject = [[MyClass alloc] init];\n    [myObject myMethod];\n    return 0;\n}\n</code></pre> <p>Info</p> <p>This simple example demonstrates a class definition, method implementation, and object creation in Objective-C.</p>"},{"location":"programming/ohtml/","title":"DOM.outerHTML","text":"<p>DOM.outerHTML is a property in the Document Object Model (DOM) of HTML and XML documents that represents the serialized HTML or XML source of the element, including the element itself.</p> <p>This property is used in web development to get or set the markup of the element and all its children.</p> <p>When used to get the content, outerHTML returns a string containing the markup of the element, including its opening and closing tags, attributes, and all its child elements.</p> <p>For example, if you have an element defined as:</p> <pre><code>&lt;div id=\"example\"&gt;\n  \\\n  &lt;p&gt;Hello\\&lt;/p&gt;\n&lt;/div&gt;\n</code></pre> <p>Using outerHTML on this element would return the entire string:</p> <pre><code>&lt;div id=\"example\"&gt;\n  \\\n  &lt;p&gt;Hello\\&lt;/p&gt;\n&lt;/div&gt;\n</code></pre> <p>When outerHTML is used to set the content of an element, it replaces the entire element (including itself) with the new content provided:</p> <pre><code>document.getElementById(\"example\").outerHTML = \"&lt;span&gt;New content&lt;/span&gt;\";\n</code></pre> <p>This would replace the entire &lt;div id=\"example\"&gt; element with &lt;span&gt;New content&lt;/span&gt;.</p> <p>In comparison with DOM.innerHTML which gets or sets the HTML or XML markup contained within the element excluding the element itself, DOM.outerHTML gets or sets the HTML or XML markup of the element including the element itself.</p> <p>When setting outerHTML with user-supplied data, there's a risk of Cross-Site Scripting (XSS) if the data isn't properly sanitized. It's crucial to ensure that any dynamic content inserted through outerHTML is safe and free from malicious scripts.</p>"},{"location":"programming/oop/","title":"Object-Oriented Programming","text":"<p>Object-oriented programming (OOP) is a programming paradigm based on the concept of \"objects,\" which can contain data and code: data in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods). OOP is a fundamental concept in modern software development, offering a structured approach to designing and building applications.</p> <p>In OOP, objects are instances of classes, which define the properties and behaviors that the objects can have. Classes serve as blueprints for creating objects.</p> <p>This principle involves bundling the data (attributes) and the methods (functions or procedures) that operate on the data into a single unit (class). It also involves restricting direct access to some of an object's components, which is a means of preventing accidental interference and misuse of the methods and data.</p> <p>OOP allows for the creation of complex systems where the specific details are hidden and only the necessary aspects are presented. This simplifies programming and increases efficiency.</p> <p>Classes can inherit properties and methods from other classes. A class that inherits from another class is typically called a subclass or derived class, and the class it inherits from is called the superclass or base class. Inheritance promotes code reuse and can lead to an efficient hierarchical structuring of code.</p> <p>Polymorphism allows objects of different classes to be treated as objects of a common super class. The most common use of polymorphism is when a parent class reference is used to refer to a child class object.</p> <p>OOP inherently promotes modularity, where applications can be broken down into smaller, manageable, and modular components (classes), which can be developed, tested, and maintained more easily.</p> <p>Thanks to inheritance and polymorphism, OOP enables code reusability, which reduces redundancy and increases the efficiency of the development process.</p> <p>Many modern programming languages support OOP principles, including Java, C#, C++, Python, Ruby, and PHP.</p> <p>Some examples include classes:</p> <pre><code>class Car:\n    def __init__(self, make, model):\n        self.make = make\n        self.model = model\n</code></pre> <p>Think of a class as a blueprint for a house. It defines the structure and capabilities, but is not a house itself.</p> <p>Objects are also used:</p> <pre><code>my_car = Car(\"Toyota\", \"Corolla\")\n</code></pre> <p>An object is a specific instance of a class. Using the house analogy, if a class is the blueprint, an object is a house built from that blueprint. </p> <p>The next concept is Inheritance:</p> <pre><code>class ElectricCar(Car):  # Inherits from Car class\n    def __init__(self, make, model, battery_capacity):\n        super().__init__(make, model)\n        self.battery_capacity = battery_capacity\n</code></pre> <p>Inheritance allows a new class to extend an existing class. The new class inherits the attributes and methods of the existing class. As above, ElectricCar is now a type of \"Car\" but with additional attributes and potentially new methods specific to electric cars.</p> <p>Polymorphism allows methods to do different things based on the object it is acting upon:</p> <pre><code>class Animal:\n    def speak(self):\n        pass\n\nclass Dog(Animal):\n    def speak(self):\n        return \"Woof!\"\n\nclass Cat(Animal):\n    def speak(self):\n        return \"Meow!\"\n</code></pre> <p>Both \"Dog\" and \"Cat\" override the \"speak\" method from \"Animal\" providing their unique implementations.</p> <p>Finally, encapsulation involves bundling of data (attributes) and methods that operate on the data into a single unit or class and restricting access to some of the object's components:</p> <pre><code>class BankAccount:\n    def __init__(self):\n        self.__balance = 0  # Private attribute\n\n    def deposit(self, amount):\n        if amount &gt; 0:\n            self.__balance += amount\n\n    def get_balance(self):\n        return self.__balance\n</code></pre> <p>Here, __balance is a private attribute. It can't be accessed directly from outside the class, thus encapsulating and protecting it from unintended interference.</p>"},{"location":"programming/orp/","title":"Object-Relational Mapping","text":"<p>Object-Relational Mapping (ORM) is a programming technique used for converting data between incompatible type systems in object-oriented programming languages. It's a common approach in software development that allows developers to manipulate database data as objects, making it easier to write database-agnostic code.</p> <p>In ORM, classes in your application (often representing entities) are mapped to database tables, and instances of those classes (objects) are tied to rows in those tables. This mapping abstracts the underlying database structure.</p> <p>ORM provides a high-level abstraction over relational database operations. Developers can interact with databases using their native programming language rather than SQL, reducing the need for database-specific SQL queries.</p> <p>Most modern programming languages like Java, Python, C#, PHP, Ruby, and others have popular ORM frameworks. ORM facilitates CRUD (Create, Read, Update, Delete) operations on the database by providing methods to easily handle these tasks without manually writing SQL queries.</p> <p>Many ORM tools allow for a level of database independence, meaning the same code can be used with different database systems (like MySQL, PostgreSQL, SQL Server, etc.) with minimal or no changes.</p> <p>ORM can significantly reduce the amount of boilerplate code required to interact with a database, speeding up development and potentially reducing errors. While ORMs allow for working with data as objects, they also usually provide a way to write complex queries, often through a Query Language or Builder, which is then translated to SQL.</p> <p>While ORMs add convenience, they can sometimes lead to less efficient database queries compared to finely-tuned SQL, especially in complex scenarios. This is sometimes referred to as the \"Object-Relational Impedance Mismatch\".</p>"},{"location":"programming/parse/","title":"parseHTML()","text":"<p>The jQuery parseHTML() function is used to parse a string of HTML into an array of DOM nodes. This function is particularly useful when you need to manipulate or examine HTML content provided as a string before inserting it into the document.</p> <p>parseHTML() takes a string of HTML and parses it into a collection of DOM nodes. This allows you to manipulate the nodes using jQuery methods before they are inserted into the DOM.</p> <p>The syntax is:</p> <pre><code>$.parseHTML(htmlString, context, keepScripts)\n</code></pre> <ul> <li>htmlString - HTML string to be parsed</li> <li>context - document in which the nodes will be created. Defaults to current document</li> <li>keepScripts - a boolean indicating whether to include script elements in the parsed HTML string. By default set to false to prevent script execution.</li> </ul> <p>An example usage:</p> <pre><code>var htmlString = \"&lt;div&gt;&lt;p&gt;Hello World&lt;/p&gt;&lt;/div&gt;\";\nvar htmlNodes = $.parseHTML(htmlString);\n$(\"#someContainer\").append(htmlNodes);\n</code></pre> <p>This example parses the htmlString into DOM nodes and appends them to an element with the ID someContainer.</p> <p>Since parseHTML() does not execute scripts by default, it provides a safer way to handle HTML strings that might contain &lt;script&gt; tags, helping to mitigate Cross-Site Scripting (XSS) vulnerabilities.</p> <p>Even though parseHTML() does not execute scripts by default, you should still sanitize the input HTML string to prevent XSS attacks, especially if the HTML is from an untrusted source.</p>"},{"location":"programming/passhash/","title":"password_hash()","text":"<p>The <code>password_hash()</code> function in PHP is a built-in function designed for creating a secure hash of a password. It is an important tool in PHP for implementing user authentication systems in a secure manner. This function simplifies the process of securely hashing passwords, which is crucial for protecting user passwords against unauthorized access, particularly in the event of a data breach.</p> <p>By default, <code>password_hash()</code> uses the BCrypt algorithm, which is currently considered a strong option for password hashing. It automatically handles tasks like generating and applying a salt (a random string added to the password before hashing to prevent rainbow table attacks).</p> <p>The function allows you to specify a cost factor, which determines how computationally expensive the hash operation is. A higher cost factor makes the hashing process slower, which helps to protect against brute-force attacks.</p> <p>The resulting hash includes information about the algorithm used, the cost factor, and the salt. This self-contained format makes it easy to store and verify passwords. An example of using it is:</p> <pre><code>$password = \"user_password\";\n$hash = password_hash($password, PASSWORD_BCRYPT);\n// Store $hash in the database\n</code></pre> <p>When storing user passwords, you would save the hash generated by <code>password_hash()</code>, not the plain password.</p> <p>The use of bcrypt and a cost factor increases the difficulty of brute-force attacks, as each password guess would require significant computational time. Automatic salting prevents the effective use of precomputed rainbow tables for password cracking.</p> <p>As security standards evolve, functions like <code>password_hash()</code> are updated in newer versions of PHP, helping developers adhere to current best practices with minimal effort. <code>password_hash()</code> abstracts the complexities of secure password storage, reducing the likelihood of implementation errors that could compromise security.</p>"},{"location":"programming/passthru/","title":"passthru","text":"<p>The <code>passthru</code> function in PHP is used to execute an external program and display raw output. It's one of the several PHP functions that allow for running system commands, similar to exec and shell_exec, but with some differences in behavior and output handling.</p> <p><code>passthru</code> is specifically used when you want to execute a system command that outputs binary data or needs to pass the output directly back to the browser. Unlike <code>exec</code>, which collects the command output and allows you to process it within PHP, <code>passthru</code> sends the output directly to the browser. This makes it suitable for executing commands that produce binary output, like displaying an image or a PDF file.</p> <p>Like other command execution functions, <code>passthru</code> is vulnerable to command injection attacks. If user-supplied input is incorporated into the command without proper sanitization, it can lead to severe security vulnerabilities.</p> <p>Since <code>passthru</code> sends output directly to the browser, there is a risk of exposing sensitive information if not carefully handled. A typical use of <code>passthru</code> might be to execute system commands for tasks that require real-time output to be sent to the client, such as streaming video or audio data.</p> <p>PHP offers other functions for executing external programs, such as exec, shell_exec, and system, each with specific use cases and output handling characteristics.</p>"},{"location":"programming/passver/","title":"password_verify()","text":"<p><code>password_verify()</code> is a PHP function used to verify that a provided password matches a previously hashed password. It's a crucial component in securely implementing user authentication systems. </p> <p>When a user's password is hashed and stored (typically during registration or password change processes), <code>password_verify()</code> allows you to compare the entered password during login with the stored hash.</p> <p>The function takes two parameters: the plain-text password provided by the user and the hashed password stored in the database. It hashes the provided password using the same algorithm, salt, and cost factor that were used to create the original hash and then checks if this newly generated hash matches the stored one.</p> <p>The function automatically identifies the hashing algorithm and salt used in the stored hash (as this information is part of the hash format generated by password_verify(), so there's no need for additional configuration.</p> <p>An example of using it may be:</p> <pre><code>// User-provided password\n$password = 'user_password';\n\n// Hashed password retrieved from the database\n$hashedPassword = '$2y$10$eCR3...'; // A hashed password\n\n// Verifying the password\nif (password_verify($password, $hashedPassword)) {\n    echo 'Password is valid!';\n} else {\n    echo 'Invalid password.';\n}\n</code></pre> <p><code>password_verify()</code> is crucial for securely checking user passwords. Storing passwords in plain text or even in a poorly hashed format can be a significant security risk. <code>password_verify()</code> works in tandem with <code>password_hash()</code> to ensure that passwords are stored and verified securely.</p> <p>The function is designed to be timing-attack safe, meaning that it takes the same amount of time to process regardless of how much of the input matches the stored hash. This prevents attackers from using timing information to guess the password.</p> <p>It abstracts the complexities of secure password verification, making it easier for developers to follow best practices without having to be experts in cryptographic functions.</p>"},{"location":"programming/perl/","title":"Perl","text":"<p>PERL is a high-level, general-purpose, interpreted and dynamic programming language. It comes in multiple versions to support different platforms and has been used by many developers to automate most things as per their industry needs.</p> <p>It provides an amazing range of text processing features, some of them include \u2014 text extraction of any size file while getting the best level of performance, having no arbitrary data length restrictions and provides hassle-free manipulation.  </p> <p>In parallel to other languages, PERL is the most used Common Gateway Interface (CGI) scripting. The CGI scripts are programs that are written specifically for web applications. It is used as a popular web server logic as it allows users to complete a request, response lifecycle over the World Wide Web effectively. </p> <p>The ccript also allows reading a request and sending a file back to the browser. Every web container has a directory Structure that contains website files. </p> <p>For example, when you type in a URL with a \u201c/index.html\u201d at the end of it, the server sends back the file marked \u201c. index.html.\u201d, but with CGI scripts, when a server receives a request for something more dynamic than just a pre-written page, it actually executes the request via the CGI script and returns the output to the browser. </p> <p>CGI programming makes servers more than file directories - they\u2019re adaptable as well as very smart file processors.</p>"},{"location":"programming/pharwrap/","title":"Phar Wrapper","text":"<p>The <code>phar://</code> wrapper in PHP is a stream wrapper that allows PHP's file handling functions to interact with PHP Archive (PHAR) files. PHAR is a format used for packaging a complete PHP application or library into a single file. This format is similar to JAR in Java and enables easy distribution and installation of PHP applications.</p> <p>The <code>phar://</code> wrapper allows direct access to the files contained within a PHAR archive, similar to accessing files in a file system. PHP scripts can read from and write to files inside a PHAR archive using standard file functions, provided that the PHAR is not read-only.</p> <p>PHAR files can be executed directly by the PHP interpreter, making them useful for distributing complete applications. PHAR archives encapsulate PHP code and resources, providing an isolated environment that reduces conflicts between different applications or libraries.</p> <p>A usage example may be:</p> <pre><code>// Reading a file from a PHAR archive\n$file = fopen('phar://myapp.phar/internal/path/to/file.php', 'r');\n$content = fread($file, filesize('phar://myapp.phar/internal/path/to/file.php'));\nfclose($file);\necho $content;\n</code></pre> <p>Info</p> <p>A file within a PHAR archive (<code>myapp.phar</code>) is being accessed, read, and its content is displayed. The internal path (<code>internal/path/to/file.php</code>) refers to the file's location within the PHAR archive.</p> <p>PHAR files can contain executable PHP code, so there are security implications to consider:</p> <ul> <li>Disabling PHAR Execution: In some security-sensitive environments, executing PHAR files is disabled to prevent potential exploitation of vulnerabilities in the PHAR handling code.</li> <li>User Uploads: If a PHP application allows users to upload PHAR files, it should implement rigorous validation and sanitation to prevent code injection attacks.</li> </ul> <p>PHAR files are particularly useful for distributing PHP libraries or applications as single files, simplifying deployment and usage. They are commonly used for command-line tools and applications that need to be easily portable without complex installation processes.</p>"},{"location":"programming/php/","title":"PHP","text":"<p>PHP is an open-source, server-side programming language that can be used to create websites, applications, customer relationship management systems and more. It is a widely-used general-purpose language that can be embedded into\u00a0HTML. </p> <p>This functionality with HTML means that the PHP language has remained popular with developers as it helps to simplify HTML code.</p> <p>PHP programming can be used to create most things that a software developer needs. However, there are three main areas in which it thrives.</p> <ol> <li>Server-side scripting - Server-side Script is PHP\u2019s main strength. If you are just learning to code and want to explore server-side scripting, PHP is a great language to learn. To get cracking with PHP server-side scripting you\u2019ll need to have a PHP parser, web server and web browser.</li> <li>Command-line scripting - Command-line scripting is ideal for scripts made using cron (Linux) or Task Scheduler (Windows). It is also great for simple text processing.</li> <li>Writing desktop applications - PHP is probably not the best language to use to create desktop applications but for the advanced web developer, it provides you with many more options than its competitors.</li> </ol> <p>Of course, PHP can do many other things. For example, it is excellent at collecting form data, encrypting user data and sending and receiving cookies. One of the major features of PHP that makes it so usable is that it is compatible with all major operating systems so you can code no matter what tech you are using.</p>"},{"location":"programming/phpfilters/","title":"PHP Filters","text":"<p>PHP Filters are a feature in PHP used to validate and sanitize external input. This feature is essential for securing PHP applications by ensuring that input data is safe before using it. PHP Filters are especially useful in preventing security vulnerabilities like SQL injection, cross-site scripting (XSS), and other common input-related attacks.</p> <p>The types of filters include:</p> <ol> <li>Validation Filters: These filters are used to validate input data. They check if the data meets certain criteria (like being a valid email address, an integer, a boolean, etc.) but don't modify the data itself. Examples include <code>FILTER_VALIDATE_EMAIL</code>, <code>FILTER_VALIDATE_INT</code>, <code>FILTER_VALIDATE_URL</code>, etc.</li> <li>Sanitization Filters: These filters are used to sanitize input data, which means they clean or modify the data to ensure there's nothing harmful (like stripping out HTML tags or encoding special characters). Examples include <code>FILTER_SANITIZE_STRING</code>, <code>FILTER_SANITIZE_EMAIL</code>, <code>FILTER_SANITIZE_URL</code>, etc.</li> <li>Other Filters: PHP also provides other filters for specialized purposes, like <code>FILTER_CALLBACK</code>, which allows you to apply a custom function to the data.</li> </ol> <p>Some examples include validating an email address:</p> <pre><code>$email = \"test@example.com\";\nif (filter_var($email, FILTER_VALIDATE_EMAIL)) {\n    echo \"This is a valid email address.\";\n} else {\n    echo \"This is not a valid email address.\";\n}\n</code></pre> <p>Or sanitizing a string:</p> <pre><code>$dirty_string = \"&lt;script&gt;alert('xss');&lt;/script&gt;Some text\";\n$clean_string = filter_var($dirty_string, FILTER_SANITIZE_STRING);\necho $clean_string;  // Output will be \"alert('xss');Some text\"\n</code></pre> <p>Or filtering an integer and validating range:</p> <pre><code>$options = array(\n    \"options\" =&gt; array(\n        \"min_range\" =&gt; 1,\n        \"max_range\" =&gt; 100\n    )\n);\n$number = 50;\nif (filter_var($number, FILTER_VALIDATE_INT, $options)) {\n    echo \"The number is within the specified range.\";\n} else {\n    echo \"The number is not within the specified range.\";\n}\n</code></pre>"},{"location":"programming/phpwrappers/","title":"PHP Wrappers","text":"<p>PHP wrappers are a powerful feature in PHP used to access various types of data streams through a common interface. These wrappers allow PHP to interact with different types of data using the same set of functions you would use with regular files</p> <p>The types of wrappers in PHP include:</p> <ol> <li>File System Wrappers: This is the default wrapper that deals with file system functions. It allows access to local file systems. For example, when you use fopen() or file_get_contents() for files, you're using this wrapper.</li> <li>HTTP and HTTPS Wrappers: They allow PHP to access data over HTTP/HTTPS. For example, you can read a web page or an online file using <code>file_get_contents('http://example.com')</code>.</li> <li>FTP and FTPS Wrappers: These are used for accessing files over FTP/FTPS. You can open, read, or write files on a remote FTP server.</li> <li>PHP Input/Output Wrappers:<ul> <li><code>php://input</code> allows you to read raw data from the request body.</li> <li><code>php://output</code> is a write-only stream that allows you to write to the output buffer.</li> <li><code>php://memory</code> and <code>php://temp</code> are used for storing data in memory or in a temporary file, respectively.</li> </ul> </li> <li>Compression Wrappers (zlib): This wrapper allows access to compressed files. For instance, <code>compress.zlib://file.gz</code> lets you read and write to gzipped files transparently.</li> <li>Data Wrapper: It is used to read data in a string as if it were a regular file. It's useful for encoding data in base64 or URL encoding.</li> <li>Glob Wrapper: Used with functions like <code>glob()</code> to match file patterns.</li> <li>SSH2 Wrapper: For accessing remote resources via the Secure Shell 2 protocol.</li> <li>Custom Stream Wrappers: PHP allows developers to define their own protocol wrappers, enabling the creation of custom stream handling logic.</li> </ol> <p>Some example uses include reading from a website:</p> <pre><code>$content = file_get_contents('http://example.com');\necho $content;\n</code></pre> <p>Or writing to a compressed file:</p> <pre><code>$fp = fopen('compress.zlib://file.gz', 'w');\nfwrite($fp, 'data to compress');\nfclose($fp);\n</code></pre> <p>Or reading JSON from PHP input:</p> <pre><code>$json = file_get_contents('php://input');\n$data = json_decode($json);\n</code></pre>"},{"location":"programming/polymorph/","title":"Polymorphism","text":"<p>Polymorphism is a fundamental concept in Object-Oriented Programming that refers to the ability of different objects to respond in their own way to the same message (or method call). The term originates from Greek, meaning \"many forms.\" In programming, it allows objects of different classes to be treated as objects of a common superclass.</p> <p>There are types of Polymorphism:</p> <ol> <li>Compile-Time Polymorphism (Static Polymorphism): This is achieved through method overloading or operator overloading. Here, the response to a function is determined at compile time. In languages like C++, for instance, you can have multiple functions with the same name but different parameters.</li> <li>Run-Time Polymorphism (Dynamic Polymorphism): This is mainly achieved through method overriding, where a method in a subclass has the same name and signature as a method in its superclass. The specific version of the method that gets executed is determined at runtime, based on the type of the object that invokes the method.</li> </ol> <p>Consider a class <code>Animal</code> with a method <code>makeSound()</code>. There are also two subclasses, <code>Dog</code> and <code>Cat</code>, each with their own implementation of <code>makeSound()</code>.</p> <pre><code>class Animal {\n    void makeSound() {\n        System.out.println(\"Some sound\");\n    }\n}\n\nclass Dog extends Animal {\n    void makeSound() {\n        System.out.println(\"Bark\");\n    }\n}\n\nclass Cat extends Animal {\n    void makeSound() {\n        System.out.println(\"Meow\");\n    }\n}\n\npublic class TestPolymorphism {\n    public static void main(String args[]) {\n        Animal a;\n        a = new Dog();\n        a.makeSound(); // Prints \"Bark\"\n\n        a = new Cat();\n        a.makeSound(); // Prints \"Meow\"\n    }\n}\n</code></pre> <p>In this Java example, <code>Animal</code> is the superclass, and <code>Dog</code> and <code>Cat</code> are subclasses. Each class has its own implementation of <code>makeSound()</code>. The type of object (<code>Dog</code> or <code>Cat</code>) determines which <code>makeSound()</code> method is called at runtime.</p> <p>Polymorphism allows for writing flexible and scalable code as you can write code that works on the superclass level but can work with any subclass. This means new subclasses can be introduced with little to no modification to existing code. It supports the use of inheritance, allowing for the reuse of code and reduction of redundancy.</p>"},{"location":"programming/pregmatch/","title":"preg_match()","text":"<p>The preg_match() function in PHP is used for performing regular expression matches. It is part of PHP's PCRE (Perl Compatible Regular Expressions) functions, which are a set of functions that implement regular expression pattern matching using a syntax that is mostly compatible with Perl's regular expressions.</p> <p>The syntax is:</p> <pre><code>int preg_match ( string $pattern , string $subject [, array &amp;$matches [, int $flags = 0 [, int $offset = 0 ]]] )\n</code></pre> <ul> <li>Parameters:<ul> <li><code>$pattern</code>: The regular expression pattern.</li> <li><code>$subject</code>: The input string.</li> <li><code>$matches</code> (optional): An array that is filled with the search results.</li> <li><code>$flags</code> (optional): Flags to control the match.</li> <li><code>$offset</code> (optional): An alternative starting point within <code>$subject</code>.</li> </ul> </li> <li>Return Value: <code>preg_match</code> returns <code>1</code> if the pattern matches, <code>0</code> if it does not, or <code>FALSE</code> if an error occurs.</li> </ul> <p>An example may be:</p> <pre><code>if (preg_match(\"/^example$/\", \"example\")) {\n    // The pattern matches the string \"example\"\n}\n</code></pre> <p>Regular expressions, and by extension preg_match(), are often used in input validation. Proper input validation is a key aspect of securing applications against various forms of injection attacks, including SQL injection (SQLi). </p> <p>However, preg_match() by itself does not prevent SQLi. It can be part of a broader strategy for ensuring that inputs conform to expected formats (like checking if an input is a valid email address, phone number, etc.), which indirectly reduces the risk of injection attacks.</p>"},{"location":"programming/pregrep/","title":"preg_replace()","text":"<p>preg_replace() is a function in PHP used for performing a regular expression search and replace. It is part of PHP's PCRE (Perl Compatible Regular Expressions) functions and is widely used for finding and replacing patterns in strings.</p> <p>The syntax is:</p> <pre><code>preg_replace(pattern, replacement, subject, limit, count)\n</code></pre> <ul> <li>pattern: The regular expression pattern to search for. It can be a string or an array of strings.</li> <li>replacement: The string or an array of strings to replace with.</li> <li>subject: The string or an array of strings to search and replace.</li> <li>limit (optional): The maximum possible replacements for each pattern in each subject string. If omitted, it defaults to -1 (no limit).</li> <li>count (optional): If specified, this variable will be filled with the number of replacements done.</li> </ul> <p>The function uses Perl-compatible regular expressions and offers powerful pattern matching capabilities. You can use any valid PCRE regex pattern. preg_replace() searches for the specified pattern in the subject string(s) and replaces them with the replacement string.</p> <p>An example may be:</p> <pre><code>$string = \"The quick brown fox jumps over the lazy dog.\";\n$pattern = \"/quick/\";\n$replacement = \"slow\";\necho preg_replace($pattern, $replacement, $string);\n// Outputs: The slow brown fox jumps over the lazy dog.\n</code></pre> <p>Both the subject and the pattern can be arrays. When provided as arrays, preg_replace() performs a search and replace on each element of the subject array. In the replacement string, you can use backreferences like $1, $2, etc., to refer to capturing groups defined in the pattern.</p> <p>Common uses of preg_replace() include formatting strings, sanitizing input, rewriting URLs, etc. Be cautious when using preg_replace() with user-supplied input as part of the pattern or replacement, as this can lead to complex security vulnerabilities, particularly if the /e modifier is used, which evaluates the replacement string as PHP code.</p>"},{"location":"programming/prepend/","title":"prepend()","text":"<p>The jQuery prepend() function is a method used to insert content at the beginning of the selected elements in the Document Object Model (DOM). This function is part of the jQuery library, a popular JavaScript toolkit used for simplifying HTML DOM tree traversal and manipulation, event handling, and animation.</p> <p>prepend() is used to insert specified content as the first child of each element in the jQuery collection of matched elements. The syntax is as follows:</p> <pre><code>$(selector).prepend(content)\n</code></pre> <ul> <li>selector - jQuery selector that identifies the elements to which the new content is prepended</li> <li>content - content to be inserted, can be HTML strings, DOM elements, jQuery objects or even functions that return content.</li> </ul> <p>An example may be inserting a text node which inserts \"Hello\" at the beginning of the element with the ID myDiv:</p> <pre><code>$('#myDiv').prepend('Hello');\n</code></pre> <p>Or you could insert an HTML element such as inserting a new paragraph at the beginning of myDiv:</p> <pre><code>$('#myDiv').prepend('&lt;p&gt;New Paragraph&lt;/p&gt;');\n</code></pre> <p>Similar to other jQuery methods, prepend() can handle script tags and event handlers in the content being added. However, this should be done with caution to avoid potential security risks like Cross-Site Scripting (XSS).</p>"},{"location":"programming/printf/","title":"printf()","text":"<p>printf is a standard output function in the C programming language, used for formatted output to the console or standard output stream. It is part of the C standard library (<code>stdio.h</code>) and is widely used for displaying information to the user.</p> <p>The syntax is as:</p> <pre><code>int printf(const char *format, ...);\n</code></pre> <ul> <li><code>format</code>: C string that contains text to be written to standard output and format tags that are replaced by the values specified in subsequent additional arguments.</li> </ul> <p>The primary security vulnerability associated with <code>printf</code> is related to format string attacks. This occurs when a function like <code>printf</code> is used improperly without proper format specifiers, and user-controlled input is passed as the format string parameter. If an attacker can control the format string, they can potentially read from or write to memory addresses or cause other types of undefined behavior.</p> <p>Consider a scenario where <code>printf</code> is used improperly:</p> <pre><code>char userInput[100];\nscanf(\"%s\", userInput);\nprintf(userInput);  // Vulnerable usage\n</code></pre> <p>In this example, the program reads user input and directly passes it to <code>printf</code> without a proper format string. An attacker could provide a string like <code>%s%s%s</code> to read from the stack or <code>%n</code> to write to memory, leading to information disclosure or corruption of program execution.</p> <p>Some exploitation scenarios could include:</p> <ol> <li>Reading Memory: An attacker can use format specifiers like <code>%s</code> to read data from the stack, potentially accessing sensitive information.</li> <li>Writing to Memory: The <code>%n</code> specifier can be used to write values to memory addresses, allowing an attacker to modify the program's execution flow or corrupt data.</li> <li>Denial of Service: Malicious format strings can cause the program to crash, leading to a denial of service.</li> </ol>"},{"location":"programming/purify/","title":"DOMPurify","text":"<p>DOMPurify is a JavaScript library designed to sanitize HTML and prevent Cross-Site Scripting (XSS) attacks. XSS attacks involve injecting malicious scripts into web pages viewed by other users, exploiting the trust a user has for a particular site.</p> <p>DOMPurify mitigates this risk by sanitizing HTML content, ensuring that it's safe to insert into the DOM (Document Object Model).</p> <p>It removes harmful HTML, JavaScript, SVG, and MathML content from user input, ensuring that only clean, safe content is rendered by the browser.</p> <p>DOMPurify is particularly useful in applications that allow user-generated content, where there is a risk of XSS attacks. For instance, in forums, comment sections, or any web application that dynamically inserts HTML content based on user input.</p> <p>When you pass a string of HTML to DOMPurify, it parses the HTML and removes any elements or attributes that could be used for XSS. This includes &lt;script&gt; tags, javascript: URLs, event handler attributes (like onclick), and many others.</p> <p>The result is a sanitized version of the HTML that is safe to insert into the DOM.</p> <p>DOMPurify is easy to integrate into web projects. It can be included as a standalone script, or installed via package managers like npm for use in larger JavaScript applications. It's commonly used in conjunction with libraries like ReactJS, AngularJS, or Vue.js to sanitize dynamic content.</p>"},{"location":"programming/python/","title":"Python","text":"<p>Python is a popular general-purpose programming language that can be used for a wide variety of applications. It includes high-level data structures, dynamic typing, dynamic binding, and many more features that make it as useful for complex application development as it is for scripting or \"glue code\" that connects components together. </p> <p>It can also be extended to make system calls to almost all operating systems and to run code written in C or C++. Due to its ubiquity and ability to run on nearly every system architecture, Python is a universal language found in a variety of different applications.</p> <p>Python is a popular programming language that is widely used in the development of web applications. It is easy to learn, has a large and active community, and is supported by a wealth of libraries and frameworks.</p>"},{"location":"programming/rails/","title":"Rails","text":"<p>Rails is a development tool which gives web developers a framework, providing structure for all the code they write. The Rails framework helps developers to build websites and applications, because it abstracts and simplifies common repetitive tasks.</p> <p>Rails is written in Ruby, the programming language which is also used alongside Rails. Ruby is to Rails as PHP is to Symfony and Zend, or as Python is to Django. The\u00a0appeal of Ruby to developers\u00a0lies in the elegance and terseness of the language.</p> <p>One of key principles of Ruby on Rails development (henceforth \u2018Rails\u2019) is convention over configuration. This means that the programmer does not have to spend a lot of time configuring files in order to get setup, Rails comes with a set of conventions which help speed up development.</p> <p>Another characteristic of Rails is the emphasis on RESTful application design. REST (Representational State Transfer) is a style of software architecture based around the client-server relationship. It encourages a logical structure within applications, which means they can easily be exposed as an API (Application Programming Interface).</p> <p>From project management point of view, the Ruby on Rails community advocate\u00a0Agile web development\u00a0- an iterative development method, that encourages collaborative and flexible approach, which is particularly well-suited for web application development with fast-changing requirements.</p> <p>Over the last few years Ruby on Rails has gained a large and enthusiastic following, but let\u2019s consider the main arguments for and against Rails.</p>"},{"location":"programming/readfile/","title":"readfile()","text":"<p>In Node.js, <code>readFile()</code> is a function provided by the File System module (<code>fs</code> module) used to read the content of a file asynchronously. When you use <code>readFile()</code>, Node.js reads the file in a non-blocking manner, meaning that it doesn't pause the execution of your program while the file is being read. Instead, it uses a callback function to handle the content after the file is read or to catch any errors that occur during the read process.</p> <p>It does not block the Node.js event loop. The rest of your code continues to execute while the file is being read. You provide a callback function that gets executed once the file reading is complete or an error occurs. By default, the content is returned in a <code>Buffer</code> object unless an encoding is specified, in which case it returns a string. The first argument to the callback function is an error object, which will be <code>null</code> if no error occurred.</p> <p>The syntax is:</p> <pre><code>fs.readFile(path[, options], callback)\n</code></pre> <ul> <li><code>path</code>: String, Buffer, URL, or file descriptor representing the file to be read.</li> <li><code>options</code> (Optional): An object or string that specifies the encoding or other options. The encoding can be set to <code>'utf8'</code>, <code>'ascii'</code>, etc.</li> <li><code>callback</code>: The function to call when the file has been read or an error occurs. It takes two parameters: an error object and the file content.</li> </ul> <p>An example usage may be:</p> <pre><code>const fs = require('fs');\n\nfs.readFile('/path/to/file.txt', 'utf8', (err, data) =&gt; {\n    if (err) {\n        console.error('Error reading the file:', err);\n        return;\n    }\n    console.log(data); // Output the file content\n});\n</code></pre> <p>Info</p> <p>In this example, <code>readFile()</code> is used to read the contents of <code>'file.txt'</code>. The encoding <code>'utf8'</code> is specified so that the content is returned as a string. The callback function checks for an error and then logs the file content.</p> <p>The <code>readFile()</code> function in Node.js itself is not inherently vulnerable; however, its use can become a security concern, especially when dealing with user-supplied input. If not properly validated or sanitized, user input can lead to vulnerabilities like Path Traversal (also known as Directory Traversal).</p> <p>An example of a vulnerable implementation:</p> <pre><code>const fs = require('fs');\nconst http = require('http');\n\nhttp.createServer((req, res) =&gt; {\n    // Get the path from the URL\n    let filePath = req.url.slice(1); // This is unsafe user input\n\n    fs.readFile(filePath, 'utf8', (err, data) =&gt; {\n        if (err) {\n            res.writeHead(404);\n            res.end('File not found');\n        } else {\n            res.writeHead(200);\n            res.end(data);\n        }\n    });\n}).listen(3000);\n</code></pre> <p>Danger</p> <p>In this example, a simple HTTP server is created which reads the file path from the URL and then uses <code>readFile()</code> to read and return the content of the file. This is a security risk because an attacker could manipulate the URL to access files outside the intended directory. For instance, requesting <code>http://localhost:3000/../../etc/passwd</code> could potentially expose sensitive system files.</p>"},{"location":"programming/render/","title":"render()","text":"<p>In the Express framework for Node.js, the <code>render()</code> function is used in the context of server-side rendering. It is a method of the response object (<code>res</code>) provided by Express to render a view template. When you call <code>res.render()</code>, Express compiles the specified template using the configured template engine, injects local variables into the template, and sends the generated HTML string as the response to the client.</p> <p>Express supports various template engines like EJS, Pug (Jade), Handlebars, etc. The choice of template engine determines the syntax and features available in your templates. The <code>render()</code> function takes a template file and a data object. It combines them to produce a complete HTML page which includes dynamic data. The resulting HTML from the rendering process is automatically sent back to the client as the response.</p> <p>The syntax is:</p> <pre><code>res.render(view [, locals] [, callback])\n</code></pre> <ul> <li><code>view</code>: The name of the view file to be rendered. This does not typically include the file extension, as that is inferred from the view engine setup.</li> <li><code>locals</code> (Optional): An object containing response local variables - data that you want to pass to the view for rendering.</li> <li><code>callback</code> (Optional): A callback function that gets called when the render process is complete. If provided, the method will not send the rendered HTML automatically, allowing for further manipulation.</li> </ul> <p>An example:</p> <pre><code>const express = require('express');\nconst app = express();\n\napp.set('view engine', 'ejs'); // Set EJS as the template engine\n\napp.get('/', (req, res) =&gt; {\n    // Render the 'index' view, passing 'title' and 'message' as data\n    res.render('index', {\n        title: 'Welcome',\n        message: 'Hello to EJS!'\n    });\n});\n\napp.listen(3000, () =&gt; console.log('Server running on port 3000'));\n</code></pre> <p>Info</p> <p>In this example, when a user visits the root URL (<code>'/'</code>), the server will render the <code>index.ejs</code> file, injecting the <code>title</code> and <code>message</code> data into it, and send the resulting HTML as the response.</p> <p>The <code>render()</code> function in Express itself is not inherently vulnerable. However, vulnerabilities can arise based on how it's used, especially when rendering data that includes user input. The primary security concern in such scenarios is Cross-Site Scripting (XSS).</p> <p>Consider an Express app using a templating engine like EJS, where user input is directly included in the rendered output without proper escaping:</p> <pre><code>app.get('/profile', (req, res) =&gt; {\n    // User input taken directly from the query string\n    const username = req.query.username;\n\n    // Rendering the username in the response without escaping\n    // This could be dangerous if username contains malicious script\n    res.render('profile', { username });\n});\n</code></pre> <p>Danger</p> <p>In this scenario, if an attacker provides a username in the query string that contains JavaScript code, this code will be rendered as-is into the HTML. If another user visits a URL like <code>http://example.com/profile?username=&lt;script&gt;maliciousCode()&lt;/script&gt;</code>, the script would execute in their browser.</p>"},{"location":"programming/replaceall/","title":"replaceAll()","text":"<p>The jQuery replaceAll() function is used to replace elements in the Document Object Model (DOM) with new content. This function is part of the jQuery library, which is widely used for simplifying HTML DOM tree traversal and manipulation, handling events, and creating animations.</p> <p>replaceAll() replaces the elements matched by the target selector with the elements specified by the calling selector. The syntax is:</p> <pre><code>$(content).replaceAll(target)\n</code></pre> <ul> <li>content - content or elements that will replace the target elements, can be HTML, a jQuery object, or a DOM element.</li> <li>target - target selector identifying elements to be replaced.</li> </ul> <p>An example may be:</p> <pre><code>$('&lt;p&gt;New Paragraph&lt;/p&gt;').replaceAll('.old-paragraph');\n</code></pre> <p>Here, every element with the class 'old-paragraph' is replaced by a new paragraph element.</p> <p>The jQuery replaceAll function, like other DOM manipulation methods, can have security implications, particularly in relation to Cross-Site Scripting (XSS) attacks. These concerns arise primarily when dynamically generated content, especially content that includes user input or data from untrusted sources, is used with the function.</p>"},{"location":"programming/replacewith/","title":"replaceWith()","text":"<p>The jQuery replaceWith function is used to replace each element in the set of matched elements with new content. It's a component of the jQuery library, a comprehensive tool for HTML DOM tree traversal, manipulation, event handling, and creating animations.</p> <p>replaceWith replaces matched elements with the specified new content. This content can be HTML text, a DOM element, a jQuery object, or content returned by a function. The syntax is:</p> <pre><code>$(selector).replaceWith(newContent)\n</code></pre> <ul> <li>selector: Identifies the elements to be replaced using a jQuery selector.</li> <li>newContent: The new content that will replace the selected elements.</li> </ul> <p>A usage example may be:</p> <pre><code>$('#oldElement').replaceWith('&lt;div&gt;New Content&lt;/div&gt;');\n</code></pre> <p>This example replaces the element with ID 'oldElement' with a new div element containing 'New Content'.</p> <p>The jQuery replaceWith function, like other DOM manipulation methods, can have security implications, especially concerning Cross-Site Scripting (XSS) attacks. These concerns primarily arise when the function is used with content that is dynamically generated or influenced by user input or data from untrusted sources.</p>"},{"location":"programming/requests/","title":"requests","text":"<p>The <code>requests</code> module in Python is a popular HTTP library used for making HTTP requests to web servers or APIs. It simplifies the process of sending HTTP requests, handling responses, and interacting with web services. Unlike the lower-level <code>http.client</code> library built into Python, <code>requests</code> provides a more user-friendly and higher-level interface.</p> <p>The module offers a straightforward way to send HTTP requests. You can perform GET, POST, PUT, DELETE, and other request types with minimal code. It makes it easy to access response data. You can retrieve the status code, response headers, and the response body. It also automatically decodes the response content based on its headers.</p> <p>Sending URL parameters and request payloads (like form data or JSON) is straightforward. The module allows you to pass these elements as simple Python dictionaries. You can easily customize request headers and add authentication (basic, digest, or custom) to your requests.</p> <p>For maintaining state across requests (like cookies), you can use session objects which persist certain parameters across requests. The module automatically processes and stores cookies sent by the server and sends them back with subsequent requests.</p> <p>By default, <code>requests</code> verifies SSL certificates for HTTPS requests, which is important for secure communication. You can set timeouts on your requests to ensure that your script doesn\u2019t hang indefinitely if the server doesn\u2019t respond. The module automatically handles HTTP redirections (like 301 and 302 status codes).</p> <p>While the <code>requests</code> module itself is secure, the way it is used can have security implications. For instance, disabling SSL certificate verification (<code>verify=False</code>) can expose the request to man-in-the-middle attacks. It's also important to be cautious with the data you send and receive, especially when interacting with unknown or untrusted services.</p>"},{"location":"programming/require/","title":"require()","text":"<p>The <code>require()</code> function in PHP is used to include and execute the contents of a specified file during the execution of a script. It's very similar to the include() function, but with a key difference in how it handles errors.</p> <p>If <code>require()</code> fails to find or open the specified file, it generates a fatal error and halts the execution of the script. This is in contrast to <code>include()</code>, which only emits a warning (E_WARNING) and the script will continue to execute. <code>require()</code> is commonly used when the file is essential for the application to run. For example, files containing necessary functions, classes, or configurations are typically included using <code>require()</code>.</p> <p>If the same file is <code>require()</code>d multiple times within a script, the file's contents will be executed each time it is called. To prevent this, <code>require_once()</code> can be used, which ensures that the file is included only once.</p> <p>The syntax is:</p> <pre><code>require 'path/to/file.php';\n</code></pre> <p>A more realistic example may be:</p> <pre><code>&lt;?php\n// Include a critical configuration file\nrequire 'config.php';\n\n// Rest of the script that depends on the configuration settings\n?&gt;\n</code></pre> <p>The <code>require()</code> function in PHP can be vulnerable to security risks, similar to include() and include_once(). The primary vulnerability associated with <code>require()</code> is Local File Inclusion (LFI), which can occur if the function is used with improperly validated or sanitized user input.</p> <p>An example of a vulnerable use:</p> <pre><code>&lt;?php\n// A vulnerable script where the file name is taken from user input\n$page = $_GET['page'];\nrequire($page . '.php');\n?&gt;\n</code></pre> <p>Danger</p> <p>In this example, if a user can control the value of <code>$_GET['page']</code>, they might be able to include files like <code>config.php</code> by manipulating the URL, such as <code>http://example.com/?page=../config</code>.</p> <p>A more secure implementation may look like:</p> <pre><code>&lt;?php\n// Define a whitelist of allowed files\n$allowedPages = [\n    'home' =&gt; 'home.php',\n    'contact' =&gt; 'contact.php',\n    'about' =&gt; 'about.php'\n];\n\n// Get the user input\n$page = $_GET['page'] ?? 'default'; // Default page if none is specified\n\n// Validate the user input against the whitelist\nif (array_key_exists($page, $allowedPages)) {\n    // Use the file from the whitelist, ensuring the input cannot affect the file path\n    require $allowedPages[$page];\n} else {\n    // Handle the error or redirect to a default page\n    echo 'Page not found.';\n    // Or you can redirect to a default page like this:\n    // header('Location: default.php');\n    // exit();\n}\n?&gt;\n</code></pre> <ol> <li>Whitelisting: Only files listed in <code>$allowedPages</code> are allowed to be included. This prevents attackers from including arbitrary files.</li> <li>Validation: The user input (<code>$page</code>) is checked against the whitelist. This ensures that only predefined paths can be used in <code>require()</code>.</li> <li>Default Values: The use of <code>$_GET['page'] ?? 'default'</code> ensures that there is always a valid value for <code>$page</code>. If the user does not provide input, it defaults to 'default'.</li> <li>Error Handling: If the user input does not match any key in the whitelist, the script handles this gracefully by displaying an error message or redirecting to a default page.</li> </ol>"},{"location":"programming/requireonce/","title":"require_once()","text":"<p>The <code>require_once()</code> function in PHP is a control structure used to include the contents of another file into the script that is currently executing. It is very similar to the require() function, but with a crucial addition: it checks if the specified file has already been included, and if so, it will not include or require it again. </p> <p>This functionality is particularly useful for including files that contain code which should only be executed once, such as function definitions, class declarations, or variable initializations.</p> <p>It ensures that the file is included only once. If the same file is attempted to be included again using <code>require_once()</code>, it will be ignored, preventing issues like function redefinitions or class redeclarations. Like <code>require()</code>, if the file cannot be found or is unavailable, <code>require_once()</code> generates a fatal error and halts the script execution. This is different from require_once(), which emits a warning but allows the script to continue.</p> <p>It is commonly used for including files where you need to ensure that the file is not included more than once. This is particularly important for files defining classes, functions, or setting up critical configuration settings.</p> <p>The syntax is:</p> <pre><code>require_once 'path/to/file.php';\n</code></pre> <p>A more realistic example is:</p> <pre><code>&lt;?php\n// Require a file containing a class definition\nrequire_once 'MyClass.php';\n\n// Use the class\n$myObject = new MyClass();\n\n// Further code...\n?&gt;\n</code></pre> <p>Info</p> <p>In this example, <code>MyClass.php</code> is included only once, regardless of how many times <code>require_once 'MyClass.php';</code> is called. This prevents errors that would occur if the class <code>MyClass</code> were defined multiple times.</p> <p><code>require_once()</code> in PHP can be vulnerable to security risks, particularly if it's used with improperly validated or sanitized user input. The primary vulnerability associated with <code>require_once()</code> is Local File Inclusion (LFI), similar to the vulnerabilities in include(), include_once(), and require().</p> <p>An example of vulnerable code is:</p> <pre><code>&lt;?php\n// A vulnerable script where the file name is taken from user input\n$page = $_GET['page'];\nrequire_once($page . '.php');\n?&gt;\n</code></pre> <p>Danger</p> <p>In this example, an attacker could manipulate the query string in the URL to include arbitrary files from the server, such as <code>http://example.com/script.php?page=../../etc/passwd</code>. This could lead to sensitive data exposure.</p> <p>A more secure implementation could be:</p> <pre><code>&lt;?php\n// Define a whitelist of allowed files\n$allowedFiles = [\n    'home' =&gt; 'home.php',\n    'contact' =&gt; 'contact.php',\n    'about' =&gt; 'about.php'\n];\n\n// Get the user input, defaulting to a specific page if not provided\n$pageKey = $_GET['page'] ?? 'home';\n\n// Validate the user input against the whitelist\nif (array_key_exists($pageKey, $allowedFiles)) {\n    // Use the file from the whitelist\n    require_once $allowedFiles[$pageKey];\n} else {\n    // Handle the error, such as showing an error message or redirecting\n    echo 'Page not found.';\n    // Alternatively, redirect to a default page or show a 404 page\n}\n?&gt;\n</code></pre> <ol> <li>Whitelisting: The <code>$allowedFiles</code> array acts as a whitelist, ensuring that only predefined file paths are used. This prevents the possibility of including arbitrary files based on user input.</li> <li>Input Validation: The script checks if the user-provided input (<code>$pageKey</code>) exists in the whitelist. If it doesn't, the script does not proceed with the <code>require_once()</code>.</li> <li>Default Values: Using <code>$_GET['page'] ?? 'home'</code> ensures that there is always a valid value for <code>$pageKey</code>, preventing undefined index notices and ensuring a valid page is loaded by default.</li> <li>Error Handling: If the input does not match any key in the whitelist, the script handles this gracefully, either by showing an error message or redirecting to a default or error page. This avoids exposing any sensitive server information.</li> </ol>"},{"location":"programming/responsewritefile/","title":"Response.WriteFile","text":"<p>In ASP.NET, <code>Response.WriteFile()</code> is a method of the <code>HttpResponse</code> class, used to write the contents of a file directly to the HTTP response output stream. This method is particularly useful when you want to serve files from your server to the client, such as downloading a file or displaying an image.</p> <p>It reads the contents of a specified file and writes them directly to the HTTP response. This is done without loading the entire file into memory, which is efficient for large files. Often used in conjunction with setting the <code>ContentType</code> property of the <code>HttpResponse</code> object, to inform the browser about the type of content being sent.</p> <p>Commonly used for implementing file download functionality in ASP.NET applications. By setting appropriate headers, you can prompt the user to download the file instead of displaying it.</p> <p>The syntax is:</p> <pre><code>Response.WriteFile(string path);\n</code></pre> <ul> <li><code>path</code>: The path of the file to be written to the response.</li> </ul> <p>An example usage may be serving an image:</p> <pre><code>Response.ContentType = \"image/jpeg\";\nResponse.WriteFile(\"/path/to/image.jpg\");\n</code></pre> <p>Or even prompting a file download:</p> <pre><code>Response.ContentType = \"application/octet-stream\";\nResponse.AppendHeader(\"Content-Disposition\", \"attachment; filename=example.txt\");\nResponse.WriteFile(\"/path/to/example.txt\");\nResponse.End();\n</code></pre> <p>Info</p> <p>In the download example, <code>ContentType</code> is set to a general binary (<code>application/octet-stream</code>), and the <code>Content-Disposition</code> header is used to prompt the browser to download the file, rather than attempting to display it.</p> <p>The <code>Response.WriteFile()</code> function in ASP.NET itself is not inherently vulnerable, but its usage can lead to security vulnerabilities, especially if user input is used to determine the file path without proper validation. The primary concern in such scenarios is a security vulnerability known as Path Traversal or Directory Traversal.</p> <p>Consider an ASP.NET web application where a user can request to view a file, and the file path is taken directly from the user input:</p> <pre><code>public void ProcessRequest(HttpContext context)\n{\n    string filePath = context.Request.QueryString[\"file\"];\n\n    // Vulnerable usage of Response.WriteFile\n    context.Response.ContentType = \"application/octet-stream\";\n    context.Response.WriteFile(filePath);\n    context.Response.End();\n}\n</code></pre> <p>Danger</p> <p>In this example, an attacker could manipulate the file path to access sensitive files. For instance, if the application is hosted at <code>http://example.com</code>, an attacker might access:</p> <pre><code>http://example.com?file=../../web.config\n</code></pre> <p>This URL could potentially give the attacker access to the <code>web.config</code> file, a critical configuration file in ASP.NET applications.</p>"},{"location":"programming/resrender/","title":"res.render()","text":"<p>The <code>res.render()</code> function is used in Express.js, a web framework for Node.js. It is a method of the response object (<code>res</code>) that compiles your template (written in a view engine like EJS, Pug, Handlebars, etc.), inserts variables into it, and sends the resulting HTML string as the response.</p> <p><code>res.render()</code> is used to render a view (template) and send its HTML output to the client. It works with different view engines supported by Express.js. The choice of view engine (like EJS, Pug, Handlebars) determines the syntax and capabilities of your templates.</p> <p>You can pass a JavaScript object as the second argument to <code>res.render()</code>, which contains data to be inserted into the template. This makes it dynamic and responsive to each request. Many view engines support layouts and partials, which allow for reusable template pieces and consistent layout structures across different views.</p> <p>The syntax is:</p> <pre><code>res.render(view [, locals] [, callback])\n</code></pre> <ul> <li><code>view</code>: A string that is the file path of the view file to render. This path is relative to the views directory you set in your Express.js configuration.</li> <li><code>locals</code> (Optional): An object containing properties that the view will use to render dynamic content.</li> <li><code>callback</code> (Optional): A callback function that lets you handle the rendered HTML string manually, rather than sending it as the HTTP response.</li> </ul> <p>As an example, assume you are using EJS as your view engine:</p> <pre><code>app.get('/', function (req, res) {\n    res.render('index', { title: 'Home', message: 'Welcome to the Home Page' });\n});\n</code></pre> <p>In this example, <code>res.render()</code> is used to render the <code>index</code> view. The second argument is an object with properties <code>title</code> and <code>message</code>, which are variables used in the <code>index.ejs</code> template to dynamically generate the HTML content.</p> <p>The <code>res.render()</code> function in Express.js itself is not inherently vulnerable. However, vulnerabilities can arise based on how it's used, particularly when dealing with user-provided data. The primary security concern in the context of <code>res.render()</code> and templating engines is Cross-Site Scripting (XSS).</p> <p>Suppose you have a route in your Express.js application that takes a query parameter and renders it directly onto the page:</p> <pre><code>app.get('/somepage', function (req, res) {\n    // User input is taken directly from the query parameter\n    const userInput = req.query.userInput;\n\n    // This could be dangerous if userInput contains malicious script\n    res.render('somepage', { userInput });\n});\n</code></pre> <p>Danger</p> <p>In this scenario, if <code>userInput</code> is not properly escaped and contains JavaScript code, it will be rendered as-is into the HTML. An attacker could exploit this by crafting a URL with a script in the <code>userInput</code> parameter. For example:</p> <pre><code>http://example.com/somepage?userInput=&lt;script&gt;maliciousCode()&lt;/script&gt;\n</code></pre>"},{"location":"programming/ror/","title":"Ruby on Rails","text":"<p>Ruby on Rails, often simply called Rails, is a popular open-source web application framework written in the Ruby programming language. It is designed to make web development faster, easier, and more fun.</p> <p>Rails follows the Model-View-Controller (MVC) architectural pattern, which separates the application into three interconnected parts. This separation helps in managing resources, processing logic, and the user interface independently.</p> <p>One of Rails' guiding principles is \"Convention over Configuration.\" This means that by default, Rails makes assumptions about what a developer needs to get started with an application, reducing the amount of configuration code needed.</p> <p>Rails emphasizes the DRY principle, encouraging developers to write reusable code and minimize redundancy, which leads to more maintainable, extendable, and less buggy code. Rails is written in Ruby, a dynamic, reflective, object-oriented programming language known for its simplicity and productivity. Ruby's readable syntax contributes to Rails' ease of use and popularity.</p> <p>Rails includes a variety of built-in tools that support common web development tasks, such as scaffolding that automatically generates the basic components of a web application. Rails uses Active Record, an ORM (Object-Relational Mapping) system, to facilitate data manipulation in the database through Ruby objects.</p> <p>Rails supports the use of \u201cgems\u201d \u2013 third-party libraries that can be integrated to add functionalities to Rails applications. This extensive ecosystem of gems means that many features can be added without manual coding.</p> <p>Rails encourages the creation of RESTful applications, which means that it aligns with the REST architecture, organizing application functionality around resources and standard HTTP methods.</p>"},{"location":"programming/ruby/","title":"Ruby","text":"<p>Ruby\u00a0is a popular, general-purpose programming language. You may have heard of it in connection to\u00a0Ruby on Rails, one of the most popular web development frameworks in any programming language. </p> <p>Although much of Ruby\u2019s popularity comes from this connection, Ruby has many uses, including web scraping, static site generation, command-line tools, automation, DevOps, and data processing.</p> <p>Ruby is often called a \u201clanguage of careful balance.\u201d</p> <p>Ruby is a very flexible\u00a0programming language that allows developers to alter how the language itself works. You can add functionality to core language features or even remove them if you need. </p> <p>Ruby is also a highly portable, cross-platform language. Code you write on one operating system will run on Linux, Mac OSX, and Windows. It will even run in UNIX, DOS, BeOS, OS/2, and more.</p> <p>Web development is one of Ruby\u2019s claims to fame because of the popular web development framework Ruby on Rails. Ruby on Rails was first released in 2005, and it changed how web development was done. Before frameworks like Ruby on Rails, developers had to spend a lot more time writing code to create a web application.</p> <p>Ruby on Rails gives web developers everything they need to build a web application. Rails uses conventions that define the structure of every Rails app, so developers can spend less time configuring their projects. It has code generators that will generate parts of your application with a simple command, so developers write less code.</p> <p>The rapid development that Ruby on Rails makes possible also made it a popular choice for startups because it allowed a small team of developers to build large applications quickly. Some sites you may have heard of that use Ruby on Rails include Github, Shopify, Kickstarter, Twitch, Instacart, Zendesk, SoundCloud, Ask.fm, Hulu, and Square.</p>"},{"location":"programming/shellarg/","title":"escapeshellarg()","text":"<p>The <code>escapeshellarg()</code> function is a security-related function used in PHP, a popular server-side scripting language. This function is designed to escape shell arguments, making it safer to pass user-supplied data to shell commands within PHP scripts. It's an important tool for preventing a type of security vulnerability known as Command Injection.</p> <p>The primary purpose of <code>escapeshellarg()</code> is to escape any characters in a string that might be used maliciously in a shell command. When a PHP script incorporates user input into shell commands, <code>escapeshellarg()</code> ensures that the input is treated as a single argument by adding single quotes around the input string and escaping any existing single quotes. This means that even if the user input contains shell command syntax, it won't be executed as part of the command.</p> <p>In PHP, the function is used as follows:</p> <pre><code>string escapeshellarg ( string $arg )\n</code></pre> <p>This will take the string <code>$arg</code> and return a version that is safe to use as a shell argument.</p> <p>In the context of hacking or security, <code>escapeshellarg()</code> plays a role in preventing shell injection attacks.</p> <ol> <li>Shell Injection Attacks: This type of attack occurs when an attacker is able to execute arbitrary shell commands on a server. This can happen if a PHP script takes user input (like form data or URL parameters) and passes it to a shell command without proper sanitization.</li> <li>Exploitation Scenario: For instance, if a PHP script uses user input to construct a shell command for file operations, database backups, etc., without sanitization, an attacker could inject additional commands or alter the intended command for malicious purposes.</li> <li>Prevention with <code>escapeshellarg()</code>: By using <code>escapeshellarg()</code>, the script ensures that any user input is safely encapsulated as a single argument to the shell command, thus preventing it from being interpreted as something else or breaking out into additional commands.</li> </ol> <p>Some examples without escapeshellarg():</p> <pre><code>$input = $_GET['user_input']; // User-supplied data\nsystem(\"somecommand \" . $input);\n</code></pre> <p>In this case, if <code>user_input</code> contains malicious shell commands, they could be executed.</p> <p>With escapeshellarg():</p> <pre><code>$input = escapeshellarg($_GET['user_input']);\nsystem(\"somecommand \" . $input);\n</code></pre> <p>Here, even if <code>user_input</code> contains malicious content, it will be treated as a single, safe argument.</p>"},{"location":"programming/shexec/","title":"shell_exec","text":"<p>The <code>shell_exec</code> function in PHP is used to execute shell commands from a PHP script and return the complete output as a string. It's similar to the exec function but with a key difference in how the output is handled. While <code>shell_exec</code> provides useful functionality for running external programs, it can pose serious security risks if not used correctly.</p> <p>The primary security risk with <code>shell_exec</code> is the potential for command injection attacks. If user-provided data is not properly sanitized, an attacker can inject and execute malicious commands on the server.</p> <p><code>shell_exec</code> can execute any command that the server\u2019s shell can execute, which can lead to unauthorized system access, data leakage, or server compromise.</p>"},{"location":"programming/small/","title":"Smalltalk","text":"<p>Smalltalk is a high-level, dynamically typed, reflective programming language and powerful development environment. Created in the 1970s at Xerox PARC by Alan Kay and others, Smalltalk played a significant role in the history of [[object-oriented programming]] (OOP) and influenced the development of many modern programming languages, including Objective-C, Python, Ruby, and Java.</p> <p>Everything in Smalltalk is an object, from numbers and strings to classes themselves. This uniformity provides a high degree of flexibility and expressiveness. In Smalltalk, types are associated with objects, not variables. This means that variables can refer to objects of any type, and type checks are performed at runtime.</p> <p>Smalltalk supports reflection, which means it can inspect and modify its structure and behavior at runtime. Smalltalk was one of the first languages to be accompanied by an integrated development environment (IDE), featuring a rich graphical user interface, an incremental compiler, and tools for debugging and code browsing.</p> <p>Smalltalk uses a unique message-sending syntax for method invocation, which is highly readable and expressive. Smalltalk had a significant impact on the development and popularization of object-oriented programming, a paradigm that emphasizes data encapsulation, inheritance, and polymorphism.</p> <p>The Smalltalk IDE introduced ideas such as \"live\" coding and the concept of an image-based environment, where all objects and code exist in a persistently running state. Many fundamental OOP design patterns were first identified and formulated in the Smalltalk community.</p> <p>An example of code:</p> <pre><code>\"Define a new class named Counter with one instance variable count\"\nCounter := Object subclass: #Counter\n    instanceVariableNames: 'count'\n    classVariableNames: ''\n    poolDictionaries: ''\n    category: 'Demo'.\n\n\"Define a method to initialize the counter\"\nCounter &gt;&gt; initialize\n    count := 0.\n\n\"Define a method to increment the count\"\nCounter &gt;&gt; increment\n    count := count + 1.\n\n\"Creating and using an instance of Counter\"\n| myCounter |\nmyCounter := Counter new.\nmyCounter initialize.\nmyCounter increment.\nTranscript show: myCounter count printString; cr.  \"Prints the count to the Transcript\"\n</code></pre> <p>Info</p> <p>In this example, a new class <code>Counter</code> is defined with methods to initialize and increment a count. An instance of <code>Counter</code> is then created, initialized, and used.</p>"},{"location":"programming/snuffle/","title":"Snuffleupagus","text":"<p>Snuffleupagus is a security module for PHP, primarily designed to strengthen the security of PHP applications by providing powerful and flexible protection mechanisms against various kinds of attacks. It's often used as a modern alternative to older tools like Suhosin or Hardening-Patch, offering a more up-to-date approach to securing PHP environments.</p> <p>It allows administrators to virtually patch vulnerabilities in their PHP applications without modifying the actual code. This is particularly useful for addressing security issues in third-party code or when immediate code fixes are not feasible. </p> <p>It also provides various configurations to mitigate common vulnerabilities and attack techniques, such as SQL injection, Remote Code Execution (RCE), Local File Inclusion (LFI), and others. Admins can write custom rules to tailor the security settings to their specific environment and needs. These rules can block, allow, or log certain PHP functions and behaviors based on configurable criteria.</p> <p>It offers robust logging features, helping administrators monitor and respond to potential security incidents. It also strengthens the PHP setup by hardening various configuration settings, reducing the attack surface of PHP applications.</p> <p>Snuffleupagus is part of a defense-in-depth strategy, adding an additional layer of security to PHP applications. Its ability to enforce flexible and powerful security policies makes it a valuable tool for protecting against zero-day vulnerabilities and other emerging threats.</p> <p>Snuffleupagus is installed as a PHP extension and requires configuration through its specific syntax. The configuration process involves creating rules that define what actions to take when certain conditions are met in PHP code execution.</p>"},{"location":"programming/sod/","title":"Sodium","text":"<p>Sodium is a modern, easy-to-use software library for encryption, decryption, signatures, password hashing, and more. It's a part of the broader Libsodium project, which is a portable, cross-platform fork of the NaCl (Networking and Cryptography Library) project. Sodium is designed to be fast, secure, and straightforward to use, even for those who are not cryptography experts.</p> <p>It offers state-of-the-art cryptographic algorithms which are chosen for their strong security properties and resistance to attacks. These include algorithms like ChaCha20 for encryption, Poly1305 for message authentication, Curve25519 for key exchange, and Ed25519 for digital signatures.</p> <p>Sodium has a user-friendly API that abstracts the complexity of cryptographic operations, making it accessible for developers with varying levels of expertise in cryptography. The library is optimized for speed without compromising security. It's suitable for performance-critical applications.</p> <p>Libsodium works across multiple platforms, including Windows, macOS, and various Unix-like systems, making it a versatile choice for a wide range of applications. Sodium is suitable for a variety of applications, including securing network communication, encrypting files, authenticating messages, and securely hashing passwords.</p> <p>It provides functions for encrypting and decrypting data, ensuring confidentiality. Sodium can be used to implement secure communication protocols, both for client-server models and peer-to-peer setups. It allows for the creation and verification of digital signatures, ensuring data integrity and non-repudiation.</p> <p>Sodium offers robust password hashing functions, which are essential for securely storing user passwords.</p> <p>Starting with PHP 7.2, Sodium became a core extension of PHP, reflecting its importance and utility in modern web development. This integration allows PHP developers to easily use Sodium's cryptographic capabilities in their applications without needing to install additional libraries.</p> <p>In PHP, using Sodium might look something like this:</p> <pre><code>// Key pair generation for asymmetric encryption\n$keypair = sodium_crypto_box_keypair();\n\n// Public and secret keys extraction\n$publicKey = sodium_crypto_box_publickey($keypair);\n$secretKey = sodium_crypto_box_secretkey($keypair);\n\n// Encrypting a message\n$nonce = random_bytes(SODIUM_CRYPTO_BOX_NONCEBYTES);\n$message = 'This is a secret message.';\n$encrypted = sodium_crypto_box($message, $nonce, $keypair);\n\n// Decrypting the message\n$decrypted = sodium_crypto_box_open($encrypted, $nonce, $keypair);\n</code></pre>"},{"location":"programming/sprintf/","title":"sprintf","text":"<p><code>sprintf</code> is a function in the C programming language used for formatted output to a string. It's part of the C standard library and is used to compose a string with the same text that would be printed if the format string was used with printf, but instead of being printed, the content is stored in a string.</p> <p>The syntax is:</p> <pre><code>int sprintf(char *str, const char *format, ...);\n</code></pre> <ul> <li><code>str</code>: Pointer to a buffer where the resulting C-string is stored.</li> <li><code>format</code>: C string that contains a format string that follows the same specifications as <code>printf</code>.</li> </ul> <p>The primary vulnerability associated with <code>sprintf</code> is buffer overflow. This occurs because <code>sprintf</code> does not perform bounds checking on the output buffer. If the formatted data exceeds the size of the buffer, it can overflow, overwriting adjacent memory, which can lead to undefined behavior, including crashing the program, corrupting data, or creating a security vulnerability.</p> <p>An example of exploitation could be the following C program:</p> <pre><code>char buffer[50];\nchar *userInput = \"Very long input string that exceeds 50 characters...\";\nsprintf(buffer, \"Input: %s\", userInput);\n</code></pre> <p>In this example, if <code>userInput</code> is longer than what <code>buffer</code> can hold, it will result in a buffer overflow. An attacker could exploit this by injecting code into <code>userInput</code> and using the overflow to overwrite a return address or other critical data in memory, potentially gaining control of the program's execution flow.</p> <p>You should use safer variants like <code>snprintf</code>, which takes an additional parameter specifying the size of the buffer and ensures that the written string does not exceed this size:</p> <pre><code>snprintf(buffer, sizeof(buffer), \"Input: %s\", userInput)\n</code></pre> <ul> <li>Input Validation: Always validate the length and content of input before processing it.</li> <li>Secure Coding Practices: Adopt secure coding practices and use modern programming languages or frameworks that provide safer alternatives and mitigate such risks.</li> </ul>"},{"location":"programming/sql/","title":"Structured Query Language","text":"<p>Structured query language (SQL) is a programming language for storing and processing information in a relational database. A relational database stores information in tabular form, with rows and columns representing different data attributes and the various relationships between the data values. You can use SQL statements to store, update, remove, search, and retrieve information from the database. You can also use SQL to maintain and optimize database performance.</p>"},{"location":"programming/stringfilt/","title":"String Filters","text":"<p>In PHP, string filters are a part of the filter extension, which provides a unified way to sanitize and validate data. These filters are specifically designed to process string data, ensuring it meets certain criteria for safety and correctness before it's used within an application. String filters in PHP fall into two main categories: sanitization and validation.</p> <p>Sanitization filters in PHP are used to \"clean\" the input data by removing or encoding unwanted characters. This is crucial for preventing security issues like Cross-Site Scripting (XSS) attacks. Some common ones include:</p> <ol> <li><code>FILTER_SANITIZE_STRING</code>: This filter strips tags and optionally strips or encodes special characters. It's a general-purpose string sanitizer.</li> <li><code>FILTER_SANITIZE_EMAIL</code>: This sanitizes the string to be safe for use as an email address by removing characters that are illegal in email addresses.</li> <li><code>FILTER_SANITIZE_URL</code>: Similar to <code>FILTER_SANITIZE_EMAIL</code>, but for URLs, removing all characters except those allowed in a URL.</li> <li><code>FILTER_SANITIZE_SPECIAL_CHARS</code>: This filter encodes special characters into HTML entities. For example, <code>&lt;</code> becomes <code>&amp;lt;</code> and <code>&gt;</code> becomes <code>&amp;gt;</code>. It's useful for preparing data to be output in an HTML context.</li> <li><code>FILTER_SANITIZE_FULL_SPECIAL_CHARS</code> / <code>FILTER_SANITIZE_ENCODED</code>: These filters offer more comprehensive encoding of special characters.</li> </ol> <p>Validation filters are used to check if the input meets certain criteria. Unlike sanitization filters, they don't modify the data; they just return a boolean indicating whether the data is valid.</p> <ol> <li><code>FILTER_VALIDATE_EMAIL</code>: Checks if the value is a valid email address.</li> <li><code>FILTER_VALIDATE_URL</code>: Checks if the value is a valid URL.</li> <li><code>FILTER_VALIDATE_REGEXP</code>: This is a versatile filter that uses regular expressions to validate the value of the string.</li> </ol> <p>An example of them includes:</p> <pre><code>// Sanitizing a string\n$dirty_string = \"&lt;script&gt;alert('XSS');&lt;/script&gt;\";\n$clean_string = filter_var($dirty_string, FILTER_SANITIZE_STRING);\n\n// Validating an email address\n$email = \"test@example.com\";\nif (filter_var($email, FILTER_VALIDATE_EMAIL)) {\n    echo \"Valid email address\";\n} else {\n    echo \"Invalid email address\";\n}\n\n// Sanitizing a URL\n$url = \"http://example.com/?param=&lt;script&gt;alert('XSS');&lt;/script&gt;\";\n$clean_url = filter_var($url, FILTER_SANITIZE_URL);\n</code></pre> <p>PHP string filters, when used correctly, significantly improve the security of a PHP application by sanitizing and validating user inputs. However, like any tool, their effectiveness depends on how they are used. There are scenarios where reliance on string filters alone might not be sufficient for security, potentially leading to vulnerabilities:</p> <ol> <li>Inadequate Usage: If a developer uses a string filter that's inappropriate for the specific type of data being handled, it may not effectively sanitize or validate the input. For example, using <code>FILTER_SANITIZE_STRING</code> to sanitize URLs or email addresses may not be sufficient.</li> <li>Complex Input Data: Certain types of complex input data might require more sophisticated validation than what basic string filters provide. Custom validation logic might be necessary alongside the use of filters.</li> <li>Bypass Techniques: Attackers may use sophisticated techniques or character encodings that bypass the sanitization done by basic string filters. This is particularly true for inputs that will be used in different contexts (like database, HTML, JavaScript), where different types of escaping or sanitization are required.</li> <li>Dependence on Default Behavior: The default behavior of some PHP filters might not be strict enough for certain applications. It's important to understand exactly what a filter does and doesn't do.</li> <li>Inherent Limitations: Some filters have inherent limitations. For instance, <code>FILTER_VALIDATE_EMAIL</code> checks if the format of an email is correct, but it doesn't verify if the email address actually exists or is operational.</li> <li>Outdated Practices: Over time, certain practices may become outdated due to changes in standards or the discovery of new vulnerabilities. It's important to keep up with current best practices in PHP security.</li> </ol>"},{"location":"programming/swift/","title":"Swift","text":"<p>Swift is a powerful and intuitive programming language created by Apple for building apps for iOS, macOS, watchOS, and tvOS. It's designed to be fast, modern, safe, and interactive, and it represents a departure from the Objective-C language historically used for Apple development. Swift combines features from both C and Objective-C, without having direct built-in C compatibility.</p> <p>Swift places a strong emphasis on safety and performance. Its syntax encourages writing clean and readable code, which is also less prone to errors. It introduces a strict typing system and automatic memory management, which help prevent common programming errors like null pointer dereferencing and buffer overflow.</p> <p>Swift is designed for performance. Its compiler is optimized to generate highly optimized code for iOS and macOS platforms. Swift also supports concurrent programming, enabling developers to write efficient, multi-threaded code. Swift has a concise and expressive syntax, making the code easier to read and write. It eliminates a lot of boilerplate code required in Objective-C.</p> <p>Swift Playgrounds are an interactive environment that allows developers to write Swift code and see the results immediately, without the need for compiling and running an app. Swift can coexist alongside Objective-C in the same project, allowing for easy adoption in existing Apple applications.</p> <p>Swift is primarily used for developing applications for Apple's platforms - iOS for iPhones and iPads, macOS for Mac computers, as well as watchOS for Apple Watch and tvOS for Apple TV. Swift is also gaining traction in server-side development, thanks to frameworks like Vapor and Kitura, which enable developers to use Swift to build backend applications.</p> <p>An example of Swift code includes:</p> <pre><code>func greet(name: String) -&gt; String {\n    return \"Hello, \\(name)!\"\n}\n\nprint(greet(name: \"World\")) // Prints \"Hello, World!\"\n</code></pre> <p>This simple function demonstrates Swift's string interpolation feature and its clean, concise syntax.</p>"},{"location":"programming/sys/","title":"sys","text":"<p>The <code>sys</code> module in Python is a standard library module which provides access to some variables used or maintained by the Python interpreter and to functions that interact strongly with the interpreter. It is part of Python's standard utility modules and is not specifically designed for hacking. </p> <p>The <code>sys</code> module is used for manipulating the Python runtime environment and for interacting with the interpreter.</p> <p><code>sys.argv</code> is a list in Python, which contains the command-line arguments passed to the script. It allows scripts to take input from users via the command line. This includes information like the largest integer (<code>sys.maxsize</code>), the Python search path (<code>sys.path</code>), and the current version of the Python interpreter.</p> <p><code>sys.stdin</code>, <code>sys.stdout</code>, and <code>sys.stderr</code> represent the standard input, output, and error streams, respectively. The <code>sys.exit()</code> function allows the programmer to exit from Python. The optional argument passed to <code>sys.exit()</code> indicates whether the program is terminating successfully (<code>0</code>) or with an error (<code>non-zero</code>). Functions like <code>sys.modules</code> provide information about loaded modules, and <code>sys.getsizeof()</code> returns the size of an object in bytes.</p> <p>The <code>sys</code> module is as secure as any standard Python module. The security risks associated with it come more from how it's used rather than the module itself. If a script with malicious intent uses the <code>sys</code> module as part of its operation, the security implications stem from the overall intent and action of the script, not directly from the <code>sys</code> module.</p> <p>When writing Python scripts, using the <code>sys</code> module is generally safe. Problems arise only if the script itself is doing something harmful or if it is poorly coded, leading to unintended behavior (e.g., incorrect handling of command-line arguments).</p>"},{"location":"programming/system/","title":"system","text":"<p>The <code>system</code> function in PHP is used to execute an external program or command and display the output. It's part of PHP's functionality for interfacing with the underlying operating system. Like other similar functions (exec, shell_exec, passthru), <code>system</code> allows PHP scripts to run system-level commands, but with specific behavior and output handling.</p> <p>The <code>system</code> function is designed to display the output of the command directly to the browser (or wherever the PHP script output goes). This makes it suitable for commands where you want to see the full output as it's generated.</p> <p>The primary security risk with <code>system</code> is command injection. If user input is incorporated into the command without proper sanitization, it can lead to execution of arbitrary and potentially harmful commands. Because <code>system</code> outputs directly, there's a risk of disclosing sensitive information if the command's output is not properly handled or restricted.</p> <p><code>system</code> might be used for tasks that require the output of system commands, like getting the status of system resources, provided that the output is non-sensitive.</p>"},{"location":"programming/valloc/","title":"VirtualAllocEx","text":"<p><code>VirtualAllocEx</code> is a Windows API function used to allocate memory in the address space of another process. It's part of the Windows memory management functions and is essential for various advanced operations that involve manipulating the memory of other processes.</p> <p><code>VirtualAllocEx</code> allocates a region of memory within the virtual address space of a specified process. The calling process (such as an application or a script) must have appropriate access rights to the target process. This function requires the handle to the process in which memory will be allocated, the desired starting address of the allocation (often set to NULL, letting the system choose the address), the size of the area to allocate, the type of memory allocation, and the type of memory protection desired.</p> <p>In the context of offensive security, such as penetration testing or ethical hacking, <code>VirtualAllocEx</code> can be used in several ways, including DLL Injection and Process Manipulation:</p> <p>DLL Injection:</p> <ul> <li>Allocating Memory for DLL Path: <code>VirtualAllocEx</code> is used to allocate memory in a target process\u2019s address space to store the path of a malicious DLL.</li> <li>Remote Thread Creation: After the path is written into the allocated memory, functions like <code>CreateRemoteThread</code> are used to create a thread in the target process that calls LoadLibrary. <code>LoadLibrary</code> loads the DLL from the specified path, effectively injecting the DLL into the target process.</li> </ul> <p>Process Manipulation:</p> <ul> <li>Altering Process Behavior: It can be used to allocate memory in a process for injecting shellcode. This shellcode can then be executed within the context of the target process, altering its behavior or enabling unauthorized actions.</li> </ul> <p>An example of VirtualAllocEx for DLL injection may be:</p> <ol> <li>An attacker gains access to a system and identifies a process they want to inject a DLL into.</li> <li>The attacker uses <code>VirtualAllocEx</code> to allocate memory in the target process's address space.</li> <li>The path to the malicious DLL is written into this allocated space.</li> <li>The attacker then creates a remote thread in the target process that calls <code>LoadLibrary</code> using the address of the memory with the DLL path.</li> <li>The target process loads the DLL, executing the attacker's code.</li> </ol>"},{"location":"programming/vbasic/","title":"Visual Basic","text":"<p>Visual Basic (VB) is a programming language and development environment created by Microsoft. It's known for its simplicity and ease of use, particularly in building Windows-based applications with graphical user interfaces (GUIs).</p> <p>Visual Basic played a significant role in popularizing event-driven programming and visual rapid application development (RAD) in the 1990s.</p> <p>Visual Basic was one of the first tools to provide a rapid application development (RAD) environment, allowing developers to quickly build and prototype Windows applications using a drag-and-drop interface for UI elements.</p> <p>VB popularized the concept of event-driven programming. In VB, code is generally executed in response to various events, such as button clicks or user actions. One of Visual Basic's strengths was its ease of use, making programming accessible to a broader range of people, including those without a formal computer science background.</p> <p>VB is based on the BASIC programming language (Beginner's All-purpose Symbolic Instruction Code), known for its simplicity. VB extended BASIC with object-oriented features and a powerful set of tools for interface design.</p> <p>VB came with an integrated development environment (IDE), which included a code editor, a debugger, and a GUI editor. VB made heavy use of the Component Object Model, which allowed for the integration of components and controls to enhance the functionality of applications.</p> <p>With the advent of the .NET framework, Microsoft introduced VB.NET, which brought Visual Basic into the .NET ecosystem, offering a more modern, object-oriented version of the language. VB was commonly used for developing database-driven applications, offering straightforward methods for database integration and manipulation.</p>"},{"location":"programming/vbnet/","title":"VB.NET","text":"<p>VB.NET (Visual Basic .NET) is a modern, object-oriented programming language developed by Microsoft as part of its .NET initiative. It is an evolution of the original Visual Basic language, designed to provide a comprehensive environment for developing software applications on the Windows platform.</p> <p>VB.NET is fully integrated with the .NET Framework, which provides a vast library of classes and functions for building Windows-based applications, web services, and more. Unlike its predecessor, VB.NET is a fully object-oriented language, supporting concepts like inheritance, polymorphism, and encapsulation, which makes it suitable for large-scale application development.</p> <p>VB.NET retains the familiar syntax of classic Visual Basic but extends it with new features to support modern programming practices and OOP paradigms. VB.NET code can interoperate seamlessly with code written in other .NET languages, such as C#, due to the common runtime environment of the .NET Framework.</p> <p>VB.NET is commonly used with Microsoft's integrated development environment (IDE), Visual Studio, which provides tools for designing, coding, testing, and deploying applications. It supports the creation of desktop applications using Windows Forms and Windows Presentation Foundation (WPF), providing a range of tools for building graphical user interfaces.</p> <p>VB.NET can be used with ASP.NET, a server-side web application framework, for creating dynamic web pages, web applications, and web services. It offers robust capabilities for database access, using ADO.NET for connectivity with various types of databases.</p>"},{"location":"programming/vbscript/","title":"VBScript","text":"<p>VBScript\u00a0(Visual Basic Script) is developed by Microsoft with the intention of developing dynamic web pages. It is client-side scripting language like JavaScript. VBScript is a light version of Microsoft Visual Basic. The syntax of VBScript is very similar to that of Visual Basic. If you want your webpage to be more lively and interactive, then you can incorporate VBScript in your code.</p> <p>VBScript is just a scripting language. So, it cannot run its code on its own. It needs a bigger programming language to host it.</p>"},{"location":"programming/wrap/","title":"Data Wrapper","text":"<p>In PHP, the <code>data</code> wrapper is a type of stream wrapper that allows data to be read from or written to a string in the same way as you would with a file. This feature is particularly useful for manipulating data in string format using file handling functions, without the need to create a physical file on the file system.</p> <p>The <code>data</code> wrapper is commonly used in scenarios where you want to treat a string as a stream resource, which enables you to use PHP's file system functions (like fopen(), fwrite(), fread(), etc.) on data stored in a string.</p> <p>A data URI using the data wrapper in PHP follows the format:</p> <pre><code>data:[&lt;mediatype&gt;][;base64],&lt;data&gt;\n</code></pre> <ul> <li><code>&lt;mediatype&gt;</code> is the MIME type of the data, like <code>text/plain</code> or <code>image/png</code>.</li> <li><code>base64</code> is an optional parameter indicating that the data is base64-encoded.</li> <li><code>&lt;data&gt;</code> is the actual data you want to encode in the URI.</li> </ul> <p>An example of how you might use it:</p> <pre><code>// Data URI containing plain text\n$data = 'data:text/plain;base64,' . base64_encode('Hello, World!');\n\n// Open a stream to the data URI\n$stream = fopen($data, 'r');\n\n// Read from the stream\n$content = fread($stream, 1024);\n\n// Close the stream\nfclose($stream);\n\n// Output the content\necho $content;  // Outputs: Hello, World!\n</code></pre> <p>Info</p> <p>A simple string 'Hello, World!' is base64-encoded and used to create a data URI. This URI is then opened as a stream, and the content is read back from the stream.</p> <p>The <code>data</code> wrapper itself in PHP is not inherently vulnerable; however, like any tool, its security depends on how it's used.</p> <p>The <code>data</code> wrapper is a feature that allows data to be treated as a file or stream, which can be extremely useful, but certain use cases can introduce security risks if not handled properly.</p> <p>If the data used in a <code>data</code> URI comes from an untrusted source, it must be properly validated and sanitized to avoid security risks such as code injection or cross-site scripting (XSS). This is particularly important when handling HTML, JavaScript, or other types of executable content.</p> <p>The <code>data</code> wrapper is often used with base64 encoded data. While base64 encoding/decoding itself is not a security risk, it's essential to ensure that the decoded data is safe and expected, especially if it's dynamically generated or derived from user input.</p> <p>Since the <code>data</code> wrapper allows data to be encoded directly in a URI, there's a potential risk of resource exhaustion if very large data strings are used. This can lead to performance degradation or crashing of the script or server.</p> <p>When used in a web context (such as embedding images in HTML or CSS), it's important to ensure that the data URIs do not contain malicious content, especially when the content is dynamically generated based on user input or external sources.</p>"},{"location":"programming/xml/","title":"Extensible Markup Language (XML)","text":"<p>Extensible Markup Language (XML) lets you define and store data in a shareable manner. XML supports information exchange between computer systems such as websites, databases, and third-party applications. Predefined rules make it easy to transmit data as XML files over any network because the recipient can use those rules to read the data accurately and efficiently.</p> <p>Extensible Markup Language (XML) is a markup language that provides rules to define any data. Unlike other programming languages, XML cannot perform computing operations by itself. Instead, any programming language or software can be implemented for structured data management.</p> <p>For example, consider a text document with comments on it. The comments might give suggestions like these:</p> <ul> <li>Make the title bold</li> <li>This sentence is a header</li> <li>This word is the author</li> </ul> <p>Such comments improve the document\u2019s usability without affecting its content. Similarly, XML uses markup symbols to provide more information about any data. Other software, like browsers and data processing applications, use this information to process structured data more efficiently.</p> <p>An example XML document is:</p> <pre><code>&lt;book&gt;\n&lt;title&gt; Learning Amazon Web Services &lt;/title&gt;\n&lt;author&gt; Mark Wilkins &lt;/author&gt;\n&lt;/book&gt;\n</code></pre>"},{"location":"programming/xmlhr/","title":"XMLHttpRequest","text":"<p>XMLHttpRequest is an API in JavaScript that provides client functionality for transferring data between a client and a server. It allows web pages to make HTTP requeststo web servers, which is essential for retrieving or submitting data without having to reload the entire page.</p> <p>This API is a key component in Ajax (Asynchronous JavaScript and XML) programming.</p> <p>It can send requests to the server asynchronously, meaning the page doesn't need to be reloaded for the entire web page to update. It can be used to transfer various types of data, including text, XML, JSON, and binary data (like images and videos).</p> <p>XMLHttpRequest supports several HTTP methods, such as GET, POST, PUT, DELETE, etc., allowing for a wide range of operations like fetching data, submitting forms, and updating or deleting resources.</p> <p>The response from a server can be processed in various formats, such as text, XML, or JSON. The API provides ways to handle these responses and update the web page accordingly.</p> <p>You can set custom HTTP headers and send credentials (like cookies or authentication data) with requests.</p>"},{"location":"programming/zipwrap/","title":"ZIP Wrapper","text":"<p>The ZIP PHP wrapper is a feature in PHP that allows for the manipulation of ZIP archives using the standard file handling functions. It provides a way to read from and write to ZIP files directly through the PHP's file stream interface, as if they were regular file systems. This feature simplifies the process of working with ZIP files in PHP scripts.</p> <p>It allows developers to use familiar file handling functions like fopen(), fread(), fwrite(), etc., to interact with ZIP files. Developers can directly access and manipulate the contents of a ZIP archive without needing to extract the files to a temporary location first. It's possible to read from and write to individual files within a ZIP archive, just like working with regular files.</p> <p>Some examples of its usage include opening a file in a ZIP archive:</p> <pre><code>$zip = 'zip://archive.zip#file.txt';\n$file = fopen($zip, 'r');\n$content = fread($file, 1000);\nfclose($file);\n</code></pre> <p>Info</p> <p>This opens a file named file.txt inside archive.zip, reads its content and closes the file.</p> <p>Or creating a new file in a ZIP archive:</p> <pre><code>$zip = 'zip://archive.zip#newfile.txt';\n$file = fopen($zip, 'w');\nfwrite($file, 'Hello, World!');\nfclose($file);\n</code></pre> <p>Info</p> <p>This creates a file \"newfile.txt\" inside \"archive.zip\" and writes Hello World! into it.</p> <p>The PHP ZIP extension must be installed and enabled to use the ZIP PHP wrapper. While local ZIP archives can be modified, remote ZIP archives (accessed via HTTP or FTP) are read-only. For very large ZIP files, using the ZIP PHP wrapper might not be the most efficient approach due to memory usage and performance considerations.</p>"},{"location":"protocols/activesync/","title":"ActiveSync","text":"<p>ActiveSync is a synchronization protocol developed by Microsoft that enables mobile devices to synchronize data with Microsoft Exchange Server. It's widely used to sync email, calendar events, contacts, tasks, and other information between mobile devices and enterprise servers, ensuring that users have consistent access to important data across all their devices.</p> <p>ActiveSync allows for the synchronization of emails, calendar information, contacts, tasks, and notes between servers and mobile devices. This feature enables real-time synchronization of emails and other data. When new data is available, it's automatically \"pushed\" to the mobile device without the user having to manually sync or pull the data.</p> <p>ActiveSync allows administrators to enforce security policies on devices connected to the Exchange Server, such as password requirements, data encryption, or remote wipe capabilities in case the device is lost or stolen.</p> <p>The protocol is designed to be efficient in terms of data transmission and battery usage, making it practical for use on mobile devices. ActiveSync has been widely adopted by various mobile device manufacturers and is supported on a range of platforms, including iOS, Android, and Windows Phone.</p> <p>ActiveSync is primarily used to provide access to enterprise email on mobile devices, ensuring that users stay connected while on the go. It keeps calendar events and contacts up to date across desktop and mobile devices, which is crucial for business users.</p> <p>ActiveSync is a key component in enterprise mobility, allowing employees to access corporate data securely from their personal or company-provided mobile devices.</p> <p>In Microsoft Exchange environments, ActiveSync plays a vital role in enabling mobile access to Exchange mailboxes. It's a core feature of Exchange Server and Exchange Online (part of Microsoft 365).</p> <p>While ActiveSync facilitates data access on mobile devices, it also raises security considerations, particularly in terms of data protection and access control. Enterprises using ActiveSync typically implement policies and security measures to mitigate potential risks associated with mobile data access.</p>"},{"location":"protocols/ajp/","title":"AJP","text":"<p>AJP, short for Apache JServ Protocol, is a binary protocol that was designed to allow a standalone web server to communicate with an application server that executes Java Servlets and JavaServer Pages (JSP). Initially developed as part of the Apache JServ project, AJP has evolved and is commonly used with Apache Tomcat and other application servers.</p> <p>The primary purpose of AJP is to allow efficient communication between a web server (like Apache HTTP Server) and an application server (like Apache Tomcat). This is typically used in environments where you have web server fronting an application server.</p> <p>AJP is a binary protocol, making it more efficient than HTTP for server-to-server communication, especially for forwarding requests and responses. In many configurations, Apache HTTP Server serves static content directly and forwards requests for dynamic content (like Servlets and JSPs) to an Apache Tomcat (or other application server) instance via AJP.</p> <p>AJP is often used in load-balanced environments where multiple application server instances are behind a web server or a Load Balancer. AJP has several versions, with AJP13 (or AJP v1.3) being the most commonly used. It operates over TCP and uses a default port of 8009.</p> <p>Setting up AJP typically involves configuring both the web server and the application server to enable them to communicate over the AJP protocol. </p> <p>AJP connections should be secured, especially in network environments where the traffic might pass through untrusted networks. Recent security concerns have led to increased scrutiny of AJP configurations to prevent unauthorized access.</p> <p>With the rise of more integrated application servers that can efficiently serve both static and dynamic content, the use of AJP has become less common. However, it is still used in certain legacy systems or in specific architectural scenarios.</p>"},{"location":"protocols/amqp/","title":"Advanced Message Queuing Protocol (AMQP)","text":"<p>The Advanced Message Queuing Protocol (AMQP) is an open standard protocol for message-oriented middleware. The primary goal of AMQP is to enable interoperability among various message systems and applications. It provides a platform-independent method to ensure messages are safely and efficiently transferred between systems, making it a popular choice for enterprise messaging solutions.</p> <p>AMQP is used in message-oriented middleware, allowing systems to communicate via messages in a reliable and scalable way. It\u2019s designed to facilitate complex messaging scenarios between distributed and diverse systems.</p> <p>Unlike protocols like HTTP or SMTP, which are text-based, AMQP is a binary protocol. This makes it more efficient for network transmission and better suited for high-volume messaging. A key feature of AMQP is its emphasis on interoperability, enabling different software systems, possibly implemented in different programming languages on different platforms, to communicate.</p> <p>AMQP provides various features to ensure reliable message delivery, including message acknowledgment, durable subscriptions, and transactions. It also supports secure communications through SSL/TLS.</p> <p>AMQP enables various patterns of communication, including point-to-point, publish-subscribe, and request-response. It allows messages to be queued, stored, and forwarded, handling complex routing scenarios. AMQP uses the concept of exchanges and bindings to route messages to the correct queues based on attributes like routing keys or headers.</p> <p>AMQP 1.0, the version standardized by OASIS (Organization for the Advancement of Structured Information Standards), focuses on the message-oriented model and is not backward compatible with earlier, broker-centric versions (0-9-1, 0-10).</p> <p>It\u2019s widely used in financial services, telecommunications, and other industries where robust messaging systems are critical. Several open-source and commercial AMQP implementations exist, such as Apache Qpid, RabbitMQ, and Microsoft Azure Service Bus.</p> <p>While similar to other messaging protocols like MQTT or JMS, AMQP is distinguished by its binary nature, interoperability, and reliability features.</p>"},{"location":"protocols/binary/","title":"Binary Protocol","text":"<p>A binary protocol is a communication protocol that uses binary data encoding for transmitting data over a network. Unlike text-based protocols that use readable text formats (like HTTP, which uses ASCII text for communication), binary protocols represent data in binary form, which is more efficient for computers to parse and process.</p> <p>In binary protocols, data is encoded as sequences of bytes. These bytes represent various types of information, such as commands, identifiers, lengths, and actual data payloads.</p> <p>Binary protocols are generally more efficient than text-based protocols in terms of data size and processing speed. They require less bandwidth and are faster for computers to parse because they are closer to the machine's native language.</p> <p>Binary protocols are commonly used in situations where performance and efficiency are critical. This includes internal communication in distributed systems, database query protocols, file transfer protocols, and communication in high-performance computing environments.</p> <p>Examples of binary protocols include the Advanced Message Queuing Protocol (AMQP), Google's Protocol Buffers (protobuf), the Remote Procedure Call protocol (RPC), and many database protocols like MySQL\u2019s client/server protocol.</p> <p>While binary protocols are efficient, they can be more complex to implement and debug compared to text-based protocols. Reading and interpreting binary data requires specific tools and understanding of the protocol\u2019s structure.</p> <p>In custom network protocol design, binary protocols are often favored for their efficiency. However, careful planning is required to define the protocol's structure and handling mechanisms. Like any protocol, binary protocols need to be designed with security in mind, including considerations for encryption, authentication, and data integrity.</p>"},{"location":"protocols/chap/","title":"CHAP (Challenge Handshake Authentication Protocol)","text":"<p>CHAP (Challenge Handshake Authentication Protocol) is an authentication protocol used in networking that provides a more secure method of ensuring the identity of a remote user, or node, trying to connect to a service or resource. It's commonly used in Point-to-Point Protocol (PPP) connections.</p> <p>Unlike a basic username and password authentication that occurs only at the time of initial connection, CHAP performs repeated authentication at random intervals during the session. This helps protect against unauthorized access in the middle of a connection.</p> <p>CHAP works on a challenge-response mechanism. When a client attempts to establish a connection, the server sends a challenge message to the client. The client responds with a value obtained by using a one-way hash function on the challenge, along with the client's password and a shared secret.</p> <p>The actual password is never sent over the network. Instead, the hash result is transmitted, minimizing the risk of password interception.</p> <p>The CHAP protocol uses a three-way handshake.</p> <ul> <li>The server sends a challenge to the client.</li> <li>The client responds with a value calculated using a hash function.</li> <li>The server checks the response by comparing it to its own calculation of the expected hash value. If they match, the server acknowledges the authentication; otherwise, the connection is terminated.</li> </ul> <p>CHAP is frequently used in PPP networks, including many types of broadband Internet connections (like DSL). CHAP provides more security than the Password Authentication Protocol (PAP), which is another authentication protocol used in PPP connections. PAP transmits passwords in clear text, making them more susceptible to interception.</p> <p>CHAP can be configured for mutual authentication, where both the server and client authenticate each other. If the initial authentication fails, CHAP allows the server to send a new challenge to the client, and the client can try to authenticate again.</p> <p>There are variants of CHAP, such as Microsoft CHAP (MS-CHAP) and MS-CHAP v2, which are used in different networking contexts and provide additional features like stronger encryption methods.</p> <p>In a network using CHAP, both the client and server must be configured with the shared secret for authentication to succeed. This requires careful management of these shared secrets.</p>"},{"location":"protocols/cifs/","title":"CIFS","text":"<p>CIFS (Common Internet File System) is a network file-sharing protocol. It is an enhanced version of the Microsoft-developed SMB (Server Message Block) protocol, used for providing shared access to files, printers, serial ports, and miscellaneous communications between nodes on a network. CIFS is typically used in Windows operating systems for network file and printer sharing.</p> <p>CIFS allows multiple clients on a network to access and manipulate files stored on a server, as well as share printers. It enables the browsing of networked resources, such as files and printers, across a network. CIFS is often considered a version of the SMB protocol. It extends SMB with additional features for Internet compatibility.</p> <p>CIFS includes support for various authentication methods, allowing it to manage access to resources in a networked environment. While most associated with Windows, CIFS clients are available for most Unix-like operating systems, enabling cross-platform file and resource sharing.</p> <p>CIFS was widely used in Windows-based networks for sharing files and printers between machines. CIFS is considered a somewhat legacy protocol, with modern iterations of SMB (like SMB 2 and SMB 3) providing enhancements in terms of performance, security, and additional features. However, the term \"CIFS\" is still sometimes used interchangeably with \"SMB,\" especially in the context of SMB 1.0/CIFS.</p> <p>Over the years, various security vulnerabilities have been identified in CIFS implementations, including susceptibility to man-in-the-middle attacks and unauthorized access. Newer versions of SMB (like SMB 3) offer significant improvements over CIFS in terms of security and performance. It's generally recommended to use the most recent version of SMB that is compatible with your networked devices.</p>"},{"location":"protocols/disco/","title":"DISCO","text":"<p>Microsoft DISCO, in the context of web services, refers to the Discovery of Web Services (DISCO) protocol. This protocol was developed by Microsoft as part of their .NET framework to facilitate the discovery of web services. DISCO is used to publish and locate web services on a network.</p> <p>DISCO was designed to help developers find web services dynamically. It provides a way to publish information about web services so that other applications can locate and use these services. DISCO uses a combination of XML documents and HTTP requests.</p> <p>A DISCO document (<code>.disco</code> file) contains information about the web services offered by a particular server, including URLs to the Web Services Description Language (WSDL) documents. These WSDL documents describe the available services, their methods, and how to communicate with them.</p> <p>Clients use DISCO to send a request to a server, asking for information about the available web services. The server responds with a DISCO document that provides links to the WSDL files for each service. The client can then use these WSDL files to understand how to interact with the services.</p> <p>DISCO can be used in conjunction with Universal Description, Discovery, and Integration (UDDI), another standard for publishing and discovering web services. UDDI registries can store DISCO documents, making it easier for clients to find services across different servers and domains.</p> <p>It's important to note that DISCO is considered a legacy protocol in the context of web services. Modern web service discovery and description are more commonly handled using other protocols and standards, such as WSDL, RESTful APIs, and other service description languages.</p>"},{"location":"protocols/fed/","title":"WS-Federation","text":"<p>WS-Federation (Web Services Federation) is a protocol used for exchanging identity, authentication, and authorization information between different realms or security domains. It is part of the larger WS-Security framework and is commonly used in scenarios involving federated identity management.</p> <p>WS-Federation allows different security realms (e.g., different organizations or different security systems within an organization) to share identity information. This is particularly useful in single sign-on (SSO) implementations where users can access resources across multiple domains with one set of credentials.</p> <p>The protocol typically involves the exchange of security tokens containing claims about a user. These claims can include user identity, roles, group memberships, and other attributes relevant to authentication and authorization. WS-Federation is designed to work across different platforms and technologies, fostering interoperability between various web services and applications.</p> <p>Although WS-Federation is a distinct protocol, it often operates in conjunction with SAML, a standard for exchanging authentication and authorization data between parties.</p> <p>WS-Federation is commonly used to enable SSO across different web applications and services, allowing users to authenticate once and gain access to multiple applications. In enterprise settings, WS-Federation facilitates integration and cooperation between different identity management systems, streamlining access control and user management across organizational boundaries.</p> <p>It enables businesses to integrate their on-premises identity management systems with cloud services, providing seamless access to cloud-based applications.</p> <p>Imagine a company, \"Company A,\" that uses Microsoft's Active Directory for internal user management and wants its employees to access services provided by \"Company B\" without creating new accounts. Company B also has its own user management system. Using WS-Federation, Company A and Company B establish trust, and Company A\u2019s users can use their existing credentials to access services at Company B with SSO, reducing the need for multiple usernames and passwords.</p>"},{"location":"protocols/ftp/","title":"File Transfer Protocol","text":"<p>FTP (File Transfer Protocol)\u00a0is a standard network protocol used for the transfer of files from one host to another over a TCP-based network, such as the Internet.</p> <p>FTP works by opening two connections that link the computers trying to communicate with each other. One connection is designated for the commands and replies that get sent between the two clients, and the other channel handles the transfer of data. </p> <p>During an FTP transmission, there are four commands used by the computers, servers, or proxy servers that are communicating. These are \u201csend,\u201d \u201cget,\u201d \u201cchange directory,\u201d and \u201ctransfer.\u201d</p> <p>While transferring files, FTP uses three different modes: block, stream, and compressed. The stream mode enables FTP to manage information in a string of data without any boundaries between them. The block mode separates the data into blocks, and in the compress mode, FTP uses an algorithm called the Lempel-Ziv to compress the data.</p>"},{"location":"protocols/ftps/","title":"File Transfer Protocol Secure","text":"<p>File Transfer Protocol Secure (FTPS), also known as FTP Secure and FTP-SSL, is an extension of the standard File Transfer Protocol (FTP). It adds support for the Transport Layer Security (TLS) and, formerly, the Secure Sockets Layer (SSL) cryptographic protocols. FTPS should not be confused with SFTP (SSH File Transfer Protocol), which is an entirely different protocol.</p> <p>FTPS uses TLS (or SSL) to encrypt data sent over the network. This encryption secures the data transfer process, protecting the data from being intercepted or read by unauthorized parties. FTPS allows for the authentication of the server and, optionally, the client. This is typically done using digital certificates.</p> <p>Two Modes:</p> <ul> <li>Explicit FTPS (FTPS/E): The client must explicitly request security from an FTPS server and then step up to a TLS-secured connection. It's often referred to as FTPES.</li> <li>Implicit FTPS (FTPS/I): A deprecated mode where TLS security is automatically initiated at the start of the connection. In this mode, an FTPS client is expected to \"speak\" TLS from the outset of the connection.</li> </ul> <p>When an FTPS client connects to an FTPS server, they establish a control connection through which the client can send commands and receive responses. This connection can be secured using TLS/SSL. For transferring files, a separate data connection is established, which can also be secured. During the process, the server (and optionally the client) is authenticated using certificates. All commands and data are encrypted when sent over the network.</p> <p>An extension of FTP with TLS for security. It uses the standard FTP protocol, securing it with TLS/SSL encryption. A different protocol built as part of SSH (Secure Shell). SFTP provides file transfer capability as part of the SSH protocol suite, securing the file transfer by the SSH encryption and authentication mechanisms.</p> <p>FTPS is used in scenarios where secure file transfer is required, such as in corporate networks, banking systems, and other areas where sensitive data is transferred. It is particularly useful in legacy systems where FTP is already in use, and an upgrade to secure file transfer is needed.</p>"},{"location":"protocols/ike/","title":"Internet Key Exchange (IKE)","text":"<p>IKE (Internet Key Exchange) is a protocol used in IPsec (Internet Protocol Security) for ensuring secure, authenticated key exchange and establishing Security Associations (SAs). IKE plays a crucial role in setting up the cryptographic parameters for securing IP communications.</p> <p>IKE automates the process of generating, exchanging, and managing cryptographic keys required for IPsec, and also negotiates the IPsec Security Associations (SAs) parameters. </p> <p>IKE is a fundamental part of the IPsec suite, which provides secure encrypted communication over IP networks. While IPsec handles the actual encryption and decryption of data, IKE ensures that secure keys are used and agreed upon by both parties.</p> <p>IKE operates in two phases:</p> <ul> <li>Phase 1: Establishes a secure channel between the two parties for further negotiation. This phase authenticates the two endpoints and sets up a secure, encrypted channel by exchanging and agreeing on encryption and authentication methods.</li> <li>Phase 2: Negotiates the IPsec SAs parameters to establish the actual IPsec tunnel. This phase uses the secure channel established in Phase 1 to negotiate the details of the IPsec connection, including which encryption and integrity algorithms to use.</li> </ul> <p>IKE uses key exchange protocols like Diffie-Hellman to establish shared secrets between the two parties, ensuring that the keys are not exposed to any eavesdroppers.</p> <p>IKE supports multiple authentication methods, including pre-shared keys, digital certificates, and public key cryptography, to ensure that both communicating parties are who they claim to be. IKE establishes SAs, which are agreements on how IPsec will encrypt and authenticate packets. An SA includes all the parameters needed for execution of encryption and authentication operations.</p> <p>There are two versions of IKE \u2013 IKEv1 and IKEv2. IKEv2 is a newer version that simplifies the protocol and improves upon the security features of IKEv1. It also offers better support for NAT traversal.</p> <p>IKE includes mechanisms for Network Address Translation (NAT) traversal, which is important for enabling IPsec traffic to pass through NAT devices commonly used in internet routing.</p> <p>IKE is widely used in setting up VPN (Virtual Private Network) connections, allowing secure and authenticated communication over untrusted networks like the internet.</p>"},{"location":"protocols/imap/","title":"Internet Message Access Protocol","text":"<p>IMAP allows you to access your email messages wherever you are; much of the time, it is accessed via the Internet. Basically, email messages are stored on servers. Whenever you check your inbox, your email client contacts the server to connect you with your messages. </p> <p>When you read an email message using IMAP, you aren't actually downloading or storing it on your computer; instead, you are reading it off of the server. As a result, it's possible to check your email from several different devices without missing a thing.</p> <p>IMAP only downloads a message when you click on it, and attachments aren't automatically downloaded. This way you're able to check your messages a lot more quickly than POP.</p>"},{"location":"protocols/imaps/","title":"Internet Message Access Protocol Secure (IMAPS)","text":"<p>Internet Message Access Protocol Secure (IMAPS) refers to the use of the Internet Message Access Protocol (IMAP) over an encrypted connection. IMAP is a standard email retrieval protocol used to access and manage a user's email on a mail server, and when it's used in conjunction with security protocols like TLS (Transport Layer Security) or SSL (Secure Sockets Layer), it becomes IMAPS.</p> <p>IMAPS uses SSL/TLS to encrypt the connection between the email client and the email server. This ensures that all communication, including email messages, login credentials, and other transmitted data, is secure and cannot be easily intercepted or read by unauthorized parties. </p> <p>While standard IMAP typically uses port 143, IMAPS usually operates over port 993. Using a designated port helps in managing and securing network traffic more effectively. In addition to encrypting data, SSL/TLS also authenticates the mail server to the email client, helping to prevent man-in-the-middle attacks.</p> <p>When an email client connects to an email server using IMAPS, it initiates a secure connection using SSL/TLS. Once the secure connection is established, the client and server exchange data securely. The client can then retrieve, read, delete, or move emails, or mark them as read/unread, all while ensuring that the data remains encrypted during transit between the server and the client.</p> <p>IMAPS is often compared with POP3S (Post Office Protocol version 3 Secure), another protocol used for retrieving emails securely. The main difference lies in how they handle emails:</p> <ul> <li>IMAP/IMAPS: Allows users to view and manage emails directly on the server. Changes made in the email client are reflected on the server, making IMAP suitable for accessing email from multiple devices.</li> <li>POP3/POP3S: Designed to download emails from the server to the client. Once downloaded, emails are typically deleted from the server.</li> </ul> <p>It encrypts the data protects against eavesdropping and ensures the confidentiality and integrity of the email communication. IMAP allows users to manage their emails directly on the server, which is convenient for users who access their emails from multiple devices.</p>"},{"location":"protocols/ip/","title":"Internet Protocol (IP)","text":"<p>The Internet Protocol (IP) is a set of rules governing the format of data sent over the Internet or other networks. Essentially, IP is the principal communications protocol in the Internet protocol suite for relaying datagrams (packets) across network boundaries. Its routing function enables internetworking and essentially establishes the Internet.</p> <p>IP works by exchanging pieces of information called packets. A packet is a small segment of data that includes the data being sent and control information about sending and receiving it.</p> <p>IP provides a unique address for each computer on the network, known as an IP address. This address is used to identify the sender or receiver of information packets. There are two versions of IP in use today:</p> <ul> <li>IPv4: The fourth version of IP and the first to be widely deployed. IPv4 uses 32-bit addresses, allowing for 4.3 billion unique addresses.</li> <li>IPv6: Developed to deal with the long-anticipated problem of IPv4 address exhaustion. IPv6 uses 128-bit addresses, allowing for a significantly larger number of devices to be simultaneously connected to the Internet.</li> </ul> <p>IP is responsible for routing packets from the source host to the destination host, potentially across multiple nodes and networks. IP is a connectionless protocol, meaning there's no continuous connection between the end points that are communicating. </p> <p>Each packet that travels through the Internet is treated as an independent unit of data without any relation to any other unit of data. Large data sets are broken down into smaller packets for transmission and are reassembled back into the original data set by the receiving device.</p> <p>In the [[OSI model]] of computer networking, IP is in the network layer. It operates above the data link layer and below the transport layer (which includes TCP and UDP). IP does not guarantee delivery of packets, the preservation of data integrity, or the order of packet delivery. Higher-level protocols like TCP are used for reliable communication.</p> <p>IP enables communication between vastly different types of devices and networks, including computers, mobile devices, and local and wide area networks. Virtually all types of network communication over the Internet use IP, making it foundational to modern digital communication.</p>"},{"location":"protocols/ipsec/","title":"IPSec","text":"<p>IPsec (Internet Protocol Security) is a suite of protocols for securing internet protocol (IP) communications by authenticating and encrypting each IP packet of a communication session. IPsec includes protocols for establishing mutual authentication between agents at the beginning of a session and negotiation of cryptographic keys to be used during the session.</p> <p>IPsec is designed to secure data transmitted across IP networks, including the internet. It provides confidentiality, data integrity, and authentication of the data packets. IPsec encrypts the data payload of each packet, which ensures confidentiality, and it authenticates the sender, providing protection against data tampering and unauthorized access.</p> <p>IPsec primarily uses two protocols:</p> <ul> <li>Encapsulating Security Payload (ESP): Provides confidentiality, along with authentication and integrity.</li> <li>Authentication Header (AH): Provides authentication and integrity but does not encrypt the data.</li> </ul> <p>IPsec operates in two modes:</p> <ul> <li>Transport Mode: Encrypts and/or authenticates the data (payload) of IP packets. IP headers are not encrypted, making this mode suitable for end-to-end communication between hosts.</li> <li>Tunnel Mode: Encrypts and/or authenticates the entire IP packet. A new IP header is added to the packet, making this mode suitable for gateway-to-gateway communications (like site-to-site VPNs).</li> </ul> <p>IPsec uses Security Associations, which are agreements on how to secure communication. SAs define the protocols and algorithms to be used for securing packet flows.</p> <p>IPsec commonly uses the Internet Key Exchange (IKE) protocol to handle the negotiation of keys and the establishment of security associations.</p> <p>IPsec is widely used in creating Virtual Private Networks (VPNs). In a VPN, IPsec provides secure connections between remote users and networks or between different networks over the internet. IPsec policies define how traffic is to be secured. These policies determine which traffic needs to be secured and how it should be processed.</p>"},{"location":"protocols/ldapp/","title":"Lightweight Directory Access Protocol","text":"<p>LDAP (Lightweight Directory Access Protocol) is a software protocol for enabling anyone to locate organizations, individuals, and other resources such as files and devices in a network, whether on the public Internet or on a corporate intranet. LDAP is a \"lightweight\" (smaller amount of code) version of Directory Access Protocol (DAP).</p> <p>An LDAP directory can be distributed among many servers. Each server can have a replicated version of the total directory that is synchronized periodically. An LDAP server is called a Directory System Agent (DSA). An LDAP server that receives a request from a user takes responsibility for the request, passing it to other DSAs as necessary, but ensuring a single coordinated response for the user.</p> <p>An LDAP directory is organized in a simple \"tree\" hierarchy consisting of the following levels:</p> <ul> <li>The root directory (the starting place or the source of the tree), which branches out to</li> <li>Countries, each of which branches out to</li> <li>Organizations, which branch out to</li> <li>Organizational units (divisions, departments, and so forth), which branches out to (includes an entry for)</li> <li>Individuals (which includes people, files, and shared resources such as printers)</li> </ul>"},{"location":"protocols/llmnr/","title":"LLMNR","text":"<p>LLMNR (Link-Local Multicast Name Resolution) is a protocol used in modern Windows operating systems as a fallback method for host name resolution. It comes into play when DNS fails to resolve a host name, and it's used in small networks where a DNS server might not be present. LLMNR operates similarly to NBT-NS (NetBIOS Name Service), using multicast over a local subnet.</p> <p>LLMNR allows hosts on the same local link (subnet) to perform name resolution without requiring a DNS server. It's used for identifying resources like computers, printers, and file shares in a local network environment. If a DNS query fails, the LLMNR multicast query is sent within the local subnet to resolve a hostname to an IP address.</p> <p>LLMNR can be exploited by attackers, particularly in poisoning and spoofing attacks, due to its lack of authentication for responses. This makes it a vector for various network attacks:</p> <ol> <li>Spoofing and Poisoning: An attacker can respond to LLMNR requests with false information, potentially redirecting network traffic through the attacker's machine (a man-in-the-middle attack).</li> <li>Credential Harvesting: By responding to LLMNR requests, attackers can direct a client to authenticate to a rogue server. The attacker can then capture the authentication attempt, which typically includes hashed user credentials. Tools like Responder are commonly used to exploit LLMNR in this way.</li> <li>Lateral Movement: Once an attacker has captured credentials, they can use them to move laterally across the network, potentially escalating privileges or accessing sensitive data.</li> </ol>"},{"location":"protocols/mdns/","title":"MDNS","text":"<p>mDNS (Multicast DNS) is a network protocol used for resolving hostnames to IP addresses within small networks that do not include a local name server. It is a part of the Zero-configuration networking (Zeroconf) protocol suite, allowing devices to use network services without manual setup or configuration.</p> <p>mDNS enables devices on the same local network to discover each other and establish communication without the need for a central DNS server. It's particularly useful in home networks, small offices, or IoT (Internet of Things) environments.</p> <p>Similar to traditional DNS, mDNS resolves hostnames to IP addresses. However, it operates in a smaller scope, typically limited to a single local network segment. mDNS uses multicast UDP to send query messages to which all listening devices on the network can respond. A device will respond to an mDNS query only if it has the requested hostname.</p> <p>Hostnames in mDNS typically end in <code>.local</code>. For example, a device named \"printer\" might advertise itself as <code>printer.local</code>. </p> <p>When a device needs to know the IP address of another device with a given hostname, it sends an mDNS query to a multicast address. All devices listening for mDNS queries check if the queried hostname matches their own. If there's a match, the device responds with its IP address. The querying device can then use this IP address to establish a direct connection to the responder.</p> <p>mDNS is used to resolve hostnames for devices and services on local networks without the need for manual DNS configuration. Common examples include printers, file servers, and collaborative software. In IoT applications, mDNS allows devices to discover and communicate with each other on a local network without complex configuration.</p>"},{"location":"protocols/mqtt/","title":"MQTT","text":"<p>MQTT (Message Queuing Telemetry Transport) is a lightweight and open messaging protocol designed for small sensors and mobile devices with high-latency or unreliable networks. It is commonly used in scenarios where low bandwidth, high latency, or an unreliable network is a concern. MQTT follows a publish/subscribe model and is known for its simplicity and efficiency. </p> <p>MQTT operates on a publish/subscribe messaging pattern. In this model, devices or applications can publish messages to a specific topic, and other devices or applications subscribe to receive messages on that topic. This decouples the sender (publisher) from the receiver (subscriber).</p> <p>MQTT uses a broker-based architecture. The broker is a server that acts as an intermediary between publishers and subscribers. It receives messages from publishers and forwards them to the appropriate subscribers based on topics. The broker helps in managing the communication flow.</p> <p>Topics are string identifiers used to categorize and route messages. Publishers specify a topic when sending a message, and subscribers express interest in specific topics to receive relevant messages. Topics provide a flexible and scalable way to organize communication.</p> <p>MQTT supports different levels of Quality of Service for message delivery: - QoS 0: At most once delivery (fire and forget). - QoS 1: At least once delivery (guaranteed delivery, but messages may be duplicated). - QoS 2: Exactly once delivery (ensures that the message is delivered exactly once by using a handshake mechanism).</p> <p>MQTT supports the concept of retained messages. When a message is sent with the \"retain\" flag, the broker stores the last message sent on a specific topic. Subscribers joining later will receive the most recent retained message for that topic.</p> <p>MQTT is designed to be lightweight, making it suitable for devices with limited resources, such as sensors and IoT devices. The protocol minimizes the amount of overhead associated with communication.</p> <p>MQTT is connectionless, meaning that clients (publishers and subscribers) do not need to maintain a continuous connection to the broker. Clients can connect, send or receive messages, and then disconnect. While MQTT itself does not define security mechanisms, it can be used in combination with secure transport protocols such as TLS/SSL for encryption. Additionally, authentication mechanisms can be implemented at the application level.</p> <p>MQTT has gained popularity in the Internet of Things (IoT) space due to its efficiency and scalability. It is well-suited for scenarios where devices need to communicate with each other or with a central server in a distributed and resource-constrained environment.</p>"},{"location":"protocols/nbns/","title":"NetBIOS Name Server (NBNS)","text":"<p>The NetBIOS Name Service (NBNS) is a protocol used in computer networks for name resolution of NetBIOS network names to network addresses. It's a part of the NetBIOS-over-TCP/IP (NBT) protocol suite and plays a role similar to that of the Domain Name System (DNS) in the Internet context, but for NetBIOS names within a local area network.</p> <p>NetBIOS provides a naming service where each device on the network can be identified by a unique 15-character name. The 16th character, known as the \"NetBIOS suffix,\" indicates the service type. NBNS is responsible for translating these NetBIOS names into IP addresses. When a machine on the network wants to communicate with another, it asks the NBNS to translate the NetBIOS name to an IP address.</p> <p>Computers on a NetBIOS network register their names with the NBNS. Other computers on the network can query the NBNS to find the IP address associated with a particular NetBIOS name. In the absence of an NBNS, NetBIOS names can also be resolved through broadcast queries within a local subnet. In this method, a machine broadcasts a request asking the machine with the target NetBIOS name to respond with its IP address.</p> <p>NBNS has been a key component in early Windows networking (especially in Windows NT and 2000 environments) before the widespread adoption of DNS and Active Directory.</p> <p>NBNS, like other older protocols, has its share of security vulnerabilities, including susceptibility to spoofing and poisoning attacks. For example, an attacker might respond to a NetBIOS name query with a false IP address, redirecting traffic to an attacker-controlled machine. </p> <p>Due to security and efficiency reasons, NBNS has largely been superseded by DNS in modern networks. However, NBNS might still be found in legacy systems or in some network configurations for backward compatibility. In contemporary network configurations, it's often recommended to disable NetBIOS over TCP/IP to reduce the attack surface, especially if it's not required for legacy application compatibility.</p>"},{"location":"protocols/nbt/","title":"NetBIOS over TCP-IP (NBT)","text":"<p>NetBIOS over TCP/IP (NBT) is a networking protocol that allows older NetBIOS services to be used over modern TCP/IP networks. NetBIOS (Network Basic Input/Output System) was developed in the 1980s for early LAN (Local Area Network) systems to enable communication between applications on different computers.</p> <p>It uses 3 ports:</p> <ul> <li>Name Service (137) - NBT uses this service for name registration and resolution. It allows a NetBIOS name (a 16-character identifier for a networked device) to be associated with an IP address. Name resolution can be done via broadcasting or a NetBIOS Name Server (NBNS), like WINS in Windows.</li> <li>Datagram Service (138) - This service provides connectionless communication. It's used for sending and receiving NetBIOS datagrams, which are typically used for one-to-many communications.</li> <li>Session Service (139) - This service allows the establishment of NetBIOS sessions for communication between two devices. It's used for reliable, connection-oriented communication, often employed for file and printer sharing in Windows networks.</li> </ul> <p>NBT can be vulnerable to various types of attacks, such as NetBIOS name spoofing or session hijacking. It is susceptible to security issues inherent in the older NetBIOS protocol. The broadcasting nature of NetBIOS name resolution can inadvertently expose network information that can be exploited by attackers. Modern Windows networks often do not require NetBIOS. It is generally recommended to disable NBT if it's not needed, to reduce the attack surface.</p>"},{"location":"protocols/nbtns/","title":"NBT-NS","text":"<p>NBT-NS (NetBIOS Name Service) is a protocol used in early Windows networking for name resolution, which allows computers on a network to find each other using NetBIOS names instead of IP addresses. It's part of the NetBIOS-over-TCP/IP suite and was commonly used in small networks, particularly before the widespread adoption of DNS (Domain Name System).</p> <p>NBT-NS enables computers to register their NetBIOS names on the network and resolve the NetBIOS names of other computers to IP addresses. In a typical setup without a dedicated name server, NBT-NS uses broadcast queries over the local subnet to resolve names. A computer needing to resolve a NetBIOS name sends a broadcast request, and the computer with that name responds with its IP address.</p> <p>In larger networks, NBT-NS can work with a WINS (Windows Internet Name Service) server, which acts like a DNS server for NetBIOS names, reducing broadcast traffic and enabling name resolution across different subnets.</p> <p>NBT-NS was primarily used in small office/home office (SOHO) networks and in legacy corporate networks for local area network (LAN) communications. It played a significant role in facilitating file and printer sharing in early Windows networks.</p> <p>NBT-NS is susceptible to various security vulnerabilities, including spoofing and man-in-the-middle attacks. Attackers can exploit NBT-NS to redirect network traffic or impersonate other computers. </p> <p>With the rise of DNS and Active Directory, NBT-NS has become largely obsolete in modern network environments. It's generally recommended to disable NetBIOS over TCP/IP in network settings to reduce the attack surface. Despite being outdated, NBT-NS might still be found in some legacy systems or specific network configurations for backward compatibility.</p>"},{"location":"protocols/netbios/","title":"NetBIOS","text":"<p>NetBIOS (Network Basic Input/Output System) is an older networking protocol used to enable communication between applications on different computers within a local area network (LAN). Originally developed in the 1980s for early IBM networks, NetBIOS became widely used in early Windows networks for local network communication and resource sharing.</p> <p>NetBIOS provides a naming service that allows computers to register and resolve friendly names (up to 15 characters long). These names are used to identify and access network resources like computers, printers, and other devices. It enables the establishment and management of sessions between network devices for communication. This includes connecting, sending, receiving, and disconnecting sessions.</p> <p>NetBIOS supports connectionless communication by sending and receiving datagrams, which are essentially broadcast messages sent to all devices on the network or directed to a specific NetBIOS name.</p> <p>Some places where it is still used include:</p> <ul> <li>File and Printer Sharing: In Windows networks, NetBIOS was commonly used for file and printer sharing.</li> <li>Network Browsing: It was used for browsing networked computers and their shared resources in a LAN.</li> <li>Integration with SMB Protocol: NetBIOS was often used in conjunction with the Server Message Block (SMB) protocol for providing shared access to files, printers, and other network resources.</li> </ul> <p>With the evolution of networking, particularly with the adoption of TCP/IP as the standard networking protocol, the functions of NetBIOS have largely been replaced by more modern protocols like DNS and DHCP.</p> <p>Even though pure NetBIOS is rarely used now, its functionality was extended over TCP/IP networks, known as NetBIOS over TCP/IP (NBT). NetBIOS is known for its security weaknesses, making networks vulnerable to various attacks like name resolution poisoning and unauthorized access. Modern networks generally avoid using NetBIOS or tightly control its usage.</p> <p>Important</p> <p>While largely obsolete, NetBIOS might still be found in some legacy systems or specific network configurations for compatibility reasons.</p>"},{"location":"protocols/nfc/","title":"Near Field Communication (NFC)","text":"<p>Near Field Communication (NFC) is a set of communication protocols that enable two electronic devices, one of which is usually a portable device such as a smartphone, to establish communication by bringing them within close proximity, typically 4 cm (1.6 in) or less. It evolved from Radio-Frequency Identification (RFID) technology.</p> <p>NFC is designed for short-range communication, with a typical maximum distance of about 4 cm, ensuring secure communication. Unlike RFID, which is primarily one-way, NFC allows for two-way communication between devices. This means both devices can send and receive information.</p> <p>NFC involves two types of devices - 'passive' (like NFC tags that don't require power) and 'active' (like smartphones that can read and write to NFC tags and communicate with each other). One of NFC's primary benefits is its simplicity. A connection is established quickly and easily by simply bringing two devices close together.</p> <p>Common uses of NFC include contactless payments, data transfer, and simplified setup of longer-range wireless communications such as Bluetooth and Wi-Fi. It is also used for social networking, for sharing contacts, photos, videos, or files, and in interactive advertising.</p> <p>NFC is widely used for mobile payment systems, like Apple Pay, Google Pay, and Samsung Pay, allowing users to make secure transactions without needing physical cards.</p> <p>NFC tags can be embedded in smart objects and used in the Internet of Things (IoT) for tasks like inventory management or asset tracking.</p>"},{"location":"protocols/nfs/","title":"Network File Share (NFS)","text":"<p>It is a client/server system that allows users to access files across a network and treat them as if they resided in a local file directory. It has the same purpose as SMB but it cannot talk to SMB.</p> <p>The NFS protocol has no mechanism for authentication or authorization. The authorization is taken from the available information of the file system where the server is responsible for translating the user information supplied by the client to that of the file system and converting the corresponding authorization information as correctly as possible into the syntax required by UNIX.</p> <p>The most common authentication is via UNIX <code>UID</code>/<code>GID</code> and <code>group memberships</code>, which is why this syntax is most likely to be applied to the NFS protocol. </p> <p>One problem is that the client and server do not necessarily have to have the same mappings of UID/GID to users and groups. No further checks can be made on the part of the server. This is why NFS should only be used with this authentication method in trusted networks.</p>"},{"location":"protocols/nmb/","title":"NetBIOS Message Block (NMB)","text":"<p>NMB (NetBIOS Message Block) refers to a protocol used in older versions of Windows networking, primarily associated with the SMB (Server Message Block) protocol, which enables file sharing, network browsing, and printer services. NMB is essentially the part of the SMB protocol that handles network name registration, resolution, and browsing.</p> <p>In NMB, machines on a network are identified by unique NetBIOS names, which are 15 characters long with a 16th character used as a suffix to denote the service type. NMB provides a way for computers on a local network to find each other by name. This can be done via broadcasting (asking all devices on the network), or through a NetBIOS Name Server (NBNS), which is similar to a DNS server but for NetBIOS names.</p> <p>NMB allows for the browsing of network shares and services. It helps in identifying what services are offered by which machines on a local network. While NMB is part of the broader SMB protocol, it specifically deals with the aspects of networking that involve NetBIOS names. SMB uses NMB for these purposes but also includes other functionalities for file and printer sharing, and later versions have evolved beyond NetBIOS.</p> <p>In modern networking, the role of NMB (and NetBIOS in general) has diminished. Newer versions of Windows and other operating systems have moved towards using DNS and other mechanisms for network name resolution and service discovery. However, NMB and NetBIOS are still in use in some environments, particularly where older systems are in operation, or for backward compatibility.</p> <p>NMB and NetBIOS are known to have security vulnerabilities and are often targeted in network attacks. They can reveal information about network structure and machines, and have been used in attacks like SMB Relay. Modern network configurations often involve disabling NetBIOS and NMB to enhance security.</p>"},{"location":"protocols/nor/","title":"NFS over RDMA","text":"<p>NFS over RDMA (Remote Direct Memory Access) is an implementation of the Network File System (NFS) protocol that utilizes RDMA technology for data transfer. This combination enhances NFS by providing a more efficient and high-performance way to access remote file systems over a network.</p> <p>NFS is a distributed file system protocol that allows a user on a client computer to access files over a network in the same way they would access local storage. It's widely used in Unix/Linux environments.  RDMA is a technology that enables the direct transfer of data from the memory of one computer to another without involving the CPU, cache, or operating system of either system. It significantly reduces latency and increases throughput.</p> <p>By leveraging RDMA, NFS over RDMA provides higher throughput and lower latency compared to traditional NFS implementations over TCP/IP. Since RDMA offloads the work of data transfer to the network hardware, it reduces CPU usage on both the client and server, making data transfers more efficient. </p> <p>RDMA's direct memory access capability significantly reduces the number of data copies and context switches, which lowers latency. NFS over RDMA can handle a larger number of simultaneous connections and higher volumes of data transfer with less impact on system resources.</p> <p>Both the NFS server and client must have RDMA-capable network adapters (RNICs) and operate in an environment that supports RDMA (like InfiniBand or iWARP). The operating system and NFS implementation must support NFS over RDMA. Many Unix/Linux distributions provide this support.</p> <p>Proper configuration of network interfaces, NFS settings, and RDMA parameters is necessary to ensure optimal performance and stability.</p>"},{"location":"protocols/ntp/","title":"Network Time Protocol (NTP)","text":"<p>The Network Time Protocol (NTP) is an application layer protocol in the TCP/IP protocol suite. It is used to synchronize the clock between the client and the server to provide high-precision time correction. </p> <p>The NTP server receives accurate Coordinated Universal Time (UTC) from an authoritative clock source, such as an atomic clock or GPS. Then, the NTP client requests and receives time from the NTP server.  </p> <p>NTP relies on User Datagram Protocol (UDP) port 123.</p>"},{"location":"protocols/openid/","title":"OpenID Connect","text":"<p>OpenID Connect (OIDC) is an authentication and authorization protocol built on top of OAuth 2.0, designed to facilitate secure and standardized authentication in web and mobile applications. OIDC provides a framework for authenticating users, obtaining their identity information, and, if necessary, authorizing them to access protected resources or services. It is often used to implement Single Sign-On (SSO) and federated identity solutions.</p> <p>OIDC allows relying parties (client applications) to authenticate users through identity providers (IDPs). Users log in to an IDP, which issues an ID token to the client application after successful authentication.</p> <p>The ID token is a JWT (JSON Web Token) that contains information about the authenticated user. It typically includes user attributes, such as username, email address, and other claims. The ID token is digitally signed by the IDP to ensure its integrity. OIDC enables SSO by allowing users to authenticate once with an IDP and then access multiple client applications without re-entering credentials. The ID token serves as proof of authentication.</p> <p>OIDC supports federated identity scenarios where users from one organization can use their home IDP's credentials to access resources in other organizations. This is useful for cross-domain authentication. OIDC defines various OAuth 2.0 flows, with the most commonly used being the Authorization Code Flow. In this flow, the client application obtains an authorization code, exchanges it for an ID token and an access token, and uses them to access resources.</p> <p>Another OIDC flow is the Implicit Flow, which is used in single-page applications (SPAs). It allows the client to obtain an ID token directly from the IDP without a server-side component. The Hybrid Flow combines elements of the Authorization Code Flow and the Implicit Flow, providing greater flexibility for applications that require ID tokens and access tokens.</p> <p>OIDC uses discovery documents, also known as well-known endpoints, to allow clients to dynamically locate and obtain the configuration details of the IDP, such as endpoints and cryptographic keys. OIDC includes a User Info Endpoint where clients can request additional user information beyond what is available in the ID token.</p> <p>OIDC defines a logout mechanism that allows users to log out from multiple applications simultaneously. This ensures a consistent logout experience. OIDC uses OAuth 2.0 scopes to request specific user information or access to protected resources. Scopes are used to control the level of authorization granted.</p> <p>OIDC incorporates security features, such as token encryption, to protect sensitive information in transit. It also supports Token Binding, which helps prevent token replay attacks.</p>"},{"location":"protocols/pap/","title":"PAP (Password Authentication Protocol)","text":"<p>Password Authentication Protocol (PAP) is a simple authentication protocol used in networking environments, particularly in Point-to-Point Protocol (PPP) connections. PAP is used to validate users trying to access a network and is known for its simplicity and basic level of security. </p> <p>PAP authenticates a user by sending a username and password to the server in plain text, without any encryption. The server then verifies the credentials against its database. The most significant drawback of PAP is that it sends the username and password over the network in clear text, making it susceptible to interception and eavesdropping.</p> <p>Typically, PAP only authenticates the client to the server. It does not provide a means for the client to authenticate the server, which can be a security risk. PAP is commonly used in PPP connections, such as those used in some dial-up internet services and older network systems.</p> <p>The main advantage of PAP is its simplicity, both in terms of implementation and operation. This simplicity, however, comes at the cost of security.</p> <p>Unlike more secure protocols like CHAP (Challenge Handshake Authentication Protocol), PAP does not use a repeated challenge-response mechanism and authenticates only once at the beginning of the session. Since PAP transmits the password in clear text and does not use random challenges, it offers no protection against replay attacks, where an attacker can capture the password and use it later.</p> <p>Setting up PAP is relatively straightforward, requiring only the configuration of the username and password on both the client and server.</p> <p>PAP is considered a legacy protocol. While it's still in use in certain older or less secure environments, it's not recommended for any scenario where data security is a concern. More secure authentication protocols, such as CHAP and EAP (Extensible Authentication Protocol), are generally preferred over PAP in modern network setups.</p>"},{"location":"protocols/pop/","title":"Post Office Protocol","text":"<p>The Post Office Protocol (POP) is an Internet standard protocol used by local email software clients to retrieve emails from a remote mail server over a TCP/IP connection. </p> <p>POP3 provides access to an inbox stored in an email server. It executes the download and deletes operations for messages. Thus, when a POP3 client connects to the mail server, it retrieves all messages from the mailbox. Then it stores them on your local computer and deletes them from the remote server.</p> <p>Info</p> <p>Modern POP3 clients allow you to keep a copy of your messages on the server if you explicitly select this option.</p>"},{"location":"protocols/pops/","title":"Post Office Protocol Secure","text":"<p>POP3 Secure, often referred to as POP3S, is an enhanced version of the Post Office Protocol version 3 (POP3), designed to provide secure email retrieval. POP3 is a standard protocol used by email clients to retrieve emails from a server, but in its basic form, it doesn't include any encryption or security mechanisms. POP3 Secure addresses this limitation by adding a layer of security to the POP3 protocol. </p>"},{"location":"protocols/rdp/","title":"Remote Desktop Protocol","text":"<p>Remote Desktop Protocol (RDP) is a proprietary protocol developed by Microsoft, which provides a user with a graphical interface to connect to another computer over a network connection. The user employs RDP client software for this purpose, while the other computer must run RDP server software.</p> <p>It facilitates secure information exchange between remotely connected machines over an encrypted communication channel.</p> <p>It enables users anywhere in the world to access and control a computer through a secure, reliable channel. RDP is a safe, useful tool for increasing productivity in your business and giving your employees the flexibility to accomplish tasks in a changing world. In other words, when using RDP, one remote computer (the client) can access all the data of another machine (the server) through a network connection. This includes access to licensed software, saved files and audio information. It eliminates the need to be physically present to log in to a specific system.</p>"},{"location":"protocols/sae/","title":"Simultaneous Authentication of Equals (SAE)","text":"<p>Simultaneous Authentication of Equals (SAE) is a secure password-based authentication and key establishment protocol used primarily in Wi-Fi Protected Access 3 (WPA3). SAE was developed to replace the Pre-Shared Key (PSK) method used in WPA2 and is designed to provide better security features.</p> <p>SAE enhances security compared to WPA2's PSK method, particularly against offline dictionary attacks, where an attacker tries to guess the network password using databases of possible passwords.</p> <p>SAE is resistant to common attacks that plagued WPA2, such as Key Reinstallation Attacks (KRACK). It is specifically designed to mitigate against these vulnerabilities. SAE is based on the Dragonfly Key Exchange, a cryptographic method that securely establishes a shared key between two parties based on a shared password.</p> <p>SAE provides forward secrecy, ensuring that if a session key is compromised, previous sessions remain secure. This means that capturing one key does not enable an attacker to decrypt all past communications.</p> <p>In SAE, a password is still used for network access, but the protocol provides a more secure way of handling password exchanges, reducing the risk of password interception or brute-force attacks. </p> <p>By using SAE, some of the inherent weaknesses of the Pre-Shared Key system, such as the vulnerability to offline guessing attacks, are addressed. SAE is a mandatory feature of WPA3, the latest Wi-Fi security protocol, providing stronger security measures for both personal and enterprise networks.</p> <p>Despite its advanced security features, SAE is designed to be user-friendly, requiring minimal configuration from the user's perspective. While SAE is a feature of WPA3, it requires compatible hardware and software, meaning that both the Wi-Fi access point and the client devices must support WPA3 for SAE to be used.</p>"},{"location":"protocols/scp/","title":"SCP (Secure Copy)","text":"<p>SCP (Secure Copy Protocol) is a network protocol that supports file transfers between hosts on a network. It uses SSH (Secure Shell) for data transfer and provides the same authentication and security as SSH. Unlike the standard file copy commands, SCP ensures that both the file and the communication channel are secure.</p> <p>SCP uses SSH for data transfer, ensuring that the entire transmission is encrypted and secure from eavesdropping. It leverages SSH's authentication, requiring valid credentials for access to both the source and destination systems. SCP is typically used via a command-line interface, allowing for easy integration with scripts and other automated processes.</p> <p>SCP is commonly used for:</p> <ul> <li>Securely Copying Files Between Systems: Transferring files securely between servers in a network.</li> <li>Backup and Archiving: Moving data to a remote server for backup purposes.</li> <li>Administrative Tasks: Performing file operations securely in scripts and automation processes.</li> </ul> <p>An example may be copying a file from a local to a remote system:</p> <pre><code>scp /path/to/local/file.txt username@remotehost:/path/to/remote/directory/\n</code></pre> <p>Info</p> <p>This command will copy <code>file.txt</code> from the local machine to the specified directory on the remote host.</p> <p>Or copying a file from a remote system to a local system:</p> <pre><code>scp username@remotehost:/path/to/remote/file.txt /path/to/local/directory/\n</code></pre> <p>Info</p> <p>This command will copy file.txt from the remote host to the specified directory on the local machine.</p> <p>You can also copy a directory recursively:</p> <pre><code>scp -r /path/to/local/directory username@remotehost:/path/to/remote/directory/\n</code></pre> <p>Info</p> <p>The <code>-r</code> flag is used to recursively copy an entire directory.</p> <p>Finally, you can use an SSH key alongside it:</p> <pre><code>scp -i /path/to/private/key file.txt username@remotehost:/path/to/remote/directory/\n</code></pre> <p>Info</p> <p>The <code>-i</code> option allows you to specify an SSH private key to be used for authentication.</p> <p>SCP ensures that files are encrypted during transfer, providing a high level of security, especially when transferring sensitive data over the internet or unsecured networks. SCP may not be the fastest file transfer method due to the encryption/decryption overhead. For larger transfers, other protocols like rsync or SFTP might be more efficient.</p>"},{"location":"protocols/scsi/","title":"SCSI Protocol","text":"<p>SCSI (Small Computer System Interface) is a set of standards for physically connecting and transferring data between computers and peripheral devices. The SCSI standards define commands, protocols, electrical, optical and logical interfaces. It has been a crucial technology in the evolution of computer storage devices.</p> <p>SCSI is primarily an interface for data transfer between computer components, such as hard drives, optical drives, tape drives, and scanners. Historically, SCSI has been widely used in enterprise environments for high-performance hard disk drives and tape drives, due to its robustness and scalability.</p> <p>SCSI defines a command set for controlling the devices. This command set is a major feature that distinguishes SCSI from other interface standards and allows for a wide range of devices to be connected with a common interface. Over the years, SCSI has evolved through several standards, including Parallel SCSI (the original standard) and Serial Attached SCSI (SAS), each with enhancements in speed and capabilities.</p> <p>SCSI standards, particularly in their more recent versions like SAS, support high data transfer rates, making them suitable for high-performance and enterprise applications. SCSI allows multiple devices to be connected in a daisy-chain configuration, enabling one SCSI port to drive several devices.</p> <p>SAS is a successor to the parallel SCSI interface, providing higher speeds, reduced cable size and cost, and more devices per controller. It's commonly used in enterprise storage systems. SCSI protocols are still relevant in server environments and storage arrays, especially in contexts where multiple hard drives or other storage devices are used.</p> <p>In consumer products and some business applications, SCSI has largely been replaced by technologies like SATA (Serial ATA), which is simpler and less expensive. However, SCSI remains significant in enterprise and high-performance computing.</p> <p>Info</p> <p>While SCSI and ATA (Advanced Technology Attachment) both serve to connect storage devices to computers, SCSI is often considered more robust and feature-rich, supporting a wider range of device types and more devices in a single chain, higher speeds, and more complex command sets. This distinction has historically made SCSI a preference in enterprise and industrial settings.</p>"},{"location":"protocols/sftp/","title":"Secure File Transfer Protocol","text":"<p>Secure File Transfer Protocol (SFTP), sometimes referred to as SSH File Transfer Protocol, is a network protocol used for secure file transfer over a secure shell (SSH) data stream. SFTP is often confused with FTPS (File Transfer Protocol Secure), but they are distinct protocols.</p> <p>SFTP provides a secure method for transferring files by using SSH for data transmission, ensuring that both the data and commands are encrypted. SFTP requires authentication of the client to the server, typically through username and password, SSH keys, or both.</p> <p>The use of SSH ensures that data is not only encrypted during transfer but also protected from unauthorized access or eavesdropping. Unlike SCP (Secure Copy), SFTP allows for a range of operations on remote files, such as browsing and managing directories, in addition to transferring files. SFTP is widely supported across different operating systems, making it a versatile choice for file transfer needs in diverse environments.</p> <p>In comparison to other protocols:</p> <ul> <li>FTP is an older protocol that doesn't inherently support encryption, making it less secure than SFTP.</li> <li>FTPS is an extension of FTP with TLS encryption. While it also provides secure file transfer, it differs from SFTP in its use of separate control and data connections and its reliance on SSL/TLS as opposed to SSH.</li> <li>SCP is another SSH-based protocol but is primarily used for transferring files. SFTP offers more functionality, such as the ability to list and manage files on the server.</li> </ul>"},{"location":"protocols/sftp2/","title":"SSH File Transfer Protocol","text":"<p>SSH File Transfer Protocol (SFTP), also known as Secure FTP, is a network protocol used for secure file transfer over a secure shell (SSH) data stream. SFTP is not to be confused with FTPS (FTP Secure), which is an extension of FTP adding support for SSL/TLS. </p> <p>SFTP is part of the SSH protocol suite and provides a secure method for file access, file transfer, and file management over a reliable data stream.</p> <p>SFTP encrypts both the commands and data, providing robust security against eavesdropping, connection hijacking, and other network attacks. Unlike FTP, which uses separate control and data connections, SFTP uses a single connection for both commands and data transfer. This simplifies firewall configurations and reduces the chances of data being intercepted.</p> <p>SFTP supports multiple forms of authentication, including password-based and public key authentication. The connection is established over the SSH protocol, ensuring secure authentication.</p> <p>Besides file transfer, SFTP allows for a range of file management operations like creating and deleting directories and files, resuming interrupted transfers, and listing directory contents.</p> <p>SFTP operates over an SSH session, typically on TCP port 22. It starts by establishing an SSH connection between the client and server. All SFTP packets are sent encrypted over this established SSH session. </p> <p>The client authenticates to the SFTP server using SSH authentication methods. This can be password authentication, public key authentication, or Kerberos authentication. Once authenticated, the client can execute a range of file operations through the SFTP session. The commands and data are all encrypted.</p> <p>The differences between SFTP and FTPS are:</p> <ul> <li>SFTP (SSH File Transfer Protocol): A secure file transfer protocol that runs over an SSH session. It's not related to FTP and uses a different protocol entirely.</li> <li>FTPS (FTP Secure): An extension of the FTP protocol, adding support for SSL/TLS to encrypt the FTP traffic.</li> </ul>"},{"location":"protocols/signal/","title":"Signal Protocol","text":"<p>The Signal Protocol is an advanced cryptographic protocol used for end-to-end encryption in messaging applications. It was developed by Open Whisper Systems and is most notably used in the Signal app, but its technology has also been implemented in other messaging services like WhatsApp, Facebook Messenger, and Skype.</p> <p>The protocol ensures that messages are encrypted on the sender's device and remain encrypted until they reach the intended recipient's device. This means that no intermediary, not even the service provider, can read the messages.  he Signal Protocol uses ephemeral keys for each message, ensuring that even if a key is compromised in the future, it cannot be used to decrypt past messages. This property is known as forward secrecy.</p> <p>The protocol employs a technique called the \"double ratchet\" algorithm, which combines a Diffie-Hellman key exchange and a symmetric-key ratchet based on the KDF chain. This mechanism allows for secure and continual updating of encryption keys.</p> <p>The Signal Protocol supports asynchronous messaging environments, meaning it works even when one of the parties is offline. New keys are generated when users go offline and come back online. The protocol has been extended to provide end-to-end encryption for group chats, not just one-on-one conversations.</p> <p>The components are:</p> <ul> <li>X3DH (Extended Triple Diffie-Hellman): A key agreement protocol used for establishing a shared secret between two parties in an asynchronous environment. It's used to set up secure sessions between users.</li> <li>Signal's Double Ratchet Algorithm: Provides end-to-end encryption for subsequent messages after the session has been established. It ensures that each message has a unique encryption key, enhancing security.</li> </ul> <p>Signal Protocol is primarily known for its use in the Signal messaging app, but its adoption extends to other major messaging platforms, ensuring secure communication for billions of users.</p> <p>The Signal Protocol operates in the background of applications, so users don't interact with it directly. However, the process can be conceptualized as follows:</p> <ol> <li>Session Setup: When two users start a chat, their devices use the Signal Protocol to agree on a set of keys for encryption and decryption.</li> <li>Message Transmission: Each message is encrypted with a unique key, and upon receipt, the recipient's device decrypts the message using the corresponding key.</li> <li>Key Ratcheting: As the conversation progresses, the keys are continually updated, ensuring each message's encryption is unique and secure.</li> </ol>"},{"location":"protocols/simpleprot/","title":"Simple and Protected GSSAPI Negotation Mechanism","text":"<p>The Simple and Protected GSSAPI Negotiation Mechanism (SPNEGO) is an authentication and negotiation protocol used to establish secure communication between client and server applications in networked environments. SPNEGO is primarily associated with the Generic Security Services Application Programming Interface (GSSAPI) and is often used in the context of web-based applications and services.</p> <p>SPNEGO is designed to enable the negotiation of authentication mechanisms between a client and a server, allowing them to select a common and mutually acceptable authentication method for secure communication. It provides a standardized way for clients to communicate their supported authentication mechanisms to servers and for servers to select the most appropriate method from the client's list.</p> <p>SPNEGO enables the negotiation of authentication mechanisms without requiring prior knowledge of the client's capabilities. It allows the client to indicate the supported authentication mechanisms it can use for secure communication. SPNEGO promotes interoperability between different authentication protocols and mechanisms, such as Kerberos, NTLM, and others. It ensures that client and server applications can communicate securely even if they support different authentication methods.</p> <p>SPNEGO is commonly used in HTTP environments, often in conjunction with the Negotiate Authentication mechanism. This integration allows web browsers and servers to negotiate and use authentication methods such as Kerberos or NTLM for securing HTTP-based communication.</p> <p>SPNEGO relies on the exchange of security tokens between the client and server. These tokens contain information related to the selected authentication mechanism and are used to establish secure communication. SPNEGO facilitates Single Sign-On solutions, allowing users to log in once and gain access to multiple services or applications without repeated authentication.</p> <p>SPNEGO is designed to work in various computing environments and is not tied to any specific platform or operating system. This promotes compatibility between different systems and applications. SPNEGO is based on industry standards and is defined in RFC 4178 (published by the Internet Engineering Task Force), ensuring that implementations adhere to a common specification.</p> <p>SPNEGO is designed to provide secure authentication and communication. It helps protect against unauthorized access and eavesdropping attacks.</p>"},{"location":"protocols/smb/","title":"Server Message Block","text":"<p>Server Message Block in modern language is also known as Common Internet File System. The system operates as an application layer network protocol primarily used for offering shared access to files, printers, serial ports, and other sorts of communications between nodes on a network.</p> <p>For instance, on Windows, SMB can run directly over TCP/IP without the need for NetBIOS over TCP/IP. </p> <p>Server Message Block is a client-server protocol that regulates access to files and entire directories and other network resources such as printers, routers, or interfaces released for the network. The main application area of the protocol has been the Windows operating system series in particular, whose network services support SMB in a downward-compatible manner - which means that devices with newer editions can easily communicate with devices that have an older Microsoft operating system installed. </p> <p>With the free software project Samba, there is also a solution that enables the use of SMB in Linux and Unix distributions and thus cross-platform communication via SMB.</p> <p>An SMB server can provide arbitrary parts of its local file system as shares. Therefore the hierarchy visible to a client is partially independent of the structure on the server. Access rights are defined by Access Control Lists. </p> <p>They can be controlled in a fine-grained manner based on attributes such as execute, read and full access for individual users or user groups. The ACLs are defined based on the shares and therefore do not correspond to the rights assigned locally on the server.</p>"},{"location":"protocols/smb1/","title":"SMB 1","text":"<p>SMB 1, the first version of the Server Message Block (SMB) protocol, is a network file sharing protocol originally designed to allow computers to read and write files to a remote host over a network. </p> <p>SMB 1 was primarily used for sharing files and printers across Windows networks. It supported network browsing, which allowed users to see other computers and shared resources on the network. SMB 1 included a basic level of authentication to control access to shared resources. </p> <p>It introduced a form of file locking that allowed for performance improvements and caching optimizations. Over the years, SMB 1 was extended by Microsoft to add additional features, although the core protocol remained limited in terms of security and performance.</p> <p>SMB 1 is considered insecure by modern standards. It lacks encryption and is susceptible to several types of attacks, including man-in-the-middle attacks. SMB 1 was infamously exploited by the WannaCry ransomware attack and other malicious software, leading to widespread calls to disable or decommission the protocol.</p> <p>Compared to its successors (SMB 2 and SMB 3), SMB 1 is less efficient in terms of speed and resource utilization, particularly over wide area networks (WANs). Due to its security and performance limitations, SMB 1 has largely been replaced by SMB 2 and SMB 3 in modern networks. These newer versions provide significant improvements, including enhanced security features (like encryption), better performance, and additional functionalities.</p> <p>Danger</p> <p>Given its vulnerabilities, it's a security best practice to disable SMB 1 in networks where it's not strictly required for legacy compatibility. </p>"},{"location":"protocols/smb2/","title":"SMB 2","text":"<p>SMB 2 (Server Message Block 2) is a network file-sharing protocol and an updated version of the original SMB protocol. It was introduced by Microsoft in Windows Vista and Windows Server 2008. SMB 2 was developed to overcome the limitations of the older SMB 1.0 protocol, particularly regarding performance, scalability, and security.</p> <p>SMB 2 includes significant performance improvements over SMB 1, particularly in reducing the \"chattiness\" of the protocol (fewer commands and subcommands), which enhances speed and efficiency, especially in high-latency networks. It reduces the amount of overhead required in the protocol, resulting in better utilization of network bandwidth and faster file transfers.</p> <p>SMB 2 is more scalable than SMB 1, supporting larger buffer sizes and a greater number of concurrent open file handles. It introduces the concept of durable file handles, which allows for a more robust handling of network disruptions and maintains file accessibility across temporary network issues.</p> <p>SMB 2 includes better mechanisms for security and encryption, laying the groundwork for the more advanced security features that were fully realized in SMB 3. SMB 2 can negotiate the use of different SMB versions, which allows for compatibility and better performance between different versions of Windows.</p> <p>Improved oplocks in SMB 2 enhance the caching and synchronization of shared files.</p> <p>SMB 3, introduced with Windows 8 and Windows Server 2012, further extends the capabilities of SMB 2, particularly in areas like encryption, performance, and fault tolerance. Many modern Windows networks utilize SMB 3, although SMB 2 remains in use, especially in environments with a mix of older and newer Windows versions.</p>"},{"location":"protocols/smb3/","title":"SMB 3","text":"<p>SMB 3, the third version of the Server Message Block (SMB) protocol, is a network file sharing protocol that was introduced by Microsoft with Windows Server 2012 and Windows 8. SMB 3 brings significant improvements over its predecessors, SMB 1 and SMB 2, in terms of performance, security, and reliability. It's designed for more efficient and secure file sharing across networks, particularly in enterprise environments.</p> <p>SMB 3 enhances security through features like end-to-end encryption, which secures data in transit, and pre-authentication integrity to prevent man-in-the-middle attacks. It introduces several performance improvements, including multichannel support, which allows SMB 3 to use multiple network connections simultaneously for higher throughput and fault tolerance.</p> <p>SMB 3 includes features for network fault tolerance, like transparent failover with durable handles, helping maintain consistent file access even during network or server failures. SMB 3 is optimized for applications like Hyper-V and SQL Server, allowing them to store virtual machine and database files on SMB file shares.</p> <p>SMB Direct uses network adapters that support RDMA (Remote Direct Memory Access) for high-speed data transfers with low latency and CPU usage. SMB Multichannel allows the aggregation of network bandwidth and network fault tolerance if multiple network paths are available between the SMB client and server.</p> <p>Improvements in opportunistic locking (oplocks) and the introduction of leasing improve the caching and synchronization of shared files, enhancing performance in multi-user scenarios.</p> <p>SMB 3 is widely used in enterprise environments for sharing and accessing files on networked servers. Its support for Hyper-V makes it suitable for storing and accessing virtual machine files in network storage. SMB 3 can be used for storing database files in environments like SQL Server.</p> <p>SMB 3 allows for secure negotiation of connections and can encrypt file transfers, making it significantly more secure against eavesdropping and tampering. Proper configuration of SMB 3 is crucial, especially in mixed environments where different versions of SMB coexist. Ensuring that clients and servers are using the most secure version of the protocol compatible with their setup is important.</p>"},{"location":"protocols/smbdir/","title":"SMB Direct","text":"<p>SMB Direct, also known as SMB over RDMA (Remote Direct Memory Access), is a feature of the Server Message Block (SMB) 3.x protocol, introduced by Microsoft. It enables the SMB protocol to operate over RDMA-capable network adapters, providing significant performance improvements for file sharing and data transfer tasks.</p> <p>SMB Direct allows SMB 3.x to leverage the high throughput and low latency capabilities of RDMA networks, resulting in faster file transfers and improved overall performance. By using RDMA, SMB Direct offloads much of the data transfer work from the CPU to the network hardware. This reduces CPU usage and can improve the efficiency of data transfers.</p> <p>RDMA technology enables direct memory-to-memory data transfers with minimal latency, which is beneficial for applications requiring fast access to network storage, such as database operations and virtualized environments. </p> <p>SMB Direct can operate over various RDMA technologies, including InfiniBand, iWARP (Internet Wide Area RDMA Protocol), and RoCE (RDMA over Converged Ethernet). With reduced CPU overhead and efficient data transfer mechanisms, SMB Direct enhances the scalability and reliability of network operations, especially in data-intensive environments.</p> <p>SMB Direct is used in enterprise environments where large file shares are common, and high-speed access is required. Microsoft Hyper-V (virtualization) and SQL Server (database) can leverage SMB Direct for storing and accessing virtual machine files and databases on SMB file shares, providing better performance.</p> <p>Both the client and server must have RDMA-capable network adapters and operate in an environment that supports RDMA (such as InfiniBand, RoCE, or iWARP). Proper configuration of the network to support RDMA, including considerations for bandwidth and latency, is essential.</p> <p>SMB Direct is supported in Windows Server 2012 and later versions, as well as in certain editions of Windows 8 and later. For SMB Direct to function, all components in the data path must support RDMA and be properly configured to work together.</p>"},{"location":"protocols/smbmulti/","title":"SMB Multichannel","text":"<p>SMB Multichannel is a feature of the Server Message Block (SMB) 3.x protocol, introduced by Microsoft in Windows Server 2012 and Windows 8. It provides enhanced performance and fault tolerance in network communications for file-sharing operations. SMB Multichannel allows a single SMB session to utilize multiple network connections simultaneously.</p> <p>By utilizing multiple network interfaces (NICs) or multiple connections through a single NIC, SMB Multichannel can aggregate the network bandwidth, leading to higher data transfer rates. It provides redundancy in network connections. If one network path fails, SMB Multichannel can continue the file transfer over the remaining paths, ensuring uninterrupted access to shared resources.</p> <p>SMB Multichannel automatically detects and uses multiple available network paths without requiring additional configuration from the user. SMB Multichannel supports Remote Direct Memory Access (RDMA) capable network adapters. RDMA allows for high-throughput, low-latency networking with minimal CPU usage, which is especially beneficial for server applications like Hyper-V and SQL Server.</p> <p>This feature enhances the overall reliability and performance of SMB file sharing, especially in environments where multiple network paths or high-speed networks are available.</p> <p>A Windows server with two network cards connected to different network segments can use SMB Multichannel to provide a high-availability and high-throughput file-sharing service. If one network experiences an outage or congestion, SMB Multichannel ensures that the file-sharing operation continues over the other network.</p> <p>In virtualization scenarios with Hyper-V, SMB Multichannel can be used to store and access virtual machine files, allowing for high-speed data transfers and continuous availability, even if one of the network paths fails.</p> <p>SMB Multichannel is typically enabled by default on systems that support SMB 3.x. However, for optimal performance, it's important to ensure that the network environment is properly configured with multiple paths and, if possible, RDMA-capable hardware. Both the SMB client and server must support SMB 3.x for Multichannel to function. Additionally, proper network configuration and hardware support are necessary to fully realize the benefits of this feature.</p>"},{"location":"protocols/smtp/","title":"Simple Mail Transfer Protocol","text":"<p>SMTP is responsible for sending email messages. This protocol is used by email clients and mail servers to exchange emails between computers.</p> <p>A mail client and the SMTP server communicate with each other over a connection established through a particular email port. Both entities are using SMTP commands and replies to process your outgoing emails. Thanks to the Simple Mail Transfer Protocol, messages can be sent from the same account on different email applications.</p> <p>It is a part of the application layer of the TCP/IP suite and plays a crucial role in the process of email delivery. SMTP is used primarily to set up communication rules between servers, allowing them to send and receive email messages.</p>"},{"location":"protocols/smtps/","title":"Simple Mail Transfer Protocol Secure","text":"<p>Simple Mail Transfer Protocol Secure (SMTPS) refers to the use of Simple Mail Transfer Protocol (SMTP) over a secure connection, typically using SSL (Secure Sockets Layer) or TLS (Transport Layer Security). </p> <p>SMTP is the standard protocol for sending emails across the Internet. When SMTP is secured with SSL/TLS, it becomes SMTPS, ensuring that the email messages are transmitted in an encrypted form, providing confidentiality and data integrity between the email client and the mail server.</p> <p>SMTPS encrypts the data being transmitted, which includes the email content, headers, and any authentication credentials. This prevents unauthorized interception and reading of email data during transmission. In addition to encryption, SMTPS also provides a means of authenticating the mail server, which can help prevent Man-in-the-Middle (MitM) attack.</p> <p>The standard port for SMTP is 25. However, for SMTPS, the commonly used port is 465. Some servers also use port 587 for SMTP with STARTTLS, which upgrades a plain SMTP connection to a secure one.</p> <p>When an email client sends an email using SMTPS, it first establishes a secure connection with the SMTP server using SSL/TLS. This ensures that all subsequent data exchange during the session is encrypted. Once the secure connection is established, the email client sends the email to the server using the SMTP protocol, but now over the encrypted channel.</p> <p>SMTPS can also be used for encrypting emails sent between email servers. However, this is not as commonly implemented as client-to-server encryption.</p> <p>The differences between SMTPS and STARTTLS are:</p> <ul> <li>SMTPS (Implicit SSL/TLS): SMTPS starts with a secure connection right from the beginning. The use of SSL/TLS is implied and is a fundamental part of the connection from the start.</li> <li>STARTTLS (Explicit SSL/TLS): This is an extension to plain SMTP. The email client and server start with a plain, unencrypted SMTP connection and then use the STARTTLS command to upgrade to a secure connection.</li> </ul> <p>SMTPS protects the contents of emails from being intercepted and read by unauthorized parties. It also ensures that the emails are not tampered with during transit. By using SSL/TLS, SMTPS can authenticate the email servers, adding an additional layer of security.</p>"},{"location":"protocols/snmp/","title":"Simple Network Management Protocol","text":"<p>SNMP stands for \"Simple Network Management Protocol.\" It\u2019s an application layer protocol included in the internet protocol suite, a set of the most commonly used communication protocols online.</p> <p>It is one of the most widely accepted protocols for network monitoring. SNMP is used to collect data related to network changes or to determine the status of network-connected devices. Every device within the network can be queried in real time with SNMP, TCP, and other types of probes for their performance metrics. </p> <p>When thresholds for certain values are exceeded, software can alert system administrators of the issue, allowing them to drill into the data and troubleshoot a solution.</p> <p>All day, traffic is ebbing and flowing across your network as users conduct transfers, browse, perform downloads, and more. SNMP talks to your network to find out information related to this network device activity. For example, it tracks bytes, packets, and errors transmitted and received on a router, connection speed between devices, or the number of hits a web server receives.</p> <p>SNMP works by sending messages, called protocol data units (PDUs), to devices within your network that \u201cspeak\u201d SNMP. These messages are called SNMP Get-Requests. Using these requests, network administrators can track virtually any data values they specify.</p>"},{"location":"protocols/sockets/","title":"WebSockets","text":"<p>A WebSocket is a communication protocol that provides full-duplex communication channels over a single\u00a0TCP\u00a0connection. It enables real-time, event-driven communication between a client and a server.</p> <p>Unlike traditional HTTP, which follows a request-response model, WebSockets allow bi-directional communication. This means that the client and the server can send data to each other anytime without continuous polling.</p> <p>WebSockets\u00a0are a bi-directional, full duplex communications protocol initiated over HTTP. They are commonly used in modern web applications for streaming data and other asynchronous traffic.</p> <p>Most communication between web browsers and web sites uses HTTP. With HTTP, the client sends a request and the server returns a response. Typically, the response occurs immediately, and the transaction is complete. Even if the network connection stays open, this will be used for a separate transaction of a request and a response.</p> <p>Some modern web sites use WebSockets. WebSocket connections are initiated over HTTP and are typically long-lived. Messages can be sent in either direction at any time and are not transactional in nature. The connection will normally stay open and idle until either the client or the server is ready to send a message.</p> <p>WebSockets are particularly useful in situations where low-latency or server-initiated messages are required, such as real-time feeds of financial data.</p>"},{"location":"protocols/ssh/","title":"Secure Shel","text":"<p>The Secure Shell (SSH) protocol is a method for securely sending commands to a computer over an unsecured network. SSH uses cryptography to authenticate and encrypt connections between devices. SSH also allows for tunnelling, or port forwarding, which is when data\u00a0packets\u00a0are able to cross networks that they would not otherwise be able to cross. SSH is often used for controlling servers remotely, for managing infrastructure, and for transferring files.</p> <p>An inherent feature of ssh is that the communication between the two computers is encrypted meaning that it is suitable for use on insecure networks.</p> <p>SSH is often used to \"login\" and perform operations on remote computers but it may also be used for transferring data.</p> <p>It is essentially a more secure version of Telnet as it uses encryption.</p>"},{"location":"protocols/starttls/","title":"STARTTLS","text":"<p>STARTTLS is a protocol command used to upgrade a plain text connection to a secure (TLS or SSL) connection rather than using a separate port for encrypted communication. It's an extension to the communication protocols SMTP, IMAP, and POP3, allowing these protocols to be used both in their regular, non-encrypted form and their secure, encrypted form.</p> <p>The client connects to the server using a standard, non-encrypted connection (such as SMTP on port 25 for email). If both the client and server support TLS, the client sends the STARTTLS command.</p> <p>The server responds, and a TLS handshake is initiated. During this handshake, the client and server agree on encryption methods and exchange keys for encrypting the session. After the handshake, the connection is encrypted, and the client and server can securely exchange data.</p> <p>STARTTLS allows the use of the same port for both encrypted and non-encrypted traffic, simplifying network configurations and supporting backward compatibility. It provides a way to encrypt data transmissions without the need for a separate secure port.</p> <p>STARTTLS is often described as providing opportunistic encryption, meaning that the encryption is used if both sides support it, but the connection can fall back to plain text if not. This can be a vulnerability if a man-in-the-middle attack is used to strip out the STARTTLS command (a form of downgrade attack).</p> <p>Proper implementation and certificate validation are crucial. Clients should verify server certificates to prevent man-in-the-middle attacks.</p> <p>While SMTPS (or using SMTP over SSL/TLS on a separate port) always creates a secure connection from the start, STARTTLS begins with an unencrypted connection and upgrades to encryption if possible. STARTTLS offers more flexibility and can help in environments where secure ports are blocked or not available, but it can be more susceptible to certain types of attacks if not properly configured and enforced.</p>"},{"location":"protocols/stomp/","title":"STOMP","text":"<p>STOMP, which stands for Simple Text Oriented Messaging Protocol, is a simple, text-based protocol designed for working with message-oriented middleware. It provides an interoperable wire format that allows clients to communicate with almost any message broker if it supports STOMP. This simplicity and versatility make STOMP popular for building messaging applications across various languages and platforms.</p> <p>Unlike other messaging protocols that use a binary format, STOMP uses a text-based protocol. This makes it easy to implement and debug. STOMP's design is aimed at providing an easy-to-implement messaging protocol that can be used to interact with a wide range of message brokers, ensuring broad interoperability.</p> <p>The protocol defines a handful of commands (like CONNECT, SEND, SUBSCRIBE, UNSUBSCRIBE, BEGIN, COMMIT, ACK, NACK, and DISCONNECT), making it straightforward to use. Messages in STOMP are organized in frames, which are similar to HTTP messages. Each frame consists of a command, optional headers, and an optional body.</p> <p>Due to its simplicity, there are STOMP clients available in many programming languages, making it a good choice for cross-language messaging. STOMP is suitable for scenarios where you need to connect different systems with a message broker but don't require the advanced features of more complex protocols like AMQP or MQTT.</p> <p>Routing in STOMP is usually done using message headers, which makes it flexible to route messages based on various criteria. Many popular message brokers like Apache ActiveMQ, RabbitMQ, and others support STOMP, making it a versatile choice for different environments.</p> <p>STOMP supports transactions, allowing a series of SEND, ACK, and NACK commands to be treated as a single atomic operation. STOMP can be used over WebSockets, which makes it an excellent choice for web applications requiring real-time messaging.</p>"},{"location":"protocols/tacacs/","title":"TACACS+","text":"<p>TACACS+ (Terminal Access Controller Access-Control System Plus) is an advanced protocol used for remote authentication and access control to network devices such as routers, switches, and firewalls. It is an enhancement of the original TACACS protocol and provides more flexibility and security.</p> <p>Unlike its predecessors, TACACS+ separates authentication, authorization, and accounting services. This separation allows for more granular control and flexibility in managing network access.</p> <p>TACACS+ authenticates users trying to access a network device. It supports various authentication methods, including password, PAP (Password Authentication Protocol), CHAP (Challenge Handshake Authentication Protocol), and more.</p> <p>After authentication, TACACS+ manages what commands or services the user is authorized to perform or use on the network device. It keeps detailed logs of user activities, such as what commands were executed, providing an audit trail that can be crucial for security and compliance.</p> <p>One of the significant advantages of TACACS+ over older protocols like RADIUS is that it encrypts the entire body of the request packets, providing more security for sensitive data like user passwords.</p> <p>TACACS+ uses TCP (Transmission Control Protocol) for reliable transport. By default, it operates on port 49. TACACS+ allows network administrators to centrally manage and control user access to network devices, simplifying the administration of network security.</p> <p>TACACS+ is extensible and supports vendor-specific options, allowing customization for different network environments and devices. While it is an open standard, TACACS+ has been primarily used in Cisco environments, as it was developed by Cisco Systems.</p> <p>While TACACS+ and RADIUS are both used for similar purposes, TACACS+ offers more granular control at the command level and encrypts the entire packet payload, not just the password. However, RADIUS is more commonly used and supports a wider range of network devices beyond Cisco.</p>"},{"location":"protocols/telnet/","title":"Telnet","text":"<p>Telnet is a network protocol that gives users an unsecure way to access a computer over a network. Telnet is a network protocol that allows a user to remotely access and control another computer over the Internet or local area network (LAN). It enables a user to establish a connection to a remote system and perform tasks as if they were sitting in front of that computer.</p> <p>It is a client-server protocol. It uses\u00a0TCP\u00a0as its underlying transport protocol.</p> <p>One of the key features of Telnet is that it is platform-independent, which means that it can be used to connect to a variety of different operating systems and computers. Therefore, it is a valuable tool for system administrators and developers who need to manage remote systems from different locations.</p> <p>One of the main differences between Telnet and SSH is the level of security. Telnet transmits data in clear text, which means that anyone with access to the network can potentially intercept and read the data, including passwords and sensitive data. On the other hand, SSH encrypts data transmission, making it much more safe and secure than Telnet.</p>"},{"location":"protocols/tftp/","title":"Trivial File Transfer Protocol","text":"<p>TFTP, or Trivial File Transfer Protocol, is a simple high-level protocol for transferring data servers use to boot diskless workstations, X-terminals, and routers by using UDP.</p> <p>Although it may sound similar, TFTP works differently than\u00a0FTP\u00a0(File Transfer Protocol) and HTTP Protocol. Although TFTP is also based in FTP technology, TFTP is an entirely different protocol. Among the differences is that TFTP\u2019s transport protocol uses UDP which is not secure while FTP uses\u00a0Transmission Control Protocol (TCP) to secure information.</p> <p>TFTP was primarily designed to read or write files by using a remote server. However, TFTP is a multi-purpose protocol that can be leveraged for an array of different tasks. </p> <p>TFTP does not need to authenticate a user. As a user, you only need to know the file\u2019s name you\u2019re trying to download, and you can send a command to request that specific file. TFTP is also slower in its transferring process. This is due to the fact that the TFTP server needs to divide data into pieces when transferring it to the TFTP client.</p>"},{"location":"protocols/tlshand/","title":"TLS Handshake","text":"<p>The TLS (Transport Layer Security) handshake is a protocol used to establish a secure communication channel between two parties \u2014 typically a web server and a client (such as a web browser). This process involves the negotiation of various parameters to create a secure connection, including authentication, cipher suite selection, and key exchange. </p> <p>The TLS handshake is more secure and is the successor to the older SSL (Secure Sockets Layer) handshake. </p> <p>The handshake begins with the client sending a \"Client Hello\" message to the server. This message includes the TLS version the client supports, a list of supported cipher suites (encryption algorithms), and a randomly generated session key. The server responds with a \"Server Hello\" message, choosing a TLS version and a cipher suite from the options provided by the client. It also sends its own randomly generated session key.</p> <p>The server sends its digital certificate to the client. The certificate typically includes the server's public key and is issued by a trusted Certificate Authority (CA). If the selected cipher suite requires additional data exchange for key generation (like in Diffie-Hellman), the server provides the necessary parameters.</p> <p>The server can optionally request a certificate from the client for mutual authentication. The \"Server Hello Done\" indicates the end of the server's response. If requested, the client sends its certificate to the server.</p> <p>The client sends a key exchange message. This often includes a pre-master secret encrypted with the server's public key, which will be used to generate a shared session key. If the client sent a certificate, it also sends a message signed with its private key, proving it owns the sent certificate.</p> <p>Both the client and server send a \"Change Cipher Spec\" message, signalling that subsequent messages will be encrypted using the agreed cipher suite and keys. Both parties exchange encrypted \"Finished\" messages, verifying that the handshake has been completed successfully.</p> <p>After the handshake, a secure communication channel is established. All data transmitted between the client and server is encrypted with the session keys derived during the handshake.</p>"},{"location":"protocols/vnc/","title":"Virtual Network Computing","text":"<p>Virtual Network Computing (VNC) is a graphical desktop-sharing system that uses the Remote Frame Buffer protocol (RFB) to remotely control another computer. It transmits the keyboard and mouse events from one computer to another, relaying the graphical-screen updates back in the other direction, over a network.</p> <p>VNC\u00a0works on a client/server model.\u00a0A server component is installed on the remote computer (the one you want to control), and a VNC viewer, or client, is installed\u00a0on the device you want to control from. This can include another computer, a tablet, or a mobile phone.\u00a0When the\u00a0server and viewer\u00a0are\u00a0connected, the server transmits a copy of the remote computer\u2019s screen to the viewer.</p> <p>Not only can the remote user see everything on the remote computer\u2019s screen,\u00a0but the program also allows for keyboard and mouse\u00a0commands\u00a0to\u00a0work on the remote computer\u00a0from afar, so the connected user\u00a0has full control\u00a0(after being granted permission\u00a0from the\u00a0remote\u00a0compute)r.</p> <p>The VNC protocol and RDP,\u00a0developed by Microsoft, share several similarities:</p> <ul> <li>These protocols both provide access to remote desktops for quick and easy troubleshooting and remote working.</li> <li>They both require\u00a0both client and server-side software to support communication.</li> <li>They use direct peer-to-peer communication, which just means that the local user computer can connect directly to the remote computer or device.</li> <li>Both support software to manage users and enable secure access.</li> </ul> <p>Both VNC and RDP connect devices through a network, either\u00a0via server or peer-to-peer.\u00a0But even though their goals are the same \u2013 to provide graphical remote desktop capabilities to a device \u2013 they also differ in how they achieve that goal.</p> <ul> <li>RDP has limited platform capabilities, whereas VNC\u00a0works across multiple operating systems.</li> <li>RDP can be faster than VNC.</li> <li>Security levels can vastly differ between the two protocols.</li> <li>VNC connects directly to the computer, but RDP connects to a shared server.</li> <li>RDP is not very compatible if you need to implement a remote desktop solution across a wide range of devices.</li> <li>Because of this, RDP can limit the ability to provide IT help.</li> </ul>"},{"location":"protocols/wep/","title":"Wired Equivalent Privacy (WEP)","text":"<p>WEP (Wired Equivalent Privacy) is a security protocol that was designed to provide a wireless local area network (WLAN) with a level of security and privacy comparable to what is usually expected of a wired LAN.</p> <p>It was part of the original IEEE 802.11 standard ratified in 1997. However, WEP has several significant weaknesses and is considered deprecated and insecure in modern networking.</p> <p>WEP uses the RC4 stream cipher for encryption. It encrypts data transmitted over the WLAN to protect it from eavesdropping. A major weakness of WEP is the use of static encryption keys that are shared among devices on the network. Once the key is known, it can be used to decrypt all traffic encrypted with it.</p> <p>WEP supports key sizes of 40 bits and 104 bits (often referred to as 64-bit and 128-bit, respectively, including a 24-bit initialization vector). Key management in WEP is poor, as keys need to be manually set and are not regularly changed.</p> <p>WEP supports two types of authentication - Open System authentication and Shared Key authentication. Both methods have significant security weaknesses. WEP uses a 24-bit IV, which is quite small. This leads to frequent reuse of the same IV, which, combined with other flaws, makes it easier to crack the encryption key.</p> <p>WEP is vulnerable to several types of attacks, most notably key recovery attacks that can extract the WEP key from captured packets. Tools like Aircrack-ng made it possible to crack WEP keys within minutes.</p> <p>Due to its vulnerabilities, WEP was superseded by Wi-Fi Protected Access (WPA) in 2003 and later WPA2. Both provide stronger security mechanisms. Despite its weaknesses, WEP was still used in some older or legacy systems that have not been updated to support newer security protocols.</p> <p>Security experts and industry standards strongly advise against using WEP due to its vulnerabilities. It's considered ineffective at providing meaningful WLAN security. While now outdated, WEP was one of the first attempts to secure wireless networks, playing a significant role in the history of WLAN development.</p>"},{"location":"protocols/whois/","title":"WHOIS","text":"<p>WHOIS is a widely used internet protocol and database system that provides information about domain names, IP addresses, and other resources on the internet.</p> <p>It serves as a public directory for domain registration and ownership information. WHOIS data includes details about domain registrants, domain registration dates, domain name servers (DNS), and administrative and technical contacts associated with a domain.</p> <p>WHOIS provides information about the owner of a domain name, including their name, organization, email address, postal address, and phone number. This data can be valuable for verifying the legitimacy of a website, contacting the domain owner for legitimate purposes, or conducting due diligence before engaging in online transactions.</p> <p>WHOIS records include information about when a domain name was registered, its expiration date, and the domain registrar responsible for managing it. This information can help assess the age and history of a domain, which may be relevant in various investigations.</p> <p>WHOIS data also includes technical contact details, which can be useful for reaching out to the individuals or entities responsible for managing the technical aspects of a domain, such as DNS configuration and server administration.</p>"},{"location":"protocols/winrm/","title":"WinRM","text":"<p>WinRM (Windows Remote Management) is Microsoft's implementation of WS-Management Protocol (Web Services-Management), a standard protocol for remote management of computers. It allows administrators to remotely run management scripts and access data on Windows-based systems across a network.</p> <p>WinRM enables administrators to interact with Windows machines remotely, executing PowerShell scripts and commands, and managing system settings. It uses the WS-Management protocol, which is based on standard web services, allowing for interoperability across different systems and platforms. WinRM can be configured to use HTTPS for encrypted communications, enhancing security for remote management activities.</p> <p>WinRM is often used in conjunction with Windows PowerShell for advanced remote administration and automation tasks. In the context of hacking or penetration testing, WinRM can be a vector for both attack and defense:</p> <ol> <li>Lateral Movement: Once an attacker gains access to a network, they can use WinRM to move laterally across the network, executing commands on other Windows machines.</li> <li>Remote Code Execution: If WinRM is enabled and accessible, and if the attacker has valid credentials, it can be used to execute arbitrary code remotely.</li> <li>Persistence: Attackers might use WinRM to establish persistence on a network, enabling them to maintain access even after initial entry points are closed.</li> </ol>"},{"location":"protocols/wins/","title":"WINS (Windows Internet Name Service)","text":"<p>Windows Internet Name Service (WINS) is a name resolution service for Windows networks that resolves NetBIOS names to IP addresses. Developed by Microsoft, it is used in networks where DNS (Domain Name System) is not available or as a supplement to DNS in mixed-environment networks. WINS is particularly significant for legacy systems and applications that rely on the NetBIOS protocol.</p> <p>WINS resolves NetBIOS names, which are short, 15-character names used to identify systems on a network, to their corresponding IP addresses. By centrally managing name resolution, WINS reduces the amount of broadcast traffic on the network, which is a common method used by NetBIOS systems in the absence of a name resolution service.</p> <p>WINS is especially important in environments that still run applications and services that depend on NetBIOS for network communication. Computers configured to use WINS automatically register their NetBIOS names and IP addresses with the WINS server when they join the network.</p> <p>WINS is used in networks where older Windows systems or applications that require NetBIOS name resolution are in use. In some networks, WINS works alongside DNS to provide comprehensive name resolution services, especially in environments that include a mix of old and new Windows operating systems. WINS can be used in small or medium-sized networks where DNS setup and maintenance might be considered too complex or unnecessary.</p> <p>Imagine a company that uses a mix of modern and legacy Windows systems. Some of the older systems run applications that use NetBIOS names for network communications. The company uses WINS to ensure these older systems can resolve NetBIOS names to IP addresses, while also using DNS for newer systems. This dual setup allows for smooth network operations across all their systems.</p>"},{"location":"protocols/wpa-eap/","title":"WPA-EAP","text":"<p>WPA-EAP (Wi-Fi Protected Access with Extensible Authentication Protocol) is a security protocol used in wireless networks. It's part of the WPA standard, which was developed to secure wireless computer networks. WPA-EAP is particularly designed for use in enterprise environments, offering advanced authentication methods that go beyond what's provided in WPA-PSK (Pre-Shared Key).</p> <p>WPA-EAP provides a framework that supports various advanced and secure authentication methods, such as EAP-TLS (Transport Layer Security), PEAP (Protected EAP), and EAP-TTLS (Tunneled Transport Layer Security). These methods allow for more secure authentication mechanisms than a simple pre-shared key.</p> <p>WPA-EAP is widely used in enterprise settings where user authentication can be centrally managed and controlled. It is well-suited for organizations with a large number of users and where user credentials need to be closely managed.</p> <p>WPA-EAP typically works with a RADIUS (Remote Authentication Dial-In User Service) server that centrally manages authentication for all users. When a user tries to connect to the network, the access point communicates with the RADIUS server to authenticate the user.</p> <p>Various EAP methods offer different levels of security and deployment complexity. For example, EAP-TLS is one of the most secure methods but requires a certificate for each client. Other methods like PEAP and EAP-TTLS provide a balance between security and ease of deployment.</p> <p>With WPA-EAP, encryption keys are dynamically generated and can be unique for each user, adding an extra layer of security compared to WPA-PSK, where every user shares the same key.</p> <p>Many EAP methods used with WPA-EAP provide mutual authentication, where both the client and the server authenticate each other. This prevents rogue access points from capturing credentials. WPA-EAP uses strong encryption mechanisms (like TKIP or AES) to protect the data over the wireless network.</p> <p>Integration with enterprise systems allows network policies to be enforced more effectively. For instance, network access can be tied to a user's employment status. WPA-EAP scales well for large networks, providing efficient management of authentication credentials and allowing for changes without needing to reconfigure each client.</p>"},{"location":"protocols/wpa-psk/","title":"WPA-PSK","text":"<p>WPA-PSK (Wi-Fi Protected Access Pre-Shared Key) is a mode of WPA (Wi-Fi Protected Access) network security designed for home and small office networks that do not require the complexity and costs associated with a more advanced WPA-EAP (Extensible Authentication Protocol) setup. It's a method of securing your wireless network using a password, or PSK (Pre-Shared Key).</p> <p>WPA-PSK is tailored for home users or small offices where it is impractical to set up complex authentication servers. It simplifies the process of securing a wireless network by using a single shared key.</p> <p>The key, or password, used in WPA-PSK is shared among all users of the wireless network. This key is used to authenticate devices joining the network and to encrypt data between devices and the access point.</p> <p>WPA-PSK offers significantly improved security compared to the older WEP (Wired Equivalent Privacy) standard. WPA-PSK uses TKIP (Temporal Key Integrity Protocol) for encryption, which dynamically changes keys to prevent unauthorized access.</p> <p>Setting up WPA-PSK is relatively straightforward. Users only need to enter the PSK on their wireless devices to connect to the network. The security of WPA-PSK depends largely on the strength and secrecy of the pre-shared key. A strong, complex password is crucial to prevent unauthorized access and brute-force attacks.</p> <p>While WPA-PSK is more secure than WEP, it is vulnerable to password-guessing attacks, particularly if a weak or default password is used. WPA-PSK is widely used in residential and small business wireless networks due to its balance of security and ease of use.</p> <p>WPA-PSK has largely been superseded by WPA2-PSK, which provides enhanced security features, including the use of AES (Advanced Encryption Standard) encryption. WPA-PSK is compatible with most modern wireless networking equipment and is supported by the majority of wireless devices such as smartphones, laptops, and tablets.</p> <p>For larger organizations or networks that require individualized authentication, WPA-PSK is not ideal. In such cases, more advanced systems like WPA-EAP with a RADIUS server are recommended.</p>"},{"location":"protocols/wpa/","title":"WPA (Wi-Fi Protected Access)","text":"<p>Wi-Fi Protected Access (WPA) is a security protocol developed for securing wireless computer networks. It was created to provide a robust security solution to replace the original and less secure Wired Equivalent Privacy (WEP) standard. WPA and its subsequent versions, WPA2 and WPA3, are used to safeguard Wi-Fi networks.</p> <p>WPA was introduced in 2003 by the Wi-Fi Alliance to replace WEP. It uses Temporal Key Integrity Protocol (TKIP) for encryption, which dynamically changes keys to prevent unauthorized access and data breaches.</p> <p>WPA supports two modes of authentication - Personal (WPA-PSK) and Enterprise (WPA-EAP). The personal mode uses a Pre-Shared Key (PSK), while the enterprise mode uses an authentication server.</p>"},{"location":"protocols/wpa2-eap/","title":"WPA2-EAP","text":"<p>WPA2-EAP (Wi-Fi Protected Access 2 with Extensible Authentication Protocol) is an advanced security protocol used in wireless networks, particularly in enterprise and business environments. It's a part of the WPA2 (Wi-Fi Protected Access 2) standard, which provides stronger security than its predecessor, WPA. WPA2-EAP is designed to give individual users unique credentials for network access, offering enhanced security features.</p> <p>WPA2-EAP uses the Extensible Authentication Protocol (EAP) to authenticate each user individually, as opposed to using a single pre-shared key like in WPA2-PSK. This allows for more secure and flexible authentication mechanisms.</p> <p>WPA2-EAP is primarily used in enterprise settings where individual user credentials can be managed and controlled. It is well-suited for organizations with a large number of users and complex security requirements.</p> <p>Typically, WPA2-EAP works with a RADIUS (Remote Authentication Dial-In User Service) server. This server handles the authentication of users based on credentials stored in a central database.</p> <p>WPA2-EAP supports various EAP methods for authentication, including EAP-TLS (Transport Layer Security), PEAP (Protected EAP), and EAP-TTLS (Tunneled Transport Layer Security). Each method offers different levels of security and deployment complexity.</p> <p>WPA2-EAP provides strong encryption through the use of the Advanced Encryption Standard (AES).</p> <p>This encryption ensures the privacy and integrity of data transmitted over the wireless network. Unlike WPA2-PSK, where the same encryption key is used for all devices, WPA2-EAP generates dynamic, per-session encryption keys, enhancing security, especially in environments with many users.</p> <p>WPA2-EAP can be integrated with network access control systems, allowing for more granular control over network resources and user access. Methods like EAP-TLS use client and server certificates for authentication, providing a high level of security but requiring a robust public key infrastructure (PKI).</p> <p>WPA2-EAP is resistant to common attacks that target wireless networks, such as dictionary attacks, man-in-the-middle attacks, and replay attacks. For businesses and organizations that must comply with regulatory standards for data security and privacy, WPA2-EAP provides a compliant solution for wireless network security.</p>"},{"location":"protocols/wpa2-psk/","title":"WPA2-PSK","text":"<p>WPA2-PSK (Wi-Fi Protected Access 2 - Pre-Shared Key) is an encryption standard for securing wireless computer networks. It is an enhancement of the original WPA (Wi-Fi Protected Access) standard and is designed to provide a higher level of security. WPA2-PSK is commonly used in home and small business networks where a central authentication server is not required or practical.</p> <p>In WPA2-PSK, a shared key, often referred to as the Wi-Fi password, is used for network access. This key is pre-shared among all devices that connect to the network.</p> <p>WPA2-PSK uses the Advanced Encryption Standard (AES) for data encryption, providing a significant improvement in security over the original WEP (Wired Equivalent Privacy) and WPA standards.</p> <p>WPA2-PSK is designed for simplicity, making it a popular choice for home networks and small businesses. The setup involves configuring a single shared key on the wireless access point and all devices that need to connect to it.</p> <p>The security of the network depends heavily on the strength and secrecy of the pre-shared key. A strong, complex password is crucial to prevent unauthorized access. If a weak password is chosen, the network is susceptible to brute-force attacks, where an attacker tries numerous passwords until the correct one is found.</p> <p>WPA2-PSK is easy to deploy and does not require complex infrastructure or extensive technical knowledge, making it accessible for most users. Devices that are certified by the Wi-Fi Alliance for WPA2 are required to support WPA2-PSK.</p> <p>WPA2-PSK is backward compatible with WPA, allowing a mixture of devices with varying levels of security capabilities. WPA2-PSK is widely adopted in personal and small business environments due to its balance of security and ease of use.</p> <p>To maintain network security, it's recommended to regularly update the PSK, use a strong and complex password, and keep the router\u2019s firmware up to date.</p>"},{"location":"protocols/wpa2/","title":"WPA2","text":"<p>Wi-Fi Protected Access 2 (WPA2) is a security protocol and certification program developed by the Wi-Fi Alliance to secure wireless computer networks. Introduced in 2004 as an enhancement to the original WPA (Wi-Fi Protected Access) standard, WPA2 has been widely adopted due to its improved security measures.</p> <p>WPA2 uses the Advanced Encryption Standard (AES), a strong encryption protocol that provides significantly more secure data protection than the Temporal Key Integrity Protocol (TKIP) used in the original WPA.</p> <p>Like WPA, WPA2 supports two modes of authentication: WPA2-Personal (WPA2-PSK) and WPA2-Enterprise (WPA2-EAP). WPA2-Personal uses a Pre-Shared Key (PSK), while WPA2-Enterprise employs an authentication server for greater security in business and enterprise environments.</p> <p>WPA2 addressed and fixed the vulnerabilities found in WPA, making it more secure against certain types of attacks, such as packet spoofing and key reuse attacks. The Wi-Fi Alliance made WPA2 mandatory in all Wi-Fi certified devices, ensuring a baseline security standard across Wi-Fi products.</p> <p>WPA2 devices are backward compatible with WPA, allowing them to work with older hardware, though they must operate in a less secure mode to do so. WPA2 quickly became the standard for Wi-Fi security in both home and business networks due to its robust security features.</p> <p>In WPA2-Personal, the PSK is typically a passphrase, which should be long and complex to ensure security against brute-force attacks. WPA2-Enterprise provides additional security through the use of an authentication server (RADIUS server), offering a higher level of security for corporate and enterprise networks.</p> <p>Despite its improvements, WPA2 has had vulnerabilities, like the KRACK (Key Reinstallation Attack) discovered in 2017. This led to increased emphasis on the adoption of the latest security patches and configurations.</p> <p>In 2018, the Wi-Fi Alliance introduced WPA3, which provides further security enhancements. However, WPA2 remains widely used and is still considered secure when configured correctly and updated regularly.</p>"},{"location":"protocols/wpa3/","title":"WPA3","text":"<p>Wi-Fi Protected Access 3 (WPA3) is the latest version of the Wi-Fi Protected Access security protocol, introduced by the Wi-Fi Alliance in 2018. WPA3 provides more robust and secure wireless network encryption than its predecessor, WPA2.</p> <p>WPA3 uses the Simultaneous Authentication of Equals (SAE) protocol, which provides stronger protections against offline dictionary attacks compared to the Pre-Shared Key (PSK) method used in WPA2.</p> <p>WPA3 offers enhanced security for users on open public networks through individualized data encryption. This means that data transmitted over a public Wi-Fi network is encrypted uniquely for each user, reducing the risk of eavesdropping.</p> <p>The SAE mechanism in WPA3 makes it more difficult for attackers to perform brute-force attacks by limiting the data they receive in response to incorrect password attempts. WPA3 provides forward secrecy, ensuring that if an attacker captures encrypted data but later cracks the network password, they still cannot decrypt previously captured traffic.</p> <p>WPA3 includes Wi-Fi Easy Connect, which simplifies the process of connecting devices with limited or no display interface (like IoT devices) to a Wi-Fi network using a secondary device, such as a smartphone.</p> <p>WPA3-Enterprise offers a 192-bit security suite aligned with the Commercial National Security Algorithm (CNSA) Suite, providing additional protection for networks transmitting sensitive data.</p> <p>While WPA3 is a significant advancement, it is designed to coexist with WPA2, allowing a gradual transition for devices and networks. The Wi-Fi Alliance requires WPA3 certification for all Wi-Fi 6 devices, ensuring that the latest devices meet the highest security standards.</p> <p>WPA3-Enterprise Mode ensures that networks are using the strongest cryptographic protocols available, which is particularly important for government, defense, and industrial applications.</p> <p>As of its introduction, WPA3 is in a transition phase, with many devices still using WPA2. Over time, as more devices support WPA3, it is expected to become the dominant Wi-Fi security standard.</p>"},{"location":"protocols/xmlrpc/","title":"XML-RPC","text":"<p>XML-RPC (XML Remote Procedure Call) is a protocol that uses XML to encode its calls and HTTP as a transport mechanism. It's a simple way to execute functions or procedures on a remote server. In XML-RPC, a client sends an XML request to a server specifying the method to be invoked and the parameters to pass. The server then returns a response in XML format.</p> <p>The client sends an XML document to the server with details of the method call. For example, an XML request to invoke a method <code>addNumbers</code> with two parameters might look like this:</p> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;methodCall&gt;\n    &lt;methodName&gt;addNumbers&lt;/methodName&gt;\n    &lt;params&gt;\n        &lt;param&gt;&lt;value&gt;&lt;int&gt;5&lt;/int&gt;&lt;/value&gt;&lt;/param&gt;\n        &lt;param&gt;&lt;value&gt;&lt;int&gt;10&lt;/int&gt;&lt;/value&gt;&lt;/param&gt;\n    &lt;/params&gt;\n&lt;/methodCall&gt;\n</code></pre> <p>The server processes the request, executes the specified method, and returns an XML response, such as:</p> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;methodResponse&gt;\n    &lt;params&gt;\n        &lt;param&gt;&lt;value&gt;&lt;int&gt;15&lt;/int&gt;&lt;/value&gt;&lt;/param&gt;\n    &lt;/params&gt;\n&lt;/methodResponse&gt;\n</code></pre> <p>This example demonstrates a basic XML-RPC interaction where the client requests the addition of two numbers, and the server responds with the result.</p>"},{"location":"security/aaa/","title":"Authentication, Authorization and Accounting (AAA)","text":"<p>Authentication, Authorization, and Accounting (AAA) is a framework for intelligently controlling access to computer resources, enforcing policies, auditing usage, and providing the information necessary to bill for services. These processes are important for effective network management and security.</p> <ol> <li>Authentication:<ul> <li>Purpose: To verify the identity of a user or device attempting to access a system or network.</li> <li>Process: This can involve checking credentials like usernames and passwords, biometric data, tokens, or other authentication factors.</li> <li>Goal: Ensure that users or devices are indeed who or what they claim to be.</li> </ul> </li> <li>Authorization:<ul> <li>Purpose: To determine what an authenticated user or device is permitted to do.</li> <li>Process: Once a user is authenticated, the system checks what access rights and privileges they have. This could include access to files, databases, services, or other network resources.</li> <li>Goal: Make sure users or devices have the appropriate permissions to perform certain actions or access certain data.</li> </ul> </li> <li>Accounting:<ul> <li>Purpose: To track the activities of users and devices on a network.</li> <li>Process: Records are kept of what actions were taken, when they were taken, which resources were used, for how long, etc. This data can include time logs, data usage, performed activities, and more.</li> <li>Goal: Provide a way to audit and bill for resource usage, as well as a means to monitor and analyze usage patterns for security and administrative purposes.</li> </ul> </li> </ol> <p>AAA is implemented through various protocols and systems, such as RADIUS (Remote Authentication Dial-In User Service) and TACACS+ (Terminal Access Controller Access-Control System Plus). </p> <p>These protocols help manage AAA for networked computing environments and are essential for enforcing security policies, controlling access to resources, auditing usage, and ensuring that only authorized users and devices can access network resources and perform actions according to their permissions. </p> <p>AAA is a cornerstone of network management and security, especially in large-scale and enterprise environments.</p>"},{"location":"security/arppoison/","title":"ARP Poisoning","text":"<p>ARP Poisoning, also known as ARP Spoofing, is a type of cyber attack carried out over a Local Area Networks (LANs)|local area network (LAN) that involves sending falsified Address Resolution Protocol (ARP)|ARP (Address Resolution Protocol) messages onto the network. This attack exploits the lack of authentication in the ARP protocol and is used to associate the attacker's MAC Address|MAC (Media Access Control) address with the IP address of another host, such as the default gateway or a specific computer on the network.</p> <p>Under normal circumstances, when a device wants to communicate with another device on the network, it sends an ARP request to determine the MAC address associated with the desired IP address. The device with that IP address replies with its MAC address. </p> <p>In ARP poisoning, the attacker sends forged ARP reply messages to a target host (or hosts) on the network. These replies falsely tell the target device(s) that the attacker's MAC address corresponds to the IP address of another important host on the network, such as the gateway.</p> <p>As a result, the target device(s) send data intended for that important host (like the gateway) to the attacker instead. The attacker can then intercept, modify, or block this data before potentially forwarding it to the intended host, thus executing a man-in-the-middle (MITM) attack.</p> <p>The attacker can eavesdrop on network traffic, capturing sensitive information such as login credentials and financial data. By intercepting and modifying data, attackers can take over sessions, such as web sessions, to gain unauthorized access to web applications. By disrupting the network communication, the attacker can render network services unavailable. ARP poisoning can lead to network slowdowns and instability due to incorrect ARP mappings.</p>"},{"location":"security/asreproasting/","title":"AS-REP Roasting","text":"<p>AS-REP Roasting is a type of attack targeting Kerberos authentication in Windows Active Directory (AD) environments. This attack exploits a vulnerability in the way Kerberos handles pre-authentication, specifically targeting accounts configured not to require pre-authentication.</p> <p>In a typical Kerberos setup, when a user logs in, their client requests an \"Authentication Service Response\" (AS-REP) from the Kerberos Key Distribution Center (KDC). Normally, this request includes pre-authentication data, proving the user's identity by encrypting the timestamp with their password hash. The KDC decrypts this to verify the user's identity before sending the AS-REP.</p> <p>Some accounts, however, may be configured without the requirement for pre-authentication. This is sometimes done for backward compatibility or specific configuration scenarios. An attacker can request AS-REP tickets for accounts without pre-authentication. The KDC will return encrypted data that can be cracked offline to reveal the user's password.</p> <p>Using tools like GetNPUsers from Impacket, an attacker enumerates user accounts in an AD domain that are set not to require pre-authentication:</p> <pre><code>GetNPUsers.py &lt;Domain&gt;/&lt;User&gt; -no-pass -usersfile users.txt\n</code></pre> <p>The tool requests AS-REP tickets for these accounts. The KDC responds with encrypted tickets. The attacker uses Password Cracking|password-cracking tools like John the Ripper or Hashcat to crack these tickets and potentially recover users' passwords.</p>"},{"location":"security/async-sqli/","title":"Asynchronous SQL Injection","text":"<p>Asynchronous SQL injection is a form of SQL injection attack where the malicious SQL commands executed by an attacker don't produce immediate results. </p> <p>In traditional SQL injection, the attacker inputs malicious SQL code into an input field (like a search box or login form) to manipulate a database in ways that benefit them, such as accessing unauthorized data. </p> <p>The results of these actions are typically immediate and directly observable by the attacker, such as retrieving hidden data or altering database content.</p> <p>In contrast, with asynchronous SQL injection, the effects of the malicious SQL commands might not be immediately visible. These attacks might involve injecting a payload that is executed at a later time or under certain conditions, making detection and prevention more challenging. </p> <p>For example, the payload might be designed to trigger when a specific event occurs in the database or application, or it might execute in a background process that doesn't provide direct output to the attacker.</p> <p>This type of attack requires a more sophisticated approach both in execution and in detection. It's also more difficult to trace, as the delayed execution can disconnect the cause (injection) from the effect (malicious action), complicating efforts to identify and mitigate the attack.</p>"},{"location":"security/auth/","title":"Authentication","text":"<p>Authentication is a process used in computing and information security to verify the identity of a user, process, or device as a prerequisite to allowing access to resources in a system. It's a critical component of most security strategies, ensuring that only authorized entities can access protected resources such as data, systems, and networks.</p> <p>Authentication typically involves validating credentials, which can include things like usernames, passwords, digital certificates, or biometric data.</p> <p>Types of Authentication Factors:</p> <ul> <li>Knowledge Factors: Something the user knows (e.g., password, PIN).</li> <li>Possession Factors: Something the user has (e.g., security token, smartphone).</li> <li>Inherence Factors: Something the user is (e.g., biometric verification like fingerprints or facial recognition).</li> <li>Location Factors: Somewhere the user is (e.g., accessing from a specific location).</li> <li>Behavior Factors: Something the user does (e.g., typing patterns).</li> </ul> <p>Combining two or more different types of authentication factors significantly increases security. For example, a system may require a password (something the user knows) and a one-time code from a smartphone (something the user has) - known as Multi-Factor Authentication (MFA).</p> <p>Single Sign-On (SSO) allows user to authenticate once and gain access to multiple systems without being prompted to log in again for each system.</p> <p>Various protocols facilitate authentication including Kerberos Authentication|Kerberos, Lightweight Directory Access Protocol|LDAP, OAuth, and SAML (Security Assertion Markup Language).</p> <p>Authentication is a fundamental part of access control systems, determining whether a user should be allowed access to a system or resource. It helps in protecting systems from unauthorized access, thus safeguarding sensitive data and resources. In digital communications and transactions, authentication establishes trust by ensuring that entities involved are who they claim to be.</p>"},{"location":"security/authy/","title":"Authy","text":"<p>Authy is a Multi-Factor Authentication (MFA)|two-factor authentication (2FA) app that provides an additional layer of security for online accounts beyond just usernames and passwords. It's similar to Google Authenticator but comes with several features that distinguish it. Authy is designed to generate Time-based One-Time Password (TOTP)|time-based one-time passwords (TOTPs) for 2FA, enhancing the security of user accounts on various online platforms.</p> <p>One of the standout features of Authy is its ability to sync across multiple devices. This means you can access your 2FA tokens from your smartphone, tablet, or desktop, which is convenient if you lose access to one of your devices. Authy allows users to back up their 2FA accounts in the cloud. If you change or lose your device, you can easily recover your accounts on a new device after verifying your identity.</p> <p>Like Google Authenticator, Authy generates TOTPs offline, making it usable even in areas without internet connectivity. In addition to generating TOTPs, Authy also supports push authentication \u2013 a simple approve or deny prompt for logging in, adding ease of use. You can use Authy to manage 2FA tokens for various services, including social media, cloud storage, email, and online banking.</p> <p>The process is:</p> <ul> <li>When setting up 2FA for an online account, if you choose to use an authenticator app, you can opt for Authy.</li> <li>You typically scan a QR code provided by the service to add your account to Authy. This process securely transfers the shared secret key used to generate the TOTPs.</li> <li>For logging in to your account, after entering your password, you'll be prompted to enter the 6-digit code from Authy.</li> <li>Open Authy to view the code, which refreshes every 30 seconds.</li> </ul> <p>Authy enhances account security by requiring a second form of verification, protecting against password theft and unauthorized access. The ability to sync across devices and back up your accounts reduces the risk of being locked out of your accounts if you lose access to your primary device.</p> <p>While the multi-device feature and cloud backups add convenience, some users might have concerns about the implications of cloud-based storage for sensitive 2FA data. The security of your Authy app depends on the security of your devices and your cloud account.</p>"},{"location":"security/authz/","title":"Authorization","text":"<p>Authorization, in the context of computer security and information systems, is the process of granting or denying rights and privileges to a user, program, or process to access resources in a system. It is a critical component of access control and is often closely linked with authentication. While authentication verifies the identity of a user or entity, authorization determines what an authenticated user or entity is allowed to do.</p> <p>Authorization involves defining and enforcing policies that determine what actions users can perform on a system, such as read, write, delete, or execute permissions on files, databases, or applications.</p> <p>In many systems, authorization is managed through Role-Based Access Control (RBAC)|RBAC, where permissions are assigned based on roles within an organization, and users are granted roles that provide appropriate access. Authorization involves managing the privileges assigned to users or groups, ensuring they have the necessary access to perform their roles efficiently but not more than what is required.</p> <p>This security principle dictates that users and programs should have the minimum levels of access - or permissions - necessary to perform their tasks. This minimizes the risk of unauthorized access. Authorization is enforced through policies set by the system or network administrators. These policies are implemented and enforced through security mechanisms in the operating system, applications, or in the network.</p> <p>Examples of authorization:</p> <ul> <li>A user attempting to access a file may be authenticated through a username and password but can only read or modify the file if their role or user account has been granted those specific permissions.</li> <li>In an enterprise setting, an employee in the finance department may have access to financial software and documents that are not accessible to someone in the marketing department.</li> <li>In a web application, a user may be authenticated to log in but will only be authorized to access certain features or data based on their user type or subscription level.</li> </ul>"},{"location":"security/ba/","title":"Broken Authentication","text":"<p>Broken authentication is typically caused by poorly implemented authentication and session management functions.\u00a0Broken authentication\u00a0attacks aim to take over one or more accounts giving the attacker the same privileges as the attacked user. </p> <p>Authentication is \u201cbroken\u201d when attackers are able to compromise passwords, keys or session tokens, user account information, and other details to assume user identities.</p> <p>Due to poor design and implementation of identity and access controls, the prevalence of broken authentication is widespread. Common risk factors include:</p> <ul> <li>Predictable login credentials</li> <li>User authentication credentials that are not protected when stored</li> <li>Session IDs exposed in the URL (e.g., URL rewriting)</li> <li>Session IDs vulnerable to session fixation attacks</li> <li>Session value that does not time out or get invalidated after logout</li> <li>Session IDs that are not rotated after successful login</li> <li>Passwords, session IDs, and other credentials sent over unencrypted connections</li> </ul> <p>Broken Authentication attackers have only to gain access to a couple of accounts to compromise an entire system by using tools such as automated password tools and dictionary attacks.</p> <p>Authentication refers to the process of verifying the identity of users, typically through usernames and passwords, while session management involves maintaining and controlling the user's session after authentication.</p> <p>When these mechanisms are compromised or misconfigured, attackers can exploit the vulnerabilities to gain unauthorized access to user accounts, impersonate other users, or hijack sessions. This can lead to severe security breaches and expose sensitive user information.</p>"},{"location":"security/bac/","title":"Broken Access Control","text":"<p>Access control is the application of constraints on who or what is authorized to perform actions or access resources. In the context of web applications, access control is dependent on authentication and session management:</p> <ul> <li>Authentication\u00a0confirms that the user is who they say they are.</li> <li>Session management\u00a0identifies which subsequent HTTP Protocol|HTTP requests are being made by that same user.</li> <li>Access control\u00a0determines whether the user is allowed to carry out the action that they are attempting to perform.</li> </ul> <p>Broken access controls are common and often present a critical security vulnerability. Design and management of access controls is a complex and dynamic problem that applies business, organizational, and legal constraints to a technical implementation. </p> <p>Access control design decisions have to be made by humans so the potential for errors is high.</p>"},{"location":"security/bindshell/","title":"Bind Shell","text":"<p>A bind shell is a type of shell used in cybersecurity contexts, particularly in the exploitation of vulnerable systems. It refers to a technique where a shell (command interpreter) is bound to a specific port on the target machine, allowing an attacker to remotely access it.</p> <p>In a bind shell scenario, an attacker exploits a vulnerability in a target system to execute arbitrary code. This code sets up a command shell (like bash, cmd.exe) that listens on a specified network port.</p> <p>Once the shell is bound to a port, the attacker can connect to this port over the network. This connection provides access to the command shell of the target system, allowing the attacker to execute commands as if they were locally logged into the system.</p> <p>Unlike a Reverse Shell, where the target system initiates a connection to the attacker\u2019s machine, a bind shell opens a listening port on the target system, which the attacker then connects to. Bind shells are often used in penetration testing and exploitation scenarios to demonstrate the impact of a vulnerability that allows remote code execution.</p> <p>Bind shells are considered a security threat, as they allow unauthorized access to a system. They can bypass Firewall|firewalls and other security measures if outbound traffic is less restricted than inbound traffic.</p> <p>Bind shells can be scripted in various languages (like Python, Perl, PHP) or set up using tools like Netcat.</p>"},{"location":"security/blacklists/","title":"Blacklists","text":"<p>In the context of web application penetration testing (pentesting), a \"blacklist\" refers to a security mechanism that blocks or restricts certain elements, inputs, or actions based on a predefined list of disallowed items. This concept is often used to prevent potentially harmful operations or data from entering or interacting with a system.</p> <p>Blacklists are commonly used in input validation processes. Web applications check user inputs against a list of forbidden characters, strings, or patterns to prevent malicious data, such as SQL injection or Cross-Site Scripting (XSS) payloads, from being processed.</p> <p>Blacklists can be implemented as filters in various parts of a web application, including form inputs, URLs, and file uploads, to block known malicious content.</p> <p>Items often found on blacklists include certain special characters (like <code>&lt;</code>, <code>&gt;</code>, <code>'</code>, <code>\"</code>), SQL keywords (like <code>SELECT</code>, <code>DROP</code>), and scripting elements (like <code>&lt;script&gt;</code>, <code>alert()</code>).</p> <p>The effectiveness of blacklisting is limited because it's often impossible to predict and enumerate all possible malicious inputs or actions. Attackers can bypass blacklists using encoding, obfuscation, or other evasion techniques. Maintaining an exhaustive blacklist can be challenging and impractical, particularly as new vulnerabilities and attack vectors emerge.</p> <p>Blacklisting is often contrasted with Whitelists|whitelisting, which allows only known safe inputs or actions. Whitelisting is generally considered more secure but can be more restrictive and harder to implement effectively.</p> <p>During pentesting, testers often attempt to bypass blacklists to demonstrate how an attacker might exploit insufficient or improperly implemented input validation. Blacklisting is a part of a defense-in-depth strategy. It should be used in conjunction with other security measures like whitelisting, secure coding practices, and regular security audits.</p>"},{"location":"security/blindinj/","title":"Blind Boolean Injection","text":"<p>Blind boolean SQL injection are a subtype of Blind Injections|blind SQL injection attacks. In these attacks, the attacker cannot see direct data outputs from the database, such as in error-based or union-based SQL injections. Instead, they infer information about the database by sending a series of true or false queries and observing how the application's responses differ based on these conditions. </p> <p>The attacker crafts a SQL query that incorporates a condition which evaluates to either true or false. They rely on observing how the application behaves when the condition is met (true) versus when it is not met (false).</p> <p>As with other SQL injections, the attacker first identifies input fields (like search boxes, login forms, or URL parameters) that are directly used in SQL queries and are vulnerable to injection.</p> <p>The attacker injects a SQL condition that is designed to be either true or false. For instance, they might inject a statement like <code>1=1</code> (which is always true) or <code>1=2</code> (which is always false).</p> <p>The key to blind boolean SQL injection is in observing how the application responds to these true or false conditions. If the application's response differs when a true condition is injected versus a false one, the attacker can infer that their injection is impacting the SQL query.</p> <p>By iteratively refining these true or false conditions and observing the application's behavior, an attacker can extract data from the database, character by character.</p> <p>For example, consider a login form:</p> <pre><code>SELECT * FROM users WHERE username = '[user_input]';\n</code></pre> <p>The attacker might input admin' AND substring(password,1,1)='a. If the application behaves differently when the first character of the admin's password is 'a', the attacker learns that information. They repeat this process for each character of the password.</p>"},{"location":"security/blinds/","title":"Blind Injections","text":"<p>Blind SQL injection is a type of SQL injection attack where the attacker cannot see the result of a query directly. This lack of direct feedback makes the attack more challenging. </p> <p>However, attackers can still infer information about the database by observing the behavior of the application or the time it takes for the query to execute. Blind SQL injections are classified into two main types:</p> <ol> <li>Blind Boolean Injection|Boolean-Based Blind SQL Injection - In this method, the attacker sends a SQL query to the database which forces the application to return a different result depending on whether the query is true or false. By observing changes in the application's response or behavior (like changes in the content, error messages, or even just a simple 'yes' or 'no' response), the attacker can infer whether the injected statement was true.</li> <li>Time-Based Boolean Injection|Time-Based Blind SQL Injection - In this technique, the attacker crafts a SQL query that causes the database to wait for a specified amount of time before responding. By measuring the time the application takes to respond, the attacker can determine whether a certain part of the SQL query was true or false.</li> </ol>"},{"location":"security/blindssrf/","title":"Blind SSRF","text":"<p>Blind Server-Side Request Forgery (SSRF) is a type of cybersecurity vulnerability where an attacker manipulates a server to make a request to a third-party system. </p> <p>In a \"blind\" SSRF attack, the attacker does not receive a direct response from the forged request. This makes it more challenging for the attacker to ascertain the success of the attack, but it also makes the attack harder to detect and prevent.</p> <p>The attacker finds a vulnerable server that can make HTTP Protocol|HTTP requests to other systems. This vulnerability typically arises when the server does not properly validate or restrict user-supplied URLs before using them in a web request.</p> <p>The attacker crafts a request that, when processed by the server, causes it to make an unintended HTTP request to an external system. This external system could be another server on the internet or, more dangerously, a system within the server\u2019s internal network.</p> <p>In a blind SSRF attack, the attacker does not receive the response from the third-party system. This \"blindness\" means the attacker must use indirect methods to infer whether the attack was successful. For example, they might observe changes in the server's behavior or use other information sources.</p> <p>Blind SSRF attacks can lead to information disclosure, internal network reconnaissance, interaction with internal services not directly accessible from the internet, and, in some cases, internal network attacks that can escalate to more serious intrusions.</p>"},{"location":"security/blindxss/","title":"Blind XSS","text":"<p>Blind Cross-Site Scripting (XSS) is a subset of the more widely known Cross-Site Scripting vulnerability, specifically Stored (Persistent) XSS|Stored XSS, but with a key difference in its discovery and exploitation. </p> <p>In a standard XSS attack, the attacker's payload (malicious script) is executed immediately in the user's browser and the results are instantly observable by the attacker. However, in a Blind XSS attack, the exploitation is not immediately visible.</p> <p>The attacker injects a malicious script into areas of a web application that are not immediately rendered or presented back to the user. Common injection points include fields that store data, like user profiles, comments, feedback forms, and support tickets.</p> <p>The injected script lies dormant and is not executed immediately. Instead, it waits until an internal user, such as a support staff member or administrator, views the data containing the script.</p> <p>When the internal user views the data, the script executes. This could potentially happen within an administrative or privileged user interface, which is not accessible to the attacker directly. The script, once executed, can perform actions such as stealing cookies, session tokens, or sensitive information from the internal user's browser, or even carry out actions on their behalf.</p>"},{"location":"security/blue/","title":"EternalBlue","text":"<p>EternalBlue is a cyber attack exploit developed by the U.S. National Security Agency (NSA). It became widely known in April 2017 when it was leaked by the hacker group known as The Shadow Brokers. EternalBlue exploits a vulnerability in Microsoft's implementation of the Server Message Block (SMB) protocol.</p> <p>EternalBlue targets a vulnerability in SMB 1, a network file sharing protocol used by Windows. The specific vulnerability is identified as CVE-2017-0144. It allows for remote code execution, meaning an attacker could send specially crafted packets to a vulnerable Windows machine, allowing them to execute arbitrary code.</p> <p>The attacker scans for and identifies machines running vulnerable versions of Windows SMBv1. The attacker crafts and sends specially designed packets to the SMB port (445) of the target machine. These packets exploit the vulnerability to allow remote code execution. Once the exploit is successful, the attacker can execute code on the affected machine. This often involves installing a backdoor for persistent access or deploying malware.</p> <p>A well-known example of EternalBlue's exploitation is the WannaCry ransomware attack in May 2017. In this attack:</p> <ul> <li>Attackers used EternalBlue to remotely access vulnerable Windows systems on a global scale.</li> <li>After gaining access, the WannaCry ransomware was deployed, which encrypted files on the infected systems.</li> <li>Victims were asked to pay a ransom in Bitcoin to get their files decrypted.</li> </ul>"},{"location":"security/blv/","title":"Business Logic Vulnerabilities","text":"<p>Business logic vulnerabilities are security weaknesses or flaws in the design and implementation of an application that can be exploited to carry out actions unintended by the application's owner. Unlike traditional vulnerabilities, which are typically flaws in coding, business logic vulnerabilities are more about the ways an application's legitimate features can be manipulated.</p> <p>These vulnerabilities exploit the expected or standard behavior of applications in unintended ways. They are often specific to the particular logic of an application and, therefore, vary widely from one application to another. Business logic vulnerabilities are usually harder to detect with automated tools since they involve understanding the intended functionality and logic of the application.</p> <p>Identifying these vulnerabilities often requires a deep understanding of the application's business logic, making manual assessment and creative thinking crucial.</p> <p>Some examples of Business Logic Vulnerabilities include:</p> <ol> <li>Authentication Bypass: An application might allow a user to access protected resources without properly authenticating, perhaps through manipulation of URLs or direct access to a backend API.</li> <li>Insecure Direct Object References (IDOR) (KB): If an application exposes internal objects through URLs or parameters (like <code>www.example.com/account?id=123</code>), an attacker might manipulate these references to access data belonging to other users.</li> <li>Multi-Step Transaction Manipulations: In applications involving multi-step transactions (like shopping carts in e-commerce sites), attackers could manipulate the process to change the order's outcome, such as altering prices or quantities after final confirmation but before payment.</li> <li>Business Rules Bypass: If certain business rules are not enforced consistently across an application, it can lead to vulnerabilities. For example, an e-commerce site might limit one promotional item per user, but this rule could be bypassed by creating multiple accounts.</li> <li>Workflow Exploitations: By understanding and manipulating the workflow of an application, attackers can exploit vulnerabilities. For instance, skipping steps in a workflow to achieve a goal that should not otherwise be allowed.</li> <li>Logic Flaws in Access Controls: Poorly implemented access controls could allow a user with lower privileges to access or modify data meant for higher-privileged users.</li> </ol>"},{"location":"security/brute/","title":"Brute Force Attack","text":"<p>A brute force attack is a hacking method that uses trial and error to crack passwords, and encryption keys. It\u00a0is a simple yet reliable tactic for gaining unauthorized access to individual accounts and organizations\u2019 systems and networks. </p> <p>The hacker tries multiple usernames and passwords, often using a computer to test a wide range of combinations, until they find the correct login information.</p> <p>Once successful, the actor can enter the system masquerading as the legitimate user and remain inside until they are detected. They use this time to move laterally, install back doors, gain knowledge about the system to use in future attacks, and, of course, steal data.</p> <p>The name \"brute force\" comes from attackers using excessively forceful attempts to gain access to user accounts. Despite being an old cyberattack method, brute force attacks are tried and tested and remain a popular tactic with hackers.</p>"},{"location":"security/buffer/","title":"Buffer Overflows","text":"<p>Buffer overflows are a type of vulnerability that occur in software when a program attempts to write more data to a buffer (a contiguous block of memory allocated to store data) than it can hold. This can lead to unexpected behavior and security vulnerabilities.</p> <p>A buffer is a region of memory used to temporarily store data while being moved from one place to another. Buffers are often used when handling data streams or user input.</p> <p>Many programming languages use fixed-size buffers. When a program writes more data to a buffer than it can hold, the excess data can overlfow into adjacent memory areas.</p> <p>Buffer overflows typically occur because of insufficient bounds checking during data copying or manipulation operations. The simplest effect of a buffer overflow is a program crash.</p> <p>More critically, buffer overflows can be exploited to execute arbitrary code. </p> <p>Web forms, Uniform Resource Locator|URL parameters and HTTP Headers are common input vectors in web app pentesting. Attackers may try to overflow buffers by providing excessively long input strings in these fields.</p> <p>Pentesters also often use fuzzing techniques like Directory Fuzzing or Parameter Fuzzing (KB), sending large amounts of data or specifically crafted payloads to test how the app handles it.</p>"},{"location":"security/bxss/","title":"Brute XSS","text":"<p>\"Brute XSS\" is an open-source tool specifically designed for identifying and testing for Cross-Site Scripting (XSS) vulnerabilities in web applications. </p> <p>XSS vulnerabilities are a common security issue where an attacker can inject malicious scripts into content that other users see. Brute XSS assists in automating the process of detecting these vulnerabilities.</p> <p>Brute XSS automates the process of sending various payloads (malicious scripts) to target web applications to test for XSS vulnerabilities. The tool often allows for customization of payloads, enabling users to adapt their testing to different types of web applications and scenarios.</p> <p>It can be used to test for XSS in various parts of a web application, such as form fields, URL parameters, headers, etc.</p>"},{"location":"security/c2/","title":"Command and Control (C2)","text":"<p>Command and Control (C2 or C&amp;C) in the context of cybersecurity refers to the means by which attackers maintain communication with compromised systems or networks within a target environment. This communication channel allows attackers to issue commands, control malware, and extract data from the infected system. Establishing a C2 channel is a common tactic in advanced persistent threats (APTs), botnets, and various other types of cyber attacks.</p> <p>C2 allows attackers to remotely control malware or compromised systems. They can execute commands, deploy additional payloads, or exfiltrate data. C2 communication can be direct (such as through a TCP-IP|TCP/IP connection) or indirect (using intermediaries like social media, email, or legitimate web services). Effective C2 channels are designed to be stealthy and persistent, often using encryption or mimicking legitimate traffic to avoid detection by network security systems.</p> <p>Some examples of C2 mechanisms:</p> <ol> <li>HTTP/HTTPS-Based C2: Utilizing web requests to communicate with a server controlled by the attacker. This method is common because HTTP Protocol|HTTP/HTTPS Protocol|HTTPS traffic is often allowed through Firewall|firewalls.</li> <li>DNS Tunneling: Using DNS queries and responses to pass commands and data. This is a stealthy method as DNS traffic is rarely inspected in detail.</li> <li>Social Media C2: Leveraging social media platforms for sending commands and receiving data. For example, a Twitter account controlled by the attacker might post encoded commands that the malware interprets and executes.</li> <li>Email-Based C2: Sending commands or receiving data through emails. The malware might check an email inbox for new commands.</li> <li>Peer-to-Peer (P2P) Networks: Using a decentralized P2P network for command and control, making it harder to disrupt the C2 channel by taking down a single server.</li> <li>Custom Protocols: Developing custom communication protocols that can be more difficult for security tools to identify and block.</li> <li>Websocket and MQTT: Using newer web technologies like Websockets or MQTT|MQTT (Message Queuing Telemetry Transport), which are designed for real-time communication in web applications and IoT devices.</li> </ol>"},{"location":"security/captcha/","title":"CAPTCHA","text":"<p>CAPTCHA, which stands for \"Completely Automated Public Turing test to tell Computers and Humans Apart,\" is a type of challenge-response test used in computing to determine whether the user is human or not. This tool is commonly used on websites to prevent automated software (like bots) from performing actions that could potentially be abusive or harmful, such as creating accounts, posting spam, or conducting Brute Force Attack|brute-force attacks.</p> <p>CAPTCHA presents a challenge that is usually easy for humans to solve but difficult for automated systems.</p> <p>Types of CAPTCHA:</p> <ul> <li>Text-based CAPTCHA: Displays distorted text that a user must correctly enter. The distortion is designed to confuse automated text recognition software.</li> <li>Image-based CAPTCHA: Requires users to identify and click on specific items in an image (like all pictures with traffic lights).</li> <li>Audio CAPTCHA: Plays a series of letters or numbers as audio for the user to enter. This type is often used as an alternative for visually impaired users.</li> <li>Mathematical or Logical CAPTCHA: Asks the user to solve a simple math problem or answer a logic question.</li> <li>reCAPTCHA: A popular service by Google, it includes the \"I'm not a robot\" checkbox and sometimes requires image identification. Advanced versions work in the background, analyzing browsing behavior to detect bots.</li> </ul> <p>CAPTCHA is effective at reducing spam, automated form submissions, and brute-force attacks by making it difficult for bots to complete the required tasks. CAPTCHA can sometimes be frustrating for users, especially if the challenges are too difficult or inaccessible.</p> <p>Traditional CAPTCHAs (like distorted text) can be challenging for users with visual impairments, leading to the development of more accessible alternatives. Improvements in AI and machine learning have led to automated systems being able to solve certain types of CAPTCHAs, which necessitates continuous evolution of CAPTCHA methods.</p>"},{"location":"security/cbts/","title":"Channel Binding Tokens (CBTs)","text":"<p>Channel Binding Tokens (CBTs) are a security mechanism used to enhance the protection of the authentication process, particularly in preventing Man-in-the-Middle (MitM) attack|man-in-the-middle (MITM) attacks. A CBT is a token or piece of data that binds the security of two separate protocols, typically an application layer protocol like HTTP Protocol|HTTP with a lower-level transport layer protocol like TLS (Transport Layer Security).</p> <p>CBTs are used to \"bind\" a high-level authentication process (such as Kerberos Authentication|Kerberos or NTLM authentication) to a specific secure channel or session (like a TLS session). The main purpose of CBTs is to prevent MITM attacks where an attacker intercepts and relays credentials from one channel to another unauthorized channel. With CBTs, the server can verify that the credentials are being presented in the correct, secured session.</p> <p>By tying the authentication process to a specific encrypted channel, CBTs ensure that authentication tokens cannot be hijacked or replayed in a different context or session.</p> <p>When a client initiates a secure session (such as a TLS connection), a unique token representing that session is generated. During the authentication phase (like when a user logs in using Kerberos), this unique session token (CBT) is included in the authentication process. The server, upon receiving the authentication request, checks the CBT against the current session. If they match, it confirms that the authentication request is valid and not being relayed or manipulated by an attacker.</p> <p>A web application configured to use CBTs will require that any HTTP-based authentication is accompanied by a token that matches the current TLS session, thus preventing an attacker from intercepting and using the authentication credentials in a different session. During a TLS handshake, a CBT is generated and later used in the authentication process to ensure that the authentication is happening over the same secure channel.</p>"},{"location":"security/challenge/","title":"Challenge-Response Protocol","text":"<p>A challenge-response protocol is a security mechanism used to authenticate a user or device in a system. It's based on the concept of one party (the verifier) presenting a challenge to another party (the prover), who must provide a valid response to be authenticated. This type of protocol is used to ensure that the entity seeking access is indeed who it claims to be.</p> <p>The key components are:</p> <ol> <li>Challenge: A random or semi-random piece of data generated by the verifier and sent to the prover. The challenge should be unique each time to prevent replay attacks.</li> <li>Response: The prover uses a secret (like a password, token, or cryptographic key) to compute a response based on the challenge and sends it back to the verifier.</li> <li>Verification: The verifier checks the response. If it matches the expected value, the prover is authenticated.</li> </ol> <p>Some examples of protocols include:</p> <ol> <li>Password Authentication: A simple form is a login system where the username is the challenge and the password is the response.</li> <li>CAPTCHA: A CAPTCHA presents a challenge (like distorted text or images) to the user (prover) who must enter the correct text or select the correct images.</li> <li>Smart Card Authentication: When accessing a secure system with a smart card, the card reader (verifier) sends a challenge to the card (prover), which then uses a stored private key to generate a response.</li> <li>Two-Factor Authentication Devices: The device generates a one-time password (OTP) as a response to a login challenge, and the user enters this OTP to complete the authentication process.</li> <li>Cryptographic Protocols: In more complex systems, cryptographic algorithms are used to create a secure challenge-response system, such as using public key cryptography where the challenge is encrypted with the prover's public key and can only be decrypted and responded to by the holder of the corresponding private key.</li> </ol> <p>They provide a secure method for verifying the identity of a user or device, as the correct response should only be producible by an entity that knows the secret. By using a unique or time-variant challenge each time, the protocol prevents attackers from capturing and reusing a response.</p> <p>The security of the protocol depends on the strength and secrecy of the response-generating secret. In some implementations, particularly those not using encryption, care must be taken to ensure that the challenge and response cannot be intercepted and exploited.</p>"},{"location":"security/cinj/","title":"Code Injection","text":"<p>Code injection is a type of security vulnerability that allows an attacker to introduce or \"inject\" malicious code into a program or system. This malicious code is then executed by the system, typically with the same privileges as the application it's attacking. The goal of code injection can vary from unauthorized data access, data manipulation, to taking complete control of the affected system.</p> <p>There are several types of code injection attacks, each targeting different aspects of a system:</p> <ol> <li>SQL Injection: Occurs when an attacker is able to insert a malicious SQL query into input fields, exploiting vulnerabilities in the application's database layer. This can lead to unauthorized access to or manipulation of database information.</li> <li>Cross-Site Scripting (XSS): Involves injecting malicious scripts into web pages viewed by other users. This can lead to the theft of cookies, session tokens, or other sensitive information from the victims' browser.</li> <li>Command Injection: Happens when an attacker is able to execute arbitrary commands on the host operating system through a vulnerable application.</li> <li>HTML Injection: Involves inserting malicious HTML code into a webpage that is then rendered by other users' browsers.</li> <li>Script Injection: Similar to XSS, this involves injecting scripts, often in languages like JavaScript, into web applications.</li> </ol>"},{"location":"security/clear/","title":"Clear Text","text":"<p>Clear-text is also known as plaintext and simple refers to any text or data that is not encrypted or scrambled in any way. It is essentially readable and understandable as it is, without requiring any form of decoding or decryption.</p> <p>In computer security, it is significant as it can be easily read by anyone who has access to it.</p> <p>When data is sent over a network or stored in a database in clear-text, it poses a huge threat. If it is intercepted by unauthorized individuals, clear-text data can be used maliciously including things like credentials and personal details.</p>"},{"location":"security/clickjacking/","title":"Clickjacking","text":"<p>Clickjacking is an interface-based attack in which a user is tricked into clicking on actionable content on a hidden website by clicking on some other content in a decoy website. Consider the following example:</p> <p>A web user accesses a decoy website (perhaps this is a link provided by an email) and clicks on a button to win a prize. Unknowingly, they have been deceived by an attacker into pressing an alternative hidden button and this results in the payment of an account on another site.</p> <p>This is an example of a clickjacking attack.</p> <p>The technique depends upon the incorporation of an invisible, actionable web page (or multiple pages) containing a button or hidden link, say, within an iframe. The iframe is overlaid on top of the user's anticipated decoy web page content.</p> <p>This attack differs from a\u00a0Cross-Site Request Forgery\u00a0attack in that the user is required to perform an action such as a button click whereas a\u00a0CSRF attack\u00a0depends upon forging an entire request without the user's knowledge or input.</p>"},{"location":"security/coll/","title":"Collision Attacks","text":"<p>Collision attacks are a type of cryptographic attack on hash functions, a critical component in various security applications like digital signatures and data integrity verification. In a collision attack, the goal is to find two different inputs that produce the same hash output, thereby causing a \"collision\" in the hash function.</p> <p>There are two types:</p> <ol> <li>Birthday Attack: This is based on the birthday paradox in probability theory. The attack involves finding two different inputs that hash to the same output. It's called a \"birthday attack\" because it exploits the mathematical principle that in a group of people, it's surprisingly likely that two will share the same birthday. In hash functions, it means that it's more feasible than intuitively expected to find two different inputs with the same hash.</li> <li>Specific-Input Collision: In this case, an attacker tries to find a collision for a specific given input. This is typically harder than a general collision attack.</li> </ol> <p>Hash functions are used to ensure data integrity. If an attacker can produce a collision, they can replace legitimate data with fraudulent data having the same hash value, potentially bypassing systems that rely on hashes for data integrity checks.</p> <p>Collision attacks can undermine digital signature schemes. If an attacker can generate a collision, they might be able to forge a digital signature, making it appear as though a trusted source signed a malicious document or file.</p> <p>MD5, an older hash function, is known to be vulnerable to collision attacks. It's possible to create two different documents that hash to the same MD5 hash, allowing for potential security breaches. Similar vulnerabilities have been discovered in SHA-1, leading to its deprecation in favour of more secure hash functions like SHA-256.</p> <p>The best defense against collision attacks is using modern, secure hash functions like SHA-256 or SHA-3, which are designed to be resistant to such attacks. As vulnerabilities are discovered, it's important for organizations to update their cryptographic practices and move to more secure algorithms.</p>"},{"location":"security/commin/","title":"Command Injection","text":"<p>Command injection is also known as shell injection. It allows an attacker to execute operating system (OS) commands on the server that is running an application, and typically fully compromise the application and its data.</p> <p>Often, an attacker can leverage an OS command injection vulnerability to compromise other parts of the hosting infrastructure, and exploit trust relationships to pivot the attack to other systems within the organization.</p> <p>An example could be a shopping application lets the user view whether an item is in stock in a particular store. This information is accessed via a URL:</p> <pre><code>https://insecure-website.com/stockStatus?productID=381&amp;storeID=29\n</code></pre> <p>To provide the stock information, the application must query various legacy systems. For historical reasons, the functionality is implemented by calling out to a shell command with the product and store IDs as arguments:</p> <pre><code>stockreport.pl 381 29\n</code></pre> <p>This command outputs the stock status for the specified item, which is returned to the user.</p> <p>The application implements no defenses against OS command injection, so an attacker can submit the following input to execute an arbitrary command:</p> <pre><code>&amp; echo aiwefwlguh &amp;\n</code></pre> <p>If this input is submitted in the\u00a0parameter, the command executed by the application is:</p> <pre><code>stockreport.pl &amp; echo aiwefwlguh &amp; 29\n</code></pre> <p>The\u00a0echo\u00a0command causes the supplied string to be echoed in the output. This is a useful way to test for some types of OS command injection. The\u00a0<code>&amp;</code>\u00a0character is a shell command separator. In this example, it causes three separate commands to execute, one after another. The output returned to the user is:</p> <pre><code>Error - productID was not provided aiwefwlguh 29: command not found\n</code></pre> <p>The three lines of output demonstrate that:</p> <ul> <li>The original\u00a0stockreport.pl\u00a0command was executed without its expected arguments, and so returned an error message.</li> <li>The injected\u00a0echo\u00a0command was executed, and the supplied string was echoed in the output.</li> <li>The original argument\u00a029\u00a0was executed as a command, which caused an error.</li> </ul> <p>Placing the additional command separator\u00a0&amp;\u00a0after the injected command is useful because it separates the injected command from whatever follows the injection point. This reduces the chance that what follows will prevent the injected command from executing.</p>"},{"location":"security/crack/","title":"Password Cracking","text":"<p>Password cracking is the process of attempting to gain unauthorized access to restricted systems or data by deciphering a user's password. This is often done by cybersecurity professionals for ethical purposes (like security testing) and, unfortunately, by malicious attackers as well.</p> <p>The primary goal is to break into a system or retrieve data that is protected by a password by guessing or calculating the correct password.</p> <p>There are different methods used including:</p> <ul> <li>Brute Force Attack - trying every possible combination of characters until the correct password is found.</li> <li>Dictionary Attacks - list of common words and phrases to guess passwords</li> <li>Rainbow Table Attack - Rainbow Tables|rainbow tables are precomputed tables for reversing cryptographic hash functions, primarily used for cracking password hashes.</li> <li>Phishing - deceptive method where attackers trick users into revealing their passwords, often through fake login pages or Social Engineering tactics.</li> </ul>"},{"location":"security/cve/","title":"Common Vulnerabilities and Exposure (CVE)","text":"<p>Common Vulnerabilities and Exposures (CVE) is a database of publicly disclosed information security issues. A CVE number uniquely identifies one vulnerability from the list. CVE provides a convenient, reliable way for vendors, enterprises, academics, and all other interested parties to exchange information about cyber security issues.</p> <p>Enterprises typically use CVE, and corresponding\u00a0Common Vulnerability Scoring System|CVSS scores, for planning and prioritization in their\u00a0vulnerability management programs.</p> <p>As defined by\u00a0CVE, a vulnerability is a \u201c...flaw in a software, firmware, hardware, or service component resulting from a weakness that can be exploited, causing a negative impact to the confidentiality, integrity, or availability of an impacted component or components.\u201d</p> <p>A vulnerability, therefore, provides an attacker with direct unauthorized access to a system or network, often with full privileges to execute commands or access restricted information. An exposure is a code or configuration error through which an attacker can gain indirect and often hard-to-discover access to application data such as customer information.</p> <p>Each CVE Record is associated with a unique alphanumeric ID and references a single specific vulnerability. The CVE Record includes a brief description of the vulnerability or exposure and at least one public reference.</p> <p>Authorized Data Publishers (ADPs) can then enrich a CVE Record with additional information such as risk scores or lists of affected products. CVE Records are added by CVE Numbering Authorities (CNAs)\u2014organizations that are permitted to assign CVE IDs to vulnerabilities.</p> <p>The primary CNA is MITRE but there are currently 149 CNAs in 25 countries, all acting within a kind of federated system.</p> <p>Each CNA has a defined scope of responsibility for identifying and publishing vulnerabilities, often related to their own products. A CNA is issued a block of CVE IDs to attach to new issues as they arise.</p> <p>The list of CNAs includes the likes of Adobe Systems, Advanced Micro Devices (AMD), McAfee, Check Point, Red Hat, Microsoft, and Google, to name but a few. Root CNAs have the authority to recruit, train, and govern other CNAs or ADPs.</p>"},{"location":"security/cvss/","title":"Common Vulnerability Scoring System (CVSS)","text":"<p>The Common Vulnerability Scoring System (CVSS) is a published standard that uses the Common Vulnerabilities and Exposure|CVE List and other sources to produce a numerical score that reflects a vulnerability\u2019s severity. CVSS is used by organizations and services around the globe to prioritize vulnerabilities and assess their vulnerability management processes.</p> <p>CVSS is an excellent example of how the standardized, publicly available CVE List is leveraged by another service to add value to vulnerability management programs. To promote its integration with other products and services, the CVE List is available in a number of human- and machine-readable formats.</p> <p>The goal of CVSS is to help you compare vulnerabilities in different applications \u2013 and from different vendors - in a standardized, repeatable, vendor agnostic approach.</p> <p>CVSS generates a score from 0 to 10 based on the severity of the vulnerability. A score of 0 means the vulnerability is less significant than the highest vulnerability with a score of 10, if you're only using CVSS.</p> <p>By using CVSS to prioritize vulnerabilities, you can focus on the most critical ones first and reduce the overall risk to your organization.</p> <p>CVSS values have been grouped as well into the rankings that you may have seen, of Critical, High, Medium, and Low.</p> <p>The CVSS score combines a lot of factors to be able to generate a score. Those factors are:</p> <ul> <li>Attack Vector</li> <li>Attack Complexity</li> <li>Privileges Required</li> <li>User Interaction</li> <li>Scope</li> <li>Confidentiality</li> <li>Integrity</li> <li>Availability</li> </ul>"},{"location":"security/cwe/","title":"Common Weaknesses Enumeration (CWE)","text":"<p>Common Weakness Enumeration (CWE) is a community-developed list of common software and hardware weakness types that have security implications. It serves as a common language for describing software security weaknesses in architecture, design, or code, and provides a standard measuring stick for software security tools and services.</p> <p>CWE provides a unified, standardized list of common security weaknesses. This helps organizations and developers to identify, discuss, and remediate software vulnerabilities in a consistent manner. Weaknesses in the CWE list are categorized and organized in various ways, such as by the nature of the weakness, its impact, or where in the software development lifecycle it typically appears. This categorization aids in understanding and addressing different types of vulnerabilities effectively.</p> <p>CWE is used as a basis for identifying, mitigating, and preventing software weaknesses. It's an essential tool for developers, security professionals, educators, and tools vendors in the realm of software security. Along with listing weaknesses, CWE often provides information on how these weaknesses can be mitigated or avoided, helping developers and organizations to build more secure software.</p> <p>Many security tools, such as static code analysis tools, use the CWE list to help identify weaknesses in software. It is also used in cybersecurity training and education to provide a framework for discussing common security issues.</p> <p>CWE is often used in conjunction with other security standards and lists, such as the Common Vulnerabilities and Exposures (CVE) system and the OWASP Top Ten, to provide a comprehensive approach to security vulnerability management.</p> <p>The CWE list is maintained and continuously updated by a broad community of industry practitioners, tool vendors, researchers, and other stakeholders in the cybersecurity field. This community involvement ensures that the list stays relevant and up-to-date with the evolving landscape of software security.</p>"},{"location":"security/dark/","title":"Dark Web","text":"<p>The dark web refers to a part of the internet that is not indexed by standard search engines and is accessible only through special software, such as Tor or I2P, which anonymize user traffic. It's known for hosting a range of anonymous and often illicit activities due to its ability to preserve user anonymity.</p> <p>The dark web forms a small part of the Deep Web|deep web, which includes all parts of the internet not indexed by search engines.</p> <p>The dark web is a known hub for cybercriminal activities, including the sale of exploited data, hacking tools, and services. Understanding the nature of these threats can inform security strategies in penetration testing.</p> <p>Cybercriminals often trade information about vulnerabilities, exploits, and hacking tools on the dark web. Penetration testers need to be aware of the latest exploits and vulnerabilities that might be in circulation. Sometimes, data from breaches (including credentials) ends up on the dark web. Penetration testers can use this information to understand common security weaknesses and trends in cyber attacks.</p> <p>While penetration testers may access the dark web for research and staying informed on cybersecurity trends, any activity must be ethical and legal. Engaging in or endorsing illegal activities, even in the name of research, is not just unethical but could have legal repercussions.</p> <p>For some security professionals, the dark web can be a source of threat intelligence. By monitoring dark web forums and marketplaces, they can gather insights about potential threats and targets.</p>"},{"location":"security/dbomb/","title":"Decompression Bomb","text":"<p>A decompression bomb, also known as a \"Zip bomb\" or \"compression bomb,\" is a maliciously crafted file designed to crash or render useless the program or system reading it. It's a type of attack against a system's file decompression functionality.</p> <p>A decompression bomb is typically a small compressed file that, when decompressed, expands to an enormous size far beyond the system's capacity to handle. For example, a few kilobytes of compressed data could expand into gigabytes or terabytes.</p> <p>The primary goal of a decompression bomb is to consume system resources, thereby causing performance issues, exhausting storage space, or crashing the system. This can be part of a Denial of Service (DoS) Attacks|denial-of-service (DoS) attack.</p> <p>Although often associated with ZIP files, decompression bombs can be created in any file format that supports compression, such as gzip, rar, or tar. These files are created using recursive or repeating patterns that compress well but expand to a disproportionately large size when decompressed.</p> <p>Decompression bombs can impact software that automatically decompresses files, such as email servers, web servers, antivirus programs, or file decompression utilities.</p>"},{"location":"security/deep/","title":"Deep Web","text":"<p>The deep web refers to all parts of the internet that are not indexed by standard search engines like Google, Bing, or Yahoo. This includes any content that is behind paywalls, requires sign-in credentials, or is blocked from Search Engine Crawlers|search engine crawlers.</p> <p>The deep web contains mundane and everyday internet content such as user databases, webmail pages, registration-required web forums, personal profiles, medical records, legal documents, confidential corporate web pages, and other similar data.</p> <p>Content on the deep web can be accessed using a standard web browser, but it requires specific knowledge of where to find it, like a direct URL. The deep web is vast, comprising a significant portion of the total internet content, much larger than the surface web (the part of the internet indexed by search engines).</p> <p>The Dark Web is a subset of the deep web. All dark web content is part of the deep web, but not all deep web content is part of the dark web. While the deep web is mostly associated with legitimate private or confidential data, the dark web is often linked with illegal and underground activities.</p> <p>Both require specific knowledge or tools to access, but the dark web's requirement for special anonymizing software like Tor makes it distinct from the broader deep web.</p>"},{"location":"security/deface/","title":"Website Defacing","text":"<p>Website defacing is a type of cyber attack where an attacker alters the visual appearance of a website or a webpage. This is typically done by modifying the site's content, replacing the original page with one created by the attacker, often for malicious purposes, political statements, or simply as an act of vandalism.</p> <p>Attackers gain unauthorized access to a web server, often exploiting security vulnerabilities such as SQL injection, Cross-Site Scripting (XSS), or using stolen File Transfer Protocol|FTP (File Transfer Protocol) credentials.</p> <p>The visible content of the website is altered. This might include changing text, images, layouts, or adding new elements. In some cases, the entire website might be replaced with a different page.</p> <p>The reasons behind such attacks vary. Some attackers do it to make a political statement, others for notoriety or to demonstrate their hacking skills, and some may have malicious intent like spreading misinformation or harming the reputation of the targeted organization.</p>"},{"location":"security/deob/","title":"Deobfuscation","text":"<p>Code deobfuscation refers to the process of transforming obfuscated code, which is intentionally made complex and difficult to understand, back into its more readable and comprehensible form.</p> <p>This process is commonly used in software analysis, especially when dealing with code that has been obfuscated for various reasons.</p> <p>Code is often obfuscated to protect intellectual property, hinder reverse engineering or conceal malicious content. Obfuscation techniques can include altering variable names, restructuring code, or using complex algorithms to mask the code's true function.</p> <p>Deobfuscation involves various techniques like Static Analysis|static analysis, Dynamic Analysis|dynamic analysis, and the use of specialised tools. Static analysis involves examining the code without executing it, while dynamic analysis involves running the code and observing its behaviour.</p> <p>Deobfuscation can be challenging as Obfuscation (KB)|obfuscation techniques are designed to make reverse engineering more difficult. It is commonly used in cybersecurity for analysing malware, in software development for understanding legacy code or third-party components.</p> <p>JavaScript, being a widely-used language for web development, is often targeted for obfuscation to protect client-side code. Some common obfuscation techniques for JavaScript include:</p> <ul> <li>Minification - removing whitespace, newlines, and comments and shortening variable names.</li> <li>String Encoding - encoding strings in a non-standard format.</li> <li>Code Transformation - changing the code structure without altering its functionality.</li> <li>Logic Bombs - inserting conditional statements that change the code behaviour under certain conditions.</li> </ul>"},{"location":"security/dict/","title":"Dictionary Attacks","text":"<p>A dictionary attack is a method used in Password Cracking where an attacker tries to guess passwords or phrases by systematically entering every word in a prearranged list, typically derived from a dictionary.</p> <p>This type of attack is based on the assumption that many users choose common words, phrases, or simple variations of them as their passwords.</p> <p>Unlike Brute Force Attack|brute force attacks that try every possible combination, dictionary attacks focus on likely possibilities, making them faster and more efficient in many cases.</p> <p>Attackers use a file containing a list of words, phrases and potentially common passwords. For more targeted attacks, the dictionary can be customized with information relevant to the individual or organization being targeted. A dictionary can also be built using a tool like CeWL to scrape the target website for relevant words.</p>"},{"location":"security/dirtrav/","title":"Directory Traversal","text":"<p>Directory traversal, also known as path traversal, is a security vulnerability in software applications. It occurs when insufficient security validation/sanitization of user-supplied input file names allows attackers to access or manipulate files outside of the intended directory. This vulnerability can allow attackers to access restricted directories and read, modify, or delete sensitive files on a web server.</p> <p>Directory traversal exploits occur due to inadequate validation of user-supplied input. This vulnerability is often found in web applications that use input to construct file paths for file operations like open, read, or write.</p> <p>Attackers manipulate file paths by using \"..\" (dot-dot-slash) sequences, which are interpreted as \"go up one directory,\" along with other techniques to navigate the file system. An attacker might use input like <code>../../../../etc/passwd</code> to traverse up to the root directory and then access a critical file like <code>passwd</code> (which stores user credential data on Unix-based systems).</p>"},{"location":"security/dll/","title":"DLL Hijacking","text":"<p>DLL hijacking is a vulnerability exploitation technique where an attacker exploits the way some Windows applications search for and load Dynamic Link Libraries (DLLs). If an application does not specify a full path for a DLL, Windows searches for the DLL in a predefined set of directories.</p> <p>An attacker can place a malicious DLL with the expected name in a directory that is searched before the legitimate one, leading the application to load the attacker's DLL instead of the legitimate one.</p> <p>When an application needs to load a DLL, it often searches for the file in a set of default directories if the full path is not specified. The attacker places a malicious DLL with the same name as the legitimate DLL in a directory that the application searches before the legitimate DLL directory. When the application runs, it inadvertently loads the attacker's malicious DLL, executing the code within it.</p> <p>Some examples may include:</p> <ul> <li>Hijacking System Utilities: An attacker places a malicious version of a commonly used DLL in a directory that is part of the system PATH. When a system utility is executed, it loads the malicious DLL, giving the attacker control or additional access.</li> <li>Exploiting Third-party Applications: Many third-party applications do not use full paths to load DLLs. By placing a malicious DLL in the application's directory or another directory in the search path, attackers can exploit this behavior.</li> <li>Bundled Software: Software that comes bundled with other applications might search for a DLL in its own directory first. If an attacker replaces one of these DLLs with a malicious version, it can lead to the execution of malicious code.</li> </ul>"},{"location":"security/dlli/","title":"DLL Injection","text":"<p>DLL Injection is a technique used in software development and cybersecurity, including penetration testing, where a Dynamic Link Library (DLLs|DLL) file is loaded into the address space of another process by force. This action causes the targeted process to run the code contained in the DLL file.</p> <p>The first step is to identify a target process into which the DLL will be injected. The injector process (controlled by the attacker or pentester) allocates memory within the target process\u2019s address space, usually using functions like VirtualAllocEx. The path of the DLL to be injected is written to the allocated memory space in the target process.</p> <p>The injector process then creates a new thread in the target process that calls functions like LoadLibrary, which load the DLL from the path written into memory. Once the DLL is loaded into the target process's address space, the code within the DLL executes as if it were a part of the target process.</p>"},{"location":"security/dos/","title":"Denial of Service (DoS) Attacks","text":"<p>DoS, or Denial of Service attacks, are cyber attacks aimed at disrupting the normal functioning of a targeted server, service, or network by overwhelming it with a flood of internet traffic. DoS attacks achieve this by utilizing one computer and an internet connection, often targeting the infrastructure of a web application.</p> <p>During penetration testing, testers may assess how resilient a web application is to DoS attacks. This involves simulating DoS scenarios to evaluate the robustness of the web application and its supporting infrastructure.</p> <p>Part of penetration testing can include stress testing the web application to see how much traffic it can handle before becoming unresponsive. Penetration testers aim to identify specific components (like APIs, server configurations, Databases (KB)) that could be potential bottlenecks or vulnerabilities under heavy load.</p> <p>Testers might verify the effectiveness of strategies in place to mitigate Distributed Denial of Service (DDoS) attacks, where the attack comes from multiple sources.</p> <p>Automated tools used for scanning and Web Crawling|crawling a website can generate a high volume of requests in a short time. This can overload the server, especially if it's not equipped to handle such traffic.</p> <p>Additionally, testing for certain vulnerabilities (like SQL injection, or XML External Entities (XXE) attacks) might involve operations that are unexpectedly resource-intensive for the server, leading to a slowdown or crash.</p>"},{"location":"security/dspoof/","title":"DNS Spoofing","text":"<p>This is an attack where forged DNS data is introduced into a DNS resolver\u2019s cache, resulting in the resolver returning an incorrect\u00a0IP Address\u00a0for a domain.</p> <p>Instead of going to the correct website, traffic can be diverted to a malicious machine or anywhere else the attacker desires; often this will be a replica of the original site used for malicious purposes such as distributing\u00a0malware\u00a0or collecting login information.</p>"},{"location":"security/dxss/","title":"Dom-Based XSS","text":"<p>Document Object Model|DOM-based XSS vulnerabilities usually arise when JavaScript takes data from an attacker-controllable source, such as the URL, and passes it to a sink that supports dynamic code execution, such as\u00a0eval()\u00a0or\u00a0innerHTML. This enables attackers to execute malicious JavaScript, which typically allows them to hijack other users' accounts.</p> <p>To deliver a DOM-based XSS attack, you need to place data into a source so that it is propagated to a sink and causes execution of arbitrary JavaScript.</p> <p>The most common source for DOM XSS is the URL, which is typically accessed with the\u00a0window.location\u00a0object. An attacker can construct a link to send a victim to a vulnerable page with a payload in the query string and fragment portions of the URL.</p> <p>In certain circumstances, such as when targeting a 404 page or a website running PHP, the payload can also be placed in the path.</p> <p>Since these attacks rely on the\u00a0Document Object Model, they are orchestrated on the client-side after loading the page. In such attacks, the HTML source code and the response to the attack remain unchanged, so the malicious input is not included in the server response. Since the malicious payload is stored within the client\u2019s browser environment, the attack cannot be detected using traditional traffic analysis tools.</p> <p>DOM-based XSS attacks can only be seen by checking the document object model and client-side scripts at runtime.</p> <p>Fundamentally, attackers perform DOM-based Cross-site scripting attacks on applications with an executable path for data to travel from a source to a sink. Sources are JavaScript properties that can act as the location of malicious input.</p> <p>These include\u00a0document.URL, document.referrer, location.search,\u00a0and\u00a0location.hash\u00a0among others. A sink is a location or function that executes the malicious function in an HTML rendering.</p> <p>Example of sinks include:\u00a0eval, setTimeout, setInterval\u00a0and\u00a0element.innerHTML\u00a0among others.</p>"},{"location":"security/dyn/","title":"Dynamic Analysis","text":"<p>Dynamic analysis, in terms of Deobfuscation refers to the process of understanding and reversing obfuscated code by executing it in a controlled environment.</p> <p>This approach contrasts Static Analysis|static analysis which involves examining the code without running it. Dynamic analysis is crucial for deobfuscation because it allows the observation of the actual behaviour of the code during execution, which can reveal insights that static analysis might miss.</p> <p>The obfuscated code is executed in a controlled, isolated environment to observe its runtime behaviour without risking the security of the main system.</p> <p>Dynamic analysis involves monitoring the program's behaviour in real-time, including changes to memory, file systems, network activities, and system processes.</p>"},{"location":"security/epa/","title":"EPA (Extended Protection for Authentication)","text":"<p>Extended Protection for Authentication (EPA) is a security feature designed to enhance protection against Man-in-the-Middle (MitM) attack|man-in-the-middle (MITM) attacks during the authentication process in network communications. It primarily strengthens the security of authentication protocols like NTLM and Kerberos Authentication|Kerberos in Windows environments.</p> <p>EPA employs Channel Binding Tokens (CBTs) to bind the authentication process to a specific secure channel (like TLS). This ensures that the authentication process is not being relayed or redirected by an attacker to another channel or session, a technique often used in MITM attacks.</p> <p>EPA is effective in preventing attacks like NTLM relay attacks, where an attacker intercepts and forwards authentication credentials to access network resources illegitimately. It enables servers to confirm that the authentication requests they receive are coming directly from the client and are associated with the current secure session.</p> <p>EPA is often used in conjunction with services like Microsoft IIS|Internet Information Services (IIS) to secure web applications, ensuring that the authentication process is tightly integrated with the TLS session. In scenarios where protocols like NTLM and Kerberos are used, EPA provides an additional layer of security against credential theft and replay attacks.</p> <p>Configuring EPA on a web server to require that all Basic HTTP Authentication|HTTP authentication requests include a CBT, thereby mitigating the risk of NTLM relay attacks. In Active Directory environments, EPA can be configured for services like AD FS (Active Directory Federation Services) to ensure secure authentication processes.</p>"},{"location":"security/exfil/","title":"Data Exfiltration","text":"<p>Data exfiltration, in the context of penetration testing and cybersecurity, refers to the unauthorized transfer of sensitive data from a target system or network to an external location controlled by an attacker. This is a critical phase in many cyber attacks, as the ultimate goal often involves accessing and removing confidential, proprietary, or sensitive information from the compromised system.</p> <p>Some methods include:</p> <ol> <li>Physical Media: Using USB drives or other physical media to copy and remove data from a compromised system.</li> <li>Email: Sending sensitive data to an external email address, either manually or through automated scripts.</li> <li>File Transfer Protocols: Utilizing File Transfer Protocol|FTP, Secure File Transfer Protocol|SFTP, or similar protocols to transfer files from the target system to an attacker-controlled server.</li> <li>Cloud Storage Services: Uploading stolen data to cloud storage services like Dropbox, Google Drive, or OneDrive.</li> <li>Covert Channels: Creating covert channels, such as steganography (hiding data within other files like images or videos), or tunneling data through other protocols (e.g., DNS Tunneling) to avoid detection.</li> <li>Web Services: Using HTTP Protocol|HTTP or HTTPS Protocol|HTTPS to post data to external websites or attacker-controlled web servers.</li> <li>Social Media Platforms: Leveraging social media platforms to transmit data, as these platforms are often allowed through network Firewall|firewalls.</li> <li>Automated Exfiltration Tools: Using specialized malware or scripts that automate the process of searching for, copying, and transmitting sensitive data.</li> <li>Encrypted Channels: Encrypting the data before exfiltration to prevent detection by network security systems that inspect outbound data.</li> </ol>"},{"location":"security/firewall/","title":"Firewall","text":"<p>A firewall is a computer network security system that restricts internet traffic in to, out of, or within a private network.</p> <p>This software or dedicated hardware-software unit functions by selectively blocking or allowing data Packet|packets. It is typically intended to help prevent malicious activity and to prevent anyone\u2014inside or outside a private network\u2014from engaging in unauthorized web activities.</p> <p>Firewalls can be viewed as gated borders or gateways that manage the travel of permitted and prohibited web activity in a private network. By comparison, network security firewalls are for web traffic management \u2014 typically intended to slow the spread of\u00a0web threats.</p> <p>Firewalls create 'choke points' to funnel web traffic, at which they are then reviewed on a set of programmed parameters and acted upon accordingly. Some firewalls also track the traffic and connections in audit logs to reference what has been allowed or blocked.</p> <p>Firewalls are typically used to gate the borders of a private network or its host devices. As such, firewalls are one security tool in the broader category of user access control. These barriers are typically set up in two locations \u2014 on dedicated computers on the network or the user computers and other endpoints themselves (hosts).</p>"},{"location":"security/fixation/","title":"Session Fixation","text":"<p>Session fixation is a type of security vulnerability in web applications. It occurs when an attacker is able to fixate (set) the session ID (SID) of another user and then hijack the user's session after the user logs in. This vulnerability can be exploited to gain unauthorized access to the system.</p> <p>Web applications often use sessions to maintain user state and track identity across multiple requests. In a session fixation attack, the attacker exploits weaknesses in the session management system of the web application.</p> <p>The attacker forces a victim's browser to use a specific session ID. This can be done in various ways, such as by persuading the victim to click on a link that contains a specific session ID as a parameter, or through other means like cross-site scripting. Once the victim logs in using the fixated session ID, the attacker, who knows this ID, can then use it to hijack the session, gaining access to the victim's account and privileges.</p> <p>If the session ID is passed through the URL, it can be easily fixated by an attacker. If the application accepts session IDs from query parameters or form fields, it can be exploited. A critical vulnerability arises when the application doesn't regenerate a new session ID at login. This means the pre-login and post-login session is the same, which is what the attacker exploits.</p> <p>Session fixation can lead to unauthorized access and control over a user's account, potentially leading to data theft, privacy breaches, and other malicious activities.</p>"},{"location":"security/format/","title":"Format String Vulnerabilities","text":"<p>Format string vulnerabilities are a class of security flaws commonly found in C or C++ programs that occur when a program uses input data as a format string for output functions without proper validation or sanitization. This can lead to various types of attacks, including reading from or writing to arbitrary memory locations, which might result in unauthorized access, information disclosure, or crashes.</p> <p>The vulnerability arises in functions like printf, sprintf, fprintf, and similar functions in C/C++, which use format strings to determine how to interpret and display data. If an attacker can control the format string, they can manipulate these functions to execute harmful actions.</p> <p>Consider a C program using <code>printf</code> function:</p> <pre><code>char user_input[100];\nscanf(\"%s\", user_input);\nprintf(user_input); // Vulnerable\n</code></pre> <p>In this example, the program reads user input into a variable and then directly passes it to the <code>printf</code> function. If the user input contains format specifiers (like <code>%s</code>, <code>%x</code>, <code>%n</code>), they will be interpreted by <code>printf</code>, causing unintended behavior.</p> <p>An attacker could use format specifiers to read memory locations adjacent to the format string. For example, inputting <code>%x %x %x</code> might print out memory contents. The <code>%n</code> specifier writes the number of characters printed so far to a provided memory address. An attacker could use this to write arbitrary values to arbitrary memory locations.</p> <p>Incorrect format strings can lead to segmentation faults or crashes, potentially part of a Denial of Service (DoS) Attacks|denial-of-service attack.</p>"},{"location":"security/fuzzing/","title":"Directory Fuzzing","text":"<p>Directory fuzzing, also known as directory brute-forcing or directory enumeration, is a technique used in cybersecurity and web application testing to identify hidden or non-public directories and files in a web server.</p> <p>The primary goal is to discover resources that are not directly linked in web pages or that are meant to be private, including directories, files, or URLs that may contain sensitive information, backups, administrative interfaces, or config files.</p> <p>It is typically performed using automated tools such as Ffuf. The tools systematically guess URLs by appending a list of potential directory or file names to the base URL.</p>"},{"location":"security/gauth/","title":"Google Authenticator","text":"<p>Google Authenticator is a software-based authentication tool that provides a Multi-Factor Authentication (MFA)|two-factor authentication (2FA) service. It's commonly used to add an additional layer of security to online accounts beyond just a username and password. The app generates Time-based One-Time Password (TOTP)|time-based one-time passwords (TOTPs) that the user must enter in addition to their regular password to gain access to an account.</p> <p>The app generates a six to eight-digit passcode which changes every 30 seconds. This code is used for the second step of the verification process. The app doesn't require an internet connection to generate codes. It works offline, which is beneficial in areas with unreliable network connectivity.</p> <p>Setting up an account with Google Authenticator typically involves scanning a QR code provided by the service with which you are setting up 2FA. This QR code securely transfers the shared secret key used to generate the TOTPs.</p> <p>The app can store and manage codes for multiple accounts, making it convenient for users with several 2FA-enabled accounts.</p> <p>The process is:</p> <ul> <li>When you enable 2FA on an account, you'll have the option to use an authenticator app. If you choose Google Authenticator, you'll typically scan a QR code using the app.</li> <li>This QR code adds your account to the app and sets up a unique, shared secret key between the server and the app.</li> <li>When you log into the account, after entering your password, you'll be prompted to enter the code from Google Authenticator.</li> <li>Open the app to see the currently valid code for that account. This code changes every 30 seconds.</li> </ul> <p>By requiring a second form of verification, Google Authenticator significantly enhances account security, protecting against password theft and unauthorized access. Even if a password is compromised, an attacker would still need the TOTP from Google Authenticator to access the account.</p>"},{"location":"security/hard/","title":"Hardening-Patch","text":"<p>The Hardening-Patch was a set of patches for the PHP programming language, aimed at improving its security. The Hardening-Patch was developed to address various security weaknesses in PHP, making it more resilient against common types of attacks. This patch was particularly relevant for versions of PHP that were widely used at the time, before many of its enhancements were integrated into the core PHP releases.</p> <p>The patch provided additional safeguards against remote code execution vulnerabilities, which are among the most critical security risks in web applications. It included mechanisms to better validate and sanitize user input, thus reducing the risks associated with injection attacks like SQL injection, Cross-Site Scripting (XSS), and others.</p> <p>The Hardening-Patch allowed administrators more flexibility in disabling certain PHP functions that were often exploited by attackers. By modifying the way PHP handles errors, the patch aimed to prevent the leakage of sensitive information that could be used by attackers.</p> <p>The Hardening-Patch was primarily used by system administrators and developers who managed servers running PHP-based applications, especially in environments where upgrading to newer versions of PHP was not feasible. It was particularly popular in shared hosting environments and situations where additional security measures were deemed necessary due to the sensitivity of the data being handled.</p> <p>Over time, many of the security enhancements from the Hardening-Patch have been integrated into the official PHP releases. As a result, the specific Hardening-Patch became less relevant with newer versions of PHP, which included improved security features out of the box. Modern PHP development focuses on using the latest PHP versions, which have built-in security improvements, and employing good coding practices, such as using prepared statements for database access, proper input validation, and error handling.</p>"},{"location":"security/hashes/","title":"Password Hashes","text":"<p>Password hashes are cryptographic representations of passwords that are stored in a secure manner to protect user credentials. Instead of storing passwords in plain text, which is highly insecure, systems store password hashes. A password hash is the result of applying a cryptographic hash function to the user's password.</p> <p>When a user creates or changes their password, the system applies a cryptographic hash function to the password. This function generates a fixed-length string of characters (the hash) from the password. The same password will always produce the same hash.</p> <p>Hash functions produce output of a fixed length, regardless of the input length. For example, a common hash function, SHA-256, produces a 256-bit (32-byte) hash value. A strong cryptographic hash function is designed to be a one-way function. It should be computationally infeasible to reverse the process and obtain the original password from the hash. This property ensures that even if the hash is compromised, the attacker cannot easily determine the password.</p> <p>To further enhance security, a unique random value called a \"Salt\" is often generated for each user. The salt is combined with the password before hashing. Salting prevents attackers from using precomputed tables (rainbow tables) to look up common passwords' hashes.</p> <p>The resulting password hash and the salt (if used) are stored in the system's database. The plain text password is not stored. When a user attempts to log in, the system hashes the entered password with the stored salt (if applicable) and compares it to the stored hash.</p> <p>During login, the system retrieves the stored hash and salt (if used), applies the hash function to the entered password with the stored salt, and compares the result to the stored hash. If they match, the entered password is correct.</p> <p>Security best practices include using strong, well-established hash functions (e.g., SHA-256), generating unique salts for each user, and periodically rehashing passwords to protect against advanced attacks.</p>"},{"location":"security/hijacking/","title":"DNS Hijacking","text":"<p>In DNS hijacking, the attacker redirects queries to a different domain name server. This can be done either with malware or with the unauthorized modification of a DNS server. Although the result is similar to that of DNS spoofing, this is a fundamentally different attack because it targets the\u00a0DNS record\u00a0of the website on the nameserver, rather than a resolver\u2019s cache.</p>"},{"location":"security/hybrid/","title":"Hybrid Attacks","text":"<p>Hybrid attacks, also known as hybrid password attacks, are a type of cybersecurity attack that combines elements of both dictionary attacks and Brute Force Attack|brute-force attacks to guess passwords or encryption keys. These attacks are used to crack passwords or encryption when simple dictionary attacks or traditional brute-force attacks may not be efficient or effective on their own. Hybrid attacks leverage the advantages of both attack methods to increase the likelihood of success.</p> <p>In a hybrid attack, the attacker combines elements of both dictionary and brute-force attacks. Typically, the attacker starts with dictionary-based attempts, trying words from a dictionary or common passwords list. If these attempts are unsuccessful, the attacker may then switch to a brute-force approach, systematically trying every possible character combination.</p> <p>Advantages:</p> <ul> <li>Efficiency: Dictionary attacks are efficient for guessing common or easily guessable passwords, while brute-force attacks are efficient at covering all possible combinations.</li> <li>Increased Coverage: Hybrid attacks increase the coverage of possible passwords by starting with the dictionary and then exploring the entire character space if necessary.</li> <li>Reduced Time: By starting with the dictionary, hybrid attacks can quickly identify passwords that are commonly used but may not be found in a traditional brute-force search.</li> </ul> <p>Hybrid attacks are often used when the attacker suspects that the password is not a simple dictionary word but may still be a relatively common or predictable phrase. Starting with a dictionary helps in quickly identifying such passwords, and if unsuccessful, the attacker can then resort to brute-force methods.</p> <p>To protect against hybrid attacks, it is crucial to use strong, unique, and complex passwords that are not easily guessable. Password policies and account lockout mechanisms can also deter attackers from using these techniques.</p>"},{"location":"security/iam/","title":"Identity and Access Management (IAM)","text":"<p>IAM stands for Identity and Access Management. It is a framework of policies, technologies, and processes that organizations use to manage and secure digital identities (i.e., individuals, employees, customers, partners, devices) and control their access to various resources within the organization's IT environment. IAM plays a critical role in enhancing security, streamlining operations, and ensuring that the right people have the right level of access to the right resources at the right time.</p> <p>IAM systems facilitate the creation, modification, and deletion of user accounts, also known as identity provisioning and deprovisioning. This includes user onboarding when employees join an organization and offboarding when they leave.</p> <p>IAM systems provide mechanisms for verifying the identities of users and devices. This can include password-based authentication, Multi-Factor Authentication (MFA), biometric authentication, and Single Sign-On (SSO) solutions.</p> <p>IAM controls determine what resources or data users and devices are allowed to access. Authorization policies define the permissions and privileges associated with different roles and identities. IAM solutions enforce access control policies, ensuring that only authorized users and devices can access specific applications, systems, networks, and data. This helps protect against unauthorized access.</p> <p>IAM enables federated identity, allowing users to access resources across multiple domains or organizations without needing separate credentials for each. Identity federation is commonly used in Single Sign-On (SSO) scenarios.</p> <p>IAM systems often use RBAC to assign and manage permissions based on user roles and responsibilities. Users are assigned roles, and roles are associated with specific access permissions. IAM platforms support the creation and management of access control policies that define who can access what resources under which conditions. Policies can be fine-tuned to meet security and compliance requirements.</p> <p>IAM solutions maintain logs and records of user activities, including authentication and access requests. These logs are crucial for auditing, compliance reporting, and detecting security incidents. IAM systems typically include features for password management, including password policies, password reset, and self-service password recovery.</p> <p>IAM solutions may include identity verification processes, such as identity proofing, to ensure that individuals are who they claim to be. IAM systems can enhance security by requiring users to provide multiple forms of authentication, such as something they know (password), something they have (smart card), or something they are (fingerprint).</p> <p>IAM helps organizations meet security and compliance requirements by enforcing access controls, monitoring user activities, and maintaining audit trails.</p>"},{"location":"security/idor/","title":"Insecure Direct Object Reference (IDOR)","text":"<p>IDOR stands for Insecure Direct Object References, a type of security vulnerability in web applications. IDOR occurs when an application provides direct access to objects based on user-supplied input. As a result, attackers can bypass authorization and access data and functionality they shouldn't have access to, such as other users' data or administrative functions.</p> <p>A direct object reference occurs when an application exposes internal implementation objects, like files, database records, or key indexes, to users through its user interface or APIs|API. IDOR vulnerabilities arise when the application does not perform adequate authorization checks when these objects are accessed. An attacker can manipulate references to gain unauthorized access to data.</p> <p>A typical example is a URL or a form parameter that includes a reference to an internal object, like <code>http://example.com/account?userid=123</code>. If proper authorization checks are not implemented, an attacker could change <code>userid=123</code> to another user's ID to access or modify their data.</p> <p>IDOR can lead to Sensitive Data Exposure|unauthorized data disclosure, modification, deletion, and other security breaches. It can be especially damaging if sensitive data, like personal information, financial details, or administrative controls, are exposed.</p> <p>Attackers typically exploit IDOR by manipulating parameters (such as URL query strings, HTTP headers, or POST data) and observing the resulting behavior to gain unauthorized access to data.</p>"},{"location":"security/ids/","title":"Intrusion Detection Systems","text":"<p>An IDS, or Intrusion Detection System, is a security technology designed to monitor networks or computer systems for unauthorised access, security breaches, or suspicious activities. </p> <p>The primary purpose of an IDS is to detect and respond to security incidents in real-time or near real-time, helping to safeguard the integrity, confidentiality, and availability of data and resources.</p> <p>An IDS only needs to detect potential threats. It is placed out of band on the network infrastructure. Consequently, it is not in the real-time communication path between the sender and receiver of information.</p> <p>IDS solutions often take advantage of a TAP or SPAN port to analyze a copy of the inline traffic stream. This ensures that the IDS does not impact inline network performance.</p> <p>When IDS was developed, the depth of analysis required to detect intrusion could not be performed quickly enough. The speed would not keep pace with components on the direct communications path of the network infrastructure.</p> <p>Network intrusion detection systems are used to detect suspicious activity to catch hackers before damage is done to the network. There are network-based and host-based intrusion detection systems. Host-based IDSes are installed on client computers; network-based IDSes are on the network itself.</p> <p>An IDS works by looking for deviations from normal activity and known attack signatures. Anomalous patterns are sent up the stack and examined at protocol and application layers. It can detect events like DNS poisonings, malformed information packets and Christmas tree scans.</p> <p>An IDS can be implemented as a network security device or a software application.</p>"},{"location":"security/imapinj/","title":"IMAP Injection","text":"<p>IMAP Injection is a type of cyber attack that exploits vulnerabilities in web applications that interact with email servers using the Internet Message Access Protocol|Internet Message Access Protocol (IMAP). IMAP is a standard email retrieval protocol used to fetch emails from a mail server. </p> <p>The vulnerability occurs when a web application constructs IMAP commands using user-supplied input without properly sanitizing or validating it.</p> <p>In an IMAP Injection attack, an attacker manipulates input fields of a web application to inject malicious IMAP commands. This is typically possible in applications that allow users to perform actions like searching their email inbox or organizing emails.</p> <p>The vulnerability arises due to the improper handling of user input in the web application. If the application directly uses user input to construct IMAP commands without adequate validation, it can lead to command injection.</p> <p>Potential Impacts:</p> <ul> <li>Unauthorized Access: An attacker could potentially access other users\u2019 emails or manipulate email actions, depending on the nature of the injected commands and the permissions of the compromised system.</li> <li>Data Exposure or Loss: The attack could lead to unauthorized reading of emails, deletion of messages, or exposure of sensitive information.</li> </ul> <p>An example of vulnerable code may be:</p> <pre><code>$command = \"SEARCH FROM \" . $_GET['user_input'];\nimap_open($mailbox, $username, $password);\nimap_search($mailbox, $command);\n</code></pre> <p>In this example, the application constructs an IMAP search command based on user input without validation, making it susceptible to injection.</p> <p>IMAP Injection, though less common than other types of injection attacks like SQL Injection, represents a significant security risk in applications that interact with email servers. It underscores the importance of proper input handling and robust security measures in application development.</p>"},{"location":"security/imperson/","title":"Token Impersonation","text":"<p>Token Impersonation is a technique in computer security, particularly in Windows environments, where an attacker or a process gains unauthorized access by using an authentication token of another user or process. In Windows, authentication tokens represent the security context of a user or process, including their identity and privileges.</p> <p>When a user logs in or a process runs, Windows creates an access token that contains security information about that session. If an attacker gains access to a system, they can potentially access the tokens of other users or processes. The attacker can then use a technique called impersonation, where they adopt the token of another user or process. This allows them to perform actions on the system with the same rights and privileges as that user or process.</p> <p>Often, token impersonation is used for privilege escalation. For example, if an attacker can impersonate a token of a user with administrative privileges, they can gain control over the entire system. After gaining initial access to a system, attackers or penetration testers use token impersonation to elevate their privileges and deepen their access.</p> <p>Tools like Incognito (part of Metasploit Framework|Metasploit), Mimikatz, and others can be used to find and impersonate tokens. Impersonating a token can also facilitate lateral movement within a network, allowing attackers to access other systems using the credentials of the impersonated token.</p>"},{"location":"security/inband/","title":"In-Band Injections","text":"<p>In-band SQL injection is a type of SQL injection where the attacker uses the same communication channel to both launch the attack and gather results. It's one of the most common types of SQL injection attacks. There are two main types of in-band SQL injection:</p> <ol> <li>Error-Based Injection|Error-based SQL Injection - This method involves the attacker intentionally making incorrect SQL queries to the database. The database then generates error messages which may contain useful information about the database's structure. These error messages are used by the attacker to further exploit the system.</li> <li>UNION-Based injection|Union-based SQL Injection - In this method, the attacker uses the UNION queries|UNION SQL operator to combine a malicious query with a legitimate query. The results of the malicious query are returned as part of the HTTP Protocol response, which the attacker can use to extract data from the database.</li> </ol>"},{"location":"security/info/","title":"Information Gathering","text":"<p>Information gathering is a critical phase of the penetration testing process, where the primary goal is to collect as much data as possible about the target system or application. </p> <p>The aim of this phase is to identify potential vulnerabilities and weaknesses that could be exploited by attackers to gain unauthorized access to a system or network. The information gathered can be used to create an attack plan and determine the best approach to exploit the identified vulnerabilities.</p> <p>You try to gain information about organization\u2019s digital footprints, like their IP Address|IP addresses, DNS records, mail server, subdomains , older snapshots of an web application, back-end components, server information, publicly disclosed vulnerabilities in the softwares being used and more.</p>"},{"location":"security/inline/","title":"Inline Queries","text":"<p>Inline queries, also known as inline SQL or dynamic SQL, refer to SQL commands that are constructed as strings within an application's code and then executed by a database.</p> <p>These queries are dynamically built using input from users or other sources. In the context of SQL injection, inline queries are particularly relevant because they can create vulnerabilities if not handled correctly.</p> <p>Inline queries are often vulnerable to SQL injection attacks when user input is concatenated directly into the query string. Attackers can manipulate the input to alter the query's structure, executing unintended commands or accessing unauthorized data.</p> <p>An example of a vulnerable inline query:</p> <pre><code>String query = \"SELECT * FROM users WHERE username = '\" + userInput + \"'\";\n</code></pre> <p>In this example, if <code>userInput</code> is not properly sanitized and contains something like <code>' OR '1'='1</code>, it could lead to a SQL injection.</p> <p>Attackers exploit inline queries by injecting malicious SQL code into the query string. This can lead to various malicious actions, such as bypassing authentication, retrieving, modifying, or deleting data, and, in severe cases, compromising the entire database or associated system.</p> <p>Inline queries often lack parameterization, a technique that separates SQL code from data inputs. Without parameterization, the query and data inputs are concatenated into a single string, making it easier for malicious inputs to alter the query structure.</p>"},{"location":"security/inputsan/","title":"Input Sanitization","text":"<p>Input sanitization in web applications refers to the process of cleaning and validating user input to ensure it is safe and appropriate before processing it or incorporating it into output. This is a critical security measure to prevent malicious inputs that could lead to vulnerabilities like SQL Injection, Cross-Site Scripting (XSS), and other types of attacks.</p> <p>Some key aspects of input sanitization include:</p> <ul> <li>Validation - involves checking if the input meets certain criteria before it is accepted. For example, ensuring an email address is in the correct format or a phone number only containing digits.</li> <li>Filtering - removing or replacing unwanted characters from the input. For example, stripping out script tags from text inputs to prevent XSS attacks.</li> <li>Escaping - in contexts where input is inserted into another language or system (like Structured Query Language|SQL, HTML or JavaScript), escaping involves modifying the input so that it is treated as data rather than code.</li> <li>Canonicalization - transforming input to a standardized or simplified form as attackers might use complex or encoded input to bypass simpler formats.</li> <li>Limiting input size - setting a max size for inputs can prevent Buffer Overflows|buffer overflows and reduce the risk of Denial of Service (DoS) Attacks|Denial of Service (DoS) attacks.</li> </ul>"},{"location":"security/ips/","title":"Intrusion Prevention Systems","text":"<p>An Intrusion Prevention System is a network security technology designed to monitor network traffic and system activities for malicious activity and known threats. </p> <p>Its primary function is to identify and prevent cyber attacks in real time. </p> <p>Unlike an Intrusion Detection Systems|Intrusion Detection System that only detects and alerts on potential threats, an IPS is proactive; it can take actions to block or prevent the threat. It might include dropping malicious packets, blocking traffic from offending IP Address|IP addresses or resetting connections.</p> <p>IPS can be deployed as a network-based system to protect a whole network or as a host-based system to protect individual devices. Network-based IPS typically sits directly behind the Firewall|firewall to inspect all traffic, while host-based IPS is installed on individual servers or workstations.</p> <p>IPS systems analyze network traffic in real time. They filter out potentially harmful packets and can be configured to recognize and allow legitimate traffic, thereby minimizing false positives.</p> <p>Many IPS solutions are part of broader security systems and can integrate with firewalls, Security Information and Event Management (SIEM)|security information and event management (SIEM) systems, and other security technologies for more comprehensive protection.</p>"},{"location":"security/ish/","title":"Improper Error Handling","text":"<p>Improper handling of errors can introduce a variety of security problems for a web site. The most common problem is when detailed internal error messages such as stack traces, database dumps, and error codes are displayed to the user (hacker). </p> <p>These messages reveal implementation details that should never be revealed. Such details can provide hackers important clues on potential flaws in the site and such messages are also disturbing to normal users.</p> <p>Web applications frequently generate error conditions during normal operation. Out of memory, null pointer exceptions, system call failure, database unavailable, network timeout, and hundreds of other common conditions can cause errors to be generated. </p> <p>These errors must be handled according to a well thought out scheme that will provide a meaningful error message to the user, diagnostic information to the site maintainers, and no useful information to an attacker.</p> <p>Even when error messages don\u2019t provide a lot of detail, inconsistencies in such messages can still reveal important clues on how a site works, and what information is present under the covers. </p> <p>For example, when a user tries to access a file that does not exist, the error message typically indicates, \u201cfile not found\u201d. When accessing a file that the user is not authorized for, it indicates, \u201caccess denied\u201d. The user is not supposed to know the file even exists, but such inconsistencies will readily reveal the presence or absence of inaccessible files or the site\u2019s directory structure.</p> <p>One common security problem caused by improper error handling is the fail-open security check. All security mechanisms should deny access until specifically granted, not grant access until denied, which is a common reason why fail open errors occur. </p> <p>Other errors can cause the system to crash or consume significant resources, effectively denying or reducing service to legitimate users.</p> <p>Good error handling mechanisms should be able to handle any feasible set of inputs, while enforcing proper security. Simple error messages should be produced and logged so that their cause, whether an error in the site or a hacking attempt, can be reviewed. </p> <p>Error handling should not focus solely on input provided by the user, but should also include any errors that can be generated by internal components such as system calls, database queries, or any other internal functions.</p>"},{"location":"security/key/","title":"Keylogging","text":"<p>Keylogging, also known as keystroke logging, is a type of surveillance technology used to record the keystrokes made on a keyboard. This can be done through hardware or software. Keyloggers are often associated with malicious activities but can also be used for legitimate purposes.</p> <p>There are 2 types of keyloggers:</p> <ol> <li>Software Keyloggers: These are programs installed on a computer system that record keystrokes. They can capture all types of keyboard input, including passwords, messages, and other sensitive information.</li> <li>Hardware Keyloggers: These are physical devices plugged into a computer, typically between the keyboard and the computer. They can be less detectable by software security measures.</li> </ol> <p>Criminals use keyloggers to steal personal information, login credentials, credit card numbers, and other sensitive data. They are also used for spying on individuals or organizations to gain unauthorized access to confidential information.</p>"},{"location":"security/lanman/","title":"LanMan","text":"<p>LanMan, or LAN Manager, was an early network operating system developed by Microsoft and 3Com in the 1980s. It was designed to manage and facilitate file and printer sharing over a local area network (LAN). LanMan introduced several technologies and concepts that have evolved over time and still influence Windows networking and security.</p> <p>One notable aspect of LanMan was its approach to password storage and authentication. LanMan stored passwords in a way that is now considered insecure:</p> <ol> <li>Password Hashing: LanMan hashed passwords were limited to 14 characters and were converted to uppercase, reducing the complexity and potential combinations.</li> <li>Splitting Passwords: Longer passwords were split into two 7-character blocks, each of which was hashed separately. This made the hashes easier to crack since each block could be attacked independently.</li> </ol> <p>The weaknesses in LanMan's password handling make it relevant in the context of hacking and penetration testing: </p> <ol> <li>Legacy Systems: Some older systems and applications still use LanMan hashing for compatibility reasons. These systems are vulnerable to password cracking attacks.</li> <li>Cracking LanMan Hashes: Due to the insecure nature of LanMan hashes, they are often targeted in password cracking. Tools like John the Ripper or Hashcat can quickly crack these hashes.</li> <li>Enumeration and Exploitation: In penetration testing, identifying systems that use LanMan hashes can reveal weak points in a network's security. Exploiting these vulnerabilities can allow attackers to gain unauthorized access.</li> </ol> <p>Modern Windows systems have moved away from LanMan authentication due to its security flaws. It's recommended to disable LanMan authentication in group policy settings. Systems still relying on LanMan should be upgraded or replaced to use more secure authentication methods. Modern systems use more secure algorithms like NTLM (NT LAN Manager) and Kerberos Authentication|Kerberos for password hashing and authentication.</p>"},{"location":"security/lat/","title":"Lateral Movement","text":"<p>Lateral movement in penetration testing refers to the techniques used by penetration testers (or attackers in a malicious scenario) to move through a network after gaining initial access. The goal is to expand access to more systems and potentially increase privileges, to reach high-value targets like data servers, Domain Controller|domain controllers, or administrative systems.</p> <p>Some techniques for lateral movement:</p> <ol> <li>Exploiting Weak Credentials: Using default or weak credentials to access other systems on the network.</li> <li>Pass-the-Hash Attacks|Pass-the-Hash/Pass-the-Ticket Attacks|Pass-the-Ticket: Using captured hash values or Kerberos tickets from one machine to authenticate to others.</li> <li>Remote Services Exploitation: Utilizing services like Remote Desktop Protocol (RDP), Secure Shell (SSH), or WinRM|Windows Remote Management (WinRM) to access and control other systems.</li> <li>Session Hijacking: Taking over existing user sessions on other machines.</li> <li>Privilege Escalation: Gaining higher-level privileges to access more secured parts of the network.</li> </ol> <p>Some tools also include:</p> <ol> <li>Mimikatz: Used for extracting credentials, such as plaintext passwords, NTLM hashes, and Kerberos tickets, from memory.</li> <li>Microsoft PsExec|PsExec: A part of Sysinternals Suite, it's used to execute processes remotely, leveraging administrative credentials.</li> <li>Empire|PowerShell Empire: A post-exploitation framework that allows extended control over compromised machines and can be used for moving laterally.</li> <li>Metasploit Framework: Contains various modules to exploit vulnerabilities, execute payloads, and move laterally in a network.</li> <li>BloodHound: Uses graph theory to reveal hidden and often unintended relationships within Active Directory environments, helpful in planning lateral movement paths.</li> </ol> <p>Some examples include:</p> <ul> <li>Using PsExec with Stolen Credentials: A penetration tester, after obtaining administrative credentials from one workstation, uses PsExec to remotely execute commands on another workstation or server.</li> <li>Pass-the-Hash Attack: The tester uses a captured NTLM hash from one machine to authenticate to another machine on the network.</li> <li>Exploiting Vulnerabilities: If a vulnerability like SMB Relay Attacks|SMB Relay or EternalBlue is found on another machine in the network, it could be exploited to gain unauthorized access.</li> </ul>"},{"location":"security/ldap/","title":"LDAP Injection","text":"<p>LDAP Injection is a type of cyber attack that exploits vulnerabilities in a web application's software when it constructs LDAP (Lightweight Directory Access Protocol) statements based on user input. LDAP is used for accessing and maintaining distributed directory information services over an Internet Protocol network. </p> <p>In an LDAP injection attack, the attacker manipulates a web application's input fields to inject and execute malicious LDAP statements. These statements can modify LDAP queries executed by the application, potentially allowing unauthorized access to sensitive information in the LDAP directory.</p> <p>Similar to SQL Injection, LDAP Injection occurs when user-supplied data is not properly sanitized before being added to an LDAP query. Attackers exploit this vulnerability to alter LDAP statements or add new criteria.</p> <p>Attackers might gain unauthorized access to sensitive data stored in the LDAP directory, such as usernames, passwords, and other personally identifiable information. In more severe cases, attackers could modify or delete information within the LDAP directory, impacting the integrity of the system.</p> <p>A web application might use user input to construct an LDAP query for authentication. If this input is not properly sanitized, an attacker could modify the LDAP filter. For instance, entering a wildcard character (*) might return all user entries, bypassing authentication controls.</p>"},{"location":"security/logp/","title":"Log Poisoning","text":"<p>Log poisoning is a technique used in cyber attacks, often in conjunction with other vulnerabilities like Local File Inclusion (LFI), to execute arbitrary code or commands on a web server. It primarily involves manipulating log files that the server writes and then exploiting these files through other vulnerabilities.</p> <p>The attacker injects malicious code or script into a log file. This can be done in several ways, such as by entering malicious strings into input fields that are logged (like user-agent, referrer, or error messages) or by making requests that get logged with the attacker's control over some part of the request (like the request URL or headers).</p> <p>If the web application is vulnerable to LFI, the attacker can include the log file in the response. Since log files contain the attacker's injected code, this code gets executed when the included log file is processed by the server.</p> <p>Some common scenarios include:</p> <ul> <li>Web Server Logs: Injecting scripts or PHP code into access or error logs of the web server. For instance, by accessing a URL with a PHP code snippet in it, knowing that the URL will be logged.</li> <li>Application Logs: Manipulating input fields that are known to be logged by the application, such as user login fields, search queries, etc.</li> </ul> <p>As an example scenario:</p> <p>The attacker visits a web page and sets their User-Agent header to a PHP code snippet, such as <code>&lt;?php system($_GET['cmd']); ?&gt;</code>. The web server logs this request, including the User-Agent string. If there's an LFI vulnerability, the attacker can request a page that includes the web server's access log. When the server processes the included log file, the PHP code from the User-Agent string is executed, allowing the attacker to run commands on the server.</p>"},{"location":"security/mfa/","title":"Multi-Factor Authentication (MFA)","text":"<p>Multi-Factor Authentication (MFA) is a security system that requires more than one method of authentication from independent categories of credentials to verify the user's identity for a login or other transaction. </p> <p>MFA is an effective way to provide enhanced security by requiring multiple forms of verification before granting access to a specific application, system, or service. This approach is significantly more secure than relying on a single form of authentication, like a password, as it decreases the likelihood that an attacker can gain access to sensitive systems or data.</p> <p>Key components of MFA include:</p> <ol> <li>Knowledge Factors: Something the user knows, like a password or a PIN.</li> <li>Possession Factors: Something the user has, such as a mobile phone (to receive a text message or use an authentication app), a smart card, or a security token.</li> <li>Inherence Factors: Something that is inherent to the user, typically involving biometrics, such as fingerprints, facial recognition, or voice patterns.</li> <li>Location Factors: Verification of the user's location, often through a GPS-enabled device.</li> <li>Time Factors: Restricting user authentication to specific time frames.</li> </ol> <p>In a typical MFA scenario, after entering a username and password (knowledge factor), a user may be prompted to enter a code sent via SMS to their phone (possession factor) or use a fingerprint scan (inherence factor). Only after successfully presenting multiple factors as requested can the user access the system or service.</p> <p>MFA is widely recommended for securing access to sensitive systems, including corporate networks, banking applications, and social media sites, especially where the information or transactions involved are of high value or sensitivity. The use of MFA has grown in importance with the increase in online security threats, where single-factor authentication, like a password alone, is no longer considered sufficiently secure.</p>"},{"location":"security/mitm/","title":"Man-in-the-Middle (MitM) Attack","text":"<p>A Man-in-the-Middle (MitM) attack is a cyber attack where an attacker secretly intercepts and possibly alters the communication between two parties who believe they are directly communicating with each other. </p> <p>The attacker positions themselves in the communication's path, making it seem like a normal exchange is happening, while in reality, they are controlling the entire conversation.</p> <p>Man-in-the-middle attacks offer hackers a path to intercept sensitive information such as usernames, passwords, credit card numbers, and bank account details. It's dangerous because the user has no idea there is another presence between them and the application they're interacting with or that their data is rerouting to a malicious party.</p> <p>Once a criminal has this information, they can manipulate account credentials, steal funds, or make unauthorized purchases. </p>"},{"location":"security/modsec/","title":"ModSecurity","text":"<p>ModSecurity, often referred to as ModSec, is a widely-used, open-source web application firewall (WAF). It is designed to protect web applications from various types of attacks and vulnerabilities by monitoring and filtering HTTP Protocol|HTTP traffic between a web server and clients. </p> <p>ModSecurity is commonly used with the Apache HTTP server, but it does support others such as Nginx and Microsoft IIS. It operates based on rules which allows it to inspect and intercept HTTP requests and responses.</p> <p>It also provides protection against common web app threats and exploits such as SQL injection, Cross-Site Scripting, Local File Inclusion and Brute Force Attack.</p>"},{"location":"security/nac/","title":"Network Access Control (NAC)","text":"<p>Network Access Control (NAC) is a security solution that enforces policy-based controls on devices seeking to access network resources. NAC systems are designed to prevent unauthorized access, enforce security compliance, and protect networks from potential threats posed by non-compliant or infected devices. </p> <p>NAC systems authenticate devices trying to connect to the network, ensuring that only authorized devices can access network resources. This authentication can be based on credentials, device type, user identity, or a combination of factors.</p> <p>NAC enforces security policies across the network. For instance, it can ensure that devices have the latest antivirus updates, required software patches, or specific configurations before allowing access.</p> <p>Based on the authentication and policy checks, NAC systems grant, deny, or limit the level of network access to devices. This can include full access, restricted access to certain resources, or quarantine in a separate network area.</p> <p>NAC systems can continuously monitor and assess the security posture of devices on the network, ensuring ongoing compliance with security policies.</p> <p>NAC allows organizations to securely manage guest access, providing limited access for visitors while protecting the internal network.</p> <p>NAC systems often integrate with other security technologies like Firewall|firewalls, intrusion prevention systems (IPS), and Security Information and Event Management (SIEM)|security information and event management (SIEM) systems for enhanced network security.</p> <p>NAC provides visibility into the devices connected to the network, including type, ownership, and compliance status, which is crucial for network management and security. In case of detection of non-compliance or a security threat, NAC systems can automatically respond by restricting a device\u2019s network access or quarantining it for remediation.</p> <p>NAC can enforce role-based access controls, ensuring users and devices can only access network resources relevant to their role or department. </p> <p>NAC systems are applicable to both wired and wireless networks, providing comprehensive security coverage.</p>"},{"location":"security/nbi/","title":"Null Byte Injection","text":"<p>Null byte injection is a type of attack that exploits a vulnerability in a computer program where a null byte (<code>\\0</code>) is used to manipulate the control flow or data interpretation. The null byte, often represented in programming languages like C and C++ as <code>'\\0'</code>, is used to signify the end of a string.</p> <p>In languages like C and C++, strings are terminated with a null byte. This is how the program knows where the string ends. An attacker injects a null byte into a data stream or input field that the program will process.</p> <p>When the program encounters the null byte, it interprets it as the end of the string, effectively truncating or altering the data that follows the null byte. This behavior can be exploited in various ways, depending on the context and the program's logic.</p> <p>An attacker might add a null byte to manipulate file paths. For example, the input <code>malicious.php\\0.png</code> could be used to upload a PHP file while the system only checks for a <code>.png</code> extension. The server might validate the extension as <code>.png</code>, but when accessing the file, the server-side language (like PHP) stops reading the path at <code>\\0</code>, executing <code>malicious.php</code>.</p> <p>Null byte injection can be used in conjunction with Buffer Overflows|buffer overflow attacks to manipulate the execution flow of an application.</p> <p>If a program sanitizes inputs by looking for dangerous characters or patterns but stops at a null byte, an attacker could inject code followed by a null byte to bypass the sanitization process.</p>"},{"location":"security/nosqli/","title":"NoSQL Injection","text":"<p>NoSQL injection is a type of security vulnerability that targets NoSQL databases. NoSQL databases, such as MongoDB, CouchDB, and Apache Cassandra|Cassandra, are increasingly popular due to their scalability and flexibility in handling large volumes of unstructured data. </p> <p>However, just like SQL databases, they are susceptible to injection attacks, albeit in a different form.</p> <p>Unlike SQL injection, which exploits vulnerabilities in the SQL query syntax, NoSQL injection attacks target the NoSQL query language or the database's API. Since NoSQL databases do not use SQL, the attack vectors differ.</p> <p>NoSQL injections typically occur when user inputs are not properly sanitized or validated before being passed to a database query. Attackers can manipulate these inputs to alter database queries, leading to unauthorized access or data manipulation.</p>"},{"location":"security/ntlm/","title":"NTLM","text":"<p>NTLM, which stands for \"NT LAN Manager,\" is a suite of authentication and security protocols developed by Microsoft. NTLM is primarily used for network authentication in Windows environments and is a predecessor to more modern authentication mechanisms like Kerberos Authentication|Kerberos and NTLMv2. It is designed to provide secure authentication for users and computers within a Windows domain.</p> <p>NTLM is used to authenticate users and computers when they attempt to access resources on a Windows-based network. It verifies the identity of the user or computer by checking their credentials (e.g., username and password). NTLM has several versions, including NTLMv1 and NTLMv2. NTLMv2 is more secure and recommended over NTLMv1 due to vulnerabilities in the latter.</p> <p>NTLM authentication relies on a challenge-response mechanism. When a user or computer attempts to log in, the server (or authentication authority) sends a random challenge to the client. The client then encrypts the challenge using the user's password and sends the encrypted response back to the server for verification.</p> <p>NTLM is commonly used in Windows domains for authenticating users and computers against a domain controller. This ensures that users have valid domain credentials before gaining access to domain resources.</p> <p>NTLM supports Single Sign-On (SSO) in Windows environments. Once a user logs in to a Windows computer, their credentials can be cached, allowing them to access other network resources without re-entering their credentials.</p> <p>NTLM has some limitations and security concerns, particularly with NTLMv1. It is vulnerable to certain types of attacks, including pass-the-hash attacks, and it does not support mutual authentication, making it less secure than more modern authentication protocols like Kerberos.</p> <p>In Windows domains, NTLM has largely been replaced by the Kerberos authentication protocol, which offers improved security and support for mutual authentication. However, NTLM may still be used in legacy environments or when Kerberos is not feasible. NTLM is still supported in Windows environments for backward compatibility with legacy systems and applications that rely on it.</p>"},{"location":"security/ntlmattack/","title":"NTLM Relay Attack","text":"<p>An NTLM Relay attack is a type of cybersecurity attack in which an attacker intercepts and relays NTLM (New Technology LAN Manager) authentication requests to access network resources. This attack exploits the NTLM protocol, which is used for authentication in Windows networks.</p> <p>The attacker positions themselves in the network to intercept an NTLM authentication request from a client (user or computer). This is often achieved through techniques like ARP poisoning or by exploiting protocols like LLMNR/NBT-NS that lack server authentication. The intercepted NTLM authentication request, which includes the user's credentials in a hashed form, is then forwarded (or \"relayed\") to another server within the network.</p> <p>The target server processes the forwarded request as a legitimate attempt to authenticate and grants access based on the relayed credentials. The attacker gains access to the server or service, impersonating the user whose credentials were relayed.</p> <p>Some examples of attacks may include:</p> <ul> <li>Accessing File Shares: An attacker intercepts an NTLM authentication request from a user and relays it to a file server. The server grants access, and the attacker can read, modify, or delete files on the share.</li> <li>Compromising a Web Server: NTLM credentials are intercepted and relayed to a web server in the network. The attacker gains access to restricted web resources or administrative interfaces.</li> </ul> <p>For mitigation:</p> <ul> <li>Disable NTLM Authentication: Where possible, replace NTLM with more secure protocols like NTLM Relay Attack.</li> <li>Use SMB Signing: Enabling SMB Signing can prevent NTLM Relay attacks on SMB (Server Message Block) protocols, as it requires each packet to be signed by the client's session key.</li> <li>Enable EPA (Extended Protection for Authentication): EPA helps prevent NTLM Relay attacks by binding the authentication process to the TLS (Transport Layer Security) session where it originated.</li> <li>Network Segmentation: Properly segmenting the network can limit the ability of an attacker to relay credentials to sensitive parts of the network.</li> <li>Patching and Updates: Ensure all systems are patched and updated, particularly regarding any security updates related to NTLM.</li> </ul>"},{"location":"security/obfuscation/","title":"Obfuscation","text":"<p>Obfuscation of code\u00a0is a technique used to transform plain, easy-to-read code into a new version that is deliberately hard to understand and reverse-engineer\u2014both for humans and machines.  </p> <p>Obfuscation has been\u00a0used in several different programming languages, notably C/C++ (there\u2019s even a competition for obfuscating C code) and Perl. But\u00a0there\u2019s a language where obfuscation has gained tremendous popularity\u00a0among developers and business owners alike:\u00a0JavaScript.</p> <p>JavaScript is an interpreted language, so client-side JavaScript requires an interpreter in the browser to read it, interpret it, and run it. This also means that anyone can use a browser debugger to easily go through the JS code and read or modify it at will.  </p> <p>With such easy access to client-side JavaScript code, it\u2019s almost effortless for an attacker to take advantage of this security weakness and target any unprotected code.  </p> <p>Companies\u2014notably, the enterprise and Fortune 500\u2014are frequently\u00a0storing important business logic on the client side\u00a0of their apps.  </p> <p>If you understand the basics of application security, you know that code secrets should always be kept on trusted execution environments like the backend server. But this is one of those cases where practice takes precedence over theory. When companies store this important logic on the client side, they typically do so because they can\u2019t feasibly keep it on the server side.  </p> <p>A common reason for this is when\u00a0there\u2019s no backend\u00a0in the first place, as in the case of some mobile applications. Another example is when there\u2019s some code that\u2019s related to the user experience (like an analytics algorithm) that must run on the client side. </p> <p>Still, the most common reason is\u00a0performance. Server calls take time, and when you have a service where performance is crucial\u2014like a streaming platform or an HTML5 game\u2014storing all the JavaScript on the server is not an option.  </p> <p>Whatever the case, companies usually don\u2019t want to expose their proprietary logic. And they definitely never want to expose code secrets. Especially when their competitors can reverse-engineer the code and copy proprietary algorithms.  </p> <p>Besides\u00a0intellectual property theft, client-side JavaScript can also be targeted in more sophisticated attacks such as\u00a0automated abuse,\u00a0piracy,\u00a0cheating, and\u00a0data exfiltration.</p> <p>JavaScript obfuscation is a series of code transformations that turn plain, easy-to-read JS code into a modified version that is extremely hard to understand and reverse-engineer.  </p> <p></p> <p>Unlike encryption, where you must supply a password used for decryption,\u00a0there\u2019s no decryption key in JavaScript obfuscation. In fact, if you encrypt JavaScript on the client side, that would be a pointless effort\u2014if we had a decryption key we needed to supply to the browser, that key could become compromised and the code could be easily accessed.  </p> <p>So, with obfuscation, the browser can access, read, and interpret the obfuscated JavaScript code just as easily as the original, un-obfuscated code. And even though the obfuscated code looks completely different,\u00a0it will generate precisely the same output in the browser.  </p>"},{"location":"security/objects/","title":"Object Injection","text":"<p>Object Injection is a type of vulnerability that occurs in programming languages that feature object serialization and deserialization. It is most commonly associated with web applications and is a serious security risk that can lead to various attacks, including Knowledge Base/Remote Code Execution|code execution, SQL injection, Directory Traversal|path traversal, and denial of service.</p> <ol> <li>Serialization and Deserialization:<ul> <li>Serialization is the process of converting an object into a format that can be stored or transmitted, often as a string.</li> <li>Deserialization is the reverse process \u2013 converting the serialized data back into an object.</li> </ul> </li> </ol> <p>Object injection vulnerabilities arise when an application deserializes data from an untrusted source without adequately sanitizing or validating it. An attacker can exploit this by injecting malicious serialized objects.</p> <p>Object Injection vulnerabilities are more common in languages that provide built-in capabilities for object serialization and deserialization, such as PHP, Java, and Dotnet|.NET.</p>"},{"location":"security/ognli/","title":"OGNL Injection","text":"<p>OGNL (Object Graph Navigation Language) injection is a security vulnerability that occurs when an application allows unsanitized user input to be evaluated as OGNL expressions. OGNL is a powerful expression language used in various Java frameworks, such as Apache Struts 2|Apache Struts 2, to navigate and manipulate object graphs.</p> <p>OGNL is primarily used for expressing expressions that navigate and manipulate object graphs. It allows users to access and modify properties of Java objects. OGNL injection arises when an application doesn't properly validate and Input Sanitization|sanitize user input before interpreting it as OGNL expressions. Attackers can manipulate input fields to inject malicious OGNL expressions, leading to unauthorized access, data manipulation, or Knowledge Base/Remote Code Execution.</p> <p>OGNL injection is often associated with web applications that use Java frameworks like Apache Struts 2. Attackers may craft malicious input to exploit vulnerabilities in the application's handling of OGNL expressions.</p> <p>To prevent OGNL injection, developers should validate and sanitize user input before using it in OGNL expressions. Input validation, proper encoding, and the use of parameterized queries or prepared statements are essential measures to protect against this type of injection.</p> <p>Consider a web app using Apache Struts 2 with the following action:</p> <pre><code>public class UserAction extends ActionSupport {\n    private String username;\n\n    // Getter and setter for username\n\n    public String execute() {\n        // Process user input\n        return SUCCESS;\n    }\n}\n</code></pre> <p>If the application uses user input directly in OGNL expressions without proper validation, an attacker could manipulate the username parameter to inject malicious OGNL expressions:</p> <pre><code>http://example.com/user.action?username=%{%23a%3d(new%20java.lang.ProcessBuilder(new%20java.lang.String[]{'command','arg1'})).start(),%23b%3d%23a.getInputStream(),%23c%3dnew%20java.io.InputStreamReader(%23b),%23d%3dnew%20java.io.BufferedReader(%23c),%23e%3dnew%20char[50000],%23d.read(%23e),%23f%3d%23e,%23fos%3dnew%20java.io.FileOutputStream(%23f),%23fos.close()}\"\n</code></pre> <p>In this example, the attacker attempts to execute arbitrary commands on the server by injecting a malicious OGNL expression.</p>"},{"location":"security/okta/","title":"Okta","text":"<p>Okta is an Identity and Access Management (IAM) company that provides cloud software to help companies manage and secure user authentication into applications, and for developers to build identity controls into applications, website web services, and devices.</p> <p>Okta allows organizations to manage user access to various systems and applications. It supports secure login processes through Multi-Factor Authentication (MFA), Single Sign-On (SSO), and universal directory services for storing and managing user profiles.</p> <p>As a cloud-based solution, Okta enables companies to implement IAM functionalities without the need for on-premise hardware, leading to potentially lower costs and easier scalability. Okta integrates with thousands of apps and services, including popular software like Microsoft Office 365, Salesforce, and Google Workspace, facilitating seamless access across a range of tools.</p> <p>It provides comprehensive identity management solutions for businesses, including employee identity management, customer identity and access management (CIAM), and B2B integration. Security is a core aspect of Okta\u2019s offerings. The platform includes features like automated provisioning and deprovisioning of users, integration with security tools, and compliance support.</p> <p>Okta offers a set of tools and APIs that developers can use to build authentication and authorization into their applications, web services, or devices. The platform is known for its flexibility and the ability to customize various aspects of identity and access management to suit specific organizational needs.</p> <p>Okta provides secure identity management for APIs, enabling organizations to control who can access their APIs and how they can be used.</p>"},{"location":"security/onpath/","title":"On-Path Attack","text":"<p>On-path attackers place themselves between two devices (often a web browser and a web server) and intercept or modify communications between the two. The attackers can then collect information as well as impersonate either of the two agents. </p> <p>In addition to websites, these attacks can target email communications,\u00a0DNS\u00a0lookups, and public WiFi networks. Typical targets of on-path attackers include\u00a0SaaS businesses, ecommerce businesses and users of financial apps.</p> <p>You can think of an on-path attacker like a rogue postal worker who sits in a post office and intercepts letters written between two people. This postal worker can read private messages and even edit the contents of those letters before passing them along to their intended recipients.</p> <p>In a more modern example, an on-path attacker can sit between a user and the website they want to visit, and collect their username and password. </p> <p>This can be done by targeting the\u00a0HTTP Protocol|HTTP connection between the user and the website; hijacking this connection lets an attacker act as a proxy, collecting and modifying information being sent between the user and the site. </p> <p>Alternately the attacker can steal a user\u2019s cookies (small pieces of data created by a website and stored on a user\u2019s computer for identification and other purposes). These stolen cookies can be used to hijack a user\u2019s session, letting an attacker impersonate that user on the site.</p> <p>On-path attackers can also target\u00a0DNS servers. In DNS on-path attacks such as\u00a0DNS spoofing\u00a0and DNS hijacking, an attacker can compromise the DNS lookup process and send users to the wrong sites, often sites that distribute\u00a0malware and/or collect sensitive information.</p>"},{"location":"security/oob/","title":"Out-of-Band Data Exfiltration","text":"<p>Out-of-Band Data Exfiltration refers to a technique used in cyber attacks to extract data from a targeted system through a channel or path that is different from the main communication channel. This technique is often used when the direct transfer of data from the target system is not possible or is too risky due to security controls in place.</p> <p>The attacker establishes a secondary communication channel that is not monitored or controlled by the target system's security measures. This can be achieved through various means like DNS queries, HTTP Protocol|HTTP requests to an external server, or other protocols that can bypass Firewall|firewalls and Intrusion Detection Systems|intrusion detection systems.</p> <p>Once the covert channel is set up, sensitive data from the target system is transmitted over this channel. The data could include anything from system files, confidential documents, user credentials, to database records. The attacker receives the exfiltrated data through the covert channel at an external location or server under their control.</p> <ul> <li>DNS-Based Exfiltration: Data is encoded into DNS queries and sent to a DNS server controlled by the attacker. Each query carries a small part of the stolen data.</li> <li>HTTP-Based Exfiltration: Data is transmitted to an external server by initiating HTTP requests (for example, through web beacons or similar methods) to a server controlled by the attacker.</li> <li>Exploiting Vulnerabilities: Techniques like Out-of-Band SQL Injection or XML External Entities (XXE)|XXE (XML External Entity) vulnerabilities can be used to initiate the exfiltration process.</li> </ul> <p>Out-of-Band Data Exfiltration can circumvent traditional security measures like firewalls, as it often uses allowed protocols and appears as legitimate traffic. This method of data exfiltration can be challenging to detect and requires advanced security solutions like anomaly detection, DNS monitoring, and egress filtering.</p>"},{"location":"security/oobi/","title":"Out-of-Band Injections","text":"<p>Out-of-band SQL injection is a type of SQL injection attack that differs from the more common in-band and blind techniques. In out-of-band SQL injections, the data is retrieved using a different channel than the one used to launch the attack. </p> <p>This method is often used when an attacker is unable to use the same channel for both attack and data retrieval due to server-side limitations or security measures. Out-of-band SQL injection can be executed in two primary ways:</p> <ul> <li>DNS-Based Data Exfiltration - the attacker exploits the SQL injection vulnerability to cause the database server to make a DNS request to a server controlled by the attacker. The attacker embeds the data they wish to exfiltrate (like usernames, passwords, etc.) within the subdomain of the DNS request. When the database server makes the request to this subdomain, the attacker's DNS server logs the query, allowing them to extract the data from the subdomain field.</li> <li>HTTP-Based Data Exfiltration - Similar to the DNS-based method, but instead, the attacker forces the database server to make an HTTP request to an external server controlled by the attacker. The data to be exfiltrated is sent as part of the HTTP Protocol|HTTP request, which can be in the URL, headers, or even the body of the request, depending on the attacker's manipulation and the capabilities of the SQL server.</li> </ul>"},{"location":"security/ormi/","title":"ORM Injection","text":"<p>ORM Injection is a type of attack targeting applications that use Object-Relational Mapping (ORM) libraries to interact with databases. ORM is a technique that allows developers to manage database data as objects in programming languages like Java, CSharp|C# and Python, etc. </p> <p>ORM Injection exploits vulnerabilities where user inputs are improperly sanitized before being passed to ORM methods or functions.</p> <p>Similar to SQL Injection, ORM Injection occurs when an attacker manipulates inputs to inject malicious code or queries. However, instead of targeting raw SQL queries, ORM Injection targets the ORM query functions or methods.</p> <p>ORMs often provide methods for building queries without the need to write raw SQL. If these methods are used with unsanitized inputs, attackers can manipulate them to alter query logic or execute unintended commands.</p> <ol> <li>Impacts of ORM Injection:<ul> <li>Unauthorized Data Access: Attackers could gain access to sensitive data stored in the database.</li> <li>Data Modification or Deletion: In cases where ORM allows data modification, an attack could lead to altering or deleting data.</li> <li>Bypassing Business Logic: ORM Injection might bypass application business logic, leading to unauthorized actions.</li> </ul> </li> </ol> <p>In a Python app using an ORM like SQLAlchemy an example of vulnerable code may be:</p> <pre><code>user_input = request.form['user_input']\nquery = session.query(User).filter(\"username = '{}'\".format(user_input))\n</code></pre> <p>Info</p> <p>If <code>user_input</code> is not properly sanitized, it could be exploited to manipulate the query.</p>"},{"location":"security/osci/","title":"OS Command Injection","text":"<p>OS Command Injection is a type of security vulnerability that occurs when an attacker is able to execute arbitrary operating system commands on a server due to insufficient input validation in a web application. This vulnerability is exploited by injecting malicious commands into inputs that are expected to be part of system commands executed by the server.</p> <p>The vulnerability arises in web applications that use user input to construct operating system commands without Input Sanitization|proper validation or sanitization. This can happen in applications that need to execute system-level commands based on user inputs.</p> <p>An attacker manipulates the input fields (like form inputs, URL parameters, etc.) to include additional commands or alterations to the intended command. This manipulation can alter the execution flow or introduce new commands.</p> <p>If the application does not properly sanitize user inputs, the web server executes the injected command with the same privileges as the application itself. This can lead to various malicious activities, such as accessing or modifying files, accessing private information, installing malware, or taking control of the server.</p> <p>The extent of exploitation depends on the permissions of the user under which the web application runs. In severe cases, it can lead to a complete system takeover.</p>"},{"location":"security/osint/","title":"OSINT","text":"<p>OSINT, which stands for Open Source Intelligence, refers to the practice of collecting and analyzing information from publicly available sources for intelligence purposes. It is widely used in various fields such as national security, law enforcement, business intelligence, and cybersecurity.</p> <p>OSINT gathers data from publicly accessible sources including the internet, mass media, publications, government records, professional and academic publications, and other data.</p> <p>OSINT is is used for gathering intelligence about potential targets to identify vulnerabilities, security loopholes or for defense purposes. </p> <p>OSINT is typically used in the reconnaissance phase, the first step in pentesting, where the goal is to collect detailed information about the target without directly interacting with the target systems. For web app pentesting, OSINT helps in collecting information about the domain, including domain registration, DNS records, and associated services.</p> <p>By using OSINT, pentesters can identify an organization's external network infrastructure, such as IP Address|IP addresses, subdomains, DNS servers, mail servers, and the technology stack of the web application.</p> <p>OSINT tools can help discover exposed services, open Port|ports, or outdated software versions running on servers. Information like this can highlight potential vulnerabilities that can be exploited in later stages.</p> <p>Information gathered through OSINT can be used to craft social engineering attacks or phishing campaigns, which are often part of a comprehensive pentesting strategy.</p>"},{"location":"security/otp/","title":"One-Time Password (OTP)","text":"<p>OTP stands for \"One-Time Password.\" It is a unique, temporary password or code that is used for a single login session or transaction. OTPs provide an additional layer of security (often referred to as Multi-Factor Authentication (MFA)|two-factor authentication or 2FA) beyond just a username and password. They are designed to combat various forms of online attacks such as phishing, credential theft, and Brute Force Attack|brute-force attacks.</p> <p>An OTP is typically valid for only a short period of time, often a few minutes, after which it expires and cannot be used. Each OTP is unique to a specific transaction or login session.</p> <p>OTPs can be generated in various ways, including:</p> <ul> <li>Algorithm-Based: Generated using algorithms (like HMAC-based One-Time Password (HOTP) or Time-based One-Time Password (TOTP)) which can synchronize between the server and the user's device.</li> <li>SMS or Email: Sent to the user's registered phone number or email address.</li> <li>Hardware Tokens: Generated by a dedicated physical device (like a security token).</li> <li>Software Tokens: Generated by an authentication app on the user's smartphone (such as Google Authenticator or Authy).</li> </ul> <p>OTPs add an extra security layer, making it more difficult for attackers to gain unauthorized access, even if they have the user\u2019s primary password. Since an OTP is only valid for one login session or transaction, it cannot be reused by an attacker.</p>"},{"location":"security/owasp10/","title":"OWASP Top Ten","text":"<p>The OWASP Top Ten is a regularly updated report outlining the most critical security risks to web applications. OWASP stands for the Open Web Application Security Project, an international non-profit organization dedicated to improving the security of software. The Top Ten is one of their most well-known projects and is widely considered as a go-to resource for understanding the most common and critical risks affecting web application security.</p> <p>The list is compiled by a team of security experts from various organizations and is based on a consensus about what the most critical web application security flaws are. The OWASP Top Ten is updated every few years to reflect the changing landscape of web application security. The list evolves as new threats emerge and old threats become less prevalent.</p> <p>Each item in the Top Ten represents a broad category of web application vulnerabilities. Examples from past editions include Injection Flaws (like SQL injection), Broken Authentication, Sensitive Data Exposure, Cross-Site Scripting (XSS), and more.</p> <p>The primary goal of the OWASP Top Ten is to raise awareness about common web application vulnerabilities and to provide guidance to developers and organizations on how to avoid these risks. The OWASP Top Ten influences the security policies and practices of many organizations. It's often used as a starting point for web application security and as a standard against which security tools and services are measured.</p> <p>The report is not just a list of vulnerabilities; it also provides explanations about each risk, examples of vulnerabilities, and how to prevent these issues. This makes it a valuable educational resource for developers and security professionals alike. The OWASP Top Ten is widely recognized and often referenced in various security standards, best practices, and regulatory frameworks, emphasizing its importance in the field of web application security.</p> <p>Due to its comprehensive, clear, and accessible format, the OWASP Top Ten is recognized globally and used by organizations worldwide to understand and mitigate web application security risks.</p>"},{"location":"security/packing/","title":"Packing","text":"<p>Packing is a technique used to compress and disguise the code, making it difficult to understand and reverse-engineer. It's a form of Obfuscation (KB)|obfuscation that goes beyond simple JavaScript Minification|minification.</p> <p>The original JavaScript code is compressed, reducing its size. This often involves removing unnecessary characters (like whitespace and comments), as in minification, but can also include more advanced transformations.</p> <p>The compressed code is then encoded into a non-standard format. This could be a base64 encoding or any other custom encoding mechanism. The objective is to make the code look like a nonsensical string of characters, which is hard to interpret.</p> <p>The encoded string is embedded within a wrapper function. This function is responsible for decoding the string back into JavaScript code at runtime.</p> <p>When the JavaScript file is loaded by a web browser, the wrapper function executes, decodes the packed code, and then evaluates it using methods like eval() to run the original JavaScript.</p> <p>The (p,a,c,k,e,d) function, often seen in packed JavaScript code, is a common pattern used in a specific JavaScript packing technique. This function is part of a method to obfuscate and compress the code. </p> <p>The letters (p,a,c,k,e,d) don't have any special meaning themselves; they are just parameter names used in this specific packing algorithm.</p> <ul> <li><code>p</code>: Usually a string containing parts of the original code.</li> <li><code>a</code>, <code>c</code>, <code>k</code>: These parameters are typically used in the function's algorithm to map, replace, or decode the packed code.</li> <li><code>e</code>: Sometimes used as a placeholder in the function's logic.</li> <li><code>d</code>: Often an empty object or another placeholder.</li> </ul>"},{"location":"security/parameterized/","title":"Parameterized Queries","text":"<p>Parameterized queries, also known as prepared statements, are a way of executing SQL queries in a more secure and efficient manner. They are used to execute the same SQL statement repeatedly with different parameters, and are especially important in preventing SQL injection attacks. </p> <p>The query is prepared by specifying the Structured Query Language|SQL command with placeholders for the parameters. These placeholders are typically represented by question marks (?) or named placeholders. For example: SELECT * FROM users WHERE username = ?.</p> <p>Before execution, the parameters are bound to these placeholders. The values for these parameters are provided by the user or the application. The database then executes the query, substituting the placeholders with the provided parameter values in a safe way. </p> <p>The crucial point here is that the parameters are treated as data, not as part of the SQL command, which prevents them from being interpreted as SQL code.</p> <p>An example in PHP may be:</p> <pre><code>$stmt = $mysqli-&gt;prepare(\"SELECT * FROM users WHERE username = ?\");\n$stmt-&gt;bind_param(\"s\", $username);\n$username = 'exampleUser';\n$stmt-&gt;execute();\n$result = $stmt-&gt;get_result();\n</code></pre>"},{"location":"security/persist/","title":"Persistence","text":"<p>Persistence in the context of penetration testing and hacking refers to the methods used by an attacker or a penetration tester to maintain access to a system or network over a prolonged period, even through restarts, credential changes, or other disruptions. The goal of establishing persistence is to ensure continued access for ongoing exploitation, Data Exfiltration, or exploration.</p> <p>Some common persistence techniques include:</p> <ol> <li>Creating Backdoors: Installing backdoors in software or systems, allowing attackers to bypass normal authentication mechanisms to regain access.<ul> <li>Example: Inserting a Remote Access Toolkit (RAT) or a reverse shell script that connects back to the attacker's server.</li> </ul> </li> <li>Scheduled Tasks/Cron Jobs: Setting up tasks that automatically execute payloads at specified times or intervals.<ul> <li>Example: Using Windows Task Scheduler or Linux cron jobs to periodically run a script that reestablishes a connection to the attacker's machine.</li> </ul> </li> <li>Registry Modifications: Adding entries to the Windows Registry to execute malware or scripts at system startup.<ul> <li>Example: Creating a new registry key under <code>HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Run</code> to launch a malicious executable upon user login.</li> </ul> </li> <li>Startup Folder: Placing scripts or executables in system startup folders which execute upon system boot or user login.<ul> <li>Example: Adding a script to the Windows \"Startup\" folder or Linux's <code>.bashrc</code> file.</li> </ul> </li> <li>Service Hijacking: Modifying existing legitimate services or creating new services to execute malicious code.<ul> <li>Example: Altering a Windows service to run a malicious executable instead of its legitimate function.</li> </ul> </li> <li>Implanting Rootkits: Installing Rootkits that hide the attacker's activities and maintain access at a low level in the operating system.<ul> <li>Example: Using a kernel-mode rootkit to intercept system calls and hide the presence of an attacker's processes.</li> </ul> </li> <li>Account Manipulation: Creating new user accounts or adding existing accounts to privileged groups for future access.<ul> <li>Example: Adding a new user with administrative privileges to ensure continued access.</li> </ul> </li> <li>Replacing Legitimate Binaries: Swapping legitimate system binaries with modified ones that include malicious code.<ul> <li>Example: Replacing the <code>ssh</code> binary with a version that also logs credentials.</li> </ul> </li> <li>Web Shells: Placing a web shell on a server to allow remote access through web requests.<ul> <li>Example: Uploading a PHP web shell to a vulnerable web server.</li> </ul> </li> </ol>"},{"location":"security/phishing/","title":"Phishing","text":"<p>Phishing is a type of cyber attack that involves deceiving individuals into revealing sensitive information, such as login credentials, credit card numbers, or personal identification details. </p> <p>It's a form of Social Engineering attack that often relies on impersonation and manipulation.</p> <p>Phishing attacks typically involve sending fraudulent communications that appear to come from a reputable source, in the form of emails, texts, phone calls, or social media messages. Attackers often create counterfeit websites or forms that look like legitimate ones.</p>"},{"location":"security/pixelf/","title":"Pixel Flood","text":"<p>A pixel flood attack, more commonly known as a \"pixel stuffing\" or \"image flood\" attack, is a type of cyber attack that targets web advertising systems. This attack method involves stuffing additional, often invisible, pixels (small units of a digital image) with various tracking codes or ad tags into a single ad impression. It's a fraudulent technique used primarily in digital advertising for the purpose of generating false impressions and skewing advertising metrics. </p> <p>In a pixel flood attack, a large number of tracking pixels or ad tags are embedded into a web page, often hidden from the user. Each pixel represents a different ad impression, so when the page is loaded, it appears as if multiple ads have been viewed, even though they might be invisible to the actual visitor.</p> <p>The pixels used in these attacks are typically tiny (1x1 pixels) and transparent, making them invisible to website visitors.</p> <p>This method creates false ad impressions, misleading advertisers into thinking their ads are being viewed more frequently than they actually are. This can result in inflated charges for advertisers and unjustified revenues for the entities executing the attack.</p> <p>Pixel flood attacks undermine the integrity of digital advertising metrics, leading to financial losses for advertisers. They distort key performance indicators like impressions, click-through rates, and conversion rate.</p> <p>Detecting pixel stuffing can be challenging due to the stealthy nature of the attack. The invisible pixels do not affect the user\u2019s experience, making the attack less noticeable.</p> <p>Ad networks and publishers implement various measures to detect and prevent pixel flooding, such as analyzing the behavior of ad requests, monitoring the number of pixels on a page, and employing ad fraud detection tools.</p> <p>Pixel flood attacks are often associated with click fraud, another form of ad fraud where false clicks on ads are generated to inflate advertising costs or deplete competitors' advertising budgets.</p>"},{"location":"security/portscan/","title":"Port Scanning","text":"<p>Port scanning is a method of determining which Port|ports on a network are open and could be receiving or sending data. It is also a process for sending packets to specific ports on a host and analyzing responses to identify vulnerabilities.</p> <p>This scanning can\u2019t take place without first identifying a list of active hosts and mapping those hosts to their IP address. This activity, called host discovery, starts by doing a network scan.</p> <p>The goal behind port and network scanning is to identify the organization of IP addresses, hosts, and ports to properly determine open or vulnerable server locations and diagnose security levels. Both network and port scanning can reveal the presence of security measures in place such as a firewall between the server and the user\u2019s device.</p> <p>After a thorough network scan is complete and a list of active hosts is compiled, port scanning can take place to identify open ports on a network that may enable unauthorized access.</p> <p>The general protocols used for port scanning are Transmission Control Protocol|TCP (transmission control protocol) and User Datagram Protocol|UDP (user datagram protocol). They are both data transmission methods for the internet but have different mechanisms.</p>"},{"location":"security/privesc/","title":"Privilege Escalation","text":"<p>Privilege escalation is a process in cybersecurity whereby an attacker exploits a vulnerability in a system or application to gain access to resources that are normally restricted from end-users or applications. This allows the attacker to gain elevated access to resources that are normally protected, and thus enables them to perform unauthorized actions.</p> <ol> <li>Vertical Privilege Escalation: This occurs when a lower-privileged user or process gains higher-level privileges, typically those of an administrative user or system account. For example, a regular user exploiting a vulnerability to gain administrator rights.</li> <li>Horizontal Privilege Escalation: This involves extending a user's abilities beyond those intended, but not necessarily gaining higher-level privileges. For example, a user accessing data or functions belonging to another user at the same privilege level.</li> </ol> <p>Privilege escalation can occur through various means, including:</p> <ul> <li>Exploiting System Vulnerabilities: Taking advantage of security flaws or bugs in the operating system, applications, or services to gain unauthorized access or privileges.</li> <li>Misconfigured Permissions: Taking advantage of improperly configured permissions on files, directories, or network shares.</li> <li>Password Cracking and Credential Theft: Using stolen login credentials to access restricted areas of the system.</li> <li>Social Engineering Attacks: Tricking legitimate users into revealing their credentials or performing actions that elevate the attacker's access.</li> </ul> <p>Privilege escalation is often a critical step in successful cyberattacks, allowing attackers to install persistent threats, access sensitive data, or take control of the system. Defending against privilege escalation involves regular patching of software, strict control and auditing of user permissions, and monitoring for suspicious activities that might indicate an attempt to gain unauthorized access.</p>"},{"location":"security/procman/","title":"Process Manipulation","text":"<p>Process manipulation in the context of cybersecurity and computer programming refers to the techniques used to modify or interact with the operational state of a process running on a computer. This can involve changing the behavior of the process, extracting information from it, or using it to execute arbitrary code. Process manipulation is a common tactic in both legitimate applications and in malicious activities, such as malware execution and cybersecurity attacks</p> <p>Some key aspects include:</p> <ol> <li>Memory Manipulation: Modifying the memory space of a process. This can include injecting code or data into a process's memory, which is commonly seen in buffer overflow attacks or DLL injection techniques.</li> <li>Process Injection: Inserting code into a running process. This is often done to execute malicious code in the context of a legitimate process, thereby bypassing security measures.</li> <li>Privilege Escalation: Exploiting a process that runs with higher privileges to perform actions that would otherwise be restricted. This is a critical step in many cyber attacks to gain broader access to a system.</li> <li>Process Hijacking: Taking control of a running process, often done by altering the process's execution flow, to perform unauthorized actions.</li> <li>Debugging and Reverse Engineering: Attaching a debugger to a process to analyze or alter its runtime behavior. This is common in software development and reverse engineering but can also be used for malicious purposes.</li> </ol> <p>In terms of hacking and penetration testing:</p> <ul> <li>Exploiting Vulnerable Processes: Identifying and exploiting vulnerabilities in processes to gain unauthorized access or control. Example: Buffer overflow attacks that manipulate the stack of a vulnerable process.</li> <li>Malware Execution: Using process manipulation techniques to execute malware in the context of a legitimate process to evade detection by antivirus software.</li> <li>Data Exfiltration: Manipulating processes to access sensitive information that they process or store in memory.</li> <li>Maintaining Access: Injecting code into system processes to maintain persistent access to a compromised system.</li> </ul>"},{"location":"security/rainbows/","title":"Rainbow Table Attack","text":"<p>A rainbow table attack is a sophisticated method used in cryptography and cybersecurity to crack password hashes. It's an efficient technique for decrypting hashed passwords, which are a common method for securely storing passwords.</p> <p>Hash functions are used to store secure passwords by converting them into a fixed-size string of characters, which is a hash. Hashing is a one-way process, meaning it is intended to be infeasible to reverse the process. </p> <p>Rainbow Tables are large, precomputed tables containing the hashes of many possible plaintext passwords. They map specific hashes back to their original plaintext passwords. An attack compares the hash from a password-protected system to the hashes in the table to find a match.</p> <p>They are much more efficient than Brute Force Attack|brute force attacks because they allow attackers to look up the hash directly instead of computing it for every attempted password.</p>"},{"location":"security/raintab/","title":"Rainbow Tables","text":"<p>Rainbow tables are a data structure used in cryptography, specifically for cracking encrypted passwords. They are a form of precomputed hash table, designed for reversing cryptographic hash functions, mainly to crack password hashes.</p> <p>When passwords are stored securely, they are often hashed using a cryptographic hash function. The function converts the password into a fixed-size string of characters which is the hash. Hash functions are designed to be one-way making it computationally difficult to reverse it.</p> <p>Rainbow tables are used to reverse these hash functions. They are essentially large databases that contain precomputed hashes of many possible plaintext passwords.</p> <p>By comparing the hash from a password-protected system to the hashes in the rainbow table, one can identify the original password if a match is found.</p> <p>Creating a rainbow table involves selecting a set of plaintexts (like all possible passwords up to a certain length), hashing them, and storing the result in a way that allows for efficient lookup. </p> <p>This process is time and resource-intensive but only needs to be done once. Once created, the table can be used repeatedly to crack different hashes.</p>"},{"location":"security/rat/","title":"Remote Access Toolkit (RAT)","text":"<p>A Remote Access Toolkit (RAT) is a type of software that allows a remote operator to control a system as if they had physical access to it. These tools are commonly used for legitimate purposes, such as IT administration and remote support, but they are also used maliciously in cybersecurity attacks.</p> <p>A Remote Access Toolkit (RAT) is a type of software that allows a remote operator to control a system as if they had physical access to it. These tools are commonly used for legitimate purposes, such as IT administration and remote support, but they are also used maliciously in cybersecurity attacks. RATs allow users to access their workstations or servers from remote locations, enabling them to work from home or while traveling.</p> <p>In the context of cybersecurity, RATs can be used for unauthorized access and control over a victim's computer, often without their knowledge. These uses include:</p> <ol> <li>Surveillance and Espionage: Attackers can use RATs to monitor user actions, capture keystrokes (keylogging), take screenshots, or activate webcams and microphones for surveillance purposes.</li> <li>Data Theft: RATs can be used to search for and exfiltrate sensitive data from a victim's computer or network.</li> <li>Launching Further Attacks: Once a RAT is installed, it can serve as a foothold for the attacker to deploy additional malware, escalate privileges, or move laterally across a network.</li> <li>Botnets: Infected machines with RATs can be organized into botnets for coordinated attacks, such as Denial of Service (DoS) Attacks|distributed denial-of-service (DDoS) attacks.</li> </ol> <p>In ethical hacking and penetration testing, RATs can be used to demonstrate the impact of a security breach and to test an organization's ability to detect and respond to such threats. Ethical use of RATs involves:</p> <ul> <li>Authorized Testing: RATs are deployed only within the scope of an authorized security assessment.</li> <li>Control and Transparency: The penetration tester must have strict control over the RAT and ensure that its use is transparent to the client.</li> </ul>"},{"location":"security/rbac/","title":"Role-Based Access Control","text":"<p>Role-based access control (RBAC), also known as role-based security, is a mechanism that restricts system access. It involves setting permissions and privileges to enable access to authorized users. Most large organizations use role-based access control to provide their employees with varying levels of access based on their roles and responsibilities. This protects\u00a0sensitive data and ensures employees can only access information and perform actions they need to do their jobs.</p> <p>An organization assigns a role-based access control role to every employee; the role determines which permissions the system grants to the user. For example, you can designate whether a user is an administrator, a specialist, or an end-user, and limit access to specific resources or tasks. An organization may let some individuals create or modify files while providing others with viewing permission only.</p> <p>One role-based access control example is a set of permissions that allow users to read, edit, or delete articles in a writing application. There are two roles, a Writer and a Reader, and their respective permission levels are presented in this truth table. Using this table, you can assign permissions to each user.</p> <p>Three common principles of role-based access control include:</p> <ol> <li>User role assignment:\u00a0The permission or access rights are granted only if the individual is assigned a role or a task.</li> <li>User role authorization:\u00a0The active role of the user in the task must be authorized.</li> <li>User role permission and access rights:\u00a0The individual can utilize their permission rights only if they\u2019re given the authorization to perform their active role.</li> </ol>"},{"location":"security/rce/","title":"Remote Code Execution (RCE)","text":"<p>Remote code execution (RCE)\u00a0refers to a class of cyberattacks in which attackers remotely execute commands to place malware or other malicious code on your computer or network. In an RCE attack, there is no need for user input from you. A remote code execution vulnerability can compromise a user\u2019s sensitive data without the hackers needing to gain physical access to your network.</p> <p>Remote code execution attacks generally occur via vulnerabilities in web applications and network infrastructure.</p> <p>Remote code execution vulnerabilities are flaws in software that allow an attacker to run malicious code on a target system. Several types of vulnerabilities can be used for RCE, including the following examples:</p> <ul> <li>Injection vulnerabilities:\u00a0An injection vulnerability \u2014 such as SQL injection or Command Injection \u2014 is enabled by poor input sanitization. If a user provides a carefully-crafted, malicious input, some of their provided data will be interpreted as commands to be run. This allows the attacker to force the vulnerable system to execute attacker-provided code.</li> <li>Insecure deserialization:\u00a0Serialization simplifies the transmission of sets of data by packing it into a single string of bits to be unpacked by the recipient system. However, if the structure of serialized data is not well defined, an attacker may be able to craft an input that is misinterpreted when it is unpacked. Depending on how the data is stored and processed, this misinterpretation may allow the attacker to achieve code execution.</li> <li>Out-of-bounds write:\u00a0A buffer is a fixed-size piece of memory that is allocated to store data. Insecure data reads or writes could allow an attacker to place data where it would be interpreted as code or as important control flow information for the application.</li> <li>File management:\u00a0Some applications allow users to upload files to a server. The access that this provides may allow an attacker to upload a file containing malicious code and trick the application into executing it.</li> </ul> <p>Malware is attacker-provided code that is designed to be executed on a target system. An RCE vulnerability simply allows an attacker to deploy malware in different ways.</p> <p>As a result, RCE vulnerabilities can be used to achieve many of the same goals as traditional malware. RCE can be used to deploy malware on a vulnerable system, perform a denial-of-service (DoS) attack, or access sensitive information stored on a system.</p>"},{"location":"security/recon/","title":"Reconnaissance","text":"<p>Reconnaissance in the context of penetration testing and web hacking refers to the preliminary phase where attackers (or ethical hackers) gather information about their target to identify potential vulnerabilities and attack vectors. This phase is crucial as it lays the groundwork for subsequent stages of the attack or penetration test.</p> <p>There are two types of recon:</p> <ol> <li>Passive Reconnaissance: Involves collecting information without directly interacting with the target system. This is often preferred in the early stages to avoid detection.</li> <li>Active Reconnaissance: Involves directly interacting with the target system to gather information. This can be more intrusive and might raise alerts if not done carefully.</li> </ol> <p>Some examples of recon techniques include:</p> <ul> <li>Domain Name and IP Address Lookup: Gathering information about the domain names and associated IP addresses using tools like WHOIS, nslookup, or dig.</li> <li>Network Scanning: Using tools like Nmap or Zmap to scan the network for open ports, running services, and detecting operating systems.</li> <li>Email Harvesting: Collecting email addresses related to the target organization through web scraping, social media, or other public sources.</li> <li>Social Engineering: Gleaning information from employees or stakeholders through social engineering tactics like pretexting or phishing.</li> <li>Website Footprinting: Analyzing the target website for information like software versions, directory structure (using tools like Dirbuster), or Content Management System|CMS systems.</li> <li>DNS Enumeration: Extracting records, subdomains, and other DNS-related information about the target.</li> <li>Public Record Searching: Looking through public records or open databases for information about the target organization.</li> <li>Social Media Analysis: Examining social media profiles related to the target for employee information, roles, and potential internal lingo or jargon that could be used in social engineering attacks.</li> <li>Google Hacking: Using advanced Google search techniques to uncover hidden information on the target\u2019s website or associated pages.</li> <li>API Testing: Analyzing publicly exposed APIs for information leakage or vulnerabilities.</li> <li>SSL/TLS Certificate Analysis: Inspecting SSL certificates|SSL/TLS certificates for misconfigurations or vulnerabilities.</li> <li>Using Tools like Shodan or Censys: These search engines can find devices and systems exposed to the internet, providing a wealth of information about potential targets.</li> </ul>"},{"location":"security/redos/","title":"Regular Expression Denial of Service (ReDoS)","text":"<p>ReDoS stands for Regular Expression Denial of Service. It is a type of Denial of Service (DoS) Attacks|Denial of Service (DoS) attack that targets the improper implementation and handling of regular expressions in various software and applications. This vulnerability can be exploited to cause a program or service to become unresponsive or consume excessive amounts of resources, such as CPU or memory, thus rendering it unable to serve legitimate requests.</p> <p>ReDoS attacks exploit the fact that certain regular expressions can cause extreme situations in terms of computational time or memory usage when processing specially crafted input strings. These are typically regular expressions that have nested quantifiers or are highly ambiguous.</p> <p>An attacker crafts a specific input string that triggers the vulnerable regular expression to perform an excessive number of operations or backtrack steps. For example, a regular expression designed to validate email addresses might be forced into extensive backtracking by a specially crafted email string, causing the service to hang or slow down significantly.</p> <p>The performance impact can be severe enough to cause the application or service to become unresponsive, leading to a denial of service for other users and processes. A common example of a potentially vulnerable regular expression pattern is one that uses multiple nested quantifiers, like:</p> <pre><code>(a+)+\n</code></pre> <p>This pattern can be exploited with an input string like <code>aaaaaaaaaaaaaaaaaaaaax</code>. The regular expression engine tries to match the pattern in many different ways due to the nested quantifiers, which can lead to a combinatorial explosion of possibilities, consuming significant processing time.</p>"},{"location":"security/refxss/","title":"Reflected XSS","text":"<p>Reflected XSS attacks, also known as non-persistent attacks, occur when a\u00a0malicious script is reflected off of a web application\u00a0to the victim\u2019s browser.</p> <p>The script is activated through a link, which sends a request to a website with a\u00a0vulnerability that enables execution of malicious scripts. The vulnerability is typically a result of incoming requests not being sufficiently sanitized, which allows for the manipulation of a web application\u2019s functions and the activation of malicious scripts.</p> <p>To distribute the malicious link, a perpetrator typically embeds it into an email or third party website (e.g., in a comment section or in social media). The link is embedded inside an anchor text that provokes the user to click on it, which initiates the Cross-Site Scripting|XSS request to an exploited website, reflecting the attack back to the user.</p> <p></p> <p>Unlike a Stored XSS|stored attack, where the perpetrator must locate a website that allows for permanent injection of malicious scripts, reflected attacks only require that the malicious script be embedded into a link. That being said, in order for the attack to be successful, the user needs to click on the\u00a0infected\u00a0link.</p> <p>As such, there are a number of key differences between reflected and stored XSS attacks, including:</p> <ul> <li>Reflected attacks are more common.</li> <li>Reflected attacks do not have the same reach as stored XSS attacks.</li> <li>Reflected attacks can be avoided by vigilant users.</li> </ul> <p>With a reflected XSS, the perpetrator plays a \u201cnumbers game\u201d by sending the malicious link to as many users as possible, thereby improving his odds of successfully executing the attack.</p>"},{"location":"security/regex/","title":"Regular Expressions","text":"<p>Regex, short for Regular Expression, is a powerful tool used in programming for pattern matching within strings. It's a sequence of characters that forms a search pattern, which can be used for string searching and manipulation operations such as searching, replacing, and splitting text in most programming languages and command-line utilities.</p> <p>Regex allows you to specify complex patterns of text to search for, such as specific characters, groups of characters, or even dynamic patterns that change within a certain context. It can match various text patterns through a combination of literal characters, wildcards, and special characters.</p> <p>Regex is often the most efficient way to perform complex text processing, like extracting email addresses from a block of text or validating the format of input data.</p> <p>A simple regex for an email could look like:</p> <pre><code>^\\w+@\\w+\\.\\w+$\n</code></pre> <p>Where:</p> <ul> <li>^ - asserts the start of a line</li> <li>\\w+ - matches one or more word characters</li> <li>\\@ - is a literal character that matches itself</li> <li>\\. - matches a period (a literal do)</li> <li>\\$ - asserts the end of a line</li> </ul> <p>During reconnaissance, regex can help in extracting information like email addresses, IP addresses, and URLs from large datasets or scraped web content. Regex helps in modifying attack payloads to evade detection by Intrusion Detection Systems|IDS, which often rely on pattern matching to identify malicious traffic.</p> <p>Regex can be used to generate complex fuzzing patterns to test applications for unexpected or insecure behavior when receiving malformed or unexpected inputs.</p> <p>Regex is utilized in testing for Cross-Site Scripting|XSS and SQL Injection vulnerabilities to identify patterns that a malicious actor could exploit.</p> <p>Regex is a powerful tool in the arsenal of a penetration tester or a web application hacker, used for efficiently searching, extracting, and manipulating text data. It enables precise targeting and analysis, making it invaluable in identifying and exploiting vulnerabilities in web applications. However, it requires a good understanding of regex syntax and patterns to be effectively used in these contexts.</p>"},{"location":"security/reviews/","title":"Code Reviews","text":"<p>Code reviews are a systematic examination of computer source code, intended to find and fix mistakes, improve the overall quality of the software, and ensure that it adheres to the established coding standards.</p> <p>They are an integral part of the software development process and are typically conducted before merging code changes into the main project codebase.</p> <p>In the context of web penetration testing (pentesting), code reviews are a detailed examination of a web application's source code to identify security vulnerabilities. Unlike automated scanning tools, code reviews involve a manual, line-by-line analysis of the code by security experts or developers.</p> <p>This process is critical for uncovering issues that automated tools might miss, especially those related to logic flaws or complex security vulnerabilities.</p> <p>Reviewers look for common security issues such as SQL injection, Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and other vulnerabilities that could be exploited by attackers.</p> <p>It is also good to understand the business logic implemented in the code to ensure it does not introduce security vulnerabilities. Logical errors are often not detected by automated tools but can lead to significant security risks.</p> <p>Checking how the application handles user authentication and authorization is also important, including session management, password handling, and access controls.</p>"},{"location":"security/revshell/","title":"Reverse Shells","text":"<p>A reverse shell in the context of penetration testing (pentesting) is a technique used to establish a command line session with a target system, where the target system initiates the connection back to the attacker\u2019s machine. This is often used by pentesters and cyber attackers to bypass firewall protections that may block incoming connections.</p> <p>In a typical shell or command line access, you connect to another system (e.g., using Secure Shell|SSH or Telnet) to execute commands. This is a forward connection. A reverse shell reverses this process. The target system connects back to the attacker\u2019s system, which is listening for incoming connections.</p> <p>Firewalls often block incoming connections to certain ports but allow outgoing connections from internal network. A reverse shell exploits this by initiating the connection from the target machine (which is usually allowed through the firewall).</p> <p>Similarly, it's effective in scenarios where the target is behind a Network Address Translation (NAT)|NAT (Network Address Translation), making direct connections difficult. </p> <p>Once a vulnerability is exploited (like a Buffer Overflows|buffer overflow, SQL injection, etc.), the pentester can use that foothold to execute a payload that opens a reverse shell. The pentester\u2019s machine listens on a specified port. When the reverse shell is executed on the target system, it connects back to the pentester\u2019s listening service, giving command line access to the target system.</p> <p>Reverse shells can be scripted in various programming languages like Python, PHP, Perl, or bash, depending on what resources are available on the target system. Tools like Netcat, nc, or advanced frameworks like Metasploit Framework|Metasploit can be used to create and handle reverse shells.</p>"},{"location":"security/rfi/","title":"Remote File Inclusion","text":"<p>Remote File Inclusion (RFI) is a type of vulnerability commonly found in web applications. It allows an attacker to include a remote file, usually through a script on the web server, into the web application. </p> <p>This vulnerability occurs when a web application dynamically includes external files or scripts from a Uniform Resource Locator|URL that is not properly sanitized.</p> <p>RFI vulnerabilities typically arise in web applications that use script-based languages like PHP, JSP, or ASP.NET|ASP. These applications often include files or scripts to extend their functionalities. The vulnerability is exploited when the application takes user input (like a URL or file path) without proper validation or sanitization and uses this input to include a script or file.</p> <p>An attacker can exploit this by supplying a URL or path to a malicious file. If the application includes this file in its execution, it can lead to severe consequences.</p>"},{"location":"security/rockyou/","title":"Rockyou.txt","text":"<p>rockyou.txt is a well-known wordlist file used in password cracking and penetration testing. It originated from a security breach in 2009, where a hacker attacked the social application website RockYou and exposed over 32 million user passwords. These passwords, which were stored in plain text, were then compiled into a wordlist file named rockyou.txt.</p> <p>The file contains millions of passwords collected from the breach. These passwords range from very simple and commonly used to more complex and unique ones. Because it's derived from real-world user passwords, <code>rockyou.txt</code> is particularly effective in dictionary attacks and Brute Force Attack|brute-force attacks, where common passwords or phrases are used to attempt to gain unauthorized access.</p>"},{"location":"security/rootkits/","title":"Rootkits","text":"<p>Rootkits are a type of malicious software designed to gain unauthorized root or administrative access to a computer or network. The term \"rootkit\" comes from \"root,\" the traditional name for the privileged administrator account in Unix and Linux systems, and \"kit,\" which refers to the software components that implement the tool.</p> <p>Rootkits are designed to hide their existence or the existence of other software (such as viruses or spyware) on the computer. They can intercept and alter standard system calls, hide files, processes, and registry keys, and mask network connections and activities.</p> <p>Rootkits often embed themselves deep within the operating system to intercept and modify system functions. Some operate at the kernel level, making them particularly hard to detect and remove. They provide persistent and undetected access to a computer system, allowing an attacker to remotely control the system and perform a range of malicious activities.</p> <p>Due to their stealth and deep integration, rootkits can be challenging to detect with standard antivirus software. Removing a rootkit often requires specialized tools and techniques, and in some cases, the only reliable method is to completely reformat the infected system's hard drive.</p> <p>There are many types of rootkits:</p> <ol> <li>Kernel-Mode Rootkits: Operate at the same security level as the operating system kernel, giving them significant control over the system.</li> <li>User-Mode Rootkits: Operate at the application layer and are easier to detect than kernel-mode rootkits, but they still offer significant control over user activities and system information.</li> <li>Bootloader Rootkits: Infect the system's bootloader and are executed before the operating system itself starts, making them extremely stealthy.</li> <li>Hardware or Firmware Rootkits: Reside in hardware firmware, making them very difficult to detect and remove.</li> <li>Memory Rootkits: Reside in the computer's RAM and are lost once the system is rebooted, but they can operate stealthily while the system is running.</li> </ol>"},{"location":"security/salt/","title":"Salt","text":"<p>A salt, in the context of cryptography and password security, is a random value that is generated and combined with a user's password before it is hashed. The resulting combination of the salt and password is then hashed together. Salting is a crucial technique to enhance the security of stored passwords.</p> <p>A salt is typically a random or pseudo-random value of a fixed length. It should be generated anew for each user and for each password. This randomness makes it unique for each user and each password instance.</p> <p>When a user creates or changes their password, the system generates a salt and combines it with the user's password. This combined value (salt + password) is then hashed.</p> <p>One of the primary reasons for using a salt is to defend against precomputed tables of password hashes, known as \"rainbow tables.\" Rainbow tables contain a list of common passwords and their corresponding hash values. Without a salt, an attacker could easily look up the hash value in a rainbow table and identify the corresponding plain text password. By using salts, each password hash becomes unique, making it impractical to precompute tables for every possible salt.</p> <p>Salting significantly enhances security because it ensures that even if two users have the same password, their hashed values will be different due to the unique salts applied to their passwords.</p> <p>Salting also thwarts dictionary attacks, where attackers try a list of common passwords and hash them to compare against stored hashes. Without salts, attackers could quickly identify matching passwords from the hashes. The salt is stored alongside the hashed password in the database. When a user attempts to log in, the system retrieves the salt associated with their account, combines it with the entered password, hashes the result, and compares it to the stored hash.</p> <p>The length of the salt can vary, but it is typically between 8 and 32 bytes. Longer salts provide added security.</p>"},{"location":"security/sam/","title":"SAM","text":"<p>The Windows Security Account Manager (SAM) is a database file in Windows operating systems that stores user credentials. SAM is used by Windows to manage user accounts and security descriptors, which control access to different resources within the system. The SAM file is a crucial component of the Windows security subsystem.</p> <p>The SAM file is typically located in the <code>%SystemRoot%\\system32\\config</code> directory. The actual file is <code>%SystemRoot%\\system32\\config\\SAM</code>, and it is locked by the system when Windows is running, making it inaccessible to regular users and processes.</p> <p>SAM contains details about all user accounts on the system, including usernames, password hashes, and other security-related information. Passwords are not stored in plaintext but as hashed values. During the login process, Windows uses the SAM to verify user credentials. When a user enters a password, it is hashed and compared with the stored hash in the SAM.</p> <p>The SAM file is a target for attackers because it holds hashed passwords. Tools like Mimikatz can extract these hashes, which can then be cracked or used in pass-the-hash attacks to gain unauthorized access. To protect the SAM, Windows restricts its access. Additionally, Windows stores the file in a way that's not easily readable when the system is offline (e.g., booting from an external OS).</p> <p>Administrators should protect access to SAM and maintain backups. However, they must ensure that these backups are secure, as they contain sensitive data.</p> <p>In penetration testing, the SAM file is often targeted to extract user credentials. This is typically done by booting the system with an alternative OS or using tools that can read locked files. The extracted hashes can be cracked or used for Lateral Movement|lateral movement within a network.</p> <p>The SAM file contains information about user accounts on the system. This includes:</p> <ul> <li>Usernames</li> <li>User IDs</li> <li>Password hashes</li> <li>Group memberships</li> <li>Other security-related user account settings</li> </ul> <p>An example representation of the kind of information contained within the SAM file (in a human-readable format) might look like this:</p> <pre><code>Username: JohnDoe\nUserID: 1001\nPassword Hash: 5F4DCC3B5AA765D61D8327DEB882CF99\nGroup Memberships: Users, Administrators\n</code></pre>"},{"location":"security/sas/","title":"Security Associations (SAs)","text":"<p>Security Associations (SAs) are fundamental components of the IPsec (Internet Protocol Security) framework, which is used to secure IP communications by authenticating and encrypting each IP packet in a communication session. </p> <p>An SA is a logical connection between two entities that describes how they will use security services to communicate securely.</p> <p>An SA is a set of policies and keys that define how two network entities will secure communication. It includes all the information required to execute various security services, such as the encryption algorithm, the encryption key, and the authentication method.</p> <p>Each SA is unidirectional. In IPsec, a one-way communication channel requires two SAs, one for inbound traffic and another for outbound traffic. A typical SA contains parameters such as:</p> <ul> <li>The encryption algorithm (e.g., Advanced Encryption Standard (AES)|AES, Triple DES (3DES)|3DES).</li> <li>The encryption key and its lifetime.</li> <li>The authentication algorithm (e.g., HMAC-SHA1).</li> <li>The IP addresses of the source and destination.</li> <li>A unique identifier called the Security Parameter Index (SPI).</li> </ul> <p>SAs can be established manually or dynamically. Dynamic establishment of SAs is usually done through the Internet Key Exchange (IKE) protocol, which is part of the IPsec suite. In IPsec, SAs can apply to either Tunnel Mode or Transport Mode, determining how the data will be encrypted and/or authenticated.</p> <p>Each SA has a lifetime after which it expires and needs to be renewed. This can be based on time or the amount of data transmitted. </p> <p>Devices implementing IPsec maintain a database of SAs, known as the Security Association Database (SAD). This database is used to store and retrieve all relevant information about each SA.</p> <p>SAs play a crucial role in Virtual Private Network|Virtual Private Networks (VPNs) where IPsec is used. They ensure that each VPN tunnel has the appropriate security parameters to protect the data being transmitted.</p> <p>The SPD is used in conjunction with the SAD. While the SAD contains the parameters of the SA, the SPD defines the policies that determine the establishment and maintenance of SAs.</p>"},{"location":"security/sensitive/","title":"Sensitive Data Exposure","text":"<p>Sensitive data exposure (information disclosure), also known as information leakage, is when a website unintentionally reveals sensitive information to its users. Depending on the context, websites may leak all kinds of information to a potential attacker, including:</p> <ul> <li>Data about other users, such as usernames or financial information</li> <li>Sensitive commercial or business data</li> <li>Technical details about the website and its infrastructure</li> </ul> <p>The dangers of leaking sensitive user or business data are fairly obvious, but disclosing technical information can sometimes be just as serious. Although some of this information will be of limited use, it can potentially be a starting point for exposing an additional attack surface, which may contain other interesting vulnerabilities. The knowledge that you are able to gather could even provide the missing piece of the puzzle when trying to construct complex, high-severity attacks.</p> <p>Occasionally, sensitive information might be carelessly leaked to users who are simply browsing the website in a normal fashion. More commonly, however, an attacker needs to elicit the information disclosure by interacting with the website in unexpected or malicious ways. They will then carefully study the website's responses to try and identify interesting behavior.</p> <p>Some basic examples of information disclosure are as follows:</p> <ul> <li>Revealing the names of hidden directories, their structure, and their contents via a\u00a0robots.txt\u00a0file or directory listing</li> <li>Providing access to source code files via temporary backups</li> <li>Explicitly mentioning database table or column names in error messages</li> <li>Unnecessarily exposing highly sensitive information, such as credit card details</li> <li>Hard-coding API keys, IP addresses, database credentials, and so on in the source code</li> <li>Hinting at the existence or absence of resources, usernames, and so on via subtle differences in application behavior</li> </ul>"},{"location":"security/sesshij/","title":"Session Hijacking","text":"<p>Session hijacking is a type of cyber attack where an attacker takes control of a user's session to gain unauthorized access to information or services in a computer system. In the context of web applications, it often involves the compromise of a session token, which is used to authenticate a user after they have logged in. </p> <p>When a user logs into a web application, a session is established between the user's browser and the web server. This session is usually identified by a session token (like a Cookies|cookie) that is unique to each user session.</p> <p>The attacker's goal is to capture this session token. This can be done through various methods such as Packet Sniffing on unsecured networks, cross-site scripting (XSS) attacks, or exploiting other security vulnerabilities.</p> <p>Once the attacker has the session token, they can use it to impersonate the legitimate user. Since the session token is what authenticates the session after login, the attacker doesn't need the user's password.</p>"},{"location":"security/shellcode/","title":"Shellcode","text":"<p>Shellcode is a small piece of code used as the payload in the exploitation of a software vulnerability. It's typically written in machine code and is used to directly control the processor's execution of instructions. The term \"shellcode\" historically refers to code that creates a command shell through which an attacker can control the system. However, it can be used for various other malicious purposes.</p> <p>The primary function of shellcode is to exploit vulnerabilities (like buffer overflows) in software and provide an attacker with control of the affected system. This control is often achieved through opening a remote shell from which commands can be executed.</p> <p>In the context of security vulnerabilities, particularly those like buffer overflows, shellcode is the payload that gets executed after the exploit has compromised the system's memory. Shellcode is often written in assembly language for precision and control and then converted into machine code. It needs to be compact and efficient due to space constraints in the exploit payload.</p> <p>In penetration testing and ethical hacking, shellcode is used to demonstrate the impact of a vulnerability and assess the effectiveness of security controls. While traditional shellcode often aims to open a shell, it can perform a variety of functions, including creating files, moving data, or sending information to a remote server.</p> <p>Shellcode can be delivered to a target system via various methods, including malicious documents, web application exploits, or buffer overflow attacks in software applications. Shellcode is generally platform-specific; it must be compatible with the architecture and operating system of the target machine.</p>"},{"location":"security/shellinjection/","title":"Shellcode Injection","text":"<p>Shellcode injection is a type of exploit used in cybersecurity attacks where an attacker injects a small piece of code, known as \"Shellcode,\" into a vulnerable program. This code typically opens up a command shell from which the attacker can control the system.</p> <p>Shellcode is a set of instructions used as a payload in the exploitation of a software vulnerability. It's called \"shellcode\" because it often opens a command shell from which an attacker can control the system.</p> <p>Shellcode injection commonly exploits Buffer Overflows|buffer overflow vulnerabilities in software. A buffer overflow occurs when more data is put into a buffer (a temporary data storage area) than it can handle, causing data to overflow into adjacent storage.</p> <p>The primary goal of shellcode injection is to execute arbitrary code on the victim's machine. The shellcode is crafted to perform actions that the attacker chooses, such as creating a backdoor for future access.</p> <p>The attacker identifies a vulnerability in a software program that can be exploited (commonly a buffer overflow). They then inject shellcode into the program's memory, typically by providing input data that the program processes without proper validation. The vulnerability is exploited to divert the program's execution flow to the injected shellcode, which then gets executed.</p> <p>Shellcode is often platform-specific; it must be written to match the architecture and operating system of the target system.</p>"},{"location":"security/shellshock/","title":"Shellshock","text":"<p>Shellshock, also known as the Bash bug, is a critical vulnerability in the Bash shell.</p> <p>It affects all operating systems (Linux and Unix based), which allows an attacker to execute arbitrary commands on a vulnerable system by sending specially crafted environment variables to a Bash-based application.</p> <p>It is a severe threat to the system and causes extreme data breaches. If this vulnerability is successfully exploited, an attacker can remotely issue commands on the target host, i.e., Knowledge Base/Remote Code Execution|remote code execution (RCE). </p> <p>Though Bash is not an Internet-facing service, many network and internet services (for example, web servers) use environment variables for communicating with the server\u2019s OS.\u00a0  </p> <p>If environment variables not sanitized before execution, an attacker can send commands through HTTP Protocol|HTTP requests and get them executed by the server\u2019s OS.\u00a0</p>"},{"location":"security/shibboleth/","title":"Shibboleth","text":"<p>Shibboleth is an open-source identity and access management system that provides federated identity and Single Sign-On (SSO) capabilities for web applications and services. It is widely used in the academic and research community, as well as in various other sectors, to enable secure authentication and authorization in a federated environment.</p> <p>Shibboleth is designed to support federated identity management, allowing organizations and institutions to establish trust relationships and share authentication and authorization information across different domains or entities.</p> <p>Shibboleth offers SSO functionality, enabling users to log in once to an Trusted Identity Provider (IdP)|identity provider (IdP) and then access multiple services and applications without the need to re-enter credentials. Shibboleth places a strong emphasis on security. It uses cryptographic techniques to protect user authentication information and attributes during transmission and provides mechanisms for secure attribute release.</p> <p>Shibboleth allows identity providers to release specific user attributes or claims to service providers (SPs) based on predefined policies. This attribute-based access control is useful for granting or denying access to resources based on user attributes.</p> <p>Shibboleth uses the SAML (Security Assertion Markup Language)|Security Assertion Markup Language (SAML) as the underlying protocol for exchanging authentication and authorization data between IdPs and SPs. SAML is a widely adopted standard for federated identity systems. Shibboleth is an open-source project, which means that the software is freely available for organizations to download, install, and customize according to their specific needs.</p> <p>The Shibboleth community consists of developers, organizations, and institutions that contribute to its development and share best practices for implementing federated identity solutions. Shibboleth provides mechanisms for users to have control over the release of their attributes and consent to the sharing of specific information with service providers.</p> <p>Shibboleth consists of two main components: the Identity Provider (IdP) and the Service Provider (SP). The IdP is responsible for authenticating users and releasing attributes, while the SP consumes these attributes to control access to resources.</p> <p>Shibboleth relies on the exchange of metadata between participating organizations to establish trust and configure federation settings. Metadata contains information about IdPs, SPs, and encryption certificates.</p> <p>Info</p> <p>Shibboleth is often used in higher education institutions, research organizations, and government agencies, where the need for secure access to resources and collaboration across multiple entities is critical. It allows organizations to streamline authentication and authorization processes while ensuring that users' identities and attributes are protected.</p>"},{"location":"security/side/","title":"Side-Channel Attacks","text":"<p>Side-channel attacks are a type of security exploit that target the implementation of a computer system rather than weaknesses in the actual algorithms themselves. These attacks are based on information gained from the physical implementation of a system, such as timing information, power consumption, electromagnetic leaks, or even sounds. </p> <p>Unlike other methods, side-channel attacks don't directly attack the cryptographic algorithm but rather exploit weaknesses in how the system executes the algorithm.</p> <p>Some key types include:</p> <ol> <li>Timing Attacks: These involve measuring the time it takes to execute cryptographic operations. Differences in timing can be used to infer information about the secret data. For example, if certain operations take longer when a specific bit in the key is set, an attacker might deduce the value of these bits by measuring the time of execution.</li> <li>Power Analysis Attacks: These look at the power consumption of a device during cryptographic processing. Different operations consume different amounts of power, and this can be used to deduce information about the secret keys.</li> <li>Electromagnetic Attacks: Similar to power analysis, these attacks measure the electromagnetic emissions of a device. By analyzing these emissions, an attacker can potentially extract secret keys or other sensitive information.</li> <li>Acoustic Cryptanalysis: This involves analyzing sounds emitted by a device, which can vary based on the operations being performed. Even subtle differences in sound can reveal information about what the device is processing.</li> </ol> <p>One classic example of a side-channel attack is the RSA (Rivest-Shamir-Adleman)|RSA timing attack demonstrated by Paul Kocher in the late 1990s. In this attack:</p> <ul> <li>Kocher showed that by measuring the amount of time a system takes to decrypt messages using the RSA algorithm, an attacker could work out the private key.</li> <li>RSA decryption involves modular exponentiation, where the exponent is the secret key. The time taken for this operation can vary slightly depending on the value of the key.</li> <li>By carefully measuring the decryption times for many different encrypted messages and performing statistical analysis, Kocher was able to recover the private key.</li> </ul>"},{"location":"security/siem/","title":"Security Information and Event Management (SIEM)","text":"<p>Security Information and Event Management (SIEM) systems are comprehensive solutions used in cybersecurity to provide real-time analysis of security alerts generated by applications and network hardware. They are designed to give organizations an overview of the security within their IT infrastructure.</p> <p>SIEM systems collect and aggregate log data generated by various sources within an organization\u2019s IT infrastructure, such as network devices, servers, domain controllers, and applications. This data is normalized to facilitate analysis and reporting.</p> <p>One of the core functionalities of SIEM is correlating events from different sources. By analyzing patterns and relationships between various log entries, SIEM can identify anomalies that might indicate a security incident.</p> <p>SIEM systems analyze data in real time to detect activities that might indicate a threat. They generate alerts based on predefined and customizable rules that signal potential security issues.</p> <p>SIEMs often integrate with other security solutions, such as intrusion prevention systems (IPS), Firewall|firewalls, and endpoint protection platforms, to provide a more comprehensive security overview.</p>"},{"location":"security/sniffing/","title":"Packet Sniffing","text":"<p>Packet sniffing on insecure networks in the context of penetration testing is a process where a penetration tester uses packet sniffing techniques to capture and analyze network traffic for security assessment and vulnerability identification purposes.</p> <p>This is particularly relevant on insecure or unencrypted networks, where data packets can be intercepted more easily.</p> <p>On insecure networks, unencrypted traffic (like HTTP Protocol) can be sniffed to find sensitive information (like passwords and session tokens) or to identify misconfigurations and vulnerable services.</p> <p>Packet sniffing helps in understanding the network layout, identifying active hosts, and the types of services and protocols in use, which is crucial for further penetration testing steps.</p> <p>Using tools like Wireshark or Tcpdump in promiscuous mode to capture all network traffic that reaches the network interface.</p>"},{"location":"security/soapspoof/","title":"SOAPAction Spoofing","text":"<p>SOAPAction Spoofing is a type of attack against web services that use the SOAP|Simple Object Access Protocol (SOAP). This attack involves manipulating or forging the <code>SOAPAction</code> header in a SOAP request to trick the server into performing an unintended action. The <code>SOAPAction</code> header in a SOAP request is supposed to indicate the specific action or operation that the request is intended to trigger. By spoofing this header, an attacker can potentially bypass security checks or access unauthorized functionality.</p> <p>The attacker modifies the <code>SOAPAction</code> header in the SOAP request to an unexpected value or to an action that they are not authorized to use. If the web service does not properly validate the <code>SOAPAction</code> header or relies solely on it for routing requests to the appropriate handlers, this manipulation can allow the attacker to access functions they shouldn't have access to.</p> <p>The spoofing might exploit logical flaws in the web service where certain actions are inadequately protected or where the routing of requests is based solely on the <code>SOAPAction</code> header.</p> <p>Imagine a web service that offers two operations: <code>getUserDetails</code> (which is intended to be publicly accessible) and <code>deleteUser</code> (which is restricted to administrators). These operations might be invoked using SOAP requests with <code>SOAPAction</code> headers like:</p> <ul> <li><code>SOAPAction: \"http://example.com/getUserDetails\"</code></li> <li><code>SOAPAction: \"http://example.com/deleteUser\"</code></li> </ul> <p>An attacker might normally only have access to <code>getUserDetails</code>. However, if the web service inadequately checks the user's permissions and relies solely on the <code>SOAPAction</code> header to route the request, the attacker could modify their SOAP request to:</p> <pre><code>SOAPAction: \"http://example.com/deleteUser\"\n</code></pre> <p>Info</p> <p>Even though they are not an administrator, if the service does not verify their authorization for the <code>deleteUser</code> action, it might process this request, allowing the attacker to delete users.</p>"},{"location":"security/soceng/","title":"Social Engineering","text":"<p>Social engineering is a tactic used in cyber attacks and fraud, involving psychological manipulation to trick individuals into divulging confidential information or performing actions that compromise security. It exploits human vulnerabilities rather than technical vulnerabilities.</p> <p>Social engineering relies on understanding and exploiting human behaviours like trust, curiosity, fear and obedience. Attackers deceive victims by posing as trusted individuals or authorities, convincing them to reveal sensitive information, click on links or download files.</p> <p>Some common techniques include Phishing|phishing which is sending fraudulent emails/messages that appear to come from legitimate sources, urging recipients to provide sensitive data.</p>"},{"location":"security/sola/","title":"Second Order LFI Attack","text":"<p>A second-order Local File Inclusion (LFI) attack is a more complex form of the standard LFI attack. In a typical LFI attack, an attacker manipulates input to include files that are already on the server (like <code>/etc/passwd</code>) into the output of a web application. </p> <p>However, in a second-order LFI attack, the malicious file inclusion is performed in two steps, making it more insidious and harder to detect.</p> <p>The attacker interacts with the web application in a way that allows them to upload or modify a file on the server. This could be through features like profile picture upload, file sharing, or document editing. Instead of a legitimate file, the attacker uploads or inserts malicious content (e.g., a PHP script) into a file. This file is saved on the server, but it's not immediately executed.</p> <p>Later, the attacker manipulates the application to include the file they uploaded or modified. This is typically done by exploiting vulnerabilities in the application that allow for file inclusion, such as poorly sanitized input parameters. When the application includes the uploaded/modified file in its execution context (for example, through a dynamic file include mechanism), the malicious code gets executed.</p> <p>Some example scenarios include:</p> <ul> <li>File Upload: An application allows users to upload a custom profile template, which is stored as a file on the server.</li> <li>Malicious Upload: An attacker uploads a file named <code>custom_template.php</code> containing a PHP script that can execute arbitrary commands on the server.</li> <li>Delayed Execution: Initially, this file just sits on the server without causing harm.</li> <li>Manipulating File Inclusion: Later, the attacker manipulates a different feature of the application, such as a dynamic template rendering function, to include <code>custom_template.php</code>.</li> <li>Code Execution: When an unsuspecting user or admin accesses the feature that includes the attacker\u2019s template, the malicious PHP script is executed, potentially compromising the server.</li> </ul>"},{"location":"security/sp/","title":"Service Provider (SP)","text":"<p>In the context of Identity and Access Management (IAM)|identity and access management (IAM) and federated identity systems, a Service Provider (SP) is an entity or system that provides access to specific resources, services, or applications to authenticated and authorized users. The SP is one of the key components in a federated identity environment and relies on identity and authentication information provided by an Trusted Identity Provider (IdP)|Identity Provider (IdP) to make access control decisions.</p> <p>The SP hosts or manages a set of resources, services, or applications that users want to access. These resources can include web applications, databases, APIs, files, or any other digital assets. The SP is responsible for controlling access to its resources. It relies on information received from the IdP to make access control decisions, such as determining which users are allowed to access specific resources and what level of access they have.</p> <p>The SP establishes a trust relationship with one or more IdPs. This trust relationship allows the SP to trust the authentication and authorization information provided by the IdPs, enabling users to log in and access resources using their IdP-issued credentials.</p> <p>The SP relies on the IdP to authenticate users. When a user attempts to access a resource protected by the SP, they are redirected to their IdP for authentication. Once authenticated, the IdP issues an authentication token or assertion, which the user presents to the SP to gain access.</p> <p>Many SPs implement Single Sign-On (SSO) functionality, allowing users to log in once to access multiple resources hosted by the same or different SPs without the need to repeatedly enter credentials. The IdP may provide the SP with additional attributes or claims about the user, which can be used for authorization purposes. For example, the IdP might provide the user's role or group membership.</p> <p>The SP must integrate with the federated identity system and implement protocols such as SAML (Security Assertion Markup Language)|Security Assertion Markup Language (SAML), OpenID Connect, or OAuth 2.0 to facilitate the exchange of authentication and authorization information with IdPs.</p> <p>SPs typically maintain metadata that describes their endpoints, configuration details, and encryption keys. This metadata is often shared with IdPs to establish trust and enable secure communication. SPs need to implement appropriate security measures to protect against unauthorized access and data breaches. They must also handle authentication tokens and user data securely.</p> <p>Examples of Service Providers include:</p> <ul> <li>Web applications that require users to log in to access protected content.</li> <li>APIs that provide access to specific functionalities or data.</li> <li>Cloud service providers that host software-as-a-service (SaaS) applications.</li> <li>Online retailers that offer personalized services and accounts.</li> </ul>"},{"location":"security/spns/","title":"Service Principle Names (SPN)","text":"<p>Service Principal Names (SPNs) in Microsoft Windows are unique identifiers assigned to each service instance on a network. They are used in Kerberos authentication to associate a service instance with a service logon account. This association is crucial for Kerberos to correctly authenticate clients accessing network services.</p> <p>An SPN uniquely identifies a service instance in a domain, ensuring that Kerberos authentication can uniquely target that service when a client requests access. SPNs have a specific format, usually as <code>serviceType/host:port/serviceName</code>. For example, a typical SPN for a web service might be <code>HTTP/webserver.domain.com</code>.</p> <p>When a client wants to access a service in a Windows network, it requests a Kerberos Tickets|Kerberos ticket for the SPN of that service. The Domain Controller then uses the SPN to find the service's account in the Active Directory and issue an appropriate ticket.</p> <p>Imagine a SQL Server named <code>sqlserver1</code> in the domain <code>company.com</code> running under the service account <code>SQLService</code>. The SPN for this SQL Server might look like:</p> <pre><code>MSSQLSvc/sqlserver1.company.com:1433\n</code></pre> <p>This SPN includes:</p> <ul> <li>The service type: <code>MSSQLSvc</code></li> <li>The host: <code>sqlserver1.company.com</code></li> <li>The port: <code>1433</code> (the default port for SQL Server)</li> </ul> <p>Info</p> <p>When a client application tries to connect to this SQL Server instance using Windows Authentication, the Kerberos protocol uses this SPN to authenticate and securely negotiate the connection.</p>"},{"location":"security/spray/","title":"Password Spraying","text":"<p>The basics of a password spraying attack involve a\u00a0threat actor using a single common password against multiple accounts on the same application. This avoids the account lockouts that typically occur when an attacker uses a brute force attack on a single account by trying many passwords. Password spraying is particularly effective against businesses that participate in password sharing.</p> <p>Password Spraying is a variant of what is known as a Brute Force Attack|brute force attack. In a traditional brute force attack, the perpetrator attempts to gain unauthorized access to a single account by guessing the password repeatedly in a very short period of time. </p> <p>Most organizations have employed countermeasures, commonly a lock-out after three to five attempts. In a Password Spraying attack, the attacker circumvents common countermeasures (e.g., account lock out) by \u201cspraying\u201d the same password across many accounts before trying another password.</p> <p>Typically used against single sign-on (SSO) and cloud-based applications using federated authentication protocols, this attack allows the malicious actor to compromise the authentication mechanisms. Once in, the attacker moves laterally, capitalizing on internal network vulnerabilities, to gain access to critical applications and sensitive data.</p> <p>Common tactics, techniques, and procedures (TTPs) involved in this type of attack include:</p> <ul> <li>Using online research and social engineering tactics to identify target organizations and user accounts</li> <li>Using easily guessed passwords (e.g., \u201cPassword123\u201d) to execute the password spray attack</li> <li>Leveraging compromised accounts to obtain email address lists to attack even more accounts</li> <li>Expand laterally within the compromised network and exfiltrate data</li> </ul>"},{"location":"security/sqli/","title":"SQL Injection","text":"<p>SQL injection (SQLi) is a web security vulnerability that allows an attacker to interfere with the queries that an application makes to its database. This can allow an attacker to view data that they are not normally able to retrieve. This might include data that belongs to other users, or any other data that the application can access. In many cases, an attacker can modify or delete this data, causing persistent changes to the application's content or behavior.</p> <p>In some situations, an attacker can escalate a SQL injection attack to compromise the underlying server or other back-end infrastructure. It can also enable them to perform denial-of-service attacks.</p> <p>A successful SQL injection attack can result in unauthorized access to sensitive data, such as:</p> <ul> <li>Passwords.</li> <li>Credit card details.</li> <li>Personal user information.</li> </ul> <p>SQL injection attacks have been used in many high-profile data breaches over the years. These have caused reputational damage and regulatory fines. In some cases, an attacker can obtain a persistent backdoor into an organization's systems, leading to a long-term compromise that can go unnoticed for an extended period.</p>"},{"location":"security/ssii/","title":"Server-Side Includes Injections","text":"<p>Server-Side Includes (SSI) Injection is a type of web application security vulnerability. This vulnerability occurs when an attacker is able to inject malicious code into a web application that uses Server-Side Includes. SSI is a server-side scripting language used primarily for including the contents of one or more files into a web page on a web server, usually for web page design purposes.</p> <p>Server-Side Includes are directives that are placed in HTML pages, and evaluated on the server while the pages are being served. They allow for dynamic content to be included in static web pages. Common uses include inserting the contents of a file, displaying the current date and time, or setting environment variables.</p> <p>The vulnerability arises when a web application does not properly Input Sanitization|sanitize user-supplied input that is incorporated into an SSI directive. An attacker can inject malicious SSI directives through user input fields, like form inputs or URL query parameters, which the server then executes.</p> <p>SSI Injection can lead to various malicious activities, depending on the level of server privileges available to the SSI engine. This might include Sensitive Data Exposure|data disclosure, cross-site scripting (XSS), and, in some cases, Knowledge Base/Remote Code Execution|command execution on the server.</p> <p>If a web application includes user input directly in a web page that is processed for SSI directives, an attacker might input something like <code>&lt;!--#exec cmd=\"ls\" --&gt;</code>. If this input is not properly sanitized, the server might execute this directive and include the output (in this case, the listing of files in the current directory) in the web page.</p>"},{"location":"security/sslstrip/","title":"SSL Stripping","text":"<p>SSL stripping is a type of Man-in-the-Middle (MitM) attack|man-in-the-middle (MITM) attack where the attacker intercepts and alters the communication between a user's browser and a web server to force the connection to downgrade from a secure HTTPS Protocol|HTTP connection to an unsecure HTTP Protocol|HTTP connection. </p> <p>This attack exploits the fact that many websites redirect from an initial HTTP connection to a secure HTTPS connection. By intercepting and manipulating this redirect, the attacker can keep the connection unencrypted, allowing them to read and modify any data passed between the two parties.</p> <p>The user attempts to connect to a website (e.g., a banking website) using HTTP. The attacker, positioned between the user and the website, intercepts this request. Instead of allowing the website to redirect the user to the secure HTTPS version, the attacker sends an unencrypted version of the site to the user, usually by stripping the \"s\" from \"https://\" in the redirection response.</p> <p>The user, unaware of the switch, sends sensitive information (like login credentials) over the unsecure HTTP connection. The attacker captures this unencrypted data, which can include personal, financial, or login information.</p> <p>Consider a user, Alice, who wants to log in to her online banking account:</p> <ol> <li>Alice's Action: Alice types <code>http://www.mybank.com</code> into her browser and hits enter.</li> <li>Interception by Attacker: A hacker, who has already infiltrated the network Alice is using (e.g., a public Wi-Fi), intercepts the request.</li> <li>SSL Stripping: Instead of allowing <code>http://www.mybank.com</code> to redirect Alice to <code>https://www.mybank.com</code>, the attacker strips the response of its secure HTTPS redirect, forcing Alice\u2019s browser to stay on the HTTP version of the site.</li> <li>Alice\u2019s Unawareness: Alice sees the bank\u2019s login page (which is actually a non-secure version presented by the attacker) and enters her username and password.</li> <li>Data Theft: The attacker captures Alice's credentials sent over HTTP, gaining unauthorized access to her bank account.</li> </ol>"},{"location":"security/sso/","title":"Single Sign-On (SSO)","text":"<p>Single Sign-On (SSO) is an authentication and access control mechanism that allows a user to log in once and gain access to multiple applications or services without the need to provide separate sets of credentials (e.g., username and password) for each individual system. </p> <p>In an SSO system, a user authenticates themselves once, and then a Trusted Identity Provider (IdP)|trusted identity provider (IdP) issues an authentication token. This token is used to verify the user's identity and grant access to various integrated applications or services without the need for additional login prompts.</p> <p>The identity provider is responsible for authenticating users and issuing authentication tokens. It serves as the trusted source of user identities. Common IdPs include Active Directory, OAuth providers like Google or Facebook, and dedicated identity management systems.</p> <p>The service provider is an application or system that relies on the IdP for user authentication. It trusts the IdP to provide accurate user identity information. Examples of SPs include web applications, cloud services, and internal company systems.</p> <p>After a user successfully logs in to an IdP, the IdP issues an authentication token or assertion. This token is a proof of authentication and contains information about the user. The token is then presented to SPs to gain access without re-entering credentials.</p> <p>The SSO flow is the process by which a user logs in once to the IdP and subsequently gains access to multiple SPs. The flow typically involves a series of redirects and token exchanges between the user, IdP, and SPs.</p> <p>SSO systems often include session management mechanisms to keep track of authenticated sessions. This ensures that users remain authenticated as they navigate between different SPs during a session. SSO implementations commonly include security measures like Multi-Factor Authentication (MFA)|multi-factor authentication (MFA) to enhance user identity verification. MFA requires users to provide additional authentication factors beyond a password.</p> <p>SSO simplifies the user experience by reducing the number of times users need to enter credentials. Users can access multiple services seamlessly. SSO allows organizations to implement stronger authentication methods like MFA, enhancing security. It also reduces the risk of users reusing weak passwords across multiple services.</p> <p>SSO reduces the administrative overhead of managing user accounts and passwords for multiple systems. It simplifies user provisioning and deprovisioning. SSO systems often provide detailed audit logs and reporting capabilities, making it easier to monitor and track user access to various services.</p> <p>Users are less likely to abandon or forget their credentials, leading to higher user adoption rates for applications and services.</p>"},{"location":"security/ssrf/","title":"Server-Side Request Forgery","text":"<p>Server-Side Request Forgery (SSRF) is a web security vulnerability that allows an attacker to induce the server-side application to make HTTP Protocol|HTTP requests to an arbitrary domain of the attacker's choosing. This vulnerability occurs when a web application fetches a remote resource without sufficiently validating the user-supplied Uniform Resource Locator|URL.</p> <p>Server-side request forgery is a web security vulnerability that allows an attacker to cause the server-side application to make requests to an unintended location.</p> <p>In a typical SSRF attack, the attacker might cause the server to make a connection to internal-only services within the organization's infrastructure. In other cases, they may be able to force the server to connect to arbitrary external systems. This could leak sensitive data, such as authorization credentials.</p> <p>In an SSRF attack, the attacker has limited direct control over the server but can manipulate the server to perform certain actions, make requests, or send data on their behalf.</p> <p>SSRF typically exploits a vulnerability in a web application that allows the attacker to manipulate the URLs that the server-side application accesses.</p> <p>The impact of SSRF can be significant, ranging from unauthorized access to internal services, Sensitive Data Exposure|information disclosure, and interaction with internal network infrastructure that might otherwise be inaccessible from the outside. In some cases, SSRF can be used to carry out more sophisticated attacks like port scanning, attacking internal applications, or accessing sensitive data.</p> <p>There are two types of SSRF attacks:</p> <ul> <li>Basic SSRF - The attacker causes the server to make a request to a domain of their choice. The response from the requested server might be returned to the attacker, allowing them to read sensitive data.</li> <li>Blind SSRF - The attacker does not receive the response directly. They might infer the success of the attack by observing changes in the application's behavior or by leveraging other information sources.</li> </ul>"},{"location":"security/ssti/","title":"Server-Side Template Injection","text":"<p>Server-Side Template Injection (SSTI) is a type of web security vulnerability that occurs when an attacker is able to inject malicious code into a server-side template, leading to the execution of unintended commands or code on the server. This vulnerability exploits web applications that use templating engines to dynamically generate HTML pages.</p> <p>Template engines are used in web development to separate HTML structure from business logic. They allow server-side variables and expressions to be embedded in HTML, which the server then processes to generate the final HTML page. Examples include Jinja2 for Python, ERB for Ruby, and Smarty for PHP.</p> <p>SSTI vulnerabilities arise when user input is improperly Input Sanitization|sanitized before being included in a template. This allows attackers to inject malicious template code, which the server then executes. The impact depends on the template engine and the server\u2019s configuration.</p> <p>In severe cases, SSTI can lead to Knowledge Base/Remote Code Execution|arbitrary code execution on the server. SSTI can be used to access sensitive data stored on the server, such as database credentials. Malicious template injections could cause server crashes or significant performance degradation.</p> <p>A web application uses user input to construct a response using a template engine. If the input is not properly sanitized, an attacker could inject template directives, leading to unintended code execution.</p> <p>For instance, in a Python application using Jinja2, injecting <code>{{ 7*'7' }}</code> would cause the server to evaluate and execute it, rendering <code>7777777</code>.</p>"},{"location":"security/stacked/","title":"Stacked Queries","text":"<p>Stacked queries, in the context of web application penetration testing and SQL injection, refer to a technique used to execute multiple SQL commands in a single query. This approach is particularly relevant when exploiting SQL injection vulnerabilities.</p> <p>In the context of SQL injection, stacked queries are a method where an attacker injects multiple SQL commands into a single SQL statement. This is often done by separating the commands with semicolons (;).</p> <p>As an example, suppose a web application's form inputs are not properly sanitized. An attacker might input something like 1; DROP TABLE users; into a form field. If vulnerable, the application will execute this as two SQL commands: </p> <p>The first command (1) might be harmless, but the second command (DROP TABLE users) could lead to destructive actions like deleting a database table.</p>"},{"location":"security/static/","title":"Static Analysis","text":"<p>Static analysis is a method of analyzing software without actually executing the program. It is conducted by examining the code to understand its structure, purpose and potential flaws. </p> <p>Static analysis involves looking at the source code or, in some cases, the compiled binary code. There are various tools that automatically perform static analysis on codebases which can check for a variety of issues including syntax errors, potential bugs and adherence to coding conventions.</p> <p>Static analysis, in the context of Deobfuscation, refers to a method of analyzing and understanding obfuscated code without executing it. The objective is to reverse or understand the obfuscation techniques used to make the code difficult to read or analyze, and to reveal the original, clearer form of the code or its functionality. </p> <p>In deobfuscation, static analysis is particularly useful because it allows for the safe examination of potentially malicious or complex code.</p> <p>Static analysis involves a detailed inspection of the obfuscated code to identify patterns, structures and algorithms. Obfuscation can involve various techniques such as renaming variables, rearranging code structure, inserting dummy code or using complex control flow structures.</p>"},{"location":"security/storedxss/","title":"Stored (Persistent) XSS","text":"<p>In a Stored XSS attack, the vulnerable web application\u00a0receives user-supplied input\u00a0from\u00a0untrusted sources\u00a0and\u00a0stores\u00a0it. This malicious content also gets included in the later HTTP responses sent by the server.</p> <p>To perform a Stored XSS attack, hackers only need to identify a security vulnerability within the backend application that allows executing malicious requests. This makes it\u00a0more exploitable\u00a0as hackers do not need to craft external methods for supplying untrusted inputs to the target application server.</p> <p>Stored XSS attacks typically rely on unsanitized user input points for scripts permanently stored on the target servers. Since these attacks allow malicious users to control how the browser executes a script, they can typically facilitate a complete user account takeover.</p> <p>The impact of a successful attack ranges from mild to full-blown compromise depending on the privileges assigned to the valid affected user.</p> <p>To successfully execute a stored XSS attack, a perpetrator has to locate a\u00a0vulnerability in a web app and then inject malicious script into its server (e.g. via a comment field):</p> <p></p> <p>Info</p> <p>The most frequent targets are websites that allow users to share content, including blogs, social networks, video sharing platforms and message boards. Every time the infected page is viewed, the malicious script is transmitted to the victim\u2019s browser.</p>"},{"location":"security/sts/","title":"Secure Token Service (STS)","text":"<p>A Secure Token Service (STS) is a vital component in web services and identity management, used to authenticate and authorize users or systems and issue security tokens. These tokens encapsulate a set of claims about the user, such as their identity, role, or permissions.</p> <p>STS verifies the identity of a user or system, often using credentials like username and password, certificates, or multi-factor authentication methods. Once authentication is successful, STS issues a security token. This token contains claims about the user, which can include user identity, roles, privileges, and other relevant attributes.</p> <p>STS can facilitate interoperability between different systems and security domains by translating authentication tokens into formats that other systems can understand. In federated identity scenarios and Single Sign-On (SSO) implementations, an STS enables users to authenticate once and access multiple related but independent software systems.</p> <p>In a service-oriented architecture (SOA), STS is used to secure web services by ensuring that only authenticated and authorized users can access them. STS is central to claims-based authentication systems, where it issues tokens based on a user's claims, which are then used to access various resources and services.</p> <p>In federated identity management, STS allows different organizations to trust each other's authentication tokens, enabling users from one domain to access resources in another.</p> <p>Consider a user trying to access a cloud application in an enterprise environment:</p> <ol> <li>The user attempts to access the application.</li> <li>The application redirects the user to the STS for authentication.</li> <li>The user provides their credentials to the STS.</li> <li>Upon successful authentication, the STS issues a token containing claims about the user.</li> <li>The user presents this token to the application.</li> <li>The application verifies the token and grants access based on the claims within it.</li> </ol>"},{"location":"security/stuff/","title":"Credential Stuffing","text":"<p>Credential stuffing is a type of cyberattack where attackers use lists of compromised user credentials (usernames and passwords) to gain unauthorized access to user accounts through large-scale automated login requests. This attack relies on the fact that many people reuse the same usernames and passwords across multiple websites and online services.</p> <p>Attackers first obtain leaked usernames and passwords from one source. These credentials often come from data breaches at various companies and are typically sold or shared on the Dark Web|dark web. Using automated tools, attackers then attempt to log in to other websites or services with these credentials. This is usually done on a large scale, testing thousands or even millions of username/password combinations across various sites.</p> <p>When a login attempt is successful, attackers gain unauthorized access to users' accounts. They can then exploit these accounts for various purposes, such as stealing personal information, committing fraud, or spreading spam.</p> <p>The main reason credential stuffing is effective is due to the common practice of password reuse. Many users use the same password across multiple sites, so a breach on one site can lead to compromised accounts on others. Attackers use sophisticated tools that can automate the login process, allowing them to test millions of credentials relatively quickly and with minimal effort.</p>"},{"location":"security/tidp/","title":"Trusted Identity Provide (IdP)","text":"<p>A trusted identity provider (IdP), in the context of authentication and access control, is a service or organization that is relied upon to verify and authenticate the identities of users or entities accessing a system, application, or resource. Trusted IdPs are fundamental components of various authentication and authorization systems, especially in Single Sign-On (SSO) and federated identity scenarios.</p> <p>The primary role of an IdP is to verify the identity of users or entities seeking access to protected resources. This verification can involve various authentication methods, such as username/password, Multi-Factor Authentication (MFA), biometrics, or token-based authentication.</p> <p>Once an IdP verifies a user's identity, it issues an authentication token or assertion to the user, signifying that the user has been authenticated. This token serves as proof of the user's identity and is presented to service providers (SPs) to gain access.</p> <p>Trusted IdPs play a crucial role in SSO systems. When users log in to an IdP, they can access multiple services and applications without the need to re-enter their credentials. The IdP's authentication token is used for authentication across various SPs.</p> <p>In federated identity systems, multiple organizations or domains trust each other's IdPs. Users from one organization can use their home IdP's credentials to access resources in other federated domains. Trusted IdPs enable this cross-domain authentication and access. IdPs often provide additional user attributes or claims along with the authentication token. These attributes may include user roles, permissions, and profile information, which can be used by SPs for authorization and access control decisions.</p> <p>A trusted IdP is expected to maintain a high level of security and trustworthiness. It should implement strong security practices, protect user data, and follow industry standards to prevent unauthorized access and data breaches. Trusted IdPs often conform to industry standards and protocols for authentication and identity management. Standards like SAML (Security Assertion Markup Language) and OAuth 2.0 are commonly used in SSO and federated identity scenarios.</p> <p>Examples of trusted identity providers include:</p> <ul> <li>Microsoft Azure Active Directory (Azure AD): Azure AD is a widely used IdP that provides authentication and identity services for Microsoft 365, Azure services, and various third-party applications.</li> <li>Okta: Okta is an identity and access management platform that serves as a trusted IdP for numerous organizations, allowing them to manage user identities and enable SSO.</li> <li>Google Identity Platform: Google provides identity and authentication services for Google Workspace (formerly G Suite) and allows users to use their Google accounts for accessing third-party services.</li> <li>Shibboleth: Shibboleth is an open-source identity federation system often used in the academic and research community for federated identity management.</li> </ul>"},{"location":"security/timebased/","title":"Time-Based Boolean Injection","text":"<p>Time-based SQL injection is a subtype of Blind Injections|blind SQL injection. In these attacks, the attacker cannot directly see the data retrieved by their injected SQL query due to the lack of error messages or direct output. Instead, they gather information about the database by observing the response time of the application. </p> <p>The attacker crafts a SQL query that includes a command to pause or delay the database's response for a certain amount of time. Commonly used functions for this purpose are SLEEP() in MySQL (KB)|MySQL, pg_sleep() in PostgreSQL, or WAITFOR DELAY in Microsoft SQL Server|SQL Server.</p> <p>The attacker injects a condition that, if true, triggers the delay. By measuring the time it takes for the application to respond, the attacker can infer whether the condition in their SQL query was true or false. If the response is delayed, the condition is true; if the response time is normal, the condition is false.</p> <p>To extract data, the attacker systematically tests different conditions. For example, to guess a password, the attacker might inject conditions to check each character of the password one by one. This process is slow as it involves sending many requests and waiting for the response time for each.</p> <p>Consider an app where the following SQL query is executed:</p> <pre><code>SELECT * FROM users WHERE username = '[user_input]';\n</code></pre> <p>An attacker might inject a statement like:</p> <pre><code>' OR IF((SELECT SUBSTRING(password, 1, 1) FROM users WHERE username = 'admin') = 'a', SLEEP(10), NULL) -- '\n</code></pre> <p>If the first character of the admin's password is 'a', the database will pause for 10 seconds, indicating to the attacker that they guessed correctly.</p>"},{"location":"security/tokenurl/","title":"Token in URL","text":"<p>A token in a URL vulnerability refers to a security risk that arises when sensitive information, such as authentication tokens, session identifiers, or other confidential data, is included in a URL. This practice can lead to several security issues due to the way URLs are handled and transmitted over the internet.</p> <p>URLs are often stored in the browser's history. If a URL contains sensitive tokens, they could be exposed to anyone with access to the user's browser history. When a user clicks on a hyperlink, the browser typically sends the Uniform Resource Locator|URL of the current page (which may contain the token) in the HTTP Protocol|HTTP referer header to the target site. This can inadvertently leak the token to third parties.</p> <p>URLs are commonly logged by web servers. If a URL with a token is logged, the token could be exposed in server logs, which might be accessible to unauthorized personnel or could be inadvertently shared. </p> <p>In non-HTTPS Protocol|HTTPS (unencrypted) connections, the entire URL, including the token, can be intercepted by anyone who can snoop on the network traffic. Users often share URLs, not realizing they may be sharing their session or other sensitive information embedded in the URL.</p> <p>Imagine a web application that uses URL parameters for session management, like this:</p> <pre><code>http://example.com/dashboard?token=abc123\n</code></pre> <p>In this scenario, <code>abc123</code> is a session token. If an attacker gains access to this URL (via browser history, network sniffing, server logs, etc.), they could hijack the user's session.</p>"},{"location":"security/tor/","title":"TOR","text":"<p>The Tor network, short for \"The Onion Router,\" is a free and open-source software that enables anonymous communication on the internet. It is designed to protect the privacy and security of its users. </p> <p>Tor's primary purpose is to conceal its users' identities and their online activity from surveillance and traffic analysis. This is achieved by routing internet traffic through a worldwide, volunteer-run network of relays.</p> <p>The name \"Onion Router\" comes from the method Tor uses to encrypt data multiple times, like layers of an onion. Each relay in the network peels away a single layer of encryption, uncovering the data's next destination, but unable to see the original message or its final destination.</p> <p>When you use Tor, your data passes through a random sequence of relays. Each relay knows only the previous and next relay in the sequence, making it extremely difficult to trace the entire path of any piece of data.</p> <p>Tor allows users to bypass internet censorship, access websites that are blocked in their country, and browse the internet without revealing their IP address.</p> <p>Tor is known for facilitating access to the \"dark web,\" a part of the internet not indexed by traditional search engines. It hosts a range of services, from the illicit to the privacy-conscious.</p> <p>While often associated with illegal activities due to its anonymity features, Tor is also used by journalists, whistleblowers, law enforcement officers, and people living under repressive regimes to protect their identity online.</p> <p>Due to the rerouting process, browsing speeds on Tor can be slower compared to a standard internet connection. Using Tor is legal in most countries. However, because of its association with the dark web and illegal activities, some countries may monitor or block its use.</p>"},{"location":"security/totp/","title":"Time-Based One-Time Password (TOTP)","text":"<p>Time-based One-Time Password (TOTP) is a widely used algorithm for generating a One-Time Password (OTP) which is valid for only a short period of time, typically 30 or 60 seconds. TOTPs provide an additional layer of security (often referred to as Multi-Factor Authentication (MFA)|two-factor authentication or 2FA) for online accounts and transactions. They are used to ensure that, in addition to a username and password, access to an account requires a code that changes at fixed time intervals.</p> <p>The TOTP algorithm relies on a shared secret key that is known only to the server and the user's device (like a smartphone running a TOTP app). The OTP is generated using the current time as a moving factor, which ensures that the OTP changes at each time step (e.g., every 30 seconds).</p> <p>The shared secret and the current time are input into a cryptographic hash function (such as SHA-1), and the output is used to generate the OTP. The generated OTP is typically valid for a short period, after which a new OTP is generated based on the updated current time.</p> <p>TOTP is implemented in various authentication apps like Google Authenticator, Authy, and others. These apps generate TOTPs that users enter during the login process to access their online accounts. When setting up TOTP for an account, the user scans a QR code or enters a setup key to synchronize the shared secret key between their app and the server.</p> <p>Each time the user logs in, they must provide the current OTP from their app, along with their regular username and password.</p> <p>Since each OTP is only valid for a short period, even if an OTP is intercepted by an attacker, it quickly becomes useless. TOTPs offer protection against phishing, as the password is constantly changing and known only to the user and the server.</p>"},{"location":"security/trafficint/","title":"Traffic Interception","text":"<p>Traffic interception, also known as traffic interception or Man-in-the-Middle (MitM) attack|man-in-the-middle (MITM) attacks, refers to the unauthorized interception and possible modification of communication between two parties. This type of cyber attack is a significant security concern because it allows an attacker to intercept, read, and potentially alter the data being exchanged.</p> <p>The attacker positions themselves in the communication flow between the sender and the receiver. Without the knowledge of the two legitimate parties, the attacker intercepts the data transfer.</p> <p>Methods of Interception:</p> <ul> <li>ARP Poisoning|ARP Spoofing: Misusing the Address Resolution Protocol (ARP) in a Local Area Networks (LANs)|local area network (LAN) to intercept data.</li> <li>DNS Spoofing: Manipulating the Domain Name System (DNS) to redirect traffic to a malicious site or server.</li> <li>SSL Stripping: Downgrading a secure HTTPS Protocol|HTTP connection to an unencrypted HTTP Protocol|HTTP connection, making it easier to intercept the data.</li> </ul> <p>Potential Impacts:</p> <ul> <li>Eavesdropping: Listening to private conversations or accessing sensitive data.</li> <li>Data Modification: Altering the data in transit, such as injecting malicious content or changing transaction details.</li> <li>Session Hijacking: Taking control of a user session after successfully capturing session tokens.</li> </ul>"},{"location":"security/uinjection/","title":"Union-Based Injection","text":"<p>Union-based SQL injection is a type of in-band SQL injection attack that leverages the UNION queries|UNION SQL operator. This operator is used to combine the results of two or more SELECT statements into a single result set.</p> <p>In the context of a SQL injection attack, the attacker uses the UNION operator to append a malicious SQL query to a legitimate query made by the application.</p> <p>The attacker first identifies input fields in the application that are vulnerable to SQL injection. The attacker then crafts a SQL query that they wish to execute on the database. This query is designed to extract data from the database that the attacker wants to access.</p> <p>The attacker combines their malicious query with the legitimate query using the UNION operator. For the UNION to work, the original query and the injected query must return the same number of columns and compatible data types. This is often achieved through trial and error.</p> <p>The combined query is executed by the database. If successful, the database returns a dataset that includes results from both the legitimate and the injected queries. This result is then sent back to the user within the application's response.</p> <p>Consider a site where the URL is used to query the database for user details:</p> <pre><code>http://example.com/userdetails?id=1\n</code></pre> <p>The SQL query might be:</p> <pre><code>SELECT name, email FROM users WHERE id = 1;\n</code></pre> <p>An attacker can modify the URL to:</p> <pre><code>http://example.com/userdetails?id=1 UNION SELECT username, password FROM admin_users;\n</code></pre> <p>Which would result in a SQL query like:</p> <pre><code>SELECT name, email FROM users WHERE id = 1 UNION SELECT username, password FROM admin_users;\n</code></pre> <p>If the query is executed, it would return data from both the 'users' and 'admin_users' tables.</p>"},{"location":"security/union/","title":"UNION Queries","text":"<p>In the context of web application penetration testing and SQL injection, \"UNION queries\" refer to a specific technique used to extract additional information from a database by combining the results of two or more SELECT statements into a single result. This technique is particularly important in the exploitation of SQL injection vulnerabilities.</p> <p>The UNION SQL operator is used to combine the results of two or more SELECT statements into a single result set. This can be exploited in SQL injection attacks to extract data from different database tables or columns that weren't intended to be displayed.</p> <p>For this to work, each SELECT statement within the UNION must have the same number of columns in the result sets with similar data types.</p> <p>As an example, consider a web application that uses a query like SELECT name, age FROM users WHERE id = [input] to retrieve user information. An attacker could input something like 1 UNION SELECT username, password FROM admin.</p> <p>If the application is vulnerable, this would cause it to return a dataset that combines the intended user information with usernames and passwords from the admin table.</p>"},{"location":"security/varinj/","title":"Environment Variable Injection","text":"<p>Environment Variable Injection is a security vulnerability that occurs when an application inadvertently allows external input to influence or overwrite environment variables. Since environment variables can control the behavior of software and the system, manipulating them can lead to various security issues.</p> <p>This vulnerability arises when an attacker is able to inject or modify environment variables used by a program. It typically happens when user-supplied input is improperly sanitized, allowing the input to alter or define the values of environment variables.</p> <p>Malicious environment variable values can lead to execution of arbitrary code if the application uses these variables to execute system commands. Attackers might change environment variables in a way that escalates their privileges on the system.</p> <p>In a web application, consider a server-side script that sets an environment variable based on query parameters:</p> <pre><code>putenv(\"LANG=\" . $_GET['lang']);\n</code></pre> <p>If <code>$_GET['lang']</code> is not properly Input Sanitization|sanitized, it can be exploited to inject malicious values.</p>"},{"location":"security/viewtamp/","title":"ViewState Tampering","text":"<p>ViewState tampering attacks occur when an attacker modifies the ViewState of an ASP.NET application to exploit the server-side logic of the web application. ViewState, a method for preserving page and control values between postbacks, can be a vector for attack if not properly secured.</p> <p>In ASP.NET, ViewState is used to maintain the state of a web page across postbacks. It's stored in a hidden field and sent back and forth between the client and server. ViewState is Base64-encoded and, optionally, can be encrypted and validated for tampering. If ViewState is not encrypted or lacks proper validation (MAC - Message Authentication Code (MAC)|Message Authentication Code), it can be read and modified by anyone who can intercept the HTTP request.</p> <p>An attacker intercepts the HTTP request and decodes the Base64-encoded ViewState. Suppose the ViewState contains information like user roles or access levels, which are not encrypted or validated for integrity. The attacker modifies the ViewState to elevate their privileges. For example, they could change a value that represents their user role from \"user\" to \"admin\".</p> <p>The attacker then re-encodes the modified ViewState and sends it back to the server as part of a POST request. If the server does not properly validate the ViewState, it accepts the tampered data. The attacker might gain unauthorized access to functionalities or data intended only for higher privilege users, like an admin.</p>"},{"location":"security/vpns/","title":"Virtual Private Network","text":"<p>A virtual private network (VPN) is an Internet security service that allows users to access the Internet as though they were connected to a private network. This encrypts Internet communications as well as providing a strong degree of anonymity.</p> <p>Some of the most common reasons people use VPNs are to protect against snooping on public WiFi, to circumvent Internet censorship, or to connect to a business\u2019s internal network for the purpose of\u00a0remote work.</p> <p></p> <p>Ordinarily, most Internet traffic is unencrypted and very public. When a user creates an Internet connection, such as visiting a website in a browser, the user\u2019s device will connect to their Internet Service Provider (ISP), and then the ISP will connect to the Internet to find the appropriate web server to communicate with to fetch the request website.</p> <p>Information about the user is exposed in every step of the website request. Since the user\u2019s\u00a0IP address\u00a0is exposed throughout the process, the ISP and any other intermediary can keep logs of the user\u2019s browsing habits.</p> <p>Additionally, the data flowing between the user\u2019s device and the web server is unencrypted; this creates opportunities for malicious actors to spy on the data or perpetrate attacks on the user, such as a\u00a0On-Path Attack|on-path attack.</p> <p>Conversely, a user connecting to the Internet using a VPN service has a higher level of security and\u00a0privacy. A VPN connection involves the following 4 steps:</p> <ol> <li>The VPN client connects to the ISP using an encrypted connection.</li> <li>The ISP connects the VPN client to the VPN server, maintaining the encrypted connection.</li> <li>The VPN server decrypts the data from the user\u2019s device and then connects to the Internet to access the web server in an unencrypted communication.</li> <li>The VPN server creates an encrypted connection with the client, known as a \u2018VPN tunnel\u2019.</li> </ol> <p>The VPN tunnel between the VPN client and VPN server passes through the ISP, but since all the data is encrypted, the ISP cannot see the user\u2019s activity. The VPN server\u2019s communications with the Internet are unencrypted, but the web servers will only log the IP address of the VPN server, which gives them no information about the user.</p>"},{"location":"security/waf/","title":"Web Application Firewall (WAF)","text":"<p>WAF or web application\u00a0firewall helps protect web applications by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web applications from attacks such as\u00a0Cross-Site Request Forgery,\u00a0Cross-Site Scripting, Local File Inclusion|file inclusion, and\u00a0SQL injection among others.</p> <p>A WAF is a protocol\u00a0Application Layer|layer 7\u00a0defense (in the\u00a0OSI Model), and is not designed to defend against all types of attacks. This method of attack mitigation is usually part of a suite of tools which together create a holistic defense against a range of attack vectors.</p> <p>By deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine\u2019s identity by using an intermediary, a WAF is a type of\u00a0Reverse Proxy|reverse proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.</p> <p>A WAF operates through a set of rules often called policies. These policies aim to protect against vulnerabilities in the application by filtering out malicious traffic. The value of a WAF comes in part from the speed and ease with which policy modification can be implemented, allowing for faster response to varying attack vectors; during a\u00a0DDoS Attack, rate limiting can be quickly implemented by modifying WAF policies.</p>"},{"location":"security/webcache/","title":"Web Cache Poisoning","text":"<p>Web Cache Poisoning is a security vulnerability in web applications and their caching mechanisms. It involves exploiting the behavior of a web cache to distribute malicious content to users.</p> <p>During web application penetration testing, identifying and exploiting web cache poisoning can reveal how attackers might manipulate cached web content to their advantage.</p> <p>Web caches store copies of web documents (like HTML pages and images) to improve response times for users. They can be located at various points in the network, including browser caches, server-side caches, and CDN (Content Delivery Network) caches.</p> <p>The attacker sends a specially crafted HTTP Protocol|HTTP request to the server. This request includes an anomaly (like a custom header or a manipulated parameter) that the caching mechanism does not properly handle.</p> <p>If the server response to this request is cacheable, the cache stores the malicious response. Subsequent users requesting the same resource receive the poisoned (malicious) content from the cache.</p> <p>Attackers exploit discrepancies between how an application server processes requests and how caches determine what is cacheable. For example, if a web server ignores an unrecognized query parameter but the cache considers it when caching content, this can be exploited to poison the cache.</p> <p>Some impacts of it include:</p> <ul> <li>Content Manipulation: malicious scripts or links could be served to users, leading to Cross-Site Scripting (XSS) attacks or redirecting users to phishing sites.</li> <li>Denial of Service: cache poisoning can be used to make a website unavailable or to serve incorrect content.</li> </ul>"},{"location":"security/webshell/","title":"Web Shell","text":"<p>A web shell is a type of malicious script or program that enables remote administration of a web server. Once uploaded and executed on a web server, a web shell allows an attacker to perform various tasks on the server, typically through a browser interface. It acts as a backdoor, granting the attacker a level of control over the server and its contents.</p> <p>The primary function of a web shell is to provide the attacker with remote management capabilities of the web server, allowing them to execute server commands from a remote location.</p> <p>Web shells are often uploaded to a server as part of another exploit, such as a SQL injection or a file upload vulnerability in a web application. They can be written in any scripting language supported by the server, like PHP, ASP.NET|ASP, JSP, or Perl.</p> <p>Once uploaded, the web shell script presents a user interface (often web-based) that allows the attacker to execute server commands. These commands might include creating, deleting, downloading, or modifying files; accessing databases; launching additional attacks; or even using the server to propagate the attack to other systems.</p> <p>Attackers can steal or manipulate data on the server or connected systems. They can use the server to host illicit content, such as phishing pages or illegal files. Compromised servers can be used as a platform for launching attacks against other targets, including Denial of Service (DoS) Attacks|DDoS attacks.</p> <p>Web shells can be difficult to detect because they often mimic legitimate files and have a small footprint. They might be obfuscated to evade detection by security tools.</p>"},{"location":"security/whitelists/","title":"Whitelists","text":"<p>In web application penetration testing (pentesting), a \"whitelist\" is a security mechanism that permits only predefined and explicitly allowed inputs, actions, or entities, while blocking everything else. Whitelisting is often considered a more secure, albeit more restrictive, approach compared to blacklisting.</p> <p>Whitelists are commonly used for input validation. Web applications compare user inputs against a list of safe characters, strings, or patterns, accepting only those that are explicitly allowed.</p> <p>Unlike Blacklists|blacklisting, which attempts to enumerate all potentially harmful inputs (a near-impossible task), whitelisting ensures that only known-safe inputs are accepted. This reduces the risk of security bypasses due to unforeseen attack vectors.</p> <p>Examples of whitelisting include allowing only alphanumeric characters in a user ID field, permitting specific file types in upload forms, or enabling only certain HTML tags in text inputs.</p> <p>Determining what to include on the whitelist can be challenging, especially in complex applications where the range of legitimate inputs is broad. Overly restrictive whitelists may hinder application usability or functionality.</p> <p>During pentesting, security testers attempt to bypass whitelists to assess their effectiveness. This involves crafting inputs that are technically on the whitelist but used in malicious ways.</p> <p>Whitelisting is most effective when used as part of a layered security strategy, combined with other measures like secure coding practices, regular security reviews, and user education. The effectiveness of a whitelist often depends on its context. For instance, a whitelist in an email system might allow different inputs compared to a whitelist in a content management system.</p> <p>In more advanced implementations, whitelists can be dynamic, adjusting the allowed inputs based on the application's state or user context.</p>"},{"location":"security/wordlist/","title":"Wordlist","text":"<p>A wordlist, in the context of computing and cybersecurity, is essentially a list of words, phrases, or potential passwords. It is often used for various purposes such as password cracking, software testing, and network security.</p> <p>One of the most common uses of wordlists is in password cracking. Attackers or security professionals use wordlists to attempt to guess passwords through methods such as Brute Force Attack|brute force attacks or dictionary attacks. In these attacks, software systematically enters every word in the wordlist as a password to try to gain unauthorized access.</p> <p>Security professionals use wordlists to test the strength of network passwords, identifying weak passwords that are vulnerable to simple dictionary attacks. Developers may use wordlists to test application responses to various inputs, ensuring that the software can handle unexpected or irregular inputs without crashing or behaving insecurely.</p> <p>Wordlists can be used in data analysis or natural language processing to filter, categorize, or analyze text data.</p> <p>They can contain common passwords, phrases, and alphanumeric combinations. Some wordlists are specifically tailored to certain languages, topics, or use cases. Wordlists can vary significantly in size, from thousands to millions of entries. Larger wordlists are more comprehensive but require more time and computing resources to use effectively.</p> <p>Users can create custom wordlists tailored to specific targets or scenarios. For example, a wordlist for cracking corporate passwords might include terms common in the business industry. Many wordlists are freely available for download and use. However, the use of these wordlists for malicious purposes is illegal and unethical.</p> <p>Tools like John the Ripper, Hydra, and Aircrack-ng often use wordlists to assist in password cracking and network security testing.</p>"},{"location":"security/wstg/","title":"OWASP Web Security Testing Guide","text":"<p>The OWASP Web Security Testing Guide (WSTG) is a comprehensive resource for testing the security of web applications and web services. OWASP, which stands for the Open Web Application Security Project, is a nonprofit foundation that works to improve the security of software. </p> <p>One of the standout features of the WSTG is its comprehensive coverage of various security testing aspects. It delves into everything from basic information gathering to more complex areas like authentication, session management, and input validation. This broad scope makes it a valuable tool not just for security professionals, but also for developers and IT personnel looking to understand and improve the security of their web applications.</p> <p>What sets the OWASP WSTG apart is its practical approach. It's not just a theoretical manual; it provides real-world examples and detailed steps for identifying and exploiting security vulnerabilities. This hands-on approach is incredibly useful for understanding the nuances of web security threats like SQL injection, cross-site scripting, and others.</p> <p>A good repository to start testing and to use as a checklist is available here</p>"},{"location":"security/xpathi/","title":"XPath Injection","text":"<p>XPath Injection is a type of cyber attack that targets web applications that use Extensible Markup Language|XML data for input and output. It occurs when a website constructs XPath queries from user-supplied data without proper validation or sanitization.</p> <p>XPath (XML Path Language) is used to query XML documents, and manipulating XPath queries can lead to unauthorized access to data or other malicious activities.</p> <p>XPath Injection is similar to SQL Injection but specifically targets applications that use XPath. Attackers inject malicious XPath expressions into queries, exploiting poorly coded XML data processing.</p> <p>By manipulating XPath queries, an attacker can potentially gain access to unauthorized XML data, retrieve hidden information, or in some cases, even modify the data if the application allows for it.</p> <p>The vulnerability primarily arises from the application's failure to properly validate or sanitize user input before incorporating it into an XPath query. This oversight allows attackers to alter the intended XPath query.</p> <p>An example of vulnerable code is:</p> <pre><code>String xpathQuery = \"/users/user[username/text()='\" + userInput + \"']\";\n</code></pre> <p>In this example, <code>userInput</code> is directly concatenated into the XPath query. If <code>userInput</code> includes malicious XPath code, it can alter the query's behavior.</p>"},{"location":"security/xqueryi/","title":"XQuery Injection","text":"<p>XQuery Injection is a security vulnerability that occurs in applications that use XQuery (Extensible Markup Language|XML Query Language) to interact with XML databases. Similar to SQL Injection, XQuery Injection involves the manipulation of XQuery expressions through unvalidated user input. Attackers exploit this vulnerability to execute malicious queries, access unauthorized data, or compromise the integrity of the database.</p> <p>The vulnerability arises when an application constructs XQuery expressions by concatenating user-supplied input without proper validation or sanitization. Attackers can craft input to alter the intended query, leading to unintended database actions or data exposure.</p> <p>Consider a web application that uses XQuery to fetch user information from an XML database:</p> <pre><code>let $user := request:get-parameter(\"username\")\nlet $query := \"doc('users.xml')/users/user[name=$user]\"\nreturn eval($query)\n</code></pre> <p>If the <code>$user</code> parameter is taken directly from user input without validation, an attacker could inject a payload that alters the query, potentially accessing all user data.</p>"},{"location":"security/xspa/","title":"Cross-Site Port Attack (XSPA)","text":"<p>A Cross-Site Port Attack (XSPA) is a type of network security vulnerability that allows an attacker to exploit the behavior of a web application to conduct port scanning of internal hosts or other external hosts from the victim\u2019s browser. Essentially, it leverages the victim's system to scan and map network ports, which can reveal information about active services and vulnerabilities on those hosts.</p> <p>The attacker identifies a web application that can be used as a proxy for port scanning. This application might be vulnerable due to improper security checks or certain functionalities (like HTTP Protocol|HTTP requests, WebSockets|WebSocket connections, or others) that can be manipulated.</p> <p>The attacker then crafts requests from this application to target internal or external systems. These requests attempt to establish connections to various ports on the specified hosts. Based on the web application\u2019s responses (or lack thereof) to these requests, the attacker can infer which ports are open. For example, a specific error message or a timeout might indicate whether a port is open or closed.</p> <p>By systematically scanning different ports, the attacker can map out the network infrastructure, identifying available services or potentially vulnerable systems.</p> <p>Some examples of XSPA include:</p> <ul> <li>Internal Network Scanning: An attacker uses a vulnerable web application within a corporate network to scan for open ports on internal servers, potentially exposing sensitive services like database management systems, email servers, or administrative interfaces.</li> <li>External Host Scanning: Using a publicly accessible web application to scan ports on external systems, which could be used for gathering intelligence before an attack.</li> </ul>"},{"location":"security/xst/","title":"Cross-Site Tracing (XST)","text":"<p>XST stands for Cross-Site Tracing, a network security vulnerability that combines Cross-Site Scripting (XSS) with the TRACE HTTP Method|HTTP TRACE method. XST exploits the TRACE method supported by some web servers to bypass certain browser security mechanisms.</p> <p>The TRACE method in HTTP is used for diagnostic purposes and echoes back the full request to the client. In an XST attack, the attacker exploits this functionality.</p> <p>Normally, cookies marked as HttpOnly Flag|HttpOnly cannot be accessed via JavaScript, which is a defense mechanism against XSS attacks. However, an XST attack can use the TRACE method to retrieve these <code>HttpOnly</code> cookies. The attacker typically injects a malicious script into a web page (XSS attack), and when the victim visits this page, the script forces their browser to issue a TRACE request to the server.</p> <p>The server\u2019s response to the TRACE request contains the victim's <code>HttpOnly</code> cookies and other header information in the body of the response. The malicious script then captures this information from the response.</p> <p>By obtaining a user's session cookies, an attacker can hijack the user's session, gaining unauthorized access to their account. XST can bypass security mechanisms designed to protect against XSS, making it a significant threat.</p>"},{"location":"security/xxe/","title":"XML External Entities (XXE)","text":"<p>XML external entity injection (also known as XXE) is a web security vulnerability that allows an attacker to interfere with an application's processing of Extensible Markup Language|XML data. It often allows an attacker to view files on the application server filesystem, and to interact with any back-end or external systems that the application itself can access.</p> <p>In some situations, an attacker can escalate an XXE attack to compromise the underlying server or other back-end infrastructure, by leveraging the XXE vulnerability to perform\u00a0server-side request forgery\u00a0(SSRF) attacks.</p> <p>Some applications use the XML format to transmit data between the browser and the server. Applications that do this virtually always use a standard library or platform APIs|API to process the XML data on the server.</p> <p>XXE vulnerabilities arise because the XML specification contains various potentially dangerous features, and standard parsers support these features even if they are not normally used by the application.</p> <p>XML external entities are a type of custom XML entity whose defined values are loaded from outside of the DTD in which they are declared. External entities are particularly interesting from a security perspective because they allow an entity to be defined based on the contents of a file path or Uniform Resource Locator|URL.</p>"},{"location":"terms/acid/","title":"ACID","text":"<p>ACID is an acronym that stands for Atomicity, Consistency, Isolation, and Durability. It is a set of properties that guarantee that database transactions are processed reliably. In the context of database systems, ACID refers to a standard for ensuring the integrity of data despite errors, power failures, and other mishaps.</p> <ol> <li>Atomicity: This property ensures that each transaction is treated as a single \"unit\", which either succeeds completely or fails completely. If any part of a transaction fails, the entire transaction fails and the database state is left unchanged. Essentially, it's an \"all or nothing\" approach.</li> <li>Consistency: Consistency ensures that a transaction brings the database from one valid state to another. Any data written to the database must be valid according to all defined rules, including constraints, cascades, triggers, and any combination thereof.</li> <li>Isolation: This property ensures that the concurrent execution of transactions leaves the database in the same state that would have been obtained if the transactions were executed sequentially. This means that transactions should not interfere with each other and intermediate transaction results should be invisible to other concurrently executed transactions.</li> <li>Durability: Durability guarantees that once a transaction has been committed, it will remain so, even in the event of a power loss, crashes, or errors. In other words, it ensures that completed transactions are saved to the database permanently and are not lost.</li> </ol>"},{"location":"terms/apis/","title":"APIs","text":"<p>API\u00a0stands for application programming interface, and it\u2019s a software intermediary that allows two applications to talk to each other.\u00a0 In other words, an API is the messenger that delivers your request to the provider that you\u2019re requesting it from and then delivers the response back to you.\u00a0</p> <p>An API defines functionalities that are independent of their respective implementations. This allows those implementations and definitions to vary without compromising each other. Therefore, a good API makes it easier to develop a program by providing the building blocks.</p> <p>When developers create code, they don\u2019t often start from scratch thanks to the\u00a0reusability\u00a0of APIs. APIs enable developers to make repetitive yet complex processes highly reusable with a little bit of code. </p> <p>Through\u00a0API reuse, developers can reduce repetitive yet complex processes and dramatically speed up their application development processes.\u00a0Thanks to API reuse, developers don\u2019t have to reinvent the wheel writing code from scratch every time they produce a new program or project.</p> <p>Imagine a waiter in a restaurant. You, the customer, are sitting at the table with a menu of choices to order from, and the kitchen is the provider who will fulfill your order.</p> <p>You need a link to communicate your order to the kitchen and then to deliver your food back to your table. It can\u2019t be the chef because they\u2019re cooking in the kitchen. You need something to connect the customer who\u2019s ordering food and the chef who prepares it. That\u2019s where the waiter - or the API\u00a0- enters the picture.</p> <p>The waiter takes your order, delivers it to the kitchen, telling the kitchen what to do. It then delivers the response, in this case, the food, back to you. Moreover, if the API is designed correctly, hopefully, your order won\u2019t crash!</p>"},{"location":"terms/client/","title":"Client","text":"<p>A \"client\" simply refers to a piece of software or hardware that accesses a service made available by a server. It is essentially a user program that connects to a server to access a service. A web browser like Firefox is a client program that makes use of web server facilities.</p> <p>The client operates within a Client-Server Architecture model, a distributed application structure that partitions tasks or workloads between providers of a resource or service (servers) and service requesters (clients).</p> <ol> <li>Types of Clients:</li> <li>Software Clients: These include web browsers (like Google Chrome, Firefox), email clients (like Outlook), and online chat clients, which interact with servers to access web pages, send and receive emails, or exchange messages, respectively.</li> <li>Hardware Clients: A device that accesses server resources, for example, a computer or a mobile phone connected to a network.</li> </ol> <p>The primary function of a client is to initiate communication with servers for the purpose of accessing services. Clients send requests to servers, which then process these requests and return the appropriate responses.</p> <p>In a network, a client is a machine or software accessing shared network resources provided by a server, like shared files or printers. In the web context, a client is typically a user's web browser which makes requests to web servers on the Internet and displays the web pages that are returned.</p>"},{"location":"terms/containers/","title":"Containers","text":"<p>The industry standard today is to use Virtual Machines (VMs) to run software applications. VMs run applications inside a guest Operating System, which runs on virtual hardware powered by the server\u2019s host OS.</p> <p>VMs are great at providing full process isolation for applications: there are very few ways a problem in the host operating system can affect the software running in the guest operating system, and vice-versa. But this isolation comes at great cost \u2014 the computational overhead spent virtualizing hardware for a guest OS to use is substantial.</p> <p>Containers take a different approach: by leveraging the low-level mechanics of the host operating system, containers provide most of the isolation of virtual machines at a fraction of the computing power.</p> <p>Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of whether the target environment is a private data center, the public cloud, or even a developer\u2019s personal laptop. This gives developers the ability to create predictable environments that are isolated from the rest of the applications and can be run anywhere.</p> <p>From an operations standpoint, apart from portability containers also give more granular control over resources giving your infrastructure improved efficiency which can result in better utilization of your compute resources.</p>"},{"location":"terms/crm/","title":"CRM","text":"<p>Customer Relationship Management (CRM) software is a category of software solutions that helps businesses manage, analyze, and improve their interactions with current and potential customers. At its core, CRM software centralizes customer information, automates marketing interactions, streamlines communication processes, and provides tools for monitoring and analyzing customer engagements.</p> <p>It stores detailed information about customers, including contact information, communication history, preferences, and past interactions with the company. It tracks sales leads, customer inquiries, and sales pipelines. It helps in managing the entire sales process from initial contact to closing a deal.</p> <p>It also automates marketing tasks like email campaigns, social media postings, and targeted advertising. It helps in segmenting customers for personalized marketing efforts and manages customer support requests, service cases, and provides tools for customer service representatives to track and resolve issues.</p> <p>It oOffers analytical tools and dashboards for tracking customer interactions, sales performance, and marketing effectiveness. It helps in making data-driven decisions. CRM systems often integrate with other business tools like email platforms, accounting software, and ERP systems for seamless operations.</p> <p>CRM tools help in delivering personalized communication and service, enhancing customer satisfaction and loyalty. CRM systems can grow with the business, adapting to changing needs and increasing customer bases.</p> <p>Some examples include:</p> <ul> <li>A retail company uses CRM software to manage customer interactions across multiple channels (online, in-store), personalize marketing communications based on purchase history, and provide quick and efficient customer service.</li> <li>A B2B company uses CRM to track leads, manage sales pipelines, and maintain detailed records of client interactions, helping sales representatives understand client needs and timelines.</li> </ul>"},{"location":"terms/crud/","title":"CRUD API","text":"<p>A CRUD API is an interface that allows software applications to interact with a database using four basic operations: Create, Read, Update, and Delete. These operations form the acronym CRUD.</p> <p>Each part is as follows:</p> <ul> <li>Create - allows new data to be added to the database</li> <li>Read - used to retrieve data from the database</li> <li>Update - modifies existing data in the database</li> <li>Delete - removes data from the database.</li> </ul> <p>In the context of an API, they are typically executed over the Internet. The API serves as a middleman between a client and a server where the database is hosted. It uses HTTP Methods to perform these operations such as:</p> <ul> <li>Create - associated with POST</li> <li>Read - associated with GET</li> <li>Update - associated with PUT or PATCH</li> <li>Delete - associated with DELETE method</li> </ul> <p>However, in more modern web apps, the update and delete operations do not use PUT/DELETE but instead use POST to specific endpoints such as POST /posts/1 or POST /posts/1/delete.</p>"},{"location":"terms/csa/","title":"Client-Server Architecture","text":"<p>Client-server architecture is a computing model that segregates the client (or front-end) from the server (or back-end), each performing specific functions within a network. This model is a fundamental concept in networked, distributed computing and forms the backbone of most modern web and business applications.</p> <p>The client and server communicate over a network. The client sends a request to the server, the server processes the request, and then returns a response. This communication is often facilitated by protocols like HTTP for web applications.</p>"},{"location":"terms/dcs/","title":"Distributed Control Systems (DCS)","text":"<p>Distributed Control Systems (DCS) are specialized systems used in industrial environments for controlling complex, large-scale processes. They are particularly common in manufacturing plants, chemical and petrochemical plants, power plants, and other settings where multiple processes need to be controlled in a coordinated way.</p> <p>DCS are designed to distribute control functions across various subsystems, each of which is responsible for managing a specific part of the overall process.</p> <p>Unlike centralized control systems, where a single controller manages the entire process, DCS distribute control across multiple interconnected subsystems. Each subsystem manages a specific part of the process. DCS are engineered for high reliability and uptime, which is crucial in continuous process industries where downtime can be very costly.</p> <p>They can be scaled to accommodate additional processes or increased capacity, making them suitable for large and complex industrial operations. DCS often integrate with other systems like PLCs (Programmable Logic Controllers) and SCADA (Supervisory Control and Data Acquisition) systems for comprehensive process management.</p> <p>DCS typically provide advanced process control features, including complex algorithms for optimizing performance, efficiency, and safety.</p> <p>An example of how they work is as follows:</p> <ul> <li>Controllers: Individual controllers, distributed throughout the plant, are responsible for executing control loops and managing local process points.</li> <li>Central Control: While control is distributed, operators can monitor and control the entire process from a central control room. This setup provides a global view of the process and allows for centralized management when needed.</li> <li>Communication Network: Controllers communicate with each other and with the central control room over a dedicated network. This network is designed for high-speed, reliable communication.</li> </ul> <p>By automating and closely controlling processes, DCS improve the stability and efficiency of industrial operations. They enhance safety by providing consistent, precise control of industrial processes and by implementing safety interlocks and alarms. DCS systems collect and analyze data from the various processes, aiding in optimization and predictive maintenance.</p>"},{"location":"terms/des/","title":"Deserialization","text":"<p>Serialization\u00a0is the process of turning some object into a data format that can be restored later. People often serialize objects in order to save them for storage, or to send as part of communications.</p> <p>Deserialization\u00a0is the reverse of that process, taking data structured in some format, and rebuilding it into an object. Today, the most popular data format for serializing data is JSON. Before that, it was XML.</p> <p>However, many programming languages have native ways to serialize objects. These native formats usually offer more features than JSON or XML, including customizability of the serialization process.</p> <p>Unfortunately, the features of these native deserialization mechanisms can sometimes be repurposed for malicious effect when operating on untrusted data. Attacks against deserializers have been found to allow denial-of-service, access control, or Remote Code Execution (RCE) attacks.</p>"},{"location":"terms/dlls/","title":"DLLs","text":"<p>DLLs, or Dynamic Link Libraries, are modules of executable functions or routines that can be used by Windows applications and services. A DLL can be shared among multiple applications, providing a way to modularize code for efficiency and reusability. In the context of penetration testing and hacking, DLLs present both opportunities and vulnerabilities.</p> <p>DLLs contain code that different programs can use simultaneously. Rather than having the same code in each program, a shared DLL can provide this functionality. Programs can use the functions and routines in a DLL as needed during runtime, which is known as dynamic linking. Windows operating systems come with numerous DLLs that provide essential functions, from basic file operations to network communication.</p> <p>If an application improperly specifies the path to a DLL, an attacker can place a malicious DLL with the same name in a location that the application searches before the legitimate path. When the application runs, it loads the attacker\u2019s DLL, executing malicious code - known as DLL Hijacking.</p> <p>DLL Injection involves injecting a DLL into a legitimate process's memory space. The injected DLL can then execute within the context of the process's permissions, potentially enabling privilege escalation or bypassing security controls.</p> <p>You can also modify an existing DLL to include malicious code, which will be executed whenever the DLL is loaded by an application. Some applications might be vulnerable to attacks that manipulate the loading and unloading of DLLs, leading to crashes, code execution, or privilege escalation.</p> <p>You can also place a malicious DLL in a location from which a legitimate application loads additional components, leading to the execution of the malicious DLL.</p> <p>Some examples include:</p> <ul> <li>DLL Hijacking: A penetration tester discovers that a third-party application does not specify the full path for a DLL it loads. The tester places a malicious DLL with the expected name in a directory that is searched before the legitimate DLL directory, leading to the execution of the tester\u2019s code.</li> <li>DLL Injection: During a red team exercise, a tester injects a DLL into a process running with higher privileges. This DLL opens a backdoor, allowing the tester to access restricted areas of the network.</li> </ul> <p>Info</p> <p>To defend against DLL-related attacks, it's important to use safe coding practices, regularly update applications and systems, monitor process behavior for unusual activity, and implement application whitelisting.</p>"},{"location":"terms/edge/","title":"Edge Computing","text":"<p>Edge computing refers to a distributed computing paradigm that brings computation and data storage closer to the location where it is needed, to improve response times and save bandwidth. It represents a shift from traditional centralized and cloud-based systems to decentralized processing at the edge of the network.</p> <p>In edge computing, data processing occurs near the source of data generation (like IoT devices or local edge servers), rather than being transmitted to a distant, centralized data center or cloud.</p> <p>By processing data locally, edge computing reduces latency, or the delay before a transfer of data begins following an instruction. This is crucial for real-time applications like autonomous vehicles, industrial automation, and smart cities.</p> <p>It minimizes the need to send large volumes of data over the network, reducing bandwidth usage and associated costs. Processing data locally can enhance privacy and security, as sensitive data doesn\u2019t need to traverse over the network to a remote server.</p> <p>Edge computing allows organizations to scale their computing resources by adding more edge devices, rather than expanding central data centers. It is ideal for situations where real-time data processing and decision-making are critical, such as in emergency response systems or on-site medical diagnostics.</p> <p>Edge computing is particularly significant in the IoT ecosystem. With billions of devices connected, sending all data to the cloud for processing is impractical due to latency and bandwidth considerations.</p> <p>Edge computing can provide more resilience in case of network issues, as local processing ensures functionality even with intermittent cloud connectivity. Common applications include smart grid control, traffic management systems, agricultural sensors, retail analytics, and augmented reality (AR) experiences.</p> <p>Edge computing complements cloud computing; it doesn\u2019t replace it. Many architectures use edge computing for immediate processing, while the cloud is used for longer-term storage and analysis. Additionally, edge computing can leverage AI and machine learning algorithms for faster processing and analytics.</p>"},{"location":"terms/hostname/","title":"Hostname","text":"<p>A hostname is essentially a label assigned to a device connected to a computer network. It's used to identify the device in various forms such as the Internet, within local networks or in software systems. Hostnames are part of the Fully Qualified Domain Name (FQDN) which uniquely identifies a device on the network.</p>"},{"location":"terms/hypervisors/","title":"Hypervisors","text":"<p>A hypervisor is a software that you can use to run multiple virtual machines on a single physical machine. Every virtual machine has its own operating system and applications. The hypervisor allocates the underlying physical computing resources such as CPU and memory to individual virtual machines as required. Thus, it supports the optimal use of physical IT infrastructure.</p> <p>Hypervisors are the underlying technology behind virtualization or the decoupling of hardware from software. IT administrators can create multiple virtual machines on a single host machine. </p> <p>Each virtual machine has its own operating system and hardware resources such as a CPU, a graphics accelerator, and storage. You can install software applications on a virtual machine, just like you do on a physical computer.</p> <p>The fundamentals of virtual machines and other virtualization technologies have enabled cloud computing services in enterprise applications. They allow you to scale computing services efficiently on limited hardware infrastructure. </p> <p>For example, different business departments can run different workloads separately by using multiple virtual machines on a single server.</p>"},{"location":"terms/iiot/","title":"Industrial IoT (IIoT)","text":"<p>Industrial Internet of Things (IIoT) refers to the application of the Internet of Things (IoT) technologies in industrial sectors and applications. It involves the use of smart sensors, advanced connectivity, and big data analytics to improve operational efficiency, productivity, and performance in industrial settings.</p> <p>IIoT uses intelligent machines and sensors to gather detailed and precise data in real-time from industrial operations. This data can include information about the performance, efficiency, and health of machines.</p> <p>IIoT devices are interconnected, often using wireless technologies, allowing for seamless communication and data exchange between machines and systems.</p> <p>The data collected by IIoT devices are analyzed, often in real-time, to monitor performance, predict maintenance needs, and identify inefficiencies. This analysis can lead to actionable insights to optimize processes.</p> <p>IIoT enables predictive maintenance, where machinery is maintained based on data-driven indicators of wear or failure, reducing downtime and maintenance costs.</p> <p>By automating and optimizing processes, IIoT can significantly increase operational efficiency and productivity in industrial settings. IIoT is used in manufacturing, supply chain logistics, energy management, mining, oil and gas, agriculture, and other industrial sectors.</p> <p>In the manufacturing sector, IIoT is a key component of smart factories, where it enables automation, real-time monitoring, and optimization of manufacturing processes.</p> <p>IIoT integrates with enterprise systems like ERP (Enterprise Resource Planning) and SCM (Supply Chain Management) to provide a holistic view of operations and support better decision-making.</p> <p>As industrial systems are increasingly connected, they become more vulnerable to cyberattacks. Hence, robust cybersecurity measures are essential in IIoT environments.</p> <p>To process data efficiently, IIoT often relies on Edge Computing, which processes data near the source of data generation, reducing latency and reliance on constant cloud connectivity.</p> <p>IIoT is a cornerstone of Industry 4.0, which represents the ongoing automation and data exchange in manufacturing technologies, including cyber-physical systems, cloud computing, and cognitive computing.</p>"},{"location":"terms/impact/","title":"Impact","text":"<p>In cybersecurity, \"impact\" refers to the consequences or effects of a cyber incident or breach on an organization, individual, system, or network. The impact of a cybersecurity event can vary widely based on several factors, including the nature of the incident, the sensitivity of the affected data, and the preparedness of the organization. </p>"},{"location":"terms/iot/","title":"IoT","text":"<p>The Internet of Things (IoT) refers to the network of physical objects - \"things\" - that are embedded with sensors, software, and other technologies for the purpose of connecting and exchanging data with other devices and systems over the internet. These devices range from ordinary household items to sophisticated industrial tools.</p> <p>IoT devices are often equipped with sensors that can collect and send data over the internet. These sensors can detect various environmental factors like temperature, motion, light, etc. </p> <p>Devices in an IoT ecosystem are connected to the internet, allowing them to send and receive data. This connectivity can be via Wi-Fi, Bluetooth, cellular networks, or other means.</p> <p>The data collected by IoT devices can be stored and analyzed to extract useful information. This processing can happen on the device itself (Edge Computing) or in a centralized cloud-based service.</p> <p>IoT enables the automation of daily tasks and processes. Devices can be programmed to make decisions and perform actions based on the data they collect.</p> <p>IoT has a wide range of applications, including smart home devices (like smart thermostats and lights), wearables (like fitness trackers), smart cities (traffic control, waste management), healthcare (patient monitoring), agriculture (crop monitoring), and Industrial IoT (IIoT) for manufacturing and supply chain management.</p> <p>With the increasing number of connected devices, security and privacy issues are a major concern. Ensuring the security of IoT devices and the data they handle is critical. IoT allows for the real-time monitoring and management of systems and environments, which is particularly valuable in industrial and urban settings.</p> <p>Many IoT applications focus on increasing energy efficiency, whether it's through smart grids in urban areas or optimized machinery in industrial settings.</p>"},{"location":"terms/likelihood/","title":"Likelihood","text":"<p>In cybersecurity, \"likelihood\" refers to the probability or chance that a potential cybersecurity threat will successfully exploit a vulnerability in a system or network. It is a key component in assessing and managing cybersecurity risk, which is often quantified as the product of likelihood and impact.</p>"},{"location":"terms/proxy/","title":"Proxy","text":"<p>A proxy server acts as a gateway between you and the internet. It\u2019s an intermediary Server separating end users from the websites they browse. Proxy servers provide varying levels of functionality, security, and privacy depending on your use case, needs, or company policy.</p> <p>If you\u2019re using a proxy server, internet traffic flows through the proxy server on its way to the address you requested. The request then comes back through that same proxy server (there are exceptions to this rule), and then the proxy server forwards the data received from the website to you.</p> <p>Modern proxy servers do much more than forwarding web requests, all in the name of data security and network performance. Proxy servers act as a firewall and web filter, provide shared network connections, and cache data to speed up common requests. </p> <p>A good proxy server keeps users and the internal network protected from the bad stuff that lives out in the wild internet. Lastly, proxy servers can provide a high level of privacy.</p> <p>A proxy server is basically a computer on the internet with its own IP address that your computer knows. When you send a web request, your request goes to the proxy server first. The proxy server then makes your web request on your behalf, collects the response from the web server, and forwards you the web page data so you can see the page in your browser.</p> <p>When the proxy server forwards your web requests, it can make changes to the data you send and still get you the information that you expect to see. A proxy server can change your IP address, so the web server doesn\u2019t know exactly where you are in the world. It can encrypt your data, so your data is unreadable in transit. And lastly, a proxy server can block access to certain web pages, based on IP address.</p>"},{"location":"terms/revprox/","title":"Reverse Proxy","text":"<p>A reverse proxy does the exact opposite of what a forward proxy does. While a forward proxy proxies on behalf of clients (or requesting hosts), a reverse proxy proxies on behalf of servers. A reverse proxy accepts requests from external clients on behalf of servers stationed behind it as shown below.</p> <p></p> <p>In the example above, the reverse proxy is providing file transfer services. The client is oblivious to the file transfer servers behind the proxy, which are actually providing those services. In effect, where a forward proxy hides the identities of clients, a reverse proxy hides the identities of servers.</p> <p>An Internet-based attacker would find it considerably more difficult to acquire data found in those file transfer servers than if he didn't have to deal with a reverse proxy.</p> <p>Just like forward proxy servers, reverse proxies also provide a single point of access and control. You typically set it up to work alongside one or two firewalls to control traffic and requests directed to your internal servers.</p> <p>In most cases, reverse proxy servers also act as load balancers for the servers behind them. Load balancers play a crucial role in providing high availability to network services that receive large volumes of requests. When a reverse proxy performs load balancing, it distributes incoming requests to a cluster of servers, all providing the same kind of service. </p> <p>Both types of proxy servers relay requests and responses between clients and destination machines. But in the case of reverse proxy servers, client requests that go through them normally originate over TCP/IP connections, while, in the case of forward proxies, client requests normally come from the internal network behind them.</p>"},{"location":"terms/risk/","title":"Risk","text":"<p>In the context of cybersecurity and web app hacking, \"risk\" refers to the potential for loss, damage, or undesirable outcomes resulting from threats exploiting vulnerabilities in a system.</p> <p>Cybersecurity risk is the probability of exposure or loss resulting from a cyber attack or data breach on your organization. A better, more encompassing definition is the potential loss or harm related to technical infrastructure, use of technology or reputation of an organization.</p> <p>It combines various things including:</p> <ul> <li>Threats - These are actors or events that can potentially cause harm. In cybersecurity, threats can be hackers, malware, or any other method or tool used to exploit vulnerabilities.</li> <li>Vulnerabilities - These are weaknesses in a system that can be exploited by threats. In web apps, vulnerabilities might include flaws in code, insecure database connections, or insufficient authentication procedures.</li> <li>Impact - This is the consequence of a threat exploiting a vulnerability. The impact can range from minor issues, like a slight slowdown in web app performance, to major problems like data breaches, financial loss, or damage to an organization's reputation.</li> <li>Likelihood - This is the probability of a threat successfully exploiting a vulnerability. Factors influencing likelihood include the complexity of the vulnerability, the skill level of the threat actor, and the effectiveness of existing security measures.</li> </ul> <p>Risk in cybersecurity is often expressed as a function of the impact and likelihood of a threat exploiting a vulnerability. It's a measure of the potential harm that could occur due to security weaknesses. Managing risk involves identifying and assessing these elements, and then implementing measures to mitigate them, such as improving security protocols, patching vulnerabilities, and educating users about safe practices.</p>"},{"location":"terms/server/","title":"Server","text":"<p>A server in computing is a powerful computer or system of computers that provides resources, data, services, or programs to other computers, known as clients, over a network. In essence, servers are dedicated to managing network resources and offering various functionalities to client devices. </p> <p>The device that makes the request, and receives a response from the server, is called a client. On the Internet, the term \"server\" commonly refers to the computer system that receives requests for a web files and sends those files to the client.</p> <p>They can be physical machines or virtual servers hosted in cloud environments. The functions and types of servers can vary widely, including:</p> <ol> <li>Web Server: Hosts websites, delivering web pages to users' browsers via HTTP or HTTPS protocols.</li> <li>File Server: Stores and manages files, allowing users to save and retrieve files over the network.</li> <li>Mail Server: Manages and transmits emails over a network, including storing incoming mail for local users.</li> <li>Database Server: Provides database services, storing, retrieving, and managing large amounts of data.</li> <li>Application Server: Hosts and runs specific software applications.</li> <li>Print Server: Manages one or more printers and accepts print jobs from the computers on the network.</li> <li>Game Server: Hosts multiplayer online games, connecting players and managing game state.</li> <li>Domain Name System (DNS) Server: Translates domain names into IP addresses, guiding internet navigation.</li> <li>Virtual Server: Software-based servers that emulate physical servers, often used in virtualized environments for better resource utilization.</li> <li>Cloud Server: Hosted in cloud computing environments, providing scalable and on-demand computing resources.</li> </ol>"},{"location":"terms/threats/","title":"Threats","text":"<p>In cybersecurity, threats refer to any potential danger that could exploit Vulnerabilities to cause harm to a digital system or network. These threats can come from various sources and take different forms. Understanding these threats is crucial for implementing effective security measures.</p>"},{"location":"terms/vulns/","title":"Vulnerabilities","text":"<p>In the context of cybersecurity, vulnerabilities refer to weaknesses or flaws in a system that can be exploited by cyber threats to gain unauthorized access, cause damage, or perform other malicious activities. These vulnerabilities can exist in various components of an IT infrastructure, including software, hardware, and network systems.</p> <p>Understanding and managing these vulnerabilities is crucial for maintaining the security of digital assets.</p>"},{"location":"tools/aircrack-ng/","title":"Aircrack-ng","text":"<p>Aircrack-ng is a network software suite consisting of a detector, packet sniffer, WEP and WPA/WPA2-PSK cracker, and analysis tool for 802.11 wireless LANs. It works with any wireless network interface controller whose driver supports raw monitoring mode and can sniff 802.11a, 802.11b, and 802.11g traffic.</p> <p>The primary use of Aircrack-ng is to crack WEP and WPA/WPA2-PSK keys. It implements standard FMS attacks along with some optimizations like KoreK attacks, as well as the PTW attack to make its attacks more potent.</p> <p>Aircrack-ng can capture network packets and then analyze them to recover wireless keys. It is capable of capturing packets that are not encrypted, as well as those encrypted with WEP, WPA, or WPA2.</p> <p>Beyond cracking, Aircrack-ng can be used for network auditing. It can test network security, detect network connections, and devices, and assess the performance and strength of a network. Aircrack-ng suite includes several tools - <code>airmon-ng</code> (puts your card into monitor mode), <code>airodump-ng</code> (packet capturing), <code>aireplay-ng</code> (packet injection), <code>aircrack-ng</code> (WEP and WPA/WPA2 cracking), and others.</p> <p>For WEP, Aircrack-ng uses statistical attacks to deduce the encryption key. The time it takes to crack WEP keys can vary depending on the number of network packets captured. Cracking WPA and WPA2 requires a different approach. It usually involves capturing a handshake process between a client and an access point and then performing a brute-force attack or dictionary attack to guess the passphrase.</p>"},{"location":"tools/anarchy/","title":"Username Anarchy","text":"<p>\"Username Anarchy\" is a tool designed for generating username lists for use in penetration testing, particularly in situations where usernames need to be guessed, such as during brute-force login attempts. The tool generates usernames based on a set of rules and patterns that mimic common username conventions in various organizations and systems.</p> <p>Given a list of full names, Username Anarchy can generate potential usernames by applying common username schemas, like using the first letter of the first name combined with the last name (e.g., <code>jdoe</code> for John Doe). It can create variations by including initials, numbers, or common separators (like dots or underscores).</p> <p>Users can customize the generation process to align with specific username patterns they expect in the target environment.</p> <p>Suppose you have a list of employee names from a company, and you want to generate possible usernames for a penetration testing exercise. The list might include names like:</p> <ul> <li>Jane Smith</li> <li>John Doe</li> <li>Emily Johnson</li> </ul> <p>You would use Username Anarchy to process this list and generate a range of potential usernames. For example:</p> <pre><code>username_anarchy -n \"Jane Smith John Doe Emily Johnson\"\n</code></pre> <p>This might result in the following:</p> <pre><code>jsmith\njdoe\nejohnson\njanes\njohn.doe\nemilyj\nsmithj\ndoej\njohnsone\n</code></pre>"},{"location":"tools/aquatone/","title":"Aquatone","text":"<p>Aquatone is a tool used in cybersecurity, specifically in the field of reconnaissance and information gathering. It is primarily designed for penetration testers and security researchers to collect various kinds of information about a domain.</p> <p>Aquatone is a tool for visual inspection of websites across a large amount of hosts and is convenient for quickly gaining an overview of HTTP-based attack surface.</p> <p>It allows users to discover domains and subdomains of a target organization. It uses various OSINT sources and techniques to find as many domains as possible.</p> <p>One notable feature is its ability to take screenshots of websites which is useful for quickly visualizing the web services running on different domains and subdomains discovered during the reconnaissance phase.</p> <p>It can also perform port scanning to identify open ports on target servers. It can also gather information about the technologies used on web servers, such as web server software, content management systems and other technologies, similiar to things like Wappalyzer or WhatWeb.</p>"},{"location":"tools/autoruns/","title":"Autoruns","text":"<p>Autoruns is a utility in the Microsoft Sysinternals Suite that comprehensively lists all programs and services configured to run automatically on a Windows system. This tool is incredibly detailed, showing auto-starting locations that traditional task managers and other utilities often miss.</p> <p>Autoruns reveals all programs, drivers, services, shell extensions, codecs, scheduled tasks, and other software automatically launched at startup or login. Users can filter out standard Windows entries to focus on third-party auto-starting images, making it easier to spot potentially unwanted or malicious software. For each entry, Autoruns shows the associated registry or file path, helping in identifying where each auto-start item is configured.</p> <p>Malware often establishes persistence by placing itself in startup locations. Autoruns can help identify these entries, which might be indicators of compromise. During incident response, Autoruns can be used to find and remove unauthorized auto-start configurations that might be part of a malware's persistence mechanism.</p> <p>Attackers or penetration testers can use Autoruns to understand all programs running on a system automatically, helping in mapping out the environment and identifying targets for further exploitation. Attackers might use knowledge gained from Autoruns to place their malware in less commonly monitored auto-start locations, potentially evading detection by security software.</p>"},{"location":"tools/bashfu/","title":"Bashfuscator","text":"<p>Bashfuscator is a tool designed for obfuscating Bash shell scripts. Its primary function is to make Bash scripts more difficult to understand or analyze. This is typically used for a variety of purposes, such as:</p> <ol> <li>Security Through Obscurity: Some developers use obfuscation to hide the workings of their scripts from potential attackers. This can add an extra layer of security, although it's important to note that obfuscation alone is not a robust security measure.</li> <li>Anti-Tampering: In some cases, scripts are obfuscated to prevent unauthorized modifications or tampering.</li> <li>Intellectual Property Protection: Developers may also use obfuscation to protect their proprietary code or intellectual property.</li> </ol> <p>Bashfuscator achieves obfuscation by using various techniques to transform the script's original code into a form that is functionally identical but much harder to read and understand. This might include encoding, complex control flow alterations, and other transformations that make the script's logic less clear.</p> <p>Bashfuscator can indeed be used for bypassing certain types of command injection filters, a practice often associated with security testing or malicious activities. </p> <p>Command injection is a security vulnerability that allows an attacker to execute arbitrary commands on a system. This usually occurs in a situation where user input is improperly sanitized before being passed to a shell command in a script or program.</p>"},{"location":"tools/between/","title":"Between","text":"<p>The \"between\" tamper script in SQLmap is a part of SQLmap's suite of tamper scripts, which are used to modify SQL queries in order to bypass web application firewalls (WAFs) or other security measures that might block malicious SQL injection.</p> <p>The \"between\" tamper script modifies the numeric payloads by changing the comparison operator in the SQL query. Instead of a direct comparison (like <code>id = 1</code>), it uses the <code>BETWEEN</code> operator to make the condition true. </p> <p>For example, <code>id = 1</code> might be changed to <code>id BETWEEN 1 AND 1</code>. This alteration can sometimes bypass filters or security rules that are looking for specific patterns in SQL queries.</p> <p>SQLmap is primarily used for automating the process of detecting and exploiting SQL injection flaws in web applications. SQL injection is a type of attack that allows an attacker to interfere with the queries that an application makes to its database.</p> <p>Some web application firewalls are configured to detect and block common SQL injection patterns. Tamper scripts like \"between\" are designed to alter these patterns in a way that might not be recognized by the security filters, allowing the SQL injection to proceed undetected.</p> <p>Tamper scripts in SQLmap are used as command-line options. You can specify one or more tamper script names to be used during the attack process. These scripts are modular and can be combined to form more complex tampering strategies.</p>"},{"location":"tools/bginfo/","title":"BgInfo","text":"<p>BgInfo, part of the Sysinternals Suite by Microsoft, is a utility that displays system configuration information on the Windows desktop background. It is primarily used for administrative purposes rather than for hacking or penetration testing.</p> <p>BgInfo can show various system details such as IP address, system name, logged-in user, operating system version, CPU, memory, and network information on the desktop background. Users can configure which pieces of information are displayed and customize the appearance (location, font, color, etc.) on the desktop.</p> <p>If a penetration tester gains access to a system where BgInfo is running, the displayed information can quickly provide valuable insights about the system's configuration, network settings, and user details.</p> <p>In an internal penetration test, understanding the configuration of various systems within an organization can help in identifying potential targets and vulnerabilities. BgInfo can expedite this process by making key system information readily visible. Knowledge about system configurations, obtained via tools like BgInfo, can aid in crafting more convincing social engineering attacks.</p>"},{"location":"tools/bloodhound/","title":"Bloodhound","text":"<p>BloodHound is a powerful tool used in cybersecurity, particularly in the fields of penetration testing and red teaming. Developed to reveal the hidden and often unintended relationships within an Active Directory (AD) environment, BloodHound uses graph theory to uncover various paths an attacker could take to gain escalated privileges within an AD domain.</p> <p>BloodHound graphically represents the relationships and trust permissions in an AD environment, illustrating potential attack paths to high-value targets like domain administrators or critical servers.</p> <p>It can identify complex chains of relationships that could be exploited for privilege escalation, such as which users have admin rights to which machines, and how these can be leveraged to compromise other accounts or machines. BloodHound queries AD to gather information about users, groups, and other objects, including their permissions and relationships.</p> <p>BloodHound can pinpoint users who have more access rights than they should, helping to minimize the risk by reconfiguring these permissions. By revealing indirect relationships and unintended trust permissions, BloodHound helps organizations identify and fix security weaknesses in their AD setup.</p> <p>During a security incident, BloodHound can be used to quickly assess how an attacker might have moved laterally or escalated privileges within the network. In ethical hacking, BloodHound is used to simulate attacks, helping testers understand how an attacker might navigate a network and where defenses could be improved.</p> <p>An example of how it helps:</p> <ul> <li>A penetration tester uses BloodHound to discover that a low-level employee's account has indirect administrative access to a critical server, highlighting a major security risk. </li> <li>An IT security team uses BloodHound to visualize all potential paths an attacker could take to gain domain admin privileges, helping them to understand and mitigate these risks.</li> <li>After a security breach, BloodHound helps in tracing the attacker's likely movements within the network, contributing valuable insights for strengthening security postures.</li> </ul>"},{"location":"tools/bsh/","title":"b374k Shell","text":"<p>The b374k shell is a PHP web shell or backdoor script widely used by attackers to gain unauthorized access to web servers. It's a piece of malicious code or script that can be uploaded to a vulnerable web server to give the attacker a variety of controls over the server. Web shells like b374k are typically used by cybercriminals and are a common tool in the arsenal of hackers engaging in web server exploitation.</p> <p>It allows the execution of shell commands directly from the web interface, giving attackers the same level of access as the server's legitimate user. It provides functionalities to upload, delete, download, and edit files on the server, effectively giving attackers control over the server's file system.</p> <p>It can be used to manage databases, allowing attackers to execute SQL queries, view database data, and even modify or delete databases. b374k includes features to bypass certain security measures, making detection and prevention more challenging.</p>"},{"location":"tools/burpsuite/","title":"Burp Suite","text":"<p>Burp Suite\u00a0is a proxy program that enables us to track, examine, and alter requests made by our browsers before they are forwarded to a distant server.</p> <p>Burp Suite\u00a0is a prominent web application security solution. It gives us the ability to manually test for vulnerabilities, intercepts HTTP messages, and change a message's body and header.</p> <p>It is the most widely used tool among experts in online app security and bug bounty hunters. It is a better option than free substitutes like\u00a0OWASP ZAP\u00a0because of how simple it is to use. The community edition of Burp Suite is accessible for free, whereas the professional edition and the enterprise edition need payment.</p>"},{"location":"tools/cat/","title":"Hashcat","text":"<p>Hashcat is a powerful and widely-used password recovery tool that supports a wide array of hashing algorithms. It's designed for both brute-force and dictionary-based attacks, allowing for the recovery of hashed passwords. </p> <p>Hashcat is notable for its speed and efficiency, particularly when leveraging the processing power of GPUs (Graphics Processing Units).</p> <p>Hashcat supports a vast range of hashing algorithms, including popular ones like MD5, SHA-1, SHA-256, NTLM, and many others. One of the most significant advantages of Hashcat is its ability to use the power of GPUs, which greatly increases the speed of password cracking compared to CPU-only cracking.</p> <p>Hashcat supports various modes of operation, including brute-force attack, combinator attack, dictionary attack, hybrid attack (combining dictionary and brute-force methods), and more. Hashcat offers features like rule-based attack, which allows for complex password cracking strategies, and mask attack, for customizing brute-force attack patterns.</p> <p>A basic example of using Hashcat for cracking a password might involve:</p> <ol> <li>Identifying the Hash Type: Determine the type of hash algorithm used for the password (e.g., MD5, SHA-256).</li> <li>Setting Up Hashcat: Configure Hashcat with the identified hash type and choose the attack mode (e.g., brute-force, dictionary).</li> <li>Running Hashcat: Execute Hashcat against the hashed passwords. For a dictionary attack, you would also specify the path to your wordlist.</li> </ol> <pre><code>hashcat -m [hash type] [hash file] -a [attack mode] [wordlist]\n</code></pre>"},{"location":"tools/cmd/","title":"Windows Command Line (CMD)","text":"<p>The Windows Command Line, often referred to as Command Prompt or cmd.exe, is a command-line interface in Microsoft Windows operating systems. It provides a way to execute commands and perform various tasks through textual input and output, as opposed to using a graphical user interface (GUI).</p> <p>The Command Prompt is a text-based interface where users type commands and receive text-based output. It is used for executing system commands, running scripts, and managing files and services.</p> <p>The Command Line uses specific syntax for commands. Common commands include <code>dir</code> (to list files in a directory), <code>cd</code> (to change directories), <code>copy</code> (to copy files), and <code>del</code> (to delete files), among others.</p> <p>Users can write batch files (.bat or .cmd files), which are scripts of multiple commands that run sequentially. Batch files are used for automating repetitive tasks. The Command Line is a powerful tool for system administration. It provides commands for managing system resources, configuring network settings, performing diagnostics, and troubleshooting.</p> <p>In addition to the traditional Command Prompt, Windows also offers PowerShell, a more powerful command-line shell and scripting language. PowerShell extends the capabilities of the Command Line with more complex operations and scripting.</p>"},{"location":"tools/cme/","title":"CrackMapExec","text":"<p>CrackMapExec (CME) is a versatile tool for penetration testers and cybersecurity professionals, designed to facilitate the assessment and exploitation of large Active Directory networks. Developed in Python, CrackMapExec automates the exploitation of common vulnerabilities in Windows environments, streamlining the process of post-exploitation and network reconnaissance.</p> <p>CME can be used to gather information about Windows machines on a network, including OS details, hostname, domain information, and [SMB] shares. It can test the validity of credentials across a network, helping identify machines where a given set of credentials is valid.</p> <p>CME supports pass-the-hash attacks and token impersonation, allowing penetration testers to leverage compromised credentials or tokens to access other network resources. It can execute commands or Windows PowerShell scripts remotely on Windows machines. CrackMapExec is modular, allowing for the easy integration of additional functionalities through its module system.</p> <p>Some examples of its usage include enumerating SMB shares:</p> <pre><code>crackmapexec smb &lt;TARGET_IP&gt; --shares\n</code></pre> <p>Validating credentials:</p> <pre><code>crackmapexec smb &lt;TARGET_IP_RANGE&gt; -u &lt;USERNAME&gt; -p &lt;PASSWORD&gt;\n</code></pre> <p>Executing commands:</p> <pre><code>crackmapexec smb &lt;TARGET_IP&gt; -u &lt;USERNAME&gt; -p &lt;PASSWORD&gt; -x 'whoami'\n</code></pre> <p>Pass-The-Hash attack:</p> <pre><code>crackmapexec smb &lt;TARGET_IP_RANGE&gt; -u &lt;USERNAME&gt; -H &lt;NTLM_HASH&gt;\n</code></pre>"},{"location":"tools/collab/","title":"Burp Collaborator","text":"<p>Burp Collaborator is a feature in the Burp Suite, a popular web application security testing tool. Burp Collaborator is designed to assist security professionals and penetration testers in identifying and exploiting security vulnerabilities in web applications. </p> <p>Burp Collaborator facilitates out-of-band interaction with external systems during web application testing. It helps testers identify interactions initiated by the target application that may not be directly visible in the application's responses. </p> <p>Some security vulnerabilities, such as blind SQL injection, may not directly expose results in the application's responses. Burp Collaborator helps in detecting these blind vulnerabilities by establishing connections to a unique external server controlled by the tester.</p> <p>Burp Collaborator uses both DNS interactions and HTTP interactions to communicate with its external server. DNS interactions involve subdomains, while HTTP interactions may include making HTTP requests to a unique domain or IP address controlled by Burp Collaborator.</p> <p>Burp Collaborator is integrated with various tools within the Burp Suite, such as the Scanner, Intruder, and Repeater. This integration allows testers to leverage the Collaborator's capabilities during different phases of the testing process.</p> <p>Burp Collaborator can be set to automatically interact with the target application during various testing activities. Additionally, testers can manually initiate interactions to gather specific information. Burp Collaborator helps in detecting potential data exfiltration channels by monitoring the interactions initiated by the target application.</p> <p>Burp Collaborator provides detailed logs and documentation of interactions, allowing testers to analyze and understand the communication patterns between the target application and external systems.</p>"},{"location":"tools/compare/","title":"Burp Comparer","text":"<p>Burp Comparer is a tool provided as part of the Burp Suite, which is a popular integrated platform for performing security testing of web applications. Burp Comparer is specifically designed to help users compare and analyze different types of data encountered during testing.</p> <p>Burp Comparer allows you to compare two pieces of data, which can be useful in various testing scenarios. For instance, you can compare server responses, requests, or other data captured during your testing process. The tool displays data side-by-side or in a combined view, making it easier to spot differences. This is particularly helpful for understanding how small changes in requests can lead to different responses from the server.</p> <p>It can compare textual data (like HTML, JSON, XML) and binary data (like images or binary files). This flexibility is useful in a wide range of testing scenarios. Differences between the two data sets are highlighted, allowing for quick identification of disparities. This feature is essential for tasks like pinpointing the cause of vulnerabilities or understanding behavior changes in applications.</p>"},{"location":"tools/cupp/","title":"Cupp","text":"<p>CUPP (Common User Passwords Profiler) is a Python tool used for generating potential password lists for targeted attacks in penetration testing or ethical hacking scenarios. It's designed to create personalized wordlists based on information about the target individual or organization.</p> <p>By utilizing known information about the target, such as their name, date of birth, pet names, and other personal details, CUPP can generate a list of potential passwords that are more likely to succeed in brute-force or dictionary attacks.</p> <p>The tool asks for various personal details about the target (such as names, birthdates, hobbies, etc.) and incorporates them into the generated wordlist. Users can customize the wordlist generation process by adding specific words or phrases that might be relevant to the target.</p> <p>CUPP usually operates in an interactive mode, prompting the user to input relevant data about the target. It offers configuration options to include common password variations, like adding numbers or special characters to base words.</p> <p>In ethical hacking, CUPP is used to simulate attacker behavior and test the strength of passwords against personalized attacks. An example usage of CUPP might involve the following steps:</p> <ol> <li>Gathering Information: Collecting known personal information about the target.</li> <li>Running CUPP: Executing the tool, inputting the gathered information when prompted.</li> <li>Generating the Wordlist: CUPP processes the input and generates a wordlist tailored to the target's personal information.</li> <li>Using the Wordlist: The resulting wordlist can then be used with other tools (like John the Ripper or Hydra) for password cracking tests.</li> </ol>"},{"location":"tools/curl/","title":"cURL","text":"<p>cURL is a command line tool for transferring data to or from a server using protocols like HTTP and HTTPS. It's widely used in pentesting and can be useful for debugging, testing, and automating tasks that involve the web, file transfers, and website interactions.</p> <p>It allows you to include sending headers, uploading/downloading files, proxy support, and user authentication.</p> <p>Some options include:</p> <pre><code>-o &lt;file&gt;    # --output: write to file\n-u user:pass # --user: authentication\n-v   # --verbose: Make curl verbose during operation\n-vv  # more verbose\n-s   # --silent: don't show progress meter or errors\n-S   # --show-error: When used with --silent (-sS), show errors but no progress meter\n-i  # --include: include HTTP headers in the output\n-I  # --head: header only\n-X POST # --request\n-L # If the page redirects, follow the link\n-F # --form: HTTP POST data for multipart/form-data\n-d 'data'\n-d @file\n-G\n-A &lt;str&gt;      # --user-agent\n-b name=val   # --cookie\n-b FILE       # --cookie\n-H \"X-Foo: y\" # --header\n--compressed  # use deflate/gzip\n--cacert &lt;file&gt;\n--capath &lt;dir&gt;\n-E, --cert &lt;cert&gt; # --cert: client certificate file\n    --cert-type # der/pem/eng\n-k, --insecure # For self-signed certificates\n</code></pre>"},{"location":"tools/devtools/","title":"DevTools","text":"<p>\"DevTools,\" commonly known as Developer Tools, refers to a set of tools integrated into most modern web browsers like Google Chrome, Mozilla Firefox, Microsoft Edge, and Safari. These tools offer developers a rich set of functionalities to debug and optimize websites and web applications.</p> <p>It allows developers to inspect and modify HTML and CSS in real-time, providing immediate feedback on how changes would affect the presentation of a webpage. The JavaScript Console offers a console for running JavaScript code in the context of the current page, viewing logged information, and debugging JavaScript issues.</p> <p>The Network tab tracks all network activity that occurs when a webpage is loaded. This is crucial for diagnosing page load issues, monitoring resource loading, and analyzing HTTP requests and responses.</p> <p>The Performance tab provides tools to assess and improve page load times and runtime performance, helping identify bottlenecks in code execution, rendering, and painting.</p> <p>The Debugger includes a powerful JavaScript debugger to step through code, set breakpoints, and inspect variables.</p> <p>It also rnables developers to test how a website will look and function on different devices and screen sizes.</p> <p>The Storage tab allows inspection and modification of cookies, local storage, indexedDB, and other client-side storage.</p> <p>The Security tab offers insights into security issues, such as problems with HTTPS implementations.</p> <p>The Application panel is for inspecting resources that are loaded, such as Web Workers, Manifests, and Service Workers.</p>"},{"location":"tools/dig/","title":"Dig","text":"<p>Dig is a command-line tool and utility for querying DNS (Domain Name System) servers to retrieve information about domain names, IP addresses, DNS records, and other DNS-related data.</p> <p>The name \"dig\" stands for \"domain information groper.\" It is commonly used on Unix-like operating systems, including Linux and macOS, for DNS troubleshooting, network diagnostics, and DNS-related tasks.</p>"},{"location":"tools/dirbuster/","title":"Dirbuster","text":"<p>DirBuster\u00a0is a Java application that performs a brute force attack on directories and filenames on the web application. It can use a file containing the possible file and directory names or generate all possible combinations.</p> <p>DirBuster uses a list produced by surfing the internet and collecting the directory and files that developers use in real-world web applications. DirBuster, which was developed by OWASP, is currently an inactive project and is provided now as a ZAP attack tool rather than a standalone tool.</p>"},{"location":"tools/dos/","title":"DOSfuscation","text":"<p>Invoke-DOSfuscation is a PowerShell v2.0+ compatible framework designed for cmd.exe command obfuscation. It is intended to counter attackers who use obfuscation techniques to evade detection systems that rely heavily on command line argument values.</p> <p>The framework enables defenders to generate thousands of uniquely obfuscated sample commands to test and improve their detection capabilities against such techniques.</p> <p>The tool's usage involves several components built into standalone formal functions. The primary function, Invoke-DOSfuscation, is the easiest way for users to explore and visualize the obfuscation techniques supported by the framework.</p>"},{"location":"tools/extend/","title":"Burp Extender","text":"<p>Burp Extender is a part of Burp Suite, which is a comprehensive platform for performing security testing of web applications. Burp Suite is developed by PortSwigger and is widely used by security professionals and ethical hackers for web application penetration testing. Burp Extender is a specific component within this suite that allows users to extend the functionality of Burp Suite through custom plugins.</p> <p>Burp Extender allows users to write their own extensions to add new functionality or integrate existing processes into Burp Suite. These extensions can be used to automate tasks, extend Burp Suite's capabilities, or integrate third-party tools. </p> <p>Extensions for Burp Extender can be written in Java, Burp Extender, or Ruby, offering flexibility for developers familiar with these languages. Burp Extender provides an API (Application Programming Interface) that exposes various functionalities of Burp Suite, allowing extensions to interact with Burp\u2019s tools and workflows.</p> <p>The security community actively develops and shares extensions, which means users can leverage a wide range of tools created by other security professionals. Extensions can include anything from custom scanners and fuzzers to more specialized functions tailored to specific testing requirements.</p> <p>Some common uses include:</p> <ul> <li>Automated Testing: Writing extensions to automate repetitive tasks in security testing.</li> <li>Customized Attack Scenarios: Creating tools for specific attack types that might not be covered in-depth by the standard Burp Suite tools.</li> <li>Data Manipulation: Extensions can be used to manipulate request and response data in real-time for specific testing needs.</li> <li>Integration with Other Tools: Extending Burp Suite to work seamlessly with other software and tools used in the security testing process.</li> </ul>"},{"location":"tools/ffuf/","title":"Tools","text":"<p>Ffuf is a fuzzer written in the\u00a0Go programming language. It is an open source Web Fuzzing tool, intended for discovering elements and content within web applications, or web servers. </p> <p>Often when you visit a website you will be presented with the content that the owner of the website wants to serve you with, this could be hosted at a page such as\u00a0index.php. </p> <p>Within security, often the challenges in a website that need to be corrected exist outside of that. For example, the owner of the website may have content hosted at\u00a0admin.php, that you both want to know about, and test. FFUF is a tool for uncovering those items, for your purusal.</p> <p>Particularly in the bug bounty scene, a lot of people have gravitated towards FFUF since its release. Whilst a good majority of this shift is likely down to the following of the crowd, there is a definite portion of the community who have made the change due to FFUF\u2019s speed, flexibility, and ability to quickly integrate into outside tooling. </p> <p>In addition, the maintenance of the project is top notch, especially when compared to compeitive offerings which although similar in features, lack the same passion and speed to market of new features that FFUF has consistently shown. </p>"},{"location":"tools/freak/","title":"LFIFreak","text":"<p>LFIFreak is a specialized tool designed for exploiting Local File Inclusion (LFI) vulnerabilities. LFI vulnerabilities are security weaknesses in web applications where an attacker can include files located on the web server into the output of a given application. These vulnerabilities can be exploited to read sensitive files from the server, leading to information disclosure and potentially more severe security breaches.</p> <p>LFIFreak is specifically designed to target and exploit Local File Inclusion vulnerabilities in web applications. Tools like LFIFreak typically provide automated means to test and exploit LFI vulnerabilities, making it easier to identify and demonstrate the presence of these vulnerabilities in a web application.</p> <p>LFIFreak may include various techniques to exploit LFI vulnerabilities effectively, such as trying different traversal sequences, using null byte injections (in cases where this is still effective), or employing other methods to bypass filters and access restricted files.</p> <p>The primary use of such a tool is to read and exfiltrate sensitive data from the server, like system files, configuration files, or other data accessible through the file system.</p>"},{"location":"tools/getadusers/","title":"GetADUsers","text":"<p>Impacket's <code>GetADUsers</code> is a script from the Impacket suite, a collection of Python classes for working with network protocols. <code>GetADUsers</code> is designed to interact with Active Directory (AD) environments. It enables the enumeration of user accounts and their attributes from a Domain Controller.</p> <p><code>GetADUsers</code> can enumerate user accounts in an Active Directory domain, gathering information about each account. The script can retrieve various attributes for each user account, such as the username, description, last logon time, password last set time, and whether the user is required to change their password at the next logon.</p> <p><code>GetADUsers</code> allows for filtering the results based on specific criteria, which can be useful for targeting particular accounts or for auditing purposes. Here\u2019s a basic example of how <code>GetADUsers</code> might be used from the command line:</p> <pre><code>python GetADUsers.py &lt;DOMAIN&gt;/&lt;USERNAME&gt;:&lt;PASSWORD&gt;\n</code></pre> <p>Info</p> <p>The script connects to the domain controller and lists user accounts along with selected attributes. You can also use various flags and options to customize the output, such as filtering for users with certain attributes or who have not changed their passwords in a long time.</p>"},{"location":"tools/getnpusers/","title":"GetNPUsers","text":"<p>Impacket's <code>GetNPUsers</code> is a Python script included in the Impacket suite that is specifically designed for querying a domain controller in a Microsoft Active Directory environment to obtain Kerberos Ticket Granting Tickets (TGTs) for accounts that do not require Kerberos pre-authentication. This script is useful in the context of penetration testing, particularly for an attack known as AS-REP Roasting.</p> <p>AS-REP Roasting is an attack targeting accounts in an Active Directory environment that have the \"Do not require Kerberos pre-authentication\" option set. When this setting is enabled for an account, it's possible to request a Kerberos TGT for the account without needing to supply a valid password. The TGT can be encrypted with weak encryption or encryption that can be cracked offline, potentially exposing the user's credentials.</p> <p><code>GetNPUsers</code> attempts to get the TGTs for those user accounts in a [[Domain Controller]] that do not require pre-authentication. The script can be executed with a list of users or can query all users in a domain.</p> <p>The basic usage of <code>GetNPUsers</code> might look like this:</p> <pre><code>python GetNPUsers.py &lt;DOMAIN&gt;/&lt;USERNAME&gt; -no-pass\n</code></pre> <ul> <li>Replace <code>&lt;DOMAIN&gt;/&lt;USERNAME&gt;</code> with the appropriate domain and username. The <code>-no-pass</code> option is used when no password is provided.</li> <li>If successful, the script will output the Kerberos TGTs for accounts not requiring pre-authentication. These TGTs can then potentially be cracked offline.</li> </ul>"},{"location":"tools/getuspn/","title":"GetUserSPNs","text":"<p>Impacket's <code>GetUserSPNs</code> is a script that targets Active Directory environments to enumerate and request Service Principal Names (SPN) for user accounts. This is particularly useful in Kerberoasting attacks.</p> <p>Kerberoasting is a type of attack against Microsoft's Kerberos authentication protocol. It takes advantage of the fact that in an Active Directory environment, service accounts (accounts that are used by applications/services) often have Service Principal Names (SPNs) set. These SPNs can be queried by any authenticated user in the domain.</p> <p>Once an attacker obtains a Service Principal Name for a service account, they can request a Kerberos ticket for that service. This ticket is encrypted with the hash of the service account's password. The attacker can then attempt to crack this ticket offline to reveal the service account's password.</p> <p><code>GetUserSPNs</code>, part of the Impacket toolkit, automates the process of querying a domain for user accounts with SPNs set and requesting the corresponding Kerberos tickets.</p> <p>An example of how <code>GetUserSPNs</code>:</p> <pre><code>python GetUserSPNs.py &lt;DOMAIN&gt;/&lt;USERNAME&gt;:&lt;PASSWORD&gt; -request\n</code></pre> <p>Info</p> <p>The output of this script will typically include the Kerberos tickets for the service accounts, which can be saved and subjected to offline cracking attempts.</p>"},{"location":"tools/gobuster/","title":"Gobuster","text":"<p>GoBuster is a tool used in cybersecurity, particularly in the field of penetration testing and ethical hacking. It is designed for brute-forcing URIs (directories and files) in web applications, DNS subdomains, and Virtual Host names (VHOSTs). </p> <p>This tool is developed in Go (Golang) and is favored for its speed and efficiency.</p> <p>It can discover hidden directories and files on a web server by trying different paths (URIs) against the target. This is useful for finding potentially unlisted pages or directories that may contain sensitive information.</p> <p>GoBuster can be used to find subdomains of a given domain. This is done by brute-forcing DNS using a wordlist, helping to uncover hidden or unadvertised subdomains. </p> <p>It can brute-force virtual host names (VHOSTs) on a server. This is particularly useful when dealing with web servers hosting multiple domains (virtual hosts) on the same IP address.</p>"},{"location":"tools/harvest/","title":"The Harvester","text":"<p>\"TheHarvester\" is a popular open-source information gathering tool used by cybersecurity professionals, ethical hackers, and penetration testers during the reconnaissance phase of security assessments. </p> <p>It is designed to collect information and discover potential targets, assets, and online presences associated with a particular domain or organization. </p> <p>The Harvester can help gather data from various online sources, including search engines, public databases, and DNS-related services. This information can be valuable for assessing an organization's attack surface and identifying potential vulnerabilities.</p> <p>It can search for emails associated with a target domain by querying search engines, social media and public websites. It can also enumerate subdomains of a target using DNS brute-forcing or by querying public DNS servers.</p> <p>The tool can also attempt to identify live hosts associated with a domain by conducting DNS queries and port scanning to determine which IPs are responsive.</p> <p>It supports multiple data sources, including search engines, public APIS and services like Shodan, PGP key servers and more.</p>"},{"location":"tools/hydra/","title":"Hydra","text":"<p>Hydra, also known as THC-Hydra, is a popular and powerful password-cracking tool that is used for performing online and offline attacks to guess passwords or perform brute-force attacks against a variety of network services and protocols. It is a command-line tool often utilized by security professionals and penetration testers to test the strength of authentication mechanisms and identify weak or easily guessable passwords.</p> <p>Hydra supports a wide range of network protocols and services, including SSH, FTP, Telnet, HTTP, RDP, SMB, SNMP, MySQL, and many others. Users can customize attack parameters, including usernames, passwords, target hosts, ports, and various attack modes.</p> <p>Hydra is highly parallelized, allowing it to make multiple connection attempts simultaneously, making it efficient for large-scale password-cracking tasks. Hydra supports both dictionary-based attacks (using wordlists) and pure brute-force attacks (trying every possible combination).</p> <p>An example may be:</p> <pre><code>hydra -l username -P password-file.txt ssh://target-host\n</code></pre> <ul> <li><code>-l username</code>: Specifies the target username.</li> <li><code>-P password-file.txt</code>: Specifies a file containing a list of passwords to try.</li> <li><code>ssh://target-host</code>: Specifies the target SSH server's hostname or IP address.</li> </ul> <p>Info</p> <p>Hydra will attempt to log in to the SSH server on the target host by trying each password from the provided file (<code>password-file.txt</code>). If it successfully finds a valid password, it will report the credentials.</p>"},{"location":"tools/impacket/","title":"Impacket","text":"<p>Impacket is an open-source collection of Python classes for working with network protocols. It is widely used in the field of network security and penetration testing. Impacket is designed to provide low-level programmatic access to the packets and, for some protocols, to the higher-level functionalities like authentication, connection, etc.</p> <p>Impacket includes support for a variety of network protocols, including IP, TCP, UDP, ICMP, SMB, MSRPC, NMB, and others. This makes it a versatile tool for network protocol analysis and manipulation. It allows for the creation and manipulation of network packets. This is useful for testing the security and resilience of network applications and services.</p> <p>For some protocols like SMB, Impacket provides high-level functionalities such as performing authentication and establishing connections. Impacket can be used to write scripts that automate common network tasks, such as gathering information, exploiting vulnerabilities, or establishing connections with network services.</p> <p>Security professionals and penetration testers use Impacket to exploit known vulnerabilities in network protocols or services. For example, it can be used to exploit weaknesses in SMB/CIFS protocols on Windows machines. Impacket scripts can gather information about networked systems, test protocols, and analyze network security.</p> <p>It can be used to perform Pass-the-Hash Attacks, Relay Attacks, or extract NTLM credentials from network traffic.</p> <p>Here\u2019s an example of how Impacket might be used in a script (note that this is a conceptual example for illustrative purposes):</p> <pre><code>from impacket.smbconnection import SMBConnection\n\n# Establish a connection to the SMB server\nsmb = SMBConnection(\"TARGET_MACHINE\", \"TARGET_MACHINE_IP\")\nsmb.login(\"username\", \"password\")\n\n# List shares available on the target machine\nshares = smb.listShares()\nfor share in shares:\n    print(share['shi1_netname'])\n\n# Other operations with the SMB connection\n</code></pre> <p>Info</p> <p>Impacket is used to connect to an SMB server, authenticate, and list the available shares.</p> <p>Impacket provides a suite of powerful tools that leverage its Python classes for various network protocols. These tools are particularly useful in the context of network security and penetration testing. Some of the common tools included in the Impacket collection are:</p> <ol> <li>smbserver: A simple SMB/CIFS server that can be used for file sharing, uploading, and downloading. It's useful in scenarios where you need a quick SMB server setup for testing or exploitation purposes.</li> <li>psexec: A tool that provides functionality similar to Microsoft's PsExec utility. It allows execution of processes remotely by creating a service on the remote system.</li> <li>mssqlclient: A minimalistic MSSQL client that allows connecting to SQL servers, executing queries, and performing database operations. It supports both Windows and SQL Server authentication.</li> <li>ntlmrelayx: A tool for performing NTLM relay attacks. It can capture NTLM authentication requests and relay them to other services, potentially allowing unauthorized access.</li> <li>secretsdump: Used for extracting various types of credentials from Windows systems, such as NTLM password hashes, Kerberos tickets, and LSA secrets.</li> <li>GetADUsers: A tool for gathering information about users in a Microsoft Active Directory environment. It can be used to enumerate users, their last login times, and password expiration dates.</li> <li>GetNPUsers: This tool attempts to list and get TGTs for those users that have the property 'Do not require Kerberos preauthentication' set in a Domain Controller. Useful for Kerberoasting attacks.</li> <li>GetUserSPNs: Used in Kerberoasting attacks, this tool requests Service Principal Names (SPN) to get TGS tickets that can be cracked offline.</li> <li>lookupsid: Allows you to perform SID enumeration on Windows systems to gather information about existing user accounts.</li> <li>smbrelayx: Similar to ntlmrelayx, it's used for SMB relay attacks, where SMB sessions are relayed to other targets.</li> <li>wmiexec: A tool that provides a semi-interactive shell, allowing the execution of commands via WMI.</li> <li>smbclient: A simple SMB client that allows for file and directory browsing, file uploading, downloading, and deletion on SMB shares.</li> </ol>"},{"location":"tools/incog/","title":"Incognito","text":"<p>Incognito is a module within the Metasploit Framework, an open-source penetration testing tool. It is specifically designed for privilege escalation and impersonation in Windows environments. Incognito focuses on exploiting Windows access token vulnerabilities to escalate privileges and impersonate logged-in users, particularly in post-exploitation phases of a penetration test.</p> <p>Incognito can enumerate and impersonate user tokens available on a compromised Windows system. Windows access tokens are objects that describe the security context of a process or thread and contain information about the user account associated with the process. By impersonating tokens with higher privileges, Incognito allows penetration testers or attackers to escalate their privileges on the compromised system.</p> <p>With elevated privileges, it becomes possible to access resources that were previously restricted, such as files, directories, or services requiring higher-level permissions.</p> <p>After gaining initial access to a system, Incognito is used to list available tokens. These tokens represent the security contexts of users currently logged into the system or services running under certain user accounts. The penetration tester or attacker can then select and impersonate a token belonging to a higher-privileged user or service account. Once impersonating a higher-privileged token, the attacker or tester can execute actions that require elevated privileges, such as accessing sensitive data, installing additional tools, or moving laterally across the network.</p> <p>Imagine a scenario where a penetration tester has gained access to a standard user account on a Windows server. The server also has an administrator account currently logged in:</p> <ol> <li>Enumeration: The tester uses Incognito to list all available tokens on the server.</li> <li>Impersonation: Among the listed tokens, the tester finds a token associated with the administrator account.</li> <li>Elevated Access: By impersonating the administrator's token, the tester gains full administrative privileges on the server, allowing them to conduct further exploration or demonstrate the impact of a full system compromise.</li> </ol>"},{"location":"tools/interact/","title":"Project Interactsh","text":"<p>\"Interactsh\" is an open-source project available on GitHub, described as an \"OOB (Out-of-Band) interaction gathering server and client library.\" This tool is primarily used in cybersecurity and penetration testing for detecting OOB data exfiltration and interaction capabilities. </p> <p>Interactsh can be related to Cross-Site Scripting (XSS) in the context of security testing and vulnerability assessment. XSS attacks involve injecting malicious scripts into web pages viewed by other users. In such scenarios, Interactsh can be used to identify and demonstrate the impact of XSS vulnerabilities.</p> <p>For instance, during penetration testing, a security researcher might use an XSS payload that triggers an interaction with the Interactsh server when executed in a victim's browser. This interaction, captured by Interactsh, serves as proof of the vulnerability, helping to assess the risk and impact of the XSS issue. By monitoring out-of-band interactions, Interactsh helps in detecting and analyzing such security flaws in web applications.</p>"},{"location":"tools/intrude/","title":"Burp Intruder","text":"<p>Burp Intruder is a tool within the Burp Suite, which is a popular set of tools used for web application penetration testing. Burp Intruder is specifically designed for automating customized attacks against web applications. It is widely used for tasks such as enumerating identifiers, harvesting useful data, and fuzzing for vulnerabilities.</p> <p>Burp Intruder can automate the process of submitting multiple HTTP requests to a web application. It is highly configurable and can be used to customize the payload and the behavior of each request.</p> <ol> <li>Key Features and Use Cases:<ul> <li>Brute Force Attacks: Testing login forms or other input fields where attackers might attempt to guess credentials or identifiers.</li> <li>Parameter Fuzzing: Automatically varying the values of parameters to test how a web application responds to unexpected or malicious input.</li> <li>Enumeration: Identifying valid usernames, IDs, or other specific data by automating requests with different input values.</li> <li>Data Harvesting: Extracting useful data from responses, such as error messages or informative headers.</li> </ul> </li> </ol> <p>Burp Intruder supports a wide range of payload types, including simple lists, numbers, dates, and custom payloads. It can generate payloads or use predefined or custom lists. Burp Intruder offers various attack types, such as Sniper, Battering Ram, Pitchfork, and Cluster Bomb, each suitable for different scenarios and objectives.</p> <p>The responses to the Intruder requests can be reviewed within the tool, which provides functionalities to analyze and filter the results. This helps in identifying interesting patterns or anomalies in the responses.</p> <p>Being part of the Burp Suite, Burp Intruder can work in tandem with other tools in the suite, like Burp Repeater and Burp Scanner, for more comprehensive testing. While powerful, Burp Intruder can be resource-intensive, especially when performing large numbers of requests. Efficiency can be managed through settings like request throttling.</p>"},{"location":"tools/john/","title":"John the Ripper","text":"<p>John the Ripper is a widely used open-source password cracking tool. It's designed to detect weak passwords by trying to crack hashed passwords recovered from a system's shadow file or obtained from other sources. John the Ripper uses a variety of techniques, including brute force and dictionary attacks, to guess passwords.</p> <p>It typically operates on password hashes. When you enter a password into a system, that password is usually not stored directly; instead, it's processed through a cryptographic hash function, and the resulting hash is stored. John the Ripper first tries a dictionary attack, where it runs through a list of common passwords (from a wordlist) and their precomputed hash values.</p> <p>If the dictionary attack fails, it employs brute-force attacks, generating every possible password combination until it finds a match. It also applies various mangling rules to dictionary words (like adding numbers, capitalizing letters, or reversing characters) to guess more complex passwords that might be derived from simple words.</p> <p>Suppose you have a file containing password hashes named <code>hashes.txt</code>. To attempt cracking these passwords with John the Ripper, you would use the following syntax in the command line:</p> <pre><code>john hashes.txt\n</code></pre> <p>This command tells John the Ripper to start cracking the hashes in <code>hashes.txt</code> using its default settings and wordlists. You can also specify different modes and options. For example, to use a specific wordlist, you can use the <code>--wordlist</code> option followed by the path to your wordlist file.</p> <pre><code>john --wordlist=/path/to/wordlist.txt hashes.txt\n</code></pre> <p>To enable rules (which apply various transformations to wordlist entries), you can use the <code>--rules</code> option.</p> <pre><code>john --wordlist=/path/to/wordlist.txt --rules hashes.txt\n</code></pre> <p>If you want to use brute-force mode, you can specify it with <code>--incremental</code>.</p> <pre><code>john --incremental hashes.txt\n</code></pre> <p>To display the passwords that have been successfully cracked, use the <code>--show</code> option.</p> <pre><code>john --show hashes.txt\n</code></pre> <p>If you know the type of hash algorithm used (e.g., MD5, SHA-256), you can specify it with the <code>--format</code> option:</p> <pre><code>john --format=md5crypt hashes.txt\n</code></pre> <p>Info</p> <p>This command tells John the Ripper to specifically use the MD5 hash algorithm when attempting to crack the hashes in <code>hashes.txt</code>.</p>"},{"location":"tools/liffy/","title":"Liffy","text":"<p>Liffy, short for Local File Inclusion Exploiter, is a tool designed to exploit Local File Inclusion (LFI) vulnerabilities in web applications. LFI is a common security vulnerability that allows an attacker to include and execute files on a server through a web application.</p> <p>Liffy is specifically tailored to identify and exploit LFI vulnerabilities. It can help in automating the process of testing and exploiting these weaknesses in web applications. The tool usually includes various techniques to exploit LFI vulnerabilities, such as directory traversal, Log Poisoning, and leveraging PHP wrappers.</p> <p>Liffy can be used to test web applications for LFI vulnerabilities, validating the security measures in place and identifying potential areas for improvement. In some cases, Liffy or similar tools might be able to leverage LFI vulnerabilities to achieve remote code execution, especially if combined with other vulnerabilities or misconfigurations.</p>"},{"location":"tools/look/","title":"lookupsid","text":"<p>Impacket's <code>lookupsid</code> is a tool that forms part of the Impacket suite of Python classes for working with network protocols. This particular tool is designed for Windows SID (Security Identifier) enumeration. It is useful in penetration testing and network security assessments for gathering information about Windows user accounts and their corresponding SIDs on a networked system.</p> <p><code>lookupsid</code> allows you to enumerate user SIDs (Security Identifiers) and group SIDs on a Windows system. Each user account and group account on a Windows system has a unique SID. By obtaining the SIDs, you can gather information about existing user accounts, which can be valuable in understanding the network's structure and potential attack vectors. The tool makes use of SMB (Server Message Block) protocol for communication, a standard protocol used in Windows networking.</p> <p>An example of how <code>lookupsid</code> might be used in a penetration testing scenario. This command-line example assumes you have the necessary network access and permissions:</p> <pre><code>python lookupsid.py &lt;DOMAIN&gt;/&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;TARGET_IP&gt;\n</code></pre> <p>Info</p> <p><code>lookupsid</code> will then attempt to connect to the target machine and enumerate SIDs. The output typically includes a list of user names and their corresponding SIDs, along with any groups and their SIDs.</p>"},{"location":"tools/medusa/","title":"Medusa","text":"<p>Medusa is a command-line, cross-platform, and modular network login brute-forcing tool. It is designed for performing brute-force attacks against various network protocols and services to guess usernames and passwords. Medusa supports a wide range of authentication protocols, making it a versatile tool for security assessments and penetration testing.</p> <p>Medusa supports a variety of network protocols and services, including SSH, FTP, HTTP, RDP, SMB, POP3, IMAP, MySQL, and more. It can perform multiple login attempts simultaneously, making it efficient for password-cracking tasks.</p> <p>Medusa's modular design allows for the addition of new protocols and services through external modules. Users can customize attack parameters, such as usernames, passwords, and attack timeouts.</p> <p>Medusa supports both dictionary-based attacks (using wordlists) and pure brute-force attacks.</p> <p>An example may be:</p> <pre><code>medusa -h target-ftp-server -U users.txt -P passwords.txt -M ftp\n</code></pre> <ul> <li><code>-h target-ftp-server</code>: Specifies the target FTP server's hostname or IP address.</li> <li><code>-U users.txt</code>: Specifies a file containing a list of usernames to try.</li> <li><code>-P passwords.txt</code>: Specifies a file containing a list of passwords to try.</li> <li><code>-M ftp</code>: Specifies the FTP module for Medusa to use.</li> </ul> <p>Info</p> <p>Medusa will attempt to log in to the FTP server by trying each username-password combination from the provided files. If it successfully finds a valid combination, it will report the credentials.</p>"},{"location":"tools/mental/","title":"The Mentalist","text":"<p>\"The Mentalist\" is a password generation tool used in the field of cybersecurity, particularly in penetration testing and ethical hacking. It assists in creating customized wordlists for targeted brute force or dictionary attacks. The tool is designed to help security professionals and ethical hackers generate highly tailored password guesses based on personal information known about the target or common password patterns.</p> <p>Unlike many command-line tools, The Mentalist typically offers a graphical user interface (GUI), making it more accessible for users who prefer visual interactions. It enables the creation of custom wordlists based on a combination of user input and predefined or custom rules. This can include patterns like common substitutions (e.g., replacing 'e' with '3'), prefixes, suffixes, and more.</p> <p>The tool combines various password creation methods, such as leet speak conversion, date and number appending, and word concatenation. By incorporating known information about a target (like names, birthdates, pet names, hobbies), The Mentalist can generate a wordlist that is more likely to include potential passwords used by the target.</p> <p>In ethical hacking, The Mentalist is used to create wordlists that closely match the password creation habits of users, enhancing the effectiveness of password cracking tools in penetration testing scenarios.</p> <p>For security professionals, it provides a way to simulate more sophisticated attacks that use personalized information, which can be crucial for testing the resilience of systems against targeted social engineering attacks.</p>"},{"location":"tools/meterpreter/","title":"Meterpreter","text":"<p>Meterpreter is a highly advanced, dynamic, and extensible payload used within the Metasploit Framework, a popular tool for penetration testing and exploit development. Meterpreter operates as an in-memory-only payload, providing extensive control over a compromised system without needing to write any data to the disk. </p> <p>This makes it stealthier compared to traditional payloads.</p> <p>Meterpreter resides entirely in memory, leaving minimal traces on the target system's disk. This characteristic significantly reduces its detection by antivirus software and forensic tools. </p> <p>Meterpreter is designed to be highly extensible. It can dynamically load additional modules and scripts into memory as needed, extending its capabilities on the fly.</p> <p>Once a Meterpreter session is established (typically after exploiting a vulnerability on the target system), it allows comprehensive command and control. Attackers or testers can interact with the system, execute commands, manipulate files, and gather information.</p> <p>Meterpreter provides a wide range of features, including file system manipulation, capturing screenshots and keystrokes, pivoting to other networks, port forwarding, and recording audio and video.</p> <p>Its ability to operate in-memory, coupled with features like SSL/TLS encrypted communications, helps in evading detection by security defenses.</p> <p>Meterpreter excels in post-exploitation, allowing testers to explore and exploit a compromised system's environment further. This includes privilege escalation, dumping system information, and accessing the system's registry.</p> <p>It can provide an interactive shell to the attacker, allowing them to run native system commands on the compromised machine. Meterpreter is tightly integrated with the Metasploit Framework, making it easy to use alongside other tools and exploits in the framework.</p>"},{"location":"tools/mimi/","title":"Mimikatz","text":"<p>Mimikatz is a well-known and powerful tool in the field of cybersecurity, particularly used in penetration testing and digital forensics. Developed by Benjamin Delpy (<code>gentilkiwi</code>), Mimikatz is designed to gather and manipulate credentials and other security-related information from Windows systems. It's famous for its ability to extract plaintext passwords, hash values, PIN codes, and Kerberos Tickets from memory.</p> <p>Mimikatz can extract plaintext passwords from memory, particularly from the LSASS (Local Security Authority Subsystem Service) process in Windows. It allows for the extraction and use of NTLM hashes and Kerberos tickets, enabling pass-the-hash attacks or Pass-the-Ticket Attacks for lateral movement in networks.</p> <p>Mimikatz can create a \"Golden Ticket,\" which is a forged Kerberos Ticket Granting Ticket (TGT) that provides broad access to a network. It can interact with various Windows authentication protocols, such as NTLM, Kerberos, and more, for testing and exploitation.</p> <p>Some example uses include extracting plaintext passwords:</p> <pre><code>mimikatz # sekurlsa::logonpasswords\n</code></pre> <p>Info</p> <p>This command lists the plaintext passwords and hashes of logged-in accounts.</p> <p>Or creating golden tickets:</p> <pre><code>mimikatz # kerberos::golden /user:Administrator /domain:&lt;DOMAIN&gt; /sid:&lt;DOMAIN_SID&gt; /krbtgt:&lt;KRBTGT_HASH&gt; /id:500\n</code></pre> <p>Info</p> <p>This creates a Golden Ticket for the domain administrator. The required parameters are the domain name, domain SID, and krbtgt account hash.</p> <p>Or extracting NTLM hashes:</p> <pre><code>mimikatz # lsadump::sam\n</code></pre> <p>Info</p> <p>This dumps the SAM database containing NTLM hashes of local accounts.</p>"},{"location":"tools/mpsexec/","title":"Microsoft PsExec","text":"<p>Microsoft's PsExec is a lightweight, yet powerful command-line tool that is part of the Sysinternals Suite. PsExec allows users to execute processes remotely on other systems. It is widely used by system administrators for its ability to execute programs on remote systems without the need to manually install client software on each target machine.</p> <p>PsExec enables you to run programs on remote systems. You can have the output of these programs displayed on your own system, or run them in the background on the remote system. PsExec operates from the command line, offering a high level of control and scripting capabilities.</p> <p>You can run commands as the local system account, as the currently logged-on user, or as a different user by providing credentials. PsExec can copy the necessary executables to the remote system to run the command and then remove them afterward. It's commonly used for network administration tasks like updating group policies, deploying software, running scripts, and performing diagnostic tasks across multiple machines.</p> <p>An example may be:</p> <pre><code>PsExec \\\\RemoteMachineName ipconfig /all\n</code></pre> <p>PsExec typically requires that you have administrator privileges on the remote machine to execute commands. PsExec communicates over the network, and the traffic is not encrypted by default. In sensitive environments, it's important to consider the potential security implications.</p> <p>Some ways it can be used offensively include:</p> <ol> <li>Lateral Movement: Once gaining access to one machine in a network, attackers can use PsExec to execute commands or deploy malware on other machines within the network, moving laterally to expand their reach.</li> <li>Running Malicious Code: Hackers can use PsExec to run malicious scripts or programs on remote systems. This could be used to install backdoors, keyloggers, or other types of malware.</li> <li>Privilege Escalation: By using PsExec with stolen credentials, attackers can execute commands with elevated privileges, potentially gaining administrative access on remote systems.</li> <li>Maintaining Persistence: PsExec can be used to install services or applications that allow attackers to maintain access to the network over time.</li> <li>Evading Detection: Because PsExec is a legitimate Windows tool, its usage might evade detection by some security software, allowing attackers to use it without immediately raising alarms.</li> </ol>"},{"location":"tools/msf/","title":"Metasploit Framework","text":"<p>The Metasploit Framework is an open-source project that provides a platform for developing, testing, and executing exploit code against remote target machines. It is one of the most widely used tools in the field of cybersecurity, particularly in penetration testing and vulnerability assessment.</p> <p>Metasploit simplifies the process of writing new exploits, payloads, and other code modules. It also provides a vast collection of existing exploits for various platforms and applications.</p> <p>Components of Metasploit: - Exploits: Code that takes advantage of a security flaw in a software application. - Payloads: Code that runs after an exploit successfully compromises a system. This can include things like reverse shells or code to gather system information. - Auxiliary Functions: Additional tools and utilities, such as scanners, fuzzers, and other modules that can be used for tasks like reconnaissance and service identification. - Encoders and Nops: Used to obfuscate payloads and maintain payload sizes, respectively.</p> <p>Metasploit runs on Unix (including Linux and macOS) and Windows systems. It can target a wide range of systems and network devices across different platforms. Metasploit can be used via the command line interface (CLI), a graphical user interface (GUI) known as Armitage, and a web-based interface.</p>"},{"location":"tools/msfvenom/","title":"Msfvenom","text":"<p>Msfvenom is a payload generation tool that is part of the Metasploit Framework, an extensive tool used for penetration testing and security research. It combines the previous stand-alone tools, msfpayload and msfencode, into a single, more powerful application. </p> <p>Msfvenom is used to create various types of payloads, from simple code that creates a shell on a target machine to complex payloads that can bypass advanced security measures.</p> <p>Msfvenom allows for the generation of custom payloads in various formats (e.g., executables, scripts, raw shellcode) for different platforms (Windows, Linux, Android, etc.). It supports a broad array of payload types, including reverse shells, bind shells, Meterpreter payloads, and others, providing flexibility depending on the penetration testing requirements.</p> <p>Payloads generated by Msfvenom can be used within the Metasploit Framework, allowing seamless integration with other Metasploit tools for exploitation, post-exploitation, and evasion. </p> <p>Msfvenom can produce payloads in various formats, suitable for different use cases, such as binary executables, Python scripts, or even raw shellcode. It provides options to encode and obfuscate payloads, which is crucial for evading detection by antivirus software and intrusion detection systems.</p>"},{"location":"tools/mssqlc/","title":"mssqlclient","text":"<p>Impacket's <code>mssqlclient</code> is a script that provides a command-line interface to interact with Microsoft SQL Server (MSSQL). It's part of the Impacket suite, a collection of Python classes and scripts for working with network protocols. <code>mssqlclient</code> is particularly useful for database querying and operations in the context of network security assessment, penetration testing, and IT administration.</p> <p>It allows for direct interaction with Microsoft SQL Server, enabling the execution of SQL queries and commands. It supports both Windows (NTLM) and SQL Server authentication methods, allowing it to be used in a variety of network environments. Some versions of <code>mssqlclient</code> support the execution of operating system commands through SQL Server, depending on the server configuration and permissions. It can be used to perform database operations such as data querying, schema exploration, and database administration tasks.</p> <p>An example of how to use it:</p> <pre><code>python mssqlclient.py &lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;TARGET_IP&gt; -windows-auth\n</code></pre> <ul> <li><code>&lt;TARGET_IP&gt;</code> is the IP address of the target MSSQL server.</li> <li>The <code>-windows-auth</code> flag is used for Windows (NTLM) authentication; omit this flag for standard SQL Server authentication.</li> </ul> <p>Info</p> <p>Once connected, you will be presented with an SQL command prompt where you can execute SQL queries and commands.</p> <p>For example, to list the databases, you might use:</p> <pre><code>SQL&gt; SELECT name FROM sys.databases;\n</code></pre>"},{"location":"tools/ncrack/","title":"Ncrack","text":"<p>Ncrack is a high-speed network authentication cracking tool. It is designed to efficiently guess passwords or perform brute-force and dictionary attacks against various network protocols and services. Ncrack is particularly useful for testing the security of networked systems by identifying weak or easily guessable passwords.</p> <p>Ncrack supports a wide range of network protocols and services, including SSH, RDP (Remote Desktop Protocol), FTP, Telnet, HTTP(S), VNC, SNMP, and more. Ncrack is highly parallelized, allowing it to make multiple connection attempts simultaneously. This speed and efficiency make it effective for large-scale password-cracking tasks.</p> <p>Ncrack can also be used to perform user enumeration attacks, where it attempts to identify valid usernames on a target system before launching a password-cracking attack. Ncrack supports both dictionary-based attacks (using a list of known passwords) and brute-force attacks (trying every possible combination).</p> <p>It can target authentication methods like password-based, public key, and keyboard-interactive authentication. Ncrack can be integrated with other security assessment tools and frameworks, such as Nmap and Metasploit, to enhance network penetration testing.</p> <p>An example may be:</p> <pre><code>ncrack -p 22 --user admin -P password-file.txt target-host\n</code></pre> <ul> <li><code>-p 22</code>: Specifies the target port (in this case, port 22 for SSH).</li> <li><code>--user admin</code>: Specifies the username to attack (in this case, \"admin\").</li> <li><code>-P password-file.txt</code>: Specifies a file containing a list of potential passwords to try.</li> <li><code>target-host</code>: Specifies the target host or IP address.</li> </ul> <p>Info</p> <p>Ncrack will attempt to log in to the SSH service on the target host using the \"admin\" username and each password from the provided password file (<code>password-file.txt</code>). It will report back if it successfully finds the correct password or if the attack is unsuccessful.</p>"},{"location":"tools/nessus/","title":"Nessus","text":"<p>Nessus is a widely used vulnerability scanner developed by Tenable Network Security. It is designed to identify vulnerabilities, misconfigurations, and potential risks in network infrastructure and software systems. </p> <p>While Nessus is not exclusively a web application vulnerability scanner, it includes features that can be used for this purpose. </p> <p>Nessus scans for a wide range of vulnerabilities in network devices, operating systems, databases, applications, and web servers. It checks against known vulnerabilities in its extensive database. It identifies misconfigurations in systems and network devices that could lead to security weaknesses.</p> <p>Nessus can audit systems against various compliance standards to ensure that security configurations align with best practices and regulatory requirements.</p> <p>When it comes to web applications, Nessus can be used to scan web apps for common vulnerabilities like SQL injection, Cross-Site Scripting, Cross-Site Request Forgery, and other vulnerabilities.</p> <p>It can also check the configuration of SSL/TLS on web servers to identify issues like weak ciphers, expired certificates and other SSL/TLS related vulnerabilities.</p>"},{"location":"tools/netcat/","title":"Netcat","text":"<p>Netcat is a computer networking utility for reading from and writing to network connections using TCP or UDP. It is a versatile tool widely used in the field of penetration testing and ethical hacking for its ability to create almost any type of connection its user could need.</p> <p>Netcat is frequently used for listening to incoming network connections, a feature that is highly valuable in various networking and cybersecurity contexts. When Netcat is configured to listen mode, it waits for incoming connections on a specified port.</p> <p>Netcat can also be used to scan for open ports on a target machine. This helps in identifying potentially vulnerable services running on these ports.</p> <p>By connecting to different services on a target machine, Netcat can grab banners. These banners often contain service and version information, which can be useful for identifying potential vulnerabilities.</p> <p>Netcat allows the creation of backdoors on a target machine. This can be used by ethical hackers to gain remote access to the machine for further analysis or demonstration of the vulnerability.</p> <p>It can be used to transfer files between machines, which is useful in both exfiltrating data during a penetration test and for transferring tools or payloads to a target machine.</p> <p>Netcat can be used to diagnose network issues, check firewall rules, and perform other network-level debugging tasks.</p>"},{"location":"tools/netcraft/","title":"Netcraft","text":"<p>Netcraft is a UK-based internet services company known for its internet security and research services. One of its prominent offerings is the Netcraft Web Server Survey, which collects and publishes data about web servers, web technologies, and internet infrastructure. </p> <p>Netcraft also provides services related to anti-phishing, anti-malware, and internet security, making it a valuable resource for organizations and individuals interested in monitoring and protecting their online presence.</p> <p>In the context of passive infrastructure identification, Netcraft's services and tools can be used to gather information about internet infrastructure, websites, hosting providers, and the technologies used on the web.</p> <p>Netcraft maintains a database of web server software and versions in use on the Internet. By querying it, you can identify the web server software (e.g. Apache, Nginx, Microsoft IIS) running on a website.</p> <p>It can also identify the hosting provider or data centre where a website is hosted. Netcraft provides tools to analyze SSL certificates used by websites which can help identify CAs, certificate expiration dates and whether a website uses secure encryption protocols.</p>"},{"location":"tools/nmap/","title":"Nmap","text":"<p>Nmap is short for Network Mapper. It is an open-source Linux command-line tool that is used to scan IP addresses and ports in a network and to detect installed applications.</p> <p>Nmap allows network admins to find which devices are running on their network, discover open ports and services, and detect vulnerabilities.</p> <p>Nmap helps you to quickly map out a network without sophisticated commands or configurations. It also supports simple commands (for example, to check if a host is up) and complex scripting through the Nmap scripting engine.</p> <p>Other features of Nmap include:</p> <ul> <li>Ability to quickly recognize all the devices including servers, routers, switches, mobile devices, etc on single or multiple networks.</li> <li>Helps identify services running on a system including web servers, DNS servers, and other common applications. Nmap can also detect application versions with reasonable accuracy to help detect existing vulnerabilities.</li> <li>Nmap can find information about the operating system running on devices. It can provide detailed information like OS versions, making it easier to plan additional approaches during penetration testing.</li> <li>During security auditing and vulnerability scanning, you can use Nmap to attack systems using existing scripts from the Nmap Scripting Engine.</li> <li>Nmap has a graphical user interface called Zenmap. It helps you develop visual mappings of a network for better usability and reporting.</li> </ul>"},{"location":"tools/nslookup/","title":"NSLookup","text":"<p>The name server lookup (nslookup) command-line tool finds the\u00a0IP Address address\u00a0or\u00a0DNS record for a specific hostname. This command also supports\u00a0reverse DNS lookups by inputting the IP addresses of the domains to be looked up.</p> <p>The nslookup tool can be used for DNS-related tasks like server testing and troubleshooting. </p>"},{"location":"tools/ntlmrelayx/","title":"ntlmrelayx","text":"<p>Impacket's <code>ntlmrelayx</code> is a powerful tool designed to perform NTLM relay attacks. An NTLM relay attack is a type of security vulnerability where an attacker intercepts NTLM (NT LAN Manager) authentication traffic and then relays this traffic to another server to authenticate as the intercepted user. This tool is part of the Impacket suite, a collection of Python classes for working with network protocols.</p> <p>The primary function of <code>ntlmrelayx</code> is to intercept and relay NTLM authentication requests from one host to another. This allows the attacker to authenticate to a target server with the credentials of a user whose traffic was intercepted. It can relay credentials to various types of services, including SMB, HTTP, and others that support NTLM authentication.</p> <p><code>ntlmrelayx</code> can be configured to automatically execute specific actions upon successful relay, such as running commands, dumping hashes, or exploiting known vulnerabilities. Often used in conjunction with other Impacket tools like responder, which can poison network traffic and facilitate the capture of NTLM authentication messages for relay.</p> <p>Here's an example:</p> <pre><code>python ntlmrelayx.py -t smb://&lt;TARGET_IP&gt;\n</code></pre> <ul> <li><code>-t smb://&lt;TARGET_IP&gt;</code> specifies the target to relay the NTLM authentication to, using SMB protocol.</li> <li>You would typically run this command alongside a tool like Impacket's <code>responder</code>, which induces network clients to send their NTLM authentication messages to you.</li> </ul>"},{"location":"tools/palt/","title":"PayloadAllTheThings","text":"<p>PayloadAllTheThings is a widely-used, open-source repository hosted on GitHub that provides a comprehensive collection of various types of payloads, useful for different kinds of security assessments and penetration tests. </p> <p>It is essentially a resource for security researchers, ethical hackers, and penetration testers, offering an extensive array of examples and techniques for exploiting different kinds of vulnerabilities in web applications and other systems.</p> <p>The repository includes payloads for a wide range of vulnerabilities, including Cross-Site Scripting (XSS), SQL Injection, Server-Side Request Forgery (SSRF), Local File Inclusion (LFI), Remote File Inclusion (RFI), and many others.</p>"},{"location":"tools/patator/","title":"Patator","text":"<p>Patator is a versatile, multi-purpose, and extensible brute-force tool designed for performing penetration testing and security assessments. It is commonly used by security professionals and penetration testers to automate password-cracking and authentication-testing tasks. Patator supports a wide range of protocols, services, and attack methods.</p> <p>Patator supports a variety of network protocols and services, including SSH, FTP, Telnet, HTTP, RDP, VNC, IMAP, SMB, and more. It can perform multiple types of attacks, including dictionary attacks, brute-force attacks, and hybrid attacks (combining dictionary and brute-force methods).</p> <p>Patator can perform multiple login attempts simultaneously, making it efficient for password-cracking tasks. Users can customize attack parameters, such as usernames, passwords, target hosts, and ports. Patator's modular design allows for the addition of new protocols and services through external modules.</p> <p>Patator supports both dictionary-based attacks (using wordlists) and pure brute-force attacks. An example may be:</p> <pre><code>patator ssh_login host=ssh.example.com user=FILE0 password=FILE1 0=users.txt 1=passwords.txt -x ignore:mesg='Authentication failed.'\n</code></pre> <ul> <li><code>ssh_login</code>: Specifies the SSH login module.</li> <li><code>host=ssh.example.com</code>: Specifies the target SSH server's hostname or IP address.</li> <li><code>user=FILE0</code>: Specifies the username parameter and indicates that usernames will be loaded from a file.</li> <li><code>password=FILE1</code>: Specifies the password parameter and indicates that passwords will be loaded from a file.</li> <li><code>0=users.txt</code>: Specifies the file containing a list of usernames.</li> <li><code>1=passwords.txt</code>: Specifies the file containing a list of passwords.</li> <li><code>-x ignore:mesg='Authentication failed.'</code>: Instructs Patator to ignore login attempts with the message \"Authentication failed.\"</li> </ul> <p>Info</p> <p>Patator will attempt to log in to the SSH server by trying each username-password combination from the provided files. If it successfully finds a valid combination, it will report the credentials.</p>"},{"location":"tools/pbox/","title":"PayloadBox","text":"<p>PayloadBox is a curated collection of various payloads, techniques, and scripts for penetration testing and vulnerability assessments. It is often used as a resource by security professionals, including penetration testers, ethical hackers, and researchers in the field of cybersecurity.</p> <p>PayloadBox typically includes a diverse range of payloads applicable to various vulnerabilities and attack scenarios. This can include, but is not limited to, Cross-Site Scripting (XSS), SQL Injection, Server-Side Request Forgery (SSRF), Local File Inclusion (LFI), Remote File Inclusion (RFI), and many other types of common web application vulnerabilities.</p>"},{"location":"tools/ping/","title":"Ping","text":"<p>The \"ping\" command is a widely used network administration utility that tests the reachability of a host on an Internet Protocol (IP) network. It also measures the round-trip time for messages sent from the originating host to a destination computer and back.</p> <p>The ping command sends Internet Control Message Protocol (ICMP) echo request packets to the target host and listens for ICMP echo response replies. This process helps determine whether the target host is reachable across an IP network.</p> <p>Ping measures the time it takes for a packet to go from the source to the destination and back. This measurement is typically presented in milliseconds and is a key indicator of the latency or delay between the two hosts.</p> <p>Ping is commonly used to troubleshoot and diagnose network connectivity issues. If the target host responds to the ping request, it confirms that the network connection between the source and destination is operational.</p> <p>Ping reports errors and packet loss. If packets are lost or an error occurs (like a timeout), it suggests issues in the network such as congestion, faulty routing, or problems with the destination host.</p> <p>While primarily a diagnostic tool, ping can also give a basic sense of network performance. High response times indicate potential problems with the network speed or stability.</p> <p>Some systems and networks block ICMP traffic (hence, the ping command) for security reasons, as ICMP can be used for malicious purposes like network reconnaissance and Denial-of-Service (DoS) attacks.</p> <p>Ping does not give detailed information about the nature of network issues; it only indicates whether a host is reachable.</p> <p>Danger</p> <p>If a ping command does not receive a response, it does not necessarily mean that the host or the entire network is down. Firewall, network policies, or the host configuration might be set to ignore or block ICMP requests.</p> <p>Hackers and pentesters use ping to identify which hosts on a network are online. By sending ICMP echo requests to different IPs on a network, they can map out which addresses are active. The response times and patterns can give insights into the network's topology and efficiency.</p> <p>Different operating systems respond with different values:</p> <ul> <li>Unix/Linux - 64</li> <li>Windows - 128</li> <li>Solaris/AIX - 265</li> </ul> <p>The TTL will be a reflection of this minus the number of hops it took to reach that host. If it took 8 hops to ping a Windows host for example, the TTL may be something like 120 or 119.</p>"},{"location":"tools/procex/","title":"Process Explorer","text":"<p>Process Explorer is a free advanced task manager and system monitoring utility for Windows, developed by Sysinternals, which is now part of Microsoft. It provides detailed information about running processes and system performance, offering more functionality and insights than the standard Task Manager included with Windows.</p> <p>Process Explorer shows comprehensive details about each process, including its parent-child hierarchy, memory usage, handles, threads, and loaded DLLs. It provides real-time information about CPU, memory, disk, and network usage, both system-wide and for individual processes.</p> <p>The utility can show which user account is running each process and the executable path of the process, which is helpful in identifying unknown or suspicious processes. Users can search for specific handles or DLLs being used by processes. This is particularly useful for debugging and for identifying resource or file locks.</p> <p>Process Explorer allows you to kill processes, set process priorities, suspend processes, and more. Processes are color-coded for quick identification (e.g., Windows system processes, third-party application processes, etc.).</p> <p>Process Explorer is used to identify which processes are consuming excessive resources, such as CPU or memory, which can help in diagnosing system slowdowns or crashes. It can help in identifying potentially malicious processes that may not be visible in the standard Task Manager.</p> <p>Developers use Process Explorer to understand the resource usage of their applications and to investigate issues such as memory leaks or handle leaks. In cybersecurity, Process Explorer can be used to detect unusual activity or processes that could indicate a security breach.</p>"},{"location":"tools/proxy/","title":"Burp Proxy","text":"<p>Burp Proxy, part of the [Burp Suite], is a tool used for intercepting and manipulating HTTP requests and responses. It acts as an intermediary between the user's browser and web servers, allowing security testers to inspect and modify the traffic to identify and exploit security vulnerabilities in web applications.</p> <p>Burp Proxy intercepts HTTP and HTTPS requests and responses between the client browser and the web server. This allows users to view and modify the requests sent by the browser and the responses sent by the server.</p> <p>It is widely used for security testing and analysis of web applications. This includes tasks such as tampering with requests, replaying requests, modifying headers, post parameters, and observing the application's responses.</p> <p>To use Burp Proxy, the user's browser must be configured to route traffic through it. This typically involves setting the browser's proxy settings to the host and port where Burp Proxy is listening (by default, it's localhost and port 8080).</p> <p>For HTTPS traffic, Burp Proxy uses its own self-signed CA certificate. The user must install this certificate in their browser to avoid security warnings and to intercept HTTPS traffic properly.</p> <p>Traffic intercepted by Burp Proxy can be sent to other tools within the Burp Suite for further analysis or exploitation, such as Burp Scanner, Burp Intruder, and Burp Repeater. Burp Proxy provides a user-friendly interface for viewing and modifying HTTP/S traffic. It displays requests and responses in a readable format, with syntax highlighting for HTML, JavaScript, CSS, and [[Extensible Markup Language|XML]].</p> <p>Common use cases include modifying sessions, testing for vulnerabilities like Cross-Site Scripting (XSS) or SQL Injection, and understanding the application's logic and data flow. It allows real-time analysis of the traffic, enabling testers to observe how the application responds to various manipulations instantly.</p> <p>While automated tools like Burp Scanner are used for vulnerability scanning, Burp Proxy is essential for manual testing, where the tester's expertise can identify issues that automated tools might miss.</p>"},{"location":"tools/proxychains/","title":"Proxychains","text":"<p>Proxychains is a tool used in Unix-like systems to redirect the network traffic of applications through proxy servers. It allows users to mask their actual IP address and route their internet traffic through one or several proxy servers. </p> <p>This tool is commonly used in penetration testing (pentesting) for various purposes.</p> <p>When used in combination with other tools, proxychains can help in accessing and assessing internal networks that are not directly accessible from the internet. </p> <p>For example, if a penetration tester has compromised an external machine that has access to an internal network, they can use proxychains to route their traffic through the compromised machine.</p>"},{"location":"tools/ps/","title":"Windows PowerShell","text":"<p>Windows PowerShell is a task automation and configuration management framework from Microsoft, consisting of a command-line shell and associated scripting language built on the .NET Framework. PowerShell extends the capabilities of the traditional Command Prompt and provides a more powerful and flexible toolset for managing and automating Windows systems.</p> <p>Unlike the traditional batch scripts of Command Prompt, PowerShell uses a more advanced scripting language that is object-based, not text-based. This allows for more complex and powerful scripts.</p> <p>PowerShell is widely used for automating administrative tasks, managing system configurations, accessing and controlling various Windows components, and handling large numbers of systems efficiently.</p> <p>PowerShell operations are performed using cmdlets (pronounced \"command-lets\"), which are specialized .NET classes implementing particular operations. These cmdlets can be combined, modified, and extended within scripts for complex tasks.</p> <p>PowerShell provides access to the underlying .NET Framework, allowing for sophisticated operations and integration with a wide range of applications and services.</p> <p>After gaining initial access to a system, hackers often use PowerShell for post-exploitation tasks because of its deep integration with Windows environments and its ability to interact with various system components. Malicious PowerShell scripts can be used to execute attacks, gather information, or move laterally within a network.</p>"},{"location":"tools/psexec/","title":"psexec","text":"<p>Impacket's <code>psexec</code> is a script within the Impacket suite that emulates the functionality of Microsoft's PsExec tool. PsExec is a part of the Sysinternals Suite and allows execution of processes remotely by creating a service on the remote system. Impacket's <code>psexec</code> provides similar functionality, enabling users to execute commands or launch an interactive shell on remote Windows machines.</p> <p>It allows for the execution of commands on a remote Windows machine. Users can spawn an interactive shell on the remote system, which is extremely useful for administration tasks or penetration testing scenarios. The script supports NTLM authentication, making it possible to authenticate against remote systems using either a password or an NTLM hash (pass-the-hash). <code>psexec</code> is widely used for legitimate network administration tasks and in penetration testing for gaining remote access to systems.</p> <p>An example:</p> <pre><code>python psexec.py &lt;DOMAIN&gt;/&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;TARGET_IP&gt; cmd.exe\n</code></pre> <ul> <li><code>&lt;TARGET_IP&gt;</code> is the IP address of the target Windows machine.</li> <li><code>cmd.exe</code> is the command to be executed on the remote system. This could be replaced with any command or even a path to an executable script.</li> </ul> <p>If you wish to spawn an interactive shell, you might use the script without specifying a command:</p> <pre><code>python psexec.py &lt;DOMAIN&gt;/&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;TARGET_IP&gt;\n</code></pre>"},{"location":"tools/ptht/","title":"PTH-Toolkit","text":"<p>The \"PTH-Toolkit\" is a set of tools designed to facilitate pass-the-hash (PtH) attacks in penetration testing and security assessment scenarios. Pass-the-hash is a technique where an attacker uses a hashed user credential (rather than the plaintext password) to authenticate to remote servers or services. The PTH-Toolkit leverages this approach to test and exploit systems that are vulnerable to this type of attack.</p> <p>The toolkit allows for the use of NTLM or LanMan hashes to authenticate against various Windows services and protocols, such as SMB, WinRM, and RDP. The toolkit typically includes tools for various protocols, enabling attackers to test multiple attack vectors within a network. It can be used in conjunction with other tools to extract hashes from a system (like Mimikatz) and then use those hashes for further exploitation.</p> <p>While the specific contents of the PTH-Toolkit can vary, it generally includes tools like:</p> <ul> <li>pth-winexe: For executing commands remotely using a hash.</li> <li>pth-wmic: For performing WMI queries with a hash.</li> <li>pth-smbclient: A version of smbclient that accepts NTLM hashes.</li> <li>pth-mssqlclient: For authenticating to SQL Servers using a hash.</li> </ul> <p>An example of using a tool from the PTH-Toolkit might be:</p> <pre><code>pth-winexe -U DOMAIN/user%aad3b435b51404eeaad3b435b51404ee:ed2b1f468c5f915f9cbe9e2fa1c6d345 //&lt;TARGET_IP&gt; cmd.exe\n</code></pre> <ul> <li><code>-U DOMAIN/user%hash</code> specifies the domain, username, and NTLM hash for authentication.</li> <li><code>&lt;TARGET_IP&gt;</code> is the IP address of the target machine.</li> <li><code>cmd.exe</code> is the command to be executed on the remote system.</li> </ul>"},{"location":"tools/pwncat/","title":"Pwncat","text":"<p>pwncat is a command and control framework which turns a basic reverse shell or bind shell into a fully-featured exploitation platform. After initial connection, the framework will probe the remote system to identify useful binaries natively available on the target system. It will then attempt to start a pseudoterminal on the remote host and provide you with raw terminal access.</p> <p>On top of raw terminal access, pwncat can programmatically interact with the remote host alongside your terminal access. pwncat provides you with a local shell interface which can utilize your connection for enumeration, file upload/download, automatic persistence installation and even automated privilege escalation.</p> <p>There are two main operating modes while interacting with a victim in pwncat: remote and local. At any given time, the prompt will include either\u00a0<code>(local)</code>\u00a0or\u00a0<code>(remote)</code>\u00a0to indicate the current mode. When using local mode, you have access to pwncat-specific commands such as upload, download, use, run and exit. In remote mode, you will have access to a platform-specific shell environment (e.g. bash or powershell).</p> <p>To toggle between these modes, you can use the\u00a0<code>C-d</code>\u00a0key combination. This combination is intercepted by pwncat before being sent to the target when in remote mode. If you need to send a\u00a0<code>C-d</code>\u00a0combination directly to the target, you can use the\u00a0<code>C-k</code>\u00a0prefix. Prefixing\u00a0<code>C-d</code>\u00a0or\u00a0<code>C-k</code>\u00a0with\u00a0<code>C-k</code>\u00a0will tell pwncat to send the literaly\u00a0<code>C-d</code>\u00a0or\u00a0<code>C-k</code>\u00a0sequence to the target.</p> <p>Some examples of its usage:</p> <pre><code># netcat syntax\npwncat-cs 192.168.1.1 4444\n# Full connection string\npwncat-cs connect://192.168.1.1:4444\n# Connection string with assumed protocol\npwncat-cs 192.168.1.1:4444\n</code></pre> <p>Info</p> <p>In this case, the victim is running a raw bind shell on an open port. The victim must be available at an address which is routable.</p> <p>You can also connect to a victim encrypted bind shell:</p> <pre><code># Full connection string\npwncat-cs connect://192.168.1.1:4444\n# ncat style syntax\npwncat-cs --ssl 192.168.1.1 4444\npwncat-cs --ssl 192.168.1.1:4444\n</code></pre> <p>Info</p> <p>In this case, the victim is running a ssl-wrapped bind shell on an open port. The victim must be available at an address which is routable (e.g. not NAT\u2019d). The\u00a0<code>ssl-connect</code>\u00a0protocol provides this capability.</p> <p>Or you can catch a victim rev shell:</p> <pre><code># netcat syntax\npwncat-cs -lp 4444\n# Full connection string\npwncat-cs bind://0.0.0.0:4444\n# Assumed protocol\npwncat-cs 0.0.0.0:4444\n# Assumed protocol, assumed bind address\npwncat-cs :4444\n</code></pre> <p>Info</p> <p>In this case, the victim was exploited in such a way that they open a connection to your attacking host on a specific port with a raw shell open on the other end. Your attacking host must be routable from the victim machine. This mode is accessed via the\u00a0<code>bind</code>\u00a0protocol.</p> <p>Or even catch a victim encrypted rev shell:</p> <pre><code># ncat style syntax\npwncat-cs --ssl --ssl-cert cert.pem --ssl-key cert.pem -lp 4444\n# Full connection string\npwncat-cs ssl-bind://0.0.0.0:4444?certfile=/path/to/cert.pem&amp;keyfile=/path/to/key.pem\n# Auto-generated self-signed certificate\npwncat-cs --ssl -lp 4444\n# Auto-generated self-signed certificate with explicit protocol\npwncat-cs ssl-bind://0.0.0.0:4444\n</code></pre> <p>Info</p> <p>In this case, the victim was exploited in such a way that they open an ssl connection to your attacking host on a specific port with a raw shell open on the other end. Your attacking host must be routable from the victim machine. This mode is accessed via the\u00a0<code>ssl-bind</code>\u00a0protocol.</p>"},{"location":"tools/repeater/","title":"Burp Repeater","text":"<p>Burp Repeater is a tool within Burp Suite, a comprehensive platform for web application security testing. Burp Repeater is designed for manual testing and analysis of individual HTTP and WebSocket requests and responses. It allows security testers to modify and resend web requests in a controlled manner. </p> <p>The primary function of Burp Repeater is to allow security testers to manually edit and resend individual HTTP/S requests to a web server without the need for re-navigating through the application in a browser.</p> <p>Burp Repeater is used to thoroughly test the security of web applications by examining how they respond to modified requests, which can include altered parameters, headers, method types, and more</p> <p>It is particularly useful for exploiting vulnerabilities like SQL injection, cross-site scripting, parameter tampering, and others.</p> <p>After modifying and resending requests, Burp Repeater captures the server's response, allowing testers to analyze the impact of their changes. It provides detailed information on HTTP status codes, headers, and the response body.</p> <p>Burp Repeater's interface is straightforward, making it easy to change request parameters and quickly observe the server's response. Requests captured by other Burp Suite tools, like Burp Proxy or Burp Scanner, can be sent to Burp Repeater for further examination and manipulation.</p> <p>Testers can use Burp Repeater to try out different inputs and attack vectors, making it an essential tool for identifying and exploiting vulnerabilities in a targeted and precise manner. Burp Repeater allows testers to open multiple instances (tabs) for comparing the outcomes of different request modifications side by side.</p> <p>In addition to HTTP/S, Burp Repeater supports testing of WebSocket communication, enabling analysis of real-time, interactive communication sessions.</p> <p>By enabling manual control over request editing and analysis, Burp Repeater speeds up the process of vulnerability verification and exploitation.</p>"},{"location":"tools/responder/","title":"Responder","text":"<p>Responder is a network tool used for penetration testing and is particularly effective for conducting LLMNR, NBT-NS, and MDNS poisoning. It is designed to listen for and respond to these broadcast protocols when a system is trying to resolve a hostname on the network. Responder can capture hashed credentials transmitted across the network, which can then potentially be cracked to gain unauthorized access.</p> <p>Responder listens for LLMNR (Link-Local Multicast Name Resolution), NBT-NS (NetBIOS Name Service), and MDNS (Multicast DNS) broadcasts, which occur when a hostname cannot be resolved by a DNS server. Responder then responds to these requests, pretending to be the unresolved hostname.</p> <p>When a Windows computer receives a response from Responder, it often automatically sends hashed user credentials to authenticate. Responder captures these hashes. It can analyze traffic to identify and exploit systems vulnerable to these types of poisoning attacks.</p> <p>In a penetration test, an ethical hacker can use Responder to listen for LLMNR, NBT-NS, and MDNS requests on a network. When a computer issues such a request (e.g., due to a typo in a network share name), Responder can respond and capture the hashed credentials sent by the computer. An example may be:</p> <pre><code>sudo responder -I eth0 -v\n</code></pre> <p>After capturing the hashed credentials, tools like John the Ripper or Hashcat can be used to crack these hashes and potentially obtain plaintext passwords. By observing the types of requests and responses on the network, an attacker can gain insights into network configurations and vulnerabilities.</p>"},{"location":"tools/rsmangler/","title":"rsmangler","text":"<p>RSMangler is a tool used in cybersecurity, particularly in the field of penetration testing and ethical hacking. It's designed to take a list of words (like usernames, passwords, or other identifiers) and generate a set of permutations and variations based on common techniques used by attackers in brute force attacks, password guessing, and dictionary attacks.</p> <p>RSMangler takes an initial wordlist and applies various mangling rules to each word to create a more comprehensive list of potential passwords. It includes common password creation techniques such as:</p> <ul> <li>Adding numbers (like 1, 123) at the beginning or end of words.</li> <li>Capitalizing words.</li> <li>Doubling words.</li> <li>Reversing words.</li> <li>Leet speak conversions (e.g., replacing 'e' with '3', 'a' with '4', etc.)</li> </ul> <p>Users can typically select which mangling rules to apply, depending on their specific needs or the target's likely password policies.</p> <p>In penetration testing, RSMangler helps in creating comprehensive wordlists that mirror the techniques users often employ to create 'complex' passwords. These wordlists can then be used with password cracking tools like John the Ripper or Hashcat. </p> <p>When specific information about a target (like their favorite sports team, birthdate, pet names) is known, these details can be included in the initial wordlist, and RSMangler will apply its rules to generate a more targeted set of potential passwords.</p> <p>An example command may be:</p> <pre><code>rsmangler --file base_words.txt --output mangled_words.txt\n</code></pre>"},{"location":"tools/rsync/","title":"Rsync","text":"<p><code>rsync</code> (short for \"remote synchronization\") is a popular utility for efficiently transferring and synchronizing files across computer systems, using a network connection. It is widely used in Unix-like operating systems, including Linux and macOS, for tasks such as backups, mirroring, and copying files both locally and remotely.</p> <p><code>rsync</code> only transfers the changes or differences within files, rather than copying entire files. This differential transfer reduces the amount of data sent over the network, making it very efficient, especially for updating large files with small changes. It can be used to copy files both locally (on the same machine) and remotely (between different machines over a network).</p> <p><code>rsync</code> compresses data during transfer and can be used with SSH for secure, encrypted data transfers. It can preserve various file attributes during transfer, such as timestamps, ownership, and permissions. The utility can delete files in the destination directory that are no longer present in the source directory, useful for maintaining exact mirrors.</p> <p><code>rsync</code> is commonly used for performing backups by copying files to external drives, network shares, or remote servers. It can mirror data from one server to another, ensuring that both locations have identical sets of files. For copying large sets of files or updating large files that have small changes.</p> <p>Some example commands include a basic file copy:</p> <pre><code>rsync /path/to/source/file /path/to/destination\n</code></pre> <p>Info</p> <p>This command copies a file from the source to the destination directory.</p> <p>Copying files to a remote server:</p> <pre><code>rsync /path/to/source username@remotehost:/path/to/destination\n</code></pre> <p>Info</p> <p>This command copies files from the local machine to a remote server using SSH.</p> <p>For synchronizing directories:</p> <pre><code>rsync -av --delete /path/to/source/ /path/to/destination/\n</code></pre> <p>Info</p> <p>The <code>-a</code> flag preserves attributes, and <code>-v</code> provides verbose output. <code>--delete</code> removes files from the destination that are not in the source directory.</p> <p>Or for creating an incremental backup:</p> <pre><code>rsync -av --link-dest=/path/to/previous/backup /path/to/source/ /path/to/current/backup\n</code></pre> <p>Info</p> <p>This creates an incremental backup, where only changes are stored, using hard links to unchanged files in the previous backup.</p>"},{"location":"tools/scanner/","title":"Burp Scanner","text":"<p>Burp Scanner is a feature within Burp Suite which is an integrated platform for performing security testing of web applications. Burp Scanner is a web vulnerability scanner that automates the process of detecting security vulnerabilities. It's designed to be used alongside manual testing and provides a comprehensive solution for web application security checks.</p> <p>Burp Scanner automatically crawls and scans web applications for a wide range of security vulnerabilities. It performs both passive and active scans. </p> <ol> <li>Types of Scans:<ul> <li>Passive Scanning: Analyzes the application's traffic and identifies issues without sending any unusual requests or payloads.</li> <li>Active Scanning: Proactively sends requests to the application, testing inputs and functionality for specific vulnerabilities.</li> </ul> </li> </ol> <p>Burp Scanner can detect various types of security issues, including SQL injection, cross-site scripting (XSS), Broken Authentication, path traversal, and many others.</p> <p>Before scanning, Burp Scanner crawls the application to map out the content and functionality. This crawl data is used to guide the active scanning process. Findings from the scanner can be further analyzed and exploited using other tools in the Burp Suite, such as Burp Intruder, Burp Repeater, and Burp Extender.</p> <p>The scanner allows for significant customization of scan settings, enabling testers to tailor the scan to the specific application and to focus on particular areas or types of vulnerabilities. Burp Scanner generates detailed reports of its findings, which include information about the vulnerabilities, their severity, potential impact, and recommendations for remediation.</p>"},{"location":"tools/seclists/","title":"SecLists","text":"<p>SecLists is a collection of multiple types of lists used during security assessments and penetration testing. It is an open-source project, widely used by security professionals and ethical hackers. </p> <p>The lists included in SecLists cover a wide range of purposes and are often used for various types of security testing and analysis.</p>"},{"location":"tools/secretsdump/","title":"secretsdump","text":"<p>Impacket's <code>secretsdump</code> is a powerful tool in the Impacket suite designed to extract various types of credentials from Windows systems. It's commonly used in penetration testing and cybersecurity assessments to extract sensitive information from compromised machines.</p> <p><code>secretsdump</code> can extract NTLM password hashes from the Security Account Manager (SAM) database found on Windows systems. These hashes can be cracked offline to potentially reveal user passwords. The tool can extract LSA (Local Security Authority) secrets, which might include stored credentials for services and applications.</p> <p>It can also retrieve cached domain credentials stored on the system, which are useful in environments where machines frequently authenticate with a domain controller. In a domain environment, <code>secretsdump</code> can be used to extract credentials from an Active Directory Domain Controller, including NTLM hashes of all domain users.</p> <p>The tool can extract Domain backup keys used in DPAPI (Data Protection API) system, which can be used to decrypt other DPAPI-protected data.</p> <p>A basic example may be:</p> <pre><code>python secretsdump.py &lt;DOMAIN&gt;/&lt;USERNAME&gt;:&lt;PASSWORD&gt;@&lt;TARGET_IP&gt;\n</code></pre> <p>Info</p> <p>The output will typically include a list of user accounts and their corresponding NTLM hashes, among other information.</p>"},{"location":"tools/setspn/","title":"SetSPN","text":"<p><code>SetSPN</code> is a command-line tool provided by Microsoft that is used to manage Service Principal Names (SPN) for Windows services in an Active Directory environment. SPNs are used in Kerberos authentication to uniquely identify a service instance on a network. The <code>SetSPN</code> tool allows administrators to view, modify, and delete SPNs associated with Active Directory service accounts.</p> <p><code>SetSPN</code> can list the SPNs registered to a specific service account in Active Directory. This is important for ensuring that services are correctly configured for Kerberos authentication. Administrators use <code>SetSPN</code> to add new SPNs to a service account. This is necessary when new services are deployed or when services are changed.</p> <p>If an SPN needs to be changed or if it's incorrectly set, <code>SetSPN</code> can modify or remove the SPN from an account. Since incorrect SPN configuration can lead to Kerberos authentication failures, <code>SetSPN</code> is often used in troubleshooting related issues.</p> <p>Some usage examples include assigning an SPN to a service account:</p> <pre><code>setspn -S HTTP/webserver.domain.com DOMAIN\\ServiceAccount\n</code></pre> <p>Info</p> <p>This command registers the SPN <code>HTTP/webserver.domain.com</code> for the specified service account. The <code>-S</code> parameter automatically checks for duplicates before adding the SPN.</p> <p>Or listing SPNs for a service account:</p> <pre><code>setspn -L DOMAIN\\ServiceAccount\n</code></pre> <p>Info</p> <p>This command lists all SPNs registered to <code>ServiceAccount</code>.</p> <p>You can even remove an SPN:</p> <pre><code>setspn -D HTTP/webserver.domain.com DOMAIN\\ServiceAccount\n</code></pre> <p>Info</p> <p>This command removes the specified SPN from <code>ServiceAccount</code>.</p> <p>As an example:</p> <p>In a company, an IT administrator sets up a new web application server <code>webserver.domain.com</code> that needs to authenticate users via Kerberos. The administrator assigns an SPN to the service account running the web service using <code>SetSPN</code>. This ensures that when users access the web application, the Kerberos authentication process can correctly identify and authenticate the service using the SPN.</p>"},{"location":"tools/smbclient/","title":"smbclient","text":"<p>Impacket's <code>smbclient</code> is a tool within the Impacket suite that acts similarly to Microsoft's command-line SMB client. It's used for interacting with SMB/CIFS shares on Windows and other systems that support the SMB/CIFS protocol. With Impacket's <code>smbclient</code>, you can list shares, upload, download, delete files, and create or remove directories on the SMB server.</p> <p>You can enumerate shares available on the SMB server. You can also upload, download, delete files, and create or delete directories on the SMB server. Some versions allow for executing commands on the server. Finally, it supports NTLM authentication, making it useful for testing and exploiting Windows networks.</p> <p>A basic example of how to use Impacket's <code>smbclient</code> to list shares on a remote SMB server. This example assumes you have Impacket installed and are running its scripts from the command line:</p> <pre><code>python smbclient.py 'DOMAIN/username:password'@&lt;IP_ADDRESS&gt;\n</code></pre> <p>After running this command, you will be presented with an interactive SMB shell where you can run commands like <code>ls</code>, <code>put</code>, <code>get</code>, <code>mkdir</code>, <code>rmdir</code>, etc., to interact with the server's file system.</p> <p>For instance, to list files in a share named <code>SHARENAME</code>, you would use:</p> <pre><code>smb&gt; use SHARENAME\nsmb&gt; ls\n</code></pre>"},{"location":"tools/smbrelayx/","title":"smbrelayx","text":"<p>Impacket's <code>smbrelayx</code> is a tool designed for performing SMB relay attacks. An SMB relay attack is a type of security exploit where an attacker intercepts and relays SMB (Server Message Block) authentication requests from one computer to another on the network. This tool is part of the Impacket suite, a collection of Python classes and tools for working with network protocols.</p> <p>The primary function of <code>smbrelayx</code> is to relay SMB authentication sessions from one host to another. It captures the authentication request from one machine and forwards it to a second machine, effectively impersonating the first machine. <code>smbrelayx</code> facilitates a man-in-the-middle (MitM) position where it can intercept and manipulate SMB traffic.</p> <p>One of the significant aspects of SMB relay attacks is that the attacker doesn't need to know the user's password. The tool uses the authentication session itself to gain access. Once authentication is relayed and access is gained, <code>smbrelayx</code> can be used to execute arbitrary commands on the target machine.</p> <p>An example of how you might use Impacket's <code>smbrelayx</code> in a command-line environment:</p> <pre><code>python smbrelayx.py -h &lt;TARGET_IP&gt; -e /path/to/executable\n</code></pre> <ul> <li><code>-h &lt;TARGET_IP&gt;</code>: The IP address of the target machine where you want to relay the SMB authentication.</li> <li><code>-e /path/to/executable</code>: Path to an executable file that will be run on the target machine upon successful relay.</li> </ul> <p>Info</p> <p>In a typical SMB relay attack scenario, the attacker would need to be in a position to intercept SMB traffic, which might involve [[ARP poisoning]] or other network manipulation techniques.</p>"},{"location":"tools/smbserver/","title":"smbserver","text":"<p>Impacket's <code>smbserver</code> is a script in the Impacket suite that allows you to set up a simple SMB (Server Message Block) server on your machine. This can be incredibly useful for various network operations and penetration testing scenarios where you need an SMB server for file sharing, file transfer, or exploitation tasks.</p> <p>It allows for the quick setup of an SMB server without the need for complex configuration or additional software beyond Python and Impacket. You can use it to share files across the network, making it useful for transferring files to and from a target during a penetration test or network administration tasks.</p> <p><code>smbserver</code> supports different versions of the SMB protocol, enhancing its compatibility with various Windows versions. In penetration testing, it can be used to host payloads, capture hashed credentials, or serve as part of an exploitation chain.</p> <p>A basic usage example:</p> <pre><code>python smbserver.py SHARE_NAME /path/to/shared/folder\n</code></pre> <ul> <li><code>SHARE_NAME</code> is the name of the SMB share that will be created.</li> <li><code>/path/to/shared/folder</code> is the local path to the directory that you want to share over SMB.</li> </ul> <p>Info</p> <p>Once run, this command will start an SMB server on your machine, sharing the specified folder under the given share name. Other machines on your network can then access this share.</p>"},{"location":"tools/sqlmap/","title":"SQLMap","text":"<p>SQLMap is an open-source penetration testing tool that automates the process of detecting and exploiting SQL injection flaws and taking over of database servers. It provides a powerful testing environment for SQL injection, which is a common security vulnerability in web applications.</p> <p>SQLMap can detect and enumerate various types of SQL injection vulnerabilities, including boolean-based blind, time-based blind, error-based, UNION query-based, and stacked queries.</p> <p>It can exploit SQL injection vulnerabilities to take over the database server. This means it can execute arbitrary commands on the server, access the underlying file system, and retrieve data from the database.</p> <p>SQLMap works with a wide range of database systems, such as MySQL, Oracle, PostgreSQL, Microsoft SQL Server, Microsoft Access, IBM DB2, SQLite, Firebird, Sybase, and SAP MaxDB.</p>"},{"location":"tools/suite/","title":"LFISuite","text":"<p>LFISuite is a security tool designed to exploit and detect Local File Inclusion (LFI) vulnerabilities in web applications. Local File Inclusion is a common security vulnerability that occurs when a web application allows an attacker to include files on a server through the web browser. This can lead to unauthorized access or disclosure of sensitive data.</p> <p>LFISuite typically provides automated ways to exploit LFI vulnerabilities. It can automatically test for these vulnerabilities in a web application. It usually includes a range of techniques to exploit LFI vulnerabilities, such as directory traversal, null byte injection, and other methods commonly used in LFI attacks.</p> <p>The tool can be used to extract sensitive data from the server, such as password files, configuration files, and other critical data accessible through the file system. Some versions of LFISuite or similar tools might also attempt to escalate the LFI vulnerability to execute commands on the server, leading to Remote Code Execution (RCE) if the server is misconfigured.</p>"},{"location":"tools/sysint/","title":"Sysinternals Suite","text":"<p>The Sysinternals Suite is a collection of powerful system utilities and diagnostic tools for Microsoft Windows, created by Mark Russinovich and Bryce Cogswell.</p> <p>These utilities are designed to help manage, troubleshoot, and diagnose Windows systems and applications. They are widely used by system administrators, IT professionals, and security experts for in-depth analysis of Windows systems.</p> <p>Some key tools include:</p> <ol> <li>Process Explorer: Provides detailed information about running processes and DLLs that they have loaded, which is more comprehensive than the standard Windows Task Manager.</li> <li>Process Monitor: An advanced monitoring tool for Windows that shows real-time file system, Registry, and process/thread activity.</li> <li>Autoruns: Shows which programs are configured to run during system bootup or login, and the full list of Registry and file system locations available for auto-start configuration.</li> <li>TCPView: Displays detailed listings of all TCP and UDP endpoints on your system, including the local and remote addresses and state of TCP connections.</li> <li>Sysmon (System Monitor): Provides advanced monitoring and logging capabilities that help detect malicious activity and aid in understanding how intruders may have breached a system.</li> <li>BgInfo: Automatically displays relevant information about a Windows computer on the desktop's background.</li> </ol>"},{"location":"tools/sysmon/","title":"Sysmon (System Monitor)","text":"<p>System Monitor, also known as Sysmon, is a utility provided by Sysinternals (now part of Microsoft) designed to monitor and log system activity to the Windows event log. It's a powerful tool often used in security monitoring and forensic analysis because it provides detailed information about process creations, network connections, and changes to file creation time.</p> <p>Sysmon can log detailed information about process creations, network connections, driver loading, file creation, and more. This information is crucial for understanding the behavior of the system and identifying malicious or suspicious activity. </p> <p>Sysmon allows users to specify complex filtering rules, making it possible to capture only the relevant events. This helps in reducing the volume of logged data and focusing on potential security threats. Sysmon events are written to the Windows event log, which can be viewed using standard Windows tools like Event Viewer or integrated with central logging and SIEM (Security Information and Event Management) solutions.</p> <p>Once installed and configured, Sysmon runs in the background as a Windows service, persistently monitoring the system for activity that matches its configuration rules.</p> <p>Sysmon is widely used in cybersecurity for real-time monitoring of systems to detect signs of compromise or suspicious activity. During incident response, Sysmon data can provide valuable insights into what occurred on a system leading up to and during a security incident. Security professionals use Sysmon logs to hunt for indicators of compromise (IOCs) and tactics, techniques, and procedures (TTPs) used by attackers.</p> <p>Consider a scenario where a company's IT department is alerted about potential malware activity on a networked computer. Sysmon, installed on the system, provides detailed logs showing:</p> <ul> <li>A previously unknown process was created.</li> <li>This process made suspicious network connections to an external server.</li> <li>The process also attempted to modify system files and registry keys.</li> </ul>"},{"location":"tools/tcpdump/","title":"Tcpdump","text":"<p>tcpdump is a widely-used command-line network packet analyzer or sniffer program that captures network packets transmitted over a network and displays their contents in a detailed format. It's available on most Unix-like operating systems.</p> <p>It can capture all types of packets on network interfaces, including TCP, UDP, ICMP, and others.</p>"},{"location":"tools/tcpview/","title":"TCPView","text":"<p>TCPView is a Windows program that is part of the Sysinternals suite, now owned by Microsoft. This utility provides a more informative and user-friendly view of the TCP and UDP endpoints on your system than the standard netstat command that comes with Windows. TCPView displays a list of all active TCP and UDP endpoints, along with the details of the owning processes.</p> <p>TCPView shows both local and remote addresses and the state of TCP connections. For each endpoint, it displays the full name of the process that opened the port. The utility updates the list of TCP and UDP endpoints in real-time, making it easier to monitor network activity as it happens.</p> <p>Unlike command-line tools like netstat, TCPView has a graphical user interface that makes it more accessible to users who are less comfortable with command-line operations. TCPView links each network connection to the process that owns it, which can be very useful for tracking down which process is responsible for a particular network activity. Users can close established TCP/IP connections and terminate processes through the TCPView interface.</p> <p>TCPView can be used to quickly identify unexpected network connections or processes that are using network resources, which is helpful in diagnosing network-related issues. Security professionals use TCPView to monitor for suspicious network activities, such as unusual outbound connections that could indicate malware activity or data exfiltration attempts.</p> <p>For system administrators, TCPView provides a quick way to check which applications are making connections to or from a server.</p> <p>Imagine you notice your computer is behaving sluggishly, and you suspect there might be an unauthorized application using your network. You open TCPView and immediately see a list of all network connections. You spot an unfamiliar process with several outbound connections to unknown remote IP addresses. This observation can lead you to further investigate this process, potentially identifying and stopping malicious software.</p>"},{"location":"tools/tgsrepcrack/","title":"tgsrepcrack","text":"<p><code>tgsrepcrack</code> is a security tool used in the context of network penetration testing and ethical hacking, particularly when exploiting the Kerberos protocol in Windows environments. The tool is designed to crack the encryption of Kerberos Ticket Granting Service (TGS) response messages, also known as TGS-REP messages.</p> <p><code>tgsrepcrack</code> is used to decrypt the encrypted part of a Kerberos TGS-REP (Ticket Granting Service Reply) ticket. This ticket is encrypted with the target service's password. The tool applies brute-force or dictionary-based attacks to guess the password of the service account associated with the SPN (Service Principal Name) of the TGS ticket.</p> <p>In a technique known as Kerberoasting, attackers or ethical hackers request TGS tickets for service accounts in an Active Directory environment. These tickets are encrypted with the service account's password hash. Using tools like mimikatz, an attacker can extract the TGS ticket from memory on a compromised host.</p> <p>The extracted TGS ticket is then fed into <code>tgsrepcrack</code> along with a wordlist to attempt to crack the password.</p>"},{"location":"tools/tplmap/","title":"Tplmap","text":"<p>Tplmap is a penetration testing tool designed for automating the identification and exploitation of Server-Side Template Injection (SSTI) vulnerabilities in web applications. SSTI vulnerabilities occur when user input is directly embedded into server-side templates without proper validation or sanitization, allowing attackers to inject and execute arbitrary code on the server.</p> <p>Tplmap is designed to be template engine agnostic, meaning it can identify and exploit SSTI vulnerabilities in various template engines used by web applications. It supports popular template engines such as Jinja2, Mako, Smarty, and more.</p> <p>The tool automates the process of detecting SSTI vulnerabilities by analyzing how user-supplied input is processed within the server-side templates. It aims to identify injection points where payloads can be injected for exploitation. </p> <p>Tplmap provides capabilities for exploiting identified SSTI vulnerabilities by injecting payloads and observing the resulting output. This allows penetration testers to assess the impact of the vulnerability and understand the extent of code execution.</p> <p>Tplmap comes with a set of predefined payloads that can be used for testing and exploiting SSTI vulnerabilities. These payloads are crafted to trigger code execution and showcase the severity of the vulnerability. Tplmap offers an interactive mode that enables penetration testers to manually explore and exploit SSTI vulnerabilities. This mode allows for more fine-tuned testing and analysis.</p> <p>Tplmap supports template engines used in different programming languages, making it versatile for testing web applications built with various technologies.</p> <p>A usage example:</p> <pre><code>tplmap -u \"http://example.com/page?input={{INJECTION_POINT}}\" --os-cmd 'uname -a'\n</code></pre> <p>Tplmap is instructed to test the specified URL with the provided injection point (<code>{{INJECTION_POINT}}</code>) and execute the operating system command <code>uname -a</code> to check the underlying system details.</p>"},{"location":"tools/traceroute/","title":"Traceroute","text":"<p>Traceroute is a network diagnostic tool used for tracking the path that an Internet Protocol (IP) packet takes from its source to its destination. It reports the IP address of all the Routers it traverses until it reaches the destination or times out. Traceroute is used to diagnose network routing issues and to gain insight into the path network traffic takes to reach its destination. </p> <p>Traceroute is used to diagnose network connectivity issues, such as delays or failures in data transmission. It helps in understanding the path (route) taken by packets across a network, which can be crucial for troubleshooting network issues or for performance analysis.</p> <p>Traceroute sends a sequence of Internet Control Message Protocol (ICMP) echo request packets to the destination with incrementally increasing Time-To-Live (TTL) field values. The TTL value limits the number of hops a packet can take.</p> <p>Each router along the path decrements the TTL value of the packet by one, and when the TTL value reaches zero, the router drops the packet and sends back an ICMP \"Time Exceeded\" message to the sender.</p> <p>By incrementing the TTL and receiving Time Exceeded messages, traceroute can determine the path the packets take to reach the destination.</p> <p>The output of traceroute shows a list of hops (routers or switches) that the packets traverse on their way to the destination. Along with the address of each hop, traceroute usually displays the time taken to reach that hop, often measured in milliseconds.</p> <p>Some routers and firewalls are configured to block ICMP packets or limit their processing, which can cause traceroute to give incomplete or misleading results. Traceroute only shows the path from the source to the destination at the time it's run. Network routes can dynamically change, so the path might be different at different times.</p>"},{"location":"tools/waf/","title":"identYwaf","text":"<p>IdentYwaf is an open-source tool designed for identifying web application firewalls (WAFs). A web application firewall is a security solution that monitors and potentially blocks HTTP traffic to and from a web application to protect it from malicious attacks such as SQL injection, cross-site scripting (XSS), file inclusion, and others.</p> <p>IdentYwaf is used to identify the type of WAF or protection used by a web server. This is crucial for cybersecurity professionals and ethical hackers who need to understand the security environment they are working with, whether for penetration testing or for assessing the security of a web application.</p> <p>It works by sending various types of payloads to the server and analyzing the responses. Different WAFs will react in unique ways to these payloads, allowing IdentYwaf to identify them based on the patterns in the responses.</p> <p>IdentYwaf is a valuable tool in the arsenal of ethical hackers, who use it to test the effectiveness of WAFs and other security measures. By identifying the WAF, they can better understand how to approach a security assessment and which vulnerabilities might be more likely to exist.</p> <p>Being open-source, it is available for anyone to use and modify. This makes it accessible to a wide range of users, from professional cybersecurity experts to students and hobbyists interested in web security.</p> <p>While IdentYwaf is a powerful tool for security testing, it's important to use it ethically and legally. Unauthorized testing or attempting to bypass security measures on websites without permission is illegal and unethical.</p>"},{"location":"tools/wafwoof/","title":"Wafw00f","text":"<p>WAFW00F is a tool designed to help identify and fingerprint Web Application Firewalls (WAFs) that are protecting a website. WAFs are security solutions that monitor and filter HTTP traffic to and from a web application to protect it against various types of attacks such as SQL injection, cross-site scripting (XSS), and others.</p> <p>It works by sending a series of HTTP requests that are crafted in specific ways to a target website. Based on the responses, it attempts to determine whether a WAF is present and which one.</p> <p>Different WAFs have unique ways of responding to malicious or malformed traffic. Wafw00f analyzes these responses to figure out the type of WAF in use including popular ones like ModSecurity, Cloudflare, AWS WAF and others.</p>"},{"location":"tools/wapp/","title":"Wappalyzer","text":"<p>Wappalyzer is a technology profiler that uncovers the technologies used on websites.</p> <p>It helps in identifying various types of technologies such as content management systems, eCommerce platforms, web frameworks, server software, analytics tools, and many others.</p> <p>Wappalyzer can be used by web developers, researchers, and businesses to gain insights into how a website is built or for competitive analysis.</p>"},{"location":"tools/wayback/","title":"Wayback Machine","text":"<p>The Wayback Machine, operated by the Internet Archive, is a web archiving service that captures and stores snapshots of websites and web pages at various points in time.</p> <p>It is a valuable resource for accessing historical web content and tracking the evolution of websites over the years. The Wayback Machine's extensive archive provides insights into how websites have changed, what content was present in the past, and potentially sensitive information that may have been inadvertently exposed.</p> <p>In the context of a web penetration test (pentest) or passive infrastructure identification, the Wayback Machine can be used as a reconnaissance tool to gather information about a target organization's online presence and infrastructure.</p> <p>It can be used to review historical versions of a target organization's website, allowing them to identify past configurations, content, design changes, and any potential security issues that may have existed in the past.</p> <p>It also may reveal subdomains associated with the target that are no longer visible on the main site. It may also provide information about the tech and web frameworks used by the target site at different points in time.</p>"},{"location":"tools/wce/","title":"Windows Credential Editor (WCE)","text":"<p>Windows Credential Editor (WCE) is a security tool that's used primarily in penetration testing and forensic analyses. It is designed to extract various types of passwords and credentials from Windows operating systems.</p> <p>While it shares some functionality with other well-known tools like Mimikatz, WCE is specifically known for its ability to harvest password hashes and plaintext passwords from memory, as well as perform pass-the-hash attacks.</p> <p>WCE can extract plaintext passwords and NTLM hashes stored in memory by the Windows authentication system. This includes active logins and session data. WCE allows attackers to use captured NTLM hashes for authenticating to other systems without needing the plaintext password. This is especially useful in lateral movement within a network.</p> <p>It can obtain credentials from both 32-bit and 64-bit Windows versions and is capable of working in different Windows environments, from XP through Windows 10 and server variants.</p> <p>An example usage could be for extracting passwords and hashes:</p> <pre><code>wce.exe -w\n</code></pre> <p>Info</p> <p>This command runs WCE to extract plaintext passwords (<code>-w</code>) from memory.</p> <p>Or even for a pass-the-hash attack:</p> <pre><code>wce.exe -s &lt;USERNAME&gt;:&lt;NTLM_HASH&gt;\n</code></pre> <p>Info</p> <p>This uses WCE to perform a pass-the-hash attack using the specified username and NTLM hash.</p>"},{"location":"tools/wfuzz/","title":"Wfuzz","text":"<p>Wfuzz is a flexible tool for brute forcing internet resources. It's widely used in penetration testing and ethical hacking to discover hidden resources on web servers. Unlike many other tools, Wfuzz is known for its versatility and ability to be tailored for different tasks.</p> <p>Wfuzz can be used to brute force various web elements, including URLs, parameters, forms, headers, and cookies. It also allows for the injection of payloads at multiple points, making it possible to test input vectors in GET and POST requests, cookies, headers, file uploads, and more.</p> <p>Wfuzz allows testers to identify resources based on the server's response (like HTTP response codes, response length, or response time). This makes it easier to identify valid resources even when there's no clear indication in the server's response text.</p> <p>A simple example may be:</p> <pre><code>wfuzz -c -z file,wordlist.txt --hc 404 http://target-site/FUZZ\n</code></pre> <ul> <li><code>-c</code>: Colorize the output for better visibility.</li> <li><code>-z file,wordlist.txt</code>: Use the \"wordlist.txt\" file as a source of fuzzing payloads.</li> <li><code>--hc 404</code>: Ignore HTTP responses with a status code of 404 (not found).</li> <li><code>http://target-site/FUZZ</code>: Specify the target URL where \"FUZZ\" will be replaced with payloads from the wordlist.</li> </ul> <p>Info</p> <p>WFuzz will attempt to access different directories and files on the target web server by replacing \"FUZZ\" with each word from the \"wordlist.txt\" file. If a directory or file exists, it will return a valid HTTP response code (e.g., 200). The tool reports the discovered directories and files.</p>"},{"location":"tools/whatweb/","title":"WhatWeb","text":"<p>WhatWeb is an open-source web fingerprinting tool used for web application discovery and profiling.</p> <p>It is designed to help identify and gather information about web applications and websites by analyzing their response headers, HTML, JavaScript, and other web page components.</p> <p>WhatWeb is particularly useful for reconnaissance and passive information gathering during web application security assessments, penetration testing, and vulnerability assessments.</p> <p>1WhatWeb uses a collection of signature-based techniques to \"fingerprint\" web applications and identify the technologies, frameworks, and software components they use.</p> <p>This can include web servers, content management systems (CMS), programming languages, JavaScript libraries, and more.</p> <p>While primarily focused on HTTP and HTTPS, WhatWeb can also analyze other web-related protocols and services, such as FTP, SSH, and SMB, to gather information about a target.</p>"},{"location":"tools/wireshark/","title":"wireshark","text":"<p>Wireshark is a network protocol analyzer, or an application that captures packets from a network connection, such as from your computer to your home office or the internet.</p> <p>Wireshark has many uses, including\u00a0troubleshooting networks that have performance issues. Cybersecurity professionals often use Wireshark to trace connections, view the contents of suspect network transactions and identify bursts of network traffic.</p> <p>Wireshark is primarily used to capture packets of data moving through a network. The tool allows users to put network interface controllers (NICs) into promiscuous mode to observe most traffic, even unicast traffic, which is not sent to a controller\u2019s MAC address.</p> <p>Warning</p> <p>However, doing this normally requires superuser permissions and may be restricted on some networks.</p> <p>Even without that ability, Wireshark is able to sniff out most packets flowing through a network, no matter the OS, the networking protocol, encryption method or file format.</p>"},{"location":"tools/wmiexec/","title":"wmiexec","text":"<p>Impacket's <code>wmiexec</code> is a tool within the Impacket suite that allows for the execution of commands on Windows systems using the Windows Management Instrumentation (WMI) service. It provides a semi-interactive shell for running commands remotely on Windows machines. This tool is particularly useful in penetration testing and network administration for executing commands on remote systems without needing to deploy an agent.</p> <p>Some key features include:</p> <ol> <li>Command Execution via WMI: Executes Windows commands remotely using WMI, a Windows management service.</li> <li>Semi-Interactive Shell: Provides a shell-like interface to run commands on the remote system.</li> <li>No Agent Required: Unlike some remote execution tools, <code>wmiexec</code> doesn't require you to install an agent on the target system; it only needs appropriate credentials and network access.</li> <li>Supports Authentication: Compatible with NTLM authentication, allowing it to work in typical Windows network environments.</li> </ol> <p>An example of how you might use Impacket's <code>wmiexec</code> to run commands on a remote Windows machine. This assumes you have Impacket installed and network access to the target machine:</p> <pre><code>python wmiexec.py 'DOMAIN/username:password'@&lt;TARGET_IP_ADDRESS&gt;\n</code></pre> <p>After running this command, you will be presented with a command-line interface where you can type and execute commands on the remote machine. For example:</p> <pre><code>C:\\&gt; ipconfig /all\n</code></pre> <p>Info</p> <p>This would display the IP configuration details of the remote machine.</p>"},{"location":"tools/wpscan/","title":"WPScan","text":"<p>WPScan is a free, for non-commercial use, black box WordPress vulnerability scanner that can be used to scan WordPress websites for security vulnerabilities. It's a command-line tool written in Ruby, and it's widely used by WordPress administrators, security professionals, and ethical hackers to assess the security of WordPress sites.</p> <p>WPScan can enumerate WordPress usernames, which can be used in brute force attacks. It can identify the plugins and themes installed on a WordPress site, along with their versions. This is useful for finding potential vulnerabilities associated with specific versions.</p> <p>WPScan has a database of known WordPress vulnerabilities and can check a site against this database to identify known security issues. WPScan can perform password brute force attacks to test the strength of user passwords. It can detect which WordPress version is being used and whether it's up-to-date or vulnerable.</p> <p>WPScan can check for vulnerabilities in the Timthumb script, which was commonly used in older WordPress installations.</p> <p>To scan a WordPress site, you can use the command:</p> <pre><code>wpscan --url [website-url]\n</code></pre> <p>To enumerate users:</p> <pre><code>wpscan --url [website-url] --enumerate u\n</code></pre> <p>To enumerate plugins:</p> <pre><code>wpscan --url [website-url] --enumerate p\n</code></pre> <p>To enumerate themes:</p> <pre><code>wpscan --url [website-url] --enumerate t\n</code></pre> <p>You can also perform a password attack:</p> <pre><code>wpscan --url [website-url] --passwords [path-to-password-file]\n</code></pre> <p>Info</p> <p>WPScan's vulnerability database is updated regularly, so it's important to update WPScan frequently to ensure it has the latest information.</p>"},{"location":"tools/wpvulndb/","title":"WPVulnDB","text":"<p>WPVulnDB is a database that catalogs known security vulnerabilities in WordPress, its plugins, and themes. WordPress is a widely used content management system (CMS) for websites, and like all software, it can have security vulnerabilities. WPVulnDB aims to provide a comprehensive and up-to-date resource for web developers, site administrators, and security professionals to track and address these vulnerabilities.</p> <p>It lists vulnerabilities found in the WordPress core software, as well as in numerous plugins and themes that are part of the WordPress ecosystem. These listings usually include details about the type of vulnerability (e.g., SQL injection, cross-site scripting, etc.), its severity, and the affected versions of the software.</p> <p>As new vulnerabilities are discovered, they are added to the database. This regular updating helps users stay aware of the latest security risks. WPVulnDB often provides an API (Application Programming Interface) that allows developers to integrate vulnerability data into their tools and workflows, enabling automated checks for vulnerable plugins or themes on WordPress sites.</p> <p>Alongside listing vulnerabilities, WPVulnDB may also provide advisories on how to mitigate or fix the vulnerabilities, which can include patching or updating to newer, secure versions of the software. Security researchers and contributors can submit information about new vulnerabilities, making WPVulnDB a community-driven resource.</p>"},{"location":"tools/xsser/","title":"XSSer","text":"<p>XSSer, short for \"Cross Site Scripter,\" is an open-source penetration testing tool specifically designed for detecting and exploiting Cross-Site Scripting (XSS) vulnerabilities in web applications.</p> <p>XSS vulnerabilities are security flaws that allow attackers to inject malicious scripts into web pages viewed by other users. XSSer is part of the arsenal of tools used by security professionals, such as penetration testers and ethical hackers, to assess the security of web applications.</p> <p>XSSer automates the process of sending various payloads to a target web application to test for different types of XSS vulnerabilities, including reflected, stored, and DOM-based XSS.</p> <p>It comes with a payload generator that can create various types of encoded and obfuscated scripts designed to bypass basic security filters and reveal vulnerabilities. XSSer can crawl websites to automatically discover points where XSS payloads can be injected, such as forms and URL parameters.</p>"},{"location":"tools/xsshunter/","title":"XSSHunter","text":"<p>XSSHunter is a tool designed for detecting and analyzing Cross-Site Scripting (XSS) vulnerabilities. It's commonly used by security researchers and penetration testers to identify areas where an application might be vulnerable to XSS attacks.</p> <p>XSSHunter works by providing a specialized payload that can be injected into target web applications. When the payload is executed as part of an XSS attack, it sends information back to XSSHunter, allowing the researcher to see how the payload interacted with the web application.</p> <p>This feedback includes details such as cookie data, the origin of the script execution, and other context that is useful for understanding the scope and impact of the vulnerability. XSSHunter is particularly valuable for detecting blind XSS vulnerabilities, where immediate feedback is not visible in the application's response.</p>"},{"location":"tools/xssstrike/","title":"XSS Strike","text":"<p>\"XSS Strike\" is a tool specifically designed for detecting and exploiting XSS vulnerabilities in web applications.</p> <p>XSS, which stands for Cross-Site Scripting, is a common security vulnerability that allows attackers to inject malicious scripts into webpages viewed by other users. XSS Strike is used in the field of web application security, particularly in penetration testing and vulnerability assessments, to identify and demonstrate the presence of XSS vulnerabilities.</p> <p>XSS Strike scans web applications to identify potential XSS vulnerabilities where malicious scripts could be injected. It goes beyond detection, providing mechanisms to exploit identified XSS vulnerabilities. This can help in demonstrating the potential impact of the vulnerability.</p>"},{"location":"tools/xxeinjector/","title":"XXEInjector","text":"<p>XXEInjector is a tool designed for penetration testers and security researchers to exploit XML External Entity (XXE) vulnerabilities in web applications. XXE vulnerabilities occur when an XML parser processes XML input containing a reference to an external entity, leading to unauthorized access to server data, denial of service, or server-side request forgery.</p> <p>XXEInjector automates the process of exploiting XXE vulnerabilities. It can be used to test whether a web application is vulnerable to XXE attacks and to what extent. The tool supports different types of XXE attacks, including retrieving files, performing SSRF (Server-Side Request Forgery) attacks, listing directories, and more.</p> <p>XXEInjector can handle various techniques like classic XXE, blind XXE, and even out-of-band (OOB) XXE, where the XML parser sends data to an attacker-controlled server. The tool allows customization of XML payloads to test different attack scenarios and parser configurations.</p>"},{"location":"tools/zap/","title":"OWASP ZAP","text":"<p>OWASP ZAP (Zed Attack Proxy) is an open-source tool used for identifying security vulnerabilities in web applications. It is developed by OWASP (Open Web Application Security Project), a prominent organization in the field of web security. </p> <p>ZAP is primarily used by security professionals and developers to test the security of web applications by automatically detecting a range of security weaknesses and vulnerabilities. </p> <p>It also allows for manual testing, offering features like intercepting proxy and various types of scans to analyze and manipulate the traffic between a user's browser and the web server.</p>"},{"location":"web/ajax/","title":"AJAX","text":"<p>Asynchronous [[JavaScript]] and [[Extensible Markup Language|XML]] (AJAX) is a combination of web application development technologies that make web applications more responsive to user interaction. Whenever your users interact with a web application, such as when they click buttons or checkmark boxes, the browser exchanges data with the remote server. </p> <p>Data exchange can cause pages to reload and interrupt the user experience. With AJAX, web applications can send and receive data in the background so that only small portions of the page refresh as required.</p> <p>Aside from XML, other formats like plain text and\u00a0[[JavaScript Object Notation|JSON]]\u00a0are frequently used for exchanging data.</p> <p>JavaScript and Extensible Markup Language work together under AJAX to ensure the web page content is updated asynchronously. In other words, with AJAX, site content can be updated without reloading the entire page.</p>"},{"location":"web/apache/","title":"Apache","text":"<p>Apache is a popular open-source, cross-platform web server that is, by the numbers, the most popular web server in existence. It\u2019s actively maintained by the\u00a0Apache Software Foundation.</p> <p>Some high-profile companies using Apache include\u00a0Cisco, IBM, Salesforce, General Electric, Adobe, VMware, Xerox, LinkedIn, Facebook, Hewlett-Packard, AT&amp;T, Siemens, eBay, and many more (source).</p> <p>Many cPanel hosts utilize Apache today. Like other web servers, Apache powers the behind-the-scenes aspects of serving your website\u2019s files to visitors.</p> <p>Although we call Apache a web server, it is not a physical server but rather a software that runs on an [[HTTP Protocol|HTTP]] server. </p> <p>Its job is to establish a connection between a server and the browsers of website visitors (Firefox, Google Chrome, Safari, etc.) while delivering files back and forth between them (client-server structure). The Apache software is also compatible with any operating system, from Windows to Unix.\u00a0</p> <p>When a visitor wants to load a page on your website, for instance, the homepage or your \u201cAbout Us\u201d page, their browser sends a request to your server, and Apache returns a response with all the requested files (text, images, etc.).</p> <p>The [[server]] and the [[client]] communicate through the HTTP protocol, and the Apache web server is responsible for the smooth and secure communication between the two machines.</p> <p>Apache is highly customizable, thanks to its open-source infrastructure. Due to this, web developers and users can adapt its source code according to the type of website they\u2019re creating.\u00a0</p> <p>In addition, Apache provides plenty of modules that allow server administrators to turn additional functionalities on and off. The Apache web server has\u00a0modules\u00a0for security, caching, URL rewriting, password authentication, and other features.\u00a0</p>"},{"location":"web/async/","title":"Asynchronous HTTP","text":"<p>Asynchronous HTTP refers to a method of [[HTTP Protocol|HTTP]] communication where a request does not require an immediate response from the server, and the client is not blocked while waiting for the server's response. Instead, the client can continue processing other tasks and handle the response whenever it arrives. This approach is particularly useful for improving the efficiency and responsiveness of web applications.</p> <p>In asynchronous HTTP, the client sends a request and then continues with other processing without waiting for the server's response. The response is handled separately, often through a callback mechanism or an event-driven approach. Asynchronous HTTP is widely used in modern web applications, especially in scenarios involving long-running server processes or when the server needs to wait for external resources. It enhances the user experience by making applications more responsive.</p> <p>[[AJAX]] is a popular technique that uses asynchronous HTTP requests for dynamic content loading on web pages. With AJAX, parts of a web page can be updated without requiring a full page reload. The HTTP/2 protocol introduces the concept of server push, which can be seen as a form of asynchronous communication, where the server can send resources to the client proactively.</p> <p>Various programming frameworks and libraries support asynchronous HTTP. In [[Java]], for instance, the <code>java.net.http.HttpClient</code> introduced in Java 11 provides native support for asynchronous requests. Asynchronous communication allows servers to handle more concurrent requests efficiently, as threads are not tied up waiting for responses, leading to better scalability.</p> <p>Responses to asynchronous requests are typically handled using callbacks, promises, or similar constructs in the programming language being used. For real-time communication, technologies like [[WebSockets]] and [[Server-sent Events (SSE)|SSE]] complement asynchronous HTTP by providing persistent, two-way communication channels between the client and server.</p> <p>Implementing asynchronous HTTP communication can introduce complexity in handling the order of responses, error handling, and managing callbacks or promises. In [[REST APIs|RESTful]] web services, asynchronous HTTP can be used to handle requests that would otherwise lead to long waiting times for the client.</p>"},{"location":"web/authhead/","title":"Authorization Header","text":"<p>The Authorization header is a part of the [[HTTP Protocol|HTTP]] (Hypertext Transfer Protocol) request header used in web communications. It contains the credentials to authenticate a user agent (such as a web browser) with a server, typically after the server has responded with a <code>401 Unauthorized</code> status code and the [[WWW-Authenticate]] header.</p> <p>The Authorization header is used to authenticate a user to a server. It carries credentials in the form of a token which can be a username and password, a bearer token, or other forms of tokens. It helps the server determine whether a client has permission to access a requested resource.</p> <p>The Authorization header generally has the following format:</p> <pre><code>Authorization: &lt;type&gt; &lt;credentials&gt;\n</code></pre> <ul> <li>\\: This is the authentication method used. Common types include:<ul> <li><code>Basic</code>: For [[Basic HTTP Authentication|Basic access authentication]], credentials are constructed by encoding the username and password joined by a colon into a [[base64]] string.</li> <li><code>Bearer</code>: Used with [[OAuth]] 2.0 and [[JSON Web Tokens|JWT (JSON Web Tokens)]], where credentials are a token string.</li> <li><code>Digest</code>: For [[Digest Authentication|Digest access authentication]], offering a more secure approach than Basic authentication.</li> </ul> <li>\\: The actual credentials or token required by the server for authentication. Its format and content vary depending on the <code>&lt;type&gt;</code>. <p>An example may be:</p> <pre><code>Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=\n</code></pre> <p>Info</p> <p>Here, \"dXNlcm5hbWU6cGFzc3dvcmQ=\" is a base64-encoded string of \"username:password\".</p> <p>A bearer token in OAuth 2.0 may appear to be:</p> <pre><code>Authorization: Bearer mF_9.B5f-4.1JqM\n</code></pre> <p>Info</p> <p>The \"mF_9.B5f-4.1JqM\" is a token granted by the authorization server.</p> <p>Since the Authorization header often contains sensitive information, it's crucial to transmit it over secure channels (such as [[HTTPS Protocol|HTTPS]]) to prevent eavesdropping. Tokens or credentials in the Authorization header should be securely stored and managed to prevent unauthorized access.</p>"},{"location":"web/basic/","title":"Basic HTTP Authentication","text":"<p>Basic authentication is a simple authentication scheme built into the HTTP protocol. The client sends HTTP requests with the\u00a0Authorization\u00a0[[HTTP Headers|header]] that contains the word\u00a0Basic\u00a0word followed by a space and a base64-encoded string\u00a0username:password. </p> <p>For example, to authorize as\u00a0demo:p@55w0rd\u00a0the client would send:</p> <pre><code>Authorization: Basic ZGVtbzpwQDU1dzByZA==\n</code></pre> <p>Warning</p> <p>Because base64 is easily decoded, Basic authentication should only be used together with other security mechanisms such as HTTPS/SSL.</p>"},{"location":"web/bear/","title":"Bearer Token Authentication","text":"<p>Bearer token authentication is a method of securing access to resources on the web, often used in the context of [[HTTP Protocol|HTTP]] (Hypertext Transfer Protocol) authentication. It is a simple and widely adopted approach for authenticating and authorizing users or clients to access protected resources in web applications and [[APIs]].</p> <p>In bearer token authentication, a \"bearer token\" is a piece of cryptographic information (often a long string of characters) that serves as proof of the authenticated user or client's identity. This token is generated and issued by an identity provider or authentication server when a user logs in or a client application obtains access to a protected resource.</p> <p>Instead of sending credentials (e.g., username and password) with every HTTP request, the client presents the bearer token in the request headers to access protected resources. The token is included in the <code>Authorization</code> header of the HTTP request using the \"Bearer\" scheme. For example:</p> <pre><code>Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\n</code></pre> <p>Bearer token authentication is stateless, meaning that the server does not need to store or maintain session information. Each request sent by the client contains all the necessary authentication information in the bearer token itself. This simplicity makes bearer tokens suitable for scaling and distributed systems.</p> <p>The server receiving the bearer token validates it to ensure its authenticity and check whether the token is still valid. The validation process may involve verifying the token's signature, checking the expiration time, and confirming that the token has not been revoked.</p> <p>Bearer tokens can carry additional information, such as user roles, permissions, or scopes, which can be used by the server to determine the level of access or actions the bearer of the token is allowed to perform.</p> <p>Bearer token authentication is commonly used in various scenarios, including:</p> <ul> <li>[[OAuth]] 2.0: Bearer tokens are a fundamental component of OAuth 2.0 for authorizing third-party applications to access user data on behalf of the user.</li> <li>API Authentication: Many [[REST APIs|RESTful]] APIs and web services use bearer tokens to secure access to their resources.</li> <li>[[Single Sign-On (SSO)]]: In some SSO systems, bearer tokens are used as proof of authentication and authorization for accessing multiple applications.</li> </ul> <p>While bearer tokens are convenient and widely used, it's essential to secure them properly. They can be vulnerable if not handled securely. Best practices include using [[HTTPS Protocol|HTTPS]] for communication, protecting tokens from disclosure, and implementing token revocation mechanisms.</p>"},{"location":"web/cacheserver/","title":"Caching Server","text":"<p>A [[caching]] server, also known as a cache server, is a type of server that stores copies of frequently accessed or requested data, known as cached content. The purpose of a caching server is to reduce latency, improve response times, and minimize the load on upstream servers by serving cached content instead of fetching it from the original source every time a request is made.</p> <p>Caching servers implement a caching mechanism to store copies of data, such as web pages, images, scripts, or other resources. Cached content is stored temporarily and can be quickly served to users upon subsequent requests.</p> <p>Caching servers prioritize caching frequently accessed content to optimize performance for users. Caching servers follow [[HTTP Protocol|HTTP]] caching headers provided by web servers and applications to determine how long to store cached content and when to revalidate it. Common HTTP caching headers include Cache-Control, Expires, Last-Modified, and ETag.</p> <p>Types of Caching Servers:</p> <ul> <li>Web Proxy Caches: These caches are often deployed at the network edge, acting as intermediaries between clients and web servers. They store copies of content requested by clients and serve it locally.</li> <li>Content Delivery Network (CDN) Caches: [[Content Delivery Network|CDNs]] consist of distributed caching servers strategically located around the globe. They cache and deliver static assets (e.g., images, stylesheets) to users based on their geographical location.</li> <li>Reverse Proxy Caches: Placed in front of web servers, reverse proxy caches store copies of dynamic content generated by web applications. They help offload server processing and improve response times.</li> <li>Browser Caches: While not traditional caching servers, web browsers maintain local caches on users' devices to store copies of recently visited web pages and resources.</li> </ul> <p>Caching servers implement cache invalidation mechanisms to ensure that stale or outdated content is periodically purged from the cache. Techniques for cache invalidation include time-based expiration, versioning, and cache purging.</p> <p>Some caching servers also function as [[Load Balancer|load balancers]], distributing incoming requests across multiple backend servers to optimize resource utilization.</p>"},{"location":"web/caching/","title":"Caching","text":"<p>Caching of web content refers to the practice of storing copies of web resources (such as [[HTML]] pages, images, stylesheets, and scripts) at various points in the network, allowing subsequent requests for the same content to be served more quickly. Caching is an essential mechanism for optimizing web performance, reducing latency, and minimizing the load on web servers.</p> <p>A cache is a temporary storage location that holds copies of frequently accessed data to speed up retrieval. Web browsers maintain a local cache on users' devices to store copies of recently visited web pages and associated resources. When a user revisits a page, the browser can retrieve resources from the local cache instead of fetching them from the web server.</p> <p>[[HTTP Protocol|HTTP]], the protocol used for transferring data on the web, supports caching mechanisms defined by headers in the HTTP response.</p> <p>Common HTTP headers related to caching include:</p> <ul> <li>Cache-Control: Specifies directives for caching mechanisms in both requests and responses.</li> <li>Expires: Indicates a specific date and time after which the response is considered stale.</li> <li>Last-Modified: Specifies the last modification date of the resource.</li> <li>ETag: A unique identifier for a specific version of a resource.</li> </ul> <p>Cache-Control Directives:</p> <ul> <li>public: Indicates that the response may be cached by any cache (including proxies).</li> <li>private: Indicates that the response is intended for a single user and should not be stored by shared caches.</li> <li>max-age: Specifies the maximum amount of time (in seconds) a response can be considered fresh.</li> <li>no-cache: Requires caches to revalidate the content with the server before serving it.</li> </ul> <p>[[Content Delivery Network]] (CDNs) cache static assets at strategically located servers worldwide. CDNs help distribute content closer to end-users, reducing latency and improving load times. Web servers can implement caching mechanisms to store generated content and reduce the need for dynamic processing.</p> <p>Info</p> <p>Popular web servers like [[Apache]] and [[Nginx]] support caching configurations.</p> <p>Entire HTML pages can be cached to avoid reprocessing on the server for each request. This is particularly useful for static or relatively static content. When content is updated, cache invalidation mechanisms ensure that stale cached copies are purged. Techniques include changing cache keys, versioning resources, or using cache purging tools.</p>"},{"location":"web/cas/","title":"Certificate Authorities (CAs)","text":"<p>Certificate Authorities (CAs) are trusted entities that issue digital certificates, which are used to establish a chain of trust on the internet, especially for securing communications over the web. These certificates are a crucial component of the [[SSL-TLS|SSL/TLS]] (Secure Sockets Layer/Transport Layer Security) protocols, which provide secure web browsing and data transmission.</p> <p>CAs issue digital certificates to entities (such as websites, organizations, or individuals) after verifying their identity. This certificate binds a public key to the entity identified in the certificate, typically through a domain name for [[SSL certificates|SSL/TLS certificates]].</p> <p>When a user visits a website secured with SSL/TLS, the browser checks the website's SSL certificate. A valid certificate issued by a trusted CA ensures the user that the website is legitimate and not an impostor. CAs are a fundamental part of the Public Key Infrastructure, an arrangement that binds public keys with respective user identities by means of a Certificate Authority (CA).</p> <p>There is often a hierarchy of trust in the CA world, with root CAs at the top issuing certificates to intermediate CAs, which in turn can issue certificates to end entities (like websites).</p> <p>CAs offer different levels of validation for issuing certificates:</p> <ul> <li>Domain Validation (DV): The CA checks the right of the applicant to use a specific domain name. This is the most basic level of validation.</li> <li>Organization Validation (OV): The CA checks the right to use a domain name and conducts some vetting of the organization.</li> <li>Extended Validation (EV): This is the highest level of validation, where the CA conducts a thorough examination of the organization, including its legal and physical existence.</li> </ul> <p>CAs maintain lists of revoked certificates. A certificate may be revoked if it is discovered that the certificate was issued improperly or the private key has been compromised. By providing verified certificates, CAs enable secure communications over the internet, protecting data from eavesdroppers and attackers.</p> <p>Web browsers and operating systems maintain a list of trusted CAs. If a certificate is issued by a CA not in this list, the browser may warn the user that the connection is not secure.</p> <p>CAs operate under specific standards and regulations to ensure they provide a high level of security and trust. They are often audited and must adhere to standards like those set by the WebTrust program or the CA/Browser Forum.</p> <p>Certificate Authorities play a crucial role in internet security. The trust model provided by CAs underpins secure online transactions, including online shopping, banking, and confidential communications.</p>"},{"location":"web/cda/","title":"Content Delivery Application (CDA)","text":"<p>A Content Delivery Application (CDA) is a component of a [[Content Management System]] (CMS) that focuses on the back-end services responsible for delivering the content to the end-user. While the [[Content Management Application (CMA)]] allows users to create, manage, and organize content, the CDA takes care of storing and delivering this content when requested by a user, typically via a web browser.</p> <p>The CDA stores the content in a database or file system and retrieves it when needed. This includes not just text content, but also media like images and videos. When a user requests a page, the CDA dynamically assembles the content from the database, applies the appropriate templates, and generates the final [[HTML]], [[CSS]], and [[Content Management Application (CMA)]] that is sent to the user's browser.</p> <p>It handles the delivery of content to the user's device, ensuring that it is accessible and displays correctly across different devices and browsers. The CDA often includes features to optimize the performance of content delivery, such as caching mechanisms, load balancing, and [[Content Delivery Network|content delivery networks (CDNs)]].</p> <p>It ensures the security of the content during its storage and delivery, implementing measures like secure data transmission, access controls, and protection against various web vulnerabilities. The CDA plays a role in optimizing content for search engines ([[SEO]]) and ensuring it is accessible to all users, including those with disabilities.</p> <p>The CDA component is integral to all CMS platforms but is not typically referenced as a standalone application. Examples of CMS platforms that include CDAs are:</p> <ol> <li>[[WordPress]]: The most popular CMS, WordPress uses a combination of [[PHP]] and a [[MySQL (KB)|MySQL]] database to store and deliver content.</li> <li>[[Joomla]]: Similar to WordPress, Joomla uses PHP and a database (like MySQL) to store content and deliver it dynamically to users.</li> <li>[[Drupal]]: Known for its robustness, Drupal also relies on PHP and database storage to manage and deliver content.</li> </ol> <p>In the context of a CMS, the CDA works in tandem with the CMA. The CMA allows users (like content creators and website administrators) to manage content, and the CDA delivers this content to the end-users (website visitors). This separation of concerns allows for more efficient content management and delivery, especially for complex and large-scale websites.</p>"},{"location":"web/cdiff/","title":"Cross-Domain iFrame","text":"<p>Cross-domain iframes are [[HTML]] elements used in web development to embed content from a different domain (or website) into a webpage.</p> <p>They represent a particular use of the \\ tag in HTML, where the source of the iframe (the content it displays) comes from a domain that is different from the domain of the parent page. <p>Cross domain iframes provide a way to isolate embedded content from the parent page. This is particular useful for including third party content while maintaining a degree of separation from the main website's content.</p> <p>Web browsers enforce the [[Same Origin Policy]], which restricts how documents or scripts loaded from one origin can interact with resources from another origin. In the context of iframes, this policy means that a script in an iframe from a different domain typically cannot directly access or modify the contents of the parent page.</p> <p>While the isolation provided by cross-domain iframes can enhance security (by preventing third-party content from accessing sensitive data on the parent page), it also poses challenges. For instance, ensuring secure communication between the iframe and the parent page requires careful handling, often using postMessage [[APIs|API]] or other secure methods.</p> <p>Sometimes, it's necessary for the embedded content in an iframe to communicate with the parent page or access resources from the parent domain. [[Cross-Origin Resource Sharing (CORS)]] is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from which the first resource was served, under certain conditions.</p>"},{"location":"web/cdn/","title":"Content Delivery Network (CDN)","text":"<p>A content delivery network (CDN) is a geographically distributed group of [[Server|servers]] that caches content close to end users. A CDN allows for the quick transfer of assets needed for loading Internet content, including [[HTML]] pages, [[JavaScript]] files, [[CSS|stylesheets]], images, and videos.</p> <p>The popularity of CDN services continues to grow, and today the majority of web traffic is served through CDNs, including traffic from major sites like Facebook, Netflix, and Amazon.</p> <p>A content delivery network (CDN) is a network of interconnected servers that speeds up webpage loading for data-heavy applications.</p> <p>When a user visits a website, data from that website's server has to travel across the internet to reach the user's computer. If the user is located far from that server, it will take a long time to load a large file, such as a video or website image. Instead, the website content is stored on CDN servers geographically closer to the users and reaches their computers much faster.</p> <p>The primary purpose of a content delivery network (CDN) is to reduce latency, or reduce the delay in communication created by a network's design. Because of the global and complex nature of the internet, communication traffic between websites (servers) and their users (clients) has to move over large physical distances. The communication is also two-way, with requests going from the client to the server and responses coming back.</p> <p>A CDN improves efficiency by introducing intermediary servers between the client and the website server. These CDN servers manage some of the client-server communications. They decrease web traffic to the web server, reduce bandwidth consumption, and improve the user experience of your applications.</p>"},{"location":"web/cgi/","title":"CGI","text":"<p>CGI is an interface which tells the webserver how to pass data to and from an application. More specifically, it describes how request information is passed in environment variables (such as request type, remote IP address), how the request body is passed in via standard input, and how the response is passed out via standard output.</p> <p>Most if not all, webservers can be configured to execute a program as a 'CGI'. This means that the webserver, upon receiving a request, will forward the data to a specific program, setting some environment variables and marshalling the parameters via standard input and standard output so the program can know where and what to look for.</p> <p>The main benefit is that you can run ANY executable code from the web, given that both the webserver and the program know how CGI works. That's why you could write web programs in C or [[Bash]] with a regular CGI-enabled webserver. That, and that most programming environments can easily use standard input, standard output and environment variables.</p>"},{"location":"web/cloudflare/","title":"Cloudflare","text":"<p>Cloudflare acts as an intermediary between a [[client]] and a [[server]], using a reverse [[proxy]] to mirror and cache websites. By storing web content for delivery on the closest edge server, it is able to optimize loading times. That also allows it to modify content, such as images and rich text, for better performance.</p> <p>This intermediary design is also how Cloudflare offers a level of filtration for security. By sitting between the client and the hosting server, it can detect malicious traffic, intercept distributed denial-of-service attacks, deflect attacks from bots, remove bot traffic and limit spam.</p> <p>Cloudflare is a [[Content Delivery Network]]. CDNs are an increasingly popular model across the internet because they solve an important problem: latency. They, at least in Cloudflare\u2019s case, provide what\u2019s known as an edge network. In short, an edge network creates a much closer entry point for data, rather than bouncing it between servers across the globe.</p> <p>With 155 data centres around the world, Cloudflare works by caching a version of a customer\u2019s website and any static resources, then delivering it to visitors based on their location.</p> <p>That ensures the least amount of distance between a visitor and a website, which reduces latency, bandwidth and page load times. By moving the content and computational work closer, Cloudflare-powered websites can work faster.</p> <p>The company\u2019s [[DNS]] services use the same network of data centers. Cloudflare offers authoritative DNS and public DNS resolver services. Both are offered as privacy and speed-first alternatives to internet service provider DNS servers.</p> <p>In addition to content delivery and DNS services, Cloudflare provides security as a service with DDoS protection, email obfuscation, web application firewall access and threat blocking. By sitting between a client and host, it can also filter traffic, reducing bot traffic and spam.</p>"},{"location":"web/cms/","title":"Content Management System (CMS)","text":"<p>The term\u00a0content management system\u00a0refers to the systems used to organize digital content for the purpose of administration, organization, and control.</p> <p>More specifically, content management systems have useful applications for websites, especially for websites that require a user interface for adding, editing, and managing the content of a website.</p> <p>One major advantage of a CMS is its collaborative nature. Multiple editors can contribute, schedule or manage content to be published. Because the user interface is usually browser-based, a CMS can be accessed from anywhere by any number of users.</p> <p>The second major advantage of a CMS is that it allows non-technical people who don\u2019t know programming languages to easily create and manage their own content. The drag-and-drop editors of a typical content management platform allows users to enter text and upload images without needing to know any HTML or CSS (programming languages).</p> <p>When a company uses a CMS\u00a0to publish its web pages, it reduces its reliance on front-end developers to make changes to the website, making it quicker and easier to publish new web pages improving the digital experience for users and visitors.</p> <p>When a company uses a CMS\u00a0to publish content to other channels\u00a0- like social, mobile apps and ecommerce, it can drastically reduce the amount of development a company needs to do and make it easier to distribute content to different channels simultaniously.</p> <p>A website is a collection of web pages and related content that is identified by a common [[Fully Qualified Domain Name (FQDN)|domain name]] and published on at least one [[server]]. In contrast, a CMS or Content Management System, is a piece of software that allows you to store, manage and publish said web pages.</p> <p>Most websites use a content management system, but you could make one without a CMS, writing directly in a programming language like HTML and CSS. More often though, it\u2019s easier to use a CMS to manage content for the editor instead of building a website from code.</p>"},{"location":"web/connmeth/","title":"Connect HTTP Method","text":"<p>The <code>CONNECT</code> [[HTTP Protocol|HTTP]] method is used by the HTTP/1.1 protocol to establish a tunnel to a server identified by a given URI. It's primarily used for establishing connections that are then upgraded to [[TLS]] (Transport Layer Security), such as when a client communicates with an [[HTTPS Protocol |HTTPS]] server through an HTTP [[proxy]].</p> <p>The <code>CONNECT</code> method is used to request that an intermediary (such as a proxy) establish a tunnel connection to the target server. For example, when a client wants to securely connect to an HTTPS website through an HTTP proxy, it sends a <code>CONNECT</code> request to the proxy with the hostname and port number of the HTTPS server.</p> <pre><code>CONNECT www.example.com:443 HTTP/1.1\n</code></pre> <p>Once the tunnel is established, the client can start a [[TLS handshake]] with the target server through the proxy, allowing secure communication.</p> <p>Malicious users can potentially use the <code>CONNECT</code> method to bypass network restrictions or access controls by tunneling through proxies. For instance, they might access restricted websites or services through a corporate proxy.</p> <p>If a web application includes a proxy server functionality, failing to properly restrict or monitor the use of the <code>CONNECT</code> method can lead to abuse. Attackers might use the proxy server to mask their IP address or conduct illegal activities. An attacker could use <code>CONNECT</code> to facilitate [[Man-in-the-Middle (MitM) attack|man-in-the-middle (MitM) attacks]], intercepting and possibly altering communications between a client and a server.</p>"},{"location":"web/cookies/","title":"Cookies","text":"<p>A cookie\u00a0is a piece of data from a website that is stored within a web browser that the website can retrieve at a later time. Cookies are used to tell the server that users have returned to a particular website. When users return to a website, a cookie provides information and allows the site to display selected settings and targeted content.</p> <p>Cookies also store information such as shopping cart contents, registration or login credentials, and user preferences. This is done so that when users revisit sites, any information that was provided in a previous session or any set preferences can be easily retrieved.</p> <p>Advertisers use cookies to track user activity across sites so they can better target ads. While this particular practice is usually offered to provide a more personalized user experience, some people also view this as a privacy concern.</p> <p>Cookies are intended to be use for session management, personalization and tracking.</p> <p>There are many types of cookies including:</p> <ul> <li>Session cookies - store information while the user is visiting the website, deleted once the user closes the session</li> <li>Persistent cookie - stored for specific length of time, remain on device until expire or deleted</li> <li>First-party and third-party cookies - set by sites that users directly visit, often store information relevant or related to the site (settings, location, etc..)</li> <li>Supercookies - similiar to session cookies but can re-create user profiles, even after deletion. Stored in different places.</li> <li>Flash cookies - data files stored on computers by sites that use Adobe Flash</li> </ul>"},{"location":"web/cors/","title":"Cross-Origin Resource Sharing (CORS)","text":"<p>Cross-Origin Resource Sharing (CORS) is a security feature in web browsers that controls how web pages in one domain can request resources from another domain.</p> <p>It's a crucial part of modern web security, designed to allow safe, controlled access across different origins while protecting against certain types of web attacks, such as [[Cross-Site Scripting]] (XSS) and data theft.</p> <p>In web security, an \"origin\" is defined by the scheme (protocol), host (domain), and port of a [[Uniform Resource Locator|URL]]. For example, <code>https://example.com</code> and <code>https://sub.example.com</code> are different origins.</p> <p>By default, web browsers enforce a [[Same Origin Policy]] (SOP), which restricts web pages from making requests to a different domain than the one that served the web page. This policy is a crucial security mechanism that prevents malicious scripts on one page from obtaining access to sensitive data on another web page through the browser.</p> <p>Modern web applications often need to make requests to different domains for resources like [[APIs]], fonts, or images. CORS provides a way to safely allow these cross-origin requests.</p> <p>CORS relies on specific [[HTTP headers]]. The most important is the Access-Control-Allow-Origin header, which the server includes in the response to indicate whether the requesting origin is permitted to access the resource</p> <p>For certain types of requests (like those using custom headers or [[HTTP Verbs|HTTP methods]] other than GET or POST), the browser sends a pre-flight request - it is an OPTIONS request to the server before the actual request, asking if it is okay to send the actual request.</p> <p>To support CORS, the server hosting the resources must be configured to send the appropriate headers. Without these headers, the browser will block the cross-origin request.</p> <p>CORS provides security by allowing servers to specify who can access their resources and under what conditions. It doesn\u2019t weaken security; rather, it enables controlled access while maintaining the protection provided by the same-origin policy.</p>"},{"location":"web/crawlers/","title":"Search Engine Crawlers","text":"<p>Search engine crawlers, also known as web crawlers, spiders, or spider-bots, are internet bots used by search engines to update their content or index. These crawlers are essential for search engines to gather information about various websites and pages on the internet, which enables them to provide relevant and updated search results to users.</p> <p>Crawlers start by visiting a set of web pages. They then follow the links on these pages, essentially \"crawling\" from one page to another. This process allows them to find new pages and add them to the list of sites to index.</p> <p>As they visit these pages, crawlers read and process the content of the pages (like text, images, video file links, and other media). They catalog this information and send it back to the search engine.  The search engine processes this data and updates its index \u2013 the database used for generating search results.</p> <p>Content that changes frequently or is generated based on user interactions can be challenging for crawlers to index effectively. The \"crawl budget\" is the number of pages a crawler will index on a site in a given timeframe. Websites with a vast number of pages may not have all their content indexed if the crawl budget is exceeded.</p> <p>Crawlers must follow rules set by website owners in [[Robots.txt|robots.txt]] files, which can restrict or guide their crawling activities.</p> <p>Understanding how crawlers work is crucial for SEO. Website designers and owners aim to make their sites crawler-friendly to ensure better indexing and higher rankings in search engine results.</p>"},{"location":"web/crawling/","title":"Web Crawling","text":"<p>A\u00a0web crawler\u00a0is a bot (AKA crawling agent, spider bot, web crawling software, website spider, or a search engine bot) that goes through websites and collects information. In other words, the spider bot crawls through websites and search engines searching for information.</p> <p>Google's search engine bot would work something like this: Google spider's main purpose is to update the content of search engines and index web pages of other websites. When the said spider crawls a certain page, it will gather the page's data for later processing and evaluation.</p> <p>Once the page is evaluated, a search engine can index the page appropriately. This is why when you type in a certain keyword into a search bar, you will see the most relevant (according to the search engine) web page.</p> <p>Web crawlers are provided with a list of [[Uniform Resource Locator|URLs]] to crawl. What the crawler does is it goes through the provided URLs, and then finds more URLs to crawl within the pages. This could become an endless process of course, and that is why all crawlers need a set of rules (what pages should they crawl, when should they crawl, etc.) Web crawlers can:</p> <ul> <li>Discover readable and reachable URLs</li> <li>Explore a list of seeds or URLs to identify new links and add them to the list</li> <li>Index all identified links</li> <li>Keep all indexed links up to date</li> </ul> <p>What's more, a web crawler can be used by companies that need to gather data for business purposes. In this case, a web crawler is usually accompanied by a web scraper that downloads, or scrapes, required information.</p> <p>For business cases, web crawlers and scrapers have to use [[Proxy|proxies]].</p> <p>Web crawling in the context of penetration testing (pentesting) refers to the automated process of systematically browsing and mapping out a web application to identify its structure, functionality, and potential vulnerabilities. This is a crucial initial step in pentesting, as it helps the tester understand the scope of the application and plan further targeted attacks.</p>"},{"location":"web/csp/","title":"Content Security Policy (CSP)","text":"<p>Content Security Policy (CSP) is a security mechanism used to define a list of trusted sources for content that a website or a specific web page is allowed to load, as well as what protocol will be used for that. This can include scripts, stylesheets, images, and other types of content that can be embedded into a web page.</p> <p>Content Security Policy is a powerful defense in depth security control that helps block unauthorized requests for content located outside of the current website. In addition to this, CSP successfully prevents the execution of inline scripts and restricts unsafe dynamic code execution.</p> <p>As an [[HTTP Protocol|HTTP]] security response header, CSP passes the instructions configured by the website owner to the visitor\u2019s browser.</p> <p>The browser, then, must follow the instructions and block the delivery of content that was not authorized by the Content Security Policy rules. This way, the browser will see that certain content was referenced by a web page but will refuse to load it.</p> <p>The Content Security Policy (CSP) is a protection standard that helps secure websites and applications against various attacks, including data injection,\u00a0[[Clickjacking]], and\u00a0[[cross-site scripting]] attacks.</p> <p>CSP implements the\u00a0[[Same Origin Policy]], ensuring that the browser only executes code from valid sources. Developers can use precisely-defined CSPs to eliminate common attack vectors by defining the content sources. This article explores a content security policy and how a CSP header can help prevent common vulnerabilities.</p>"},{"location":"web/csrf/","title":"Cross-Site Request Forgery (CSRF)","text":"<p>Cross-site request forgery (also known as CSRF) is a web security vulnerability that allows an attacker to induce users to perform actions that they do not intend to perform.</p> <p>It allows an attacker to partly circumvent the same origin policy, which is designed to prevent different websites from interfering with each other.</p> <p>An attacker\u2019s aim for carrying out a CSRF attack is to force the user to submit a state-changing request. Examples include:</p> <ul> <li>Submitting or deleting a record.</li> <li>Submitting a transaction.</li> <li>Purchasing a product.</li> <li>Changing a password.</li> <li>Sending a message.</li> </ul> <p>Social engineering platforms are often used by attackers to launch a CSRF attack. This tricks the victim into clicking a [[Uniform Resource Locator|URL]] that contains a maliciously crafted, unauthorized request for a particular Web application.</p> <p>The user\u2019s browser then sends this maliciously crafted request to a targeted Web application. The request also includes any credentials related to the particular website (e.g., user session cookies).</p> <p>If the user is in an active session with a targeted Web application, the application treats this new request as an authorized request submitted by the user. Thus, the attacker succeeds in exploiting the Web application\u2019s CSRF vulnerability.</p> <p>A CSRF attack targets Web applications failing to differentiate between valid requests and forged requests controlled by attacker. There are many ways for an attacker to try and exploit the CSRF vulnerability.</p> <p>For a CSRF attack to be possible, three key conditions must be in place:</p> <ul> <li>A relevant action.\u00a0There is an action within the application that the attacker has a reason to induce. This might be a privileged action (such as modifying permissions for other users) or any action on user-specific data (such as changing the user's own password).</li> <li>Cookie-based session handling.\u00a0Performing the action involves issuing one or more [[HTTP Protocol|HTTP]] requests, and the application relies solely on session cookies to identify the user who has made the requests. There is no other mechanism in place for tracking sessions or validating user requests.</li> <li>No unpredictable request parameters.\u00a0The requests that perform the action do not contain any parameters whose values the attacker cannot determine or guess. For example, when causing a user to change their password, the function is not vulnerable if an attacker needs to know the value of the existing password.</li> </ul>"},{"location":"web/csrs/","title":"Certificate Signing Requests (CSRs)","text":"<p>A Certificate Signing Request (CSR) is a request sent from an applicant to a [[Certificate Authorities (CAs)|Certificate Authority (CA]]) to apply for a digital identity certificate. It contains information that will be included in the certificate, such as the applicant's public key, organization name, common name (domain name), locality, and country.</p> <p>The CSR is used in the process of obtaining an [[SSL certificates|SSL/TLS certificate]] for secure websites and other services that require encrypted data transmission.</p> <p>The CSR includes the public key that will be included in the certificate. The corresponding private key is kept secure and is not transmitted. This includes the organization's name, the common name (e.g., a domain name for [[SSL]] certificates), and other identifying information. The CSR is signed by the applicant's private key. This signature is used by the CA to verify the authenticity of the request.</p> <p>The applicant generates a private key and a CSR. The CSR is generated using software tools and is based on the private key. The applicant submits the CSR to a Certificate Authority. The CA verifies the identity and authority of the applicant. Once verified, the CA issues a certificate based on the CSR, which contains the applicant's public key and other information from the CSR.</p> <p>An example of generating a CSR using OpenSSL:</p> <ol> <li>Generate a private key:</li> </ol> <pre><code>openssl genrsa -out private.key 2048\n</code></pre> <p>This command creates a 2048-bit RSA private key and saves it in a file named private.key.</p> <ol> <li>Generate a CSR:</li> </ol> <pre><code>openssl req -new -key private.key -out mycsr.csr\n</code></pre> <p>This command prompts for details like the common name (domain name), organization, country, etc., and creates a CSR (<code>mycsr.csr</code>) using the private key (<code>private.key</code>).</p>"},{"location":"web/da/","title":"Digest Authentication","text":"<p>Digest authentication is one of the [[HTTP Protocol|HTTP]] authentication methods used to secure web applications and services. It is designed to address some of the security weaknesses of the [[Basic HTTP Authentication|Basic Authentication]] method by providing a more secure way for clients and servers to authenticate each other.</p> <p>Digest authentication operates on a challenge-response mechanism, similar to Basic Authentication. However, it improves security by not transmitting plaintext passwords over the network.</p> <p>Instead of sending passwords directly, Digest authentication requires the client to send a hashed version of the password. This hashing is done using a one-way cryptographic hash function, such as [[MD5]] or [[SHA-256]]. The server also stores hashed versions of user passwords.</p> <p>The server sends a unique \"nonce\" value (a random number or string) in the authentication challenge. The nonce is used to prevent replay attacks. The client includes this nonce in the hashed response. The server specifies a \"realm\" in the challenge, which is a description of the protected area or security domain. The client may display this realm to the user, allowing the user to provide the appropriate credentials.</p> <p>Digest authentication can support various \"quality of protection\" options, such as \"auth\" (authentication) and \"auth-int\" (authentication with message integrity). The QOP value is included in the authentication parameters.</p> <p>To create the response, the client hashes several pieces of information, including the username, password, nonce, realm, request method, URI, and other parameters. This hashed value is sent to the server. Digest authentication provides a higher level of security compared to Basic Authentication because it does not transmit plaintext passwords over the network. However, it is not considered as secure as modern authentication mechanisms like [[Knowledge Base/OAuth]] 2.0.</p> <p>The client includes the <code>Authorization</code> header in the HTTP request with the \"Digest\" scheme and the calculated response. For example:</p> <pre><code>Authorization: Digest username=\"alice\", realm=\"Example\", nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\", uri=\"/resource\", response=\"f3a2556be9021ac2db4e06d562396fa8\", qop=auth, nc=00000001, cnonce=\"0a4f113b\", opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"\n</code></pre> <p>Upon receiving the authentication information, the server calculates the expected response based on the stored information and compares it to the received response. If they match, the client is authenticated. The client includes a nonce count (NC) value in the authentication parameters to prevent replay attacks. The server tracks the NC value to ensure that each request is unique.</p>"},{"location":"web/del/","title":"Delete HTTP Method","text":"<p>The <code>DELETE</code> [[HTTP Verbs|HTTP method]] is used in web development as part of the [[HTTP protocol]] to request the removal of a specific resource identified by a URL. It's one of the methods defined by the HTTP/1.1 specification and is commonly used in [[REST APIs|RESTful APIs]] and web services.</p> <p>The primary purpose of the <code>DELETE</code> method is to request that the server delete the resource located at the specified URL. Like <code>GET</code> and <code>PUT</code> methods, <code>DELETE</code> is idempotent, meaning multiple identical requests should have the same effect as a single request.</p> <p>When a server receives a <code>DELETE</code> request, it deletes the resource and usually returns a status code indicating the outcome (e.g., <code>200 OK</code> for successful deletion, <code>404 Not Found</code> if the resource doesn\u2019t exist, etc.).</p> <p>If access controls are not properly implemented, an attacker might exploit the <code>DELETE</code> method to remove critical data or resources. For instance, without proper authorization checks, an attacker could send a <code>DELETE</code> request to a URL like <code>http://example.com/user/123</code> and potentially delete user data.</p> <p>Insecure implementation of the <code>DELETE</code> method could lead to accidental or intentional data loss, impacting the integrity and availability of the application's data. Like other HTTP methods, inputs (such as URL parameters) in <code>DELETE</code> requests should be validated to prevent injection attacks or unintended actions.</p>"},{"location":"web/doctype/","title":"DOCTYPE","text":"<p>In XML ([[Extensible Markup Language]]), a <code>DOCTYPE</code> declaration, also known as a [[Document Type Definition (DTD)|Document Type Declaration]], serves a purpose similar to its counterpart in [[HTML]]. It defines the structure and the rules for an XML document. However, in XML, the <code>DOCTYPE</code> declaration is used to specify the Document Type Definition (DTD) that the document adheres to.</p> <p>The <code>DOCTYPE</code> declaration in an XML document is used to reference a DTD. A DTD defines the structure and the legal elements and attributes for an XML document. The syntax for a <code>DOCTYPE</code> declaration in XML can be either internal or external:</p> <p>For internal, the DTD is defined within the XML document itself:</p> <pre><code>&lt;!DOCTYPE root-element [\n    ... DTD definitions ...\n]&gt;\n</code></pre> <p>For external, the DTD is defined in an external file, and the declaration references the external file:</p> <pre><code>&lt;!DOCTYPE root-element SYSTEM \"URL or path to DTD file\"&gt;\n</code></pre> <p>The various components include:</p> <ul> <li><code>root-element</code>: Specifies the root element of the document.</li> <li><code>SYSTEM</code>: Indicates that the DTD is external. Alternatively, <code>PUBLIC</code> can be used to reference a public DTD.</li> <li><code>\"URL or path to DTD file\"</code>: The location of the DTD file.</li> </ul> <p>The <code>DOCTYPE</code> declaration allows an XML parser to validate the document against the specified DTD, ensuring that the document adheres to the rules of that DTD. While DTD is one way to define the rules and structure for XML documents, another more powerful and complex way is using XML Schema Definitions (XSD). XML Schemas provide more functionalities and are written in XML syntax.</p> <p>An example of an XML document with an internal DTD:</p> <pre><code>&lt;!DOCTYPE note [\n  &lt;!ELEMENT note (to,from,heading,body)&gt;\n  &lt;!ELEMENT to (#PCDATA)&gt;\n  &lt;!ELEMENT from (#PCDATA)&gt;\n  &lt;!ELEMENT heading (#PCDATA)&gt;\n  &lt;!ELEMENT body (#PCDATA)&gt;\n]&gt;\n&lt;note&gt;\n  &lt;to&gt;Tove&lt;/to&gt;\n  &lt;from&gt;Jani&lt;/from&gt;\n  &lt;heading&gt;Reminder&lt;/heading&gt;\n  &lt;body&gt;Don't forget the meeting!&lt;/body&gt;\n&lt;/note&gt;\n</code></pre> <p>In this example, the <code>DOCTYPE</code> declaration defines the structure of the <code>note</code> element and its sub-elements. An XML parser can use this information to validate the document.</p>"},{"location":"web/dom/","title":"Document Object Model","text":"<p>The Document Object Model (DOM) is an application programming interface (API) for [[HTML]] and [[Extensible Markup Language|XML]] documents. It defines the logical structure of documents and the way a document is accessed and manipulated.</p> <p>In the DOM specification, the term \"document\" is used in the broad sense - increasingly, XML is being used as a way of representing many different kinds of information that may be stored in diverse systems, and much of this would traditionally be seen as data rather than as documents. Nevertheless, XML presents this data as documents, and the DOM may be used to manage this data.</p> <p>With the Document Object Model, programmers can build documents, navigate their structure, and add, modify, or delete elements and content. Anything found in an HTML or XML document can be accessed, changed, deleted, or added using the Document Object Model, with a few exceptions - in particular, the DOM interfaces for the XML internal and external subsets have not yet been specified.</p> <p>There are 3 parts of the DOM:</p> <ul> <li>Core DOM - standard for all document types</li> <li>XML DOM - standard model for XML documents</li> <li>HTML DOM - standard model for HTML documents</li> </ul> <p>The Document Object Model (DOM) is a programming interface that defines how to create, modify or erase elements in an HTML or XML document. DOM provides a standard API for the dynamic modification of the content, style, and structure of web page documents. A DOM model represents each\u00a0element as a node\u00a0within a tree-like system, enabling\u00a0easier programmatic access\u00a0and\u00a0management of the elements.</p> <p>By allowing the manipulation of documents, a DOM model enables object-oriented web page representation. This way, programming languages like\u00a0[[JavaScript]] can modify and build dynamic web pages. DOM is platform and language-neutral to be used concurrently by multiple applications and environments.</p>"},{"location":"web/domsink/","title":"DOM Sink","text":"<p>In the context of the [[Document Object Model]] (DOM), \"sinks\" are points in the application where data is output or where the data can lead to code execution. These are functions or properties that can dynamically change the content of the web page or execute code based on the provided input.</p> <p>Some examples include:</p> <ul> <li>innerHTML - sets or returns the [[HTML]] content of a element. Writing to it can potentially execute malicious scripts if the input is not properly sanitized.</li> <li>document.write - writes HTML expressions or [[JavaScript]] code to a document. Can be harmful if the data written is untrusted.</li> <li>eval - executes a string as JavaScript code, which is a significant security risk if the string contains untrusted data.</li> <li>setTimeout and setInterval - can evaluate strings as code, posing a risk if the string is constructed from unsafe sources.</li> </ul> <p>The main risk with DOM sinks is the possibility of executing untrusted data as code. This is the primary mechanism through which [[Cross-Site Scripting|XSS]] attacks are conducted. When a sink like innerHTML is used with data from an unsafe source, it can lead to script injection and the execution of malicious scripts.</p>"},{"location":"web/domsource/","title":"DOM Source","text":"<p>In the context of the [[Document Object Model]] (DOM), \"sources\" refer to methods or properties that can read data from potentially untrusted or unsafe sources. This data might include user inputs, URL parameters, responses from external APIs, or any other data that the web application processes.</p> <p>Some examples include:</p> <ul> <li>document.URL - contains the [[Uniform Resource Locator|URL]] of the current document</li> <li>document.cookie - provides access to the cookies associated with the document</li> <li>document.referrer - indicates the address of the webpage that linked to the current page</li> <li>location.search - contains the query string part of the URL</li> <li>User input fields like text boxes or text areas</li> </ul> <p>The primary risk associated with DOM sources is the potential for this data to be manipulated or crafted in a malicious way. If not properly handled, such data can be used in [[Cross-Site Scripting|XSS]] attacks.</p>"},{"location":"web/drupal/","title":"Drupal","text":"<p>Drupal is an open-source [[content management system]] (CMS) and web application framework that is used to build and manage a wide variety of websites and web applications.</p> <p>It is written in [[PHP]] and provides a flexible and extensible platform for developers, content creators, and site administrators. Drupal is known for its robustness, scalability, and the ability to handle complex websites with advanced features.</p>"},{"location":"web/dtd/","title":"Document Type Definition (DTD)","text":"<p>A Document Type Definition (DTD) is a set of markup declarations that define a document type for an [[Standard Generalized Markup Language (SGML)|SGML]]-family markup language (such as [[HTML]] and [[Extensible Markup Language|XML]]). A DTD specifies the legal building blocks of an XML document. It defines the document structure with a list of legal elements and attributes.</p> <p>A DTD defines elements, their composition, and their content model. For example, it specifies which elements are allowed, in what order, and what content they can contain. It also defines attributes for elements and constrains their possible values. DTD allows the definition of entities, which can be used to define shortcuts for complex or frequently used text.</p> <p>In web applications, DTDs are commonly used in XML data interchange formats. They ensure that XML documents conform to a predefined structure and data types, which is critical for data integrity and successful data exchange. XML parsers can use a DTD to validate XML documents, ensuring they meet the structure and constraints defined in the DTD.</p> <p>[[XML External Entities (XXE)|XXE]] vulnerabilities arise when an XML processor evaluates external entity references within an XML document. An attacker can exploit XXE vulnerabilities by including hostile content in an XML document, which can lead to unauthorized data disclosure, [[Denial of Service (DoS) Attacks|denial of service]], [[server-side request forgery]], and other security issues.</p> <p>If an XML parser processes XML files with DTDs and allows the definition of external entities, an attacker could define an entity that accesses a file on the server or interacts with external systems. An example of an XXE attack via DTD:</p> <pre><code>&lt;!DOCTYPE data [\n&lt;!ELEMENT data (#ANY)&gt;\n&lt;!ENTITY xxe SYSTEM \"file:///etc/passwd\"&gt;]&gt;\n&lt;data&gt;&amp;xxe;&lt;/data&gt;\n</code></pre> <p>In this example, the DTD defines an external entity <code>xxe</code> that tries to read the content of <code>/etc/passwd</code> (a sensitive file on Unix-like systems).</p>"},{"location":"web/ejs/","title":"EJS (Embedded JavaScript)","text":"<p>Embedded JavaScript (EJS) is a [[Template Engines|templating language]] that allows developers to embed [[JavaScript]] code directly within [[HTML]] markup. It enables the dynamic generation of HTML content by incorporating server-side logic directly into the templates. EJS is often used in web development frameworks that follow the [[NodeJS|Node.js]] ecosystem, but it can be used in various environments where JavaScript is supported.</p> <p>EJS allows developers to embed JavaScript code within <code>&lt;% %&gt;</code> tags in HTML files. This embedded code can include variables, loops, conditionals, and other JavaScript expressions.</p> <p>Example:</p> <pre><code>&lt;ul&gt;\n  &lt;% for (let i = 0; i &lt; items.length; i++) { %&gt;\n  &lt;li&gt;&lt;%= items[i] %&gt;&lt;/li&gt;\n  &lt;% } %&gt;\n&lt;/ul&gt;\n</code></pre> <p>To output dynamic content securely, EJS provides <code>&lt;%= %&gt;</code> tags. Content within these tags is HTML-escaped by default, preventing potential cross-site scripting (XSS) vulnerabilities.</p> <p>Example:</p> <pre><code>&lt;p&gt;Name: &lt;%= user.name %&gt;&lt;/p&gt;\n</code></pre> <p>EJS supports control flow structures such as if, else, for, and more. This allows developers to create dynamic templates with conditional logic and iterations.</p> <p>Example:</p> <pre><code>&lt;% if (user.isAdmin) { %&gt;\n&lt;p&gt;Welcome, admin!&lt;/p&gt;\n&lt;% } else { %&gt;\n&lt;p&gt;Welcome, user!&lt;/p&gt;\n&lt;% } %&gt;\n</code></pre> <p>EJS allows the inclusion of other templates or partials using &lt;%- include('partial.ejs') %&gt;. This promotes code reuse and modularization.</p> <p>Example:</p> <pre><code>&lt;header&gt;&lt;%- include('header.ejs') %&gt;&lt;/header&gt;\n</code></pre> <p>Developers can define custom tags and functions to extend EJS's functionality. This provides flexibility in creating reusable components and helpers.</p> <p>Example:</p> <pre><code>&lt;p&gt;&lt;%= customFunction(data) %&gt;&lt;/p&gt;\n</code></pre> <p>EJS is lightweight, easy to use, and integrates seamlessly with Node.js applications. It is commonly used for server-side rendering (SSR) in web frameworks like [[Express|Express.js]]. Additionally, EJS templates can be rendered on the server side or client side, depending on the use case.</p>"},{"location":"web/entity/","title":"Parameter Entity","text":"<p>Parameter entities in [[Extensible Markup Language|XML]] are a special type of entity used within [[DTD (Document Type Definition)|Document Type Definitions (DTDs)]] to define reusable components. They are similar to general entities but are specifically designed for use within the DTD to define and structure the DTD itself. Parameter entities are not used directly in the XML document's body; rather, they are used to parameterize the DTD, making it more modular and easier to maintain.</p> <p>Parameter entities are declared in a DTD using the following syntax:</p> <pre><code>&lt;!ENTITY % entity_name \"entity_value\"&gt;\n</code></pre> <p><code>%</code> indicates that it is a parameter entity, <code>entity_name</code> is the name of the entity, and <code>entity_value</code> is the value or content of the entity. Once declared, parameter entities are referenced within the DTD using the <code>%</code> symbol followed by the entity name and a semicolon (<code>;</code>). For example:</p> <pre><code>%entity_name;\n</code></pre> <p>As an example, suppose you have a set of elements that are reused across various element declarations. You can define a parameter entity for this set:</p> <pre><code>&lt;!ENTITY % items \"item1 | item2 | item3\"&gt;\n</code></pre> <p>And use it in an element declaration like this:</p> <pre><code>&lt;!ELEMENT myElement (%items;)&gt;\n</code></pre> <p>Parameter entities can be used to include entire sections of a DTD, making it modular. For example:</p> <pre><code>&lt;!ENTITY % section1 SYSTEM \"section1.dtd\"&gt;\n&lt;!ENTITY % section2 SYSTEM \"section2.dtd\"&gt;\n</code></pre> <p>Then, these sections can be included in the DTD:</p> <pre><code>%section1;\n%section2;\n</code></pre> <p>Parameter entities, like other types of DTD entities, can be exploited in [[XML External Entities (XXE)|XML External Entity (XXE)]] attacks if an attacker can inject or alter DTDs in an XML document. This is particularly risky when the parameter entities reference external resources. To mitigate this, it's recommended to configure XML parsers to disable the processing of external entities and parameter entities from untrusted sources.</p>"},{"location":"web/erb/","title":"ERB","text":"<p>ERB, which stands for \"Embedded Ruby\", is a templating system that is part of the standard library for the [[Ruby]] programming language. It allows Ruby code to be embedded within a text document, typically [[HTML]]. This can be particularly useful in web development for dynamically generating webpage content.</p> <p>ERB lets you embed Ruby code into a text file, usually an HTML file, to create dynamic content. The Ruby code is evaluated, and the output is inserted into the document in place of the code itself.</p> <p>ERB uses tags to denote the Ruby code that should be evaluated. The most common tags are <code>&lt;% %&gt;</code> and <code>&lt;%= %&gt;</code>.</p> <ul> <li><code>&lt;% %&gt;</code>: This tag runs Ruby code but doesn't output anything to the final text. It's used for logic like loops and conditionals.</li> <li><code>&lt;%= %&gt;</code>: This tag runs Ruby code and outputs the result to the document. It's often used for displaying variable values or results of Ruby expressions.</li> </ul> <p>In Ruby web frameworks like [[Ruby on Rails]], ERB is commonly used for creating views. It allows developers to write HTML templates with embedded Ruby code to generate dynamic web pages based on user requests and data from a database.</p> <p>A simple ERB template might look like this:</p> <pre><code>&lt;html&gt;\n&lt;body&gt;\n  &lt;h1&gt;Welcome, &lt;%= @user.name %&gt;&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>In this example, <code>@user.name</code> is a Ruby expression whose value is displayed within the <code>&lt;h1&gt;</code> tag. ERB enables a clear separation of HTML structure from the Ruby code used for business logic, adhering to the principle of separation of concerns in software development.</p> <p>ERB can be used in various contexts, not just for web pages. It's suitable for any scenario where dynamic content generation is needed. While ERB is part of the standard Ruby library, it is particularly prominent in Ruby on Rails applications, where it's the default templating engine for generating HTML.</p>"},{"location":"web/erl/","title":"Entity Reference Loops","text":"<p>Entity reference loops occur when an entity in an [[Extensible Markup Language|XML]] document refers to itself directly or indirectly, creating an infinite loop. This issue arises in the context of XML entities, which are a way of defining shortcuts for larger blocks of text or external data. Entity reference loops are particularly relevant in the context of [[XML External Entities (XXE)|XML External Entity (XXE)]] attacks and can lead to [[Denial of Service (DoS) Attacks|denial of service (DoS)]] conditions.</p> <p>In XML, you can define entities, which are placeholders for some content. When an XML processor encounters an entity, it replaces the entity with the content it represents. A loop occurs when the replacement text of an entity includes a reference to the same entity, either directly or through other entities.</p> <p>A simple XML document with a [[Document Type Definition (DTD)]] that defines entities could be:</p> <pre><code>&lt;!DOCTYPE root [\n&lt;!ENTITY loop \"loop: &amp;loop;\"&gt;\n]&gt;\n&lt;root&gt;&amp;loop;&lt;/root&gt;\n</code></pre> <p>In this example, the entity <code>loop</code> is defined to include a reference to itself. When the XML processor tries to expand <code>loop</code>, it finds that it needs to expand <code>loop</code> again, and this goes on indefinitely, potentially causing the processor to crash or hang.</p> <p>In web applications, if an XML parser tries to process a document with an entity reference loop, it can consume excessive system resources, leading to a DoS condition. Attackers might exploit XXE vulnerabilities by crafting malicious XML input that includes entity reference loops, aiming to crash the server or service that processes the XML.</p>"},{"location":"web/errorsql/","title":"Error-Based Injection","text":"<p>Error-based [[SQL injection]] is a technique used in SQL injection attacks where the attacker intentionally performs actions that cause the database to produce error messages. These error messages can reveal critical information about the database's structure, such as table names, column names, and other details.</p> <p>The attacker can then use this information to craft more effective and targeted SQL injection attacks.</p> <p>The attacker first identifies parts of a web application that interact with a database, such as form inputs, URL parameters, or [[HTTP headers]]. These points are potential targets for injection.</p> <p>The attacker inputs data that is likely to cause the database to generate an error. For example, they might input a single quote (') to disrupt a SQL query. This is done in the hope that the database will return an error message that contains information about the database structure</p> <p>When the database returns an error, the message might include information about the database schema, such as table names, column names, data types, and the SQL query structure. Error messages can be quite detailed, especially if the database is not properly configured to suppress sensitive information.</p> <p>Using the information gleaned from the error messages, the attacker can craft more specific and targeted SQL queries to extract data, bypass authentication, or even modify database contents.</p> <p>Consider a simple SQL query:</p> <pre><code>SELECT * FROM users WHERE username = '[user_input]';\n</code></pre> <p>If an attacker inputs ' OR '1'='1, the query becomes:</p> <pre><code>SELECT * FROM users WHERE username = '' OR '1'='1';\n</code></pre> <p>This might cause the database to return a syntax error message that reveals information about the query structure or database schema.</p> <p>Error-based SQL injection is effective in environments where the database errors are verbose and provide detailed information. However, it is less effective or completely ineffective in environments where error messages are suppressed or generalized.</p>"},{"location":"web/esii/","title":"Edge-Side Includes Injections","text":"<p>Edge-Side Includes (ESI) Injection is a web security vulnerability that targets web caching systems using Edge-Side Includes, a markup language used for dynamic web content assembly at the edge of the network (i.e., in edge servers or [[Content Delivery Network|content delivery networks]]).</p> <p>ESI is intended to optimize web traffic and reduce server load by allowing dynamic content to be assembled and updated independently of the static content on a webpage.</p> <p>ESI tags are inserted into [[HTML]] documents to instruct a compatible web cache or edge server to take specific actions, like including content from another source or variable. When a client requests an ESI-enabled page, the server processes these ESI tags to assemble and deliver the final content.</p> <p>ESI Injection occurs when an attacker is able to insert malicious ESI tags into content that will be processed by a caching server. This can happen if user input is not properly sanitized before being included in a web page that is then processed for ESI directives.</p> <p>Depending on the capabilities of the ESI processor and the rights of the caching server, an attacker might use ESI Injection to perform actions like executing arbitrary code, manipulating cache content, or stealing sensitive information.</p> <p>Consider a web application that includes user comments in a page without proper sanitization. An attacker could submit a comment containing ESI tags (<code>&lt;esi:include src=\"...\"/&gt;</code>). If this input is processed by an ESI-capable cache, the injected tag could lead to the inclusion of malicious content or code.</p>"},{"location":"web/exchange/","title":"Key Exchange","text":"<p>A key exchange in the context of web communication refers to the process of exchanging cryptographic keys between a [[Client|client]] and a [[Server|server]] during the establishment of a secure [[HTTPS Protocol|HTTPS]] connection.</p> <p>This key exchange is a crucial part of the SSL/TLS (Secure Socket Layer/Transport Layer Security) protocol, which ensures secure communication over the internet.</p> <p>The key exchange process typically involves the following steps:</p> <ol> <li>Initiation: When you connect to a secure website (one using HTTPS), your browser sends a 'ClientHello' message to the server, indicating its SSL/TLS capabilities</li> <li>Server Response: The server replies with a 'ServerHello' message, agreeing on the SSL/TLS version and cryptographic methods to use. The server also sends its digital certificate, which contains the server's public key</li> <li>Key Exchange: The browser verifies the server's certificate (to ensure it's trustworthy) and then uses the server's public key to encrypt a pre-master secret. This encrypted secret is sent to the server.</li> <li>Secret Derivation: Both the server and the browser independently use this pre-master secret to generate a common 'master secret'. From this master secret, they both derive a set of symmetric encryption keys.</li> <li>Encrypted Communication: All further communication in this session is encrypted using the symmetric keys, ensuring that the data exchanged between the browser and the server is secure and private.</li> </ol>"},{"location":"web/fba/","title":"Form-Based Authentication","text":"<p>Form-based authentication is a common method of user authentication used in web applications. It involves presenting the user with a form that requests credentials, typically a username and a password. This method is widely used due to its simplicity and effectiveness in providing a basic level of security for web-based applications.</p> <p>The user is presented with a form on a web page, where they are required to enter their credentials (usually a username and password). Upon submission, the form data is sent to the server, typically via an HTTP POST request. The server then checks the submitted credentials against a stored database of user information. This process usually involves comparing the provided password with a stored [[Password Hashes|password hash]].</p> <p>If the credentials are correct, the server creates a session for the user. It often sends back a session cookie to the user's browser, which is used for tracking the session on subsequent requests. Once authenticated, the user can access protected areas of the application during that session.</p> <p>Form-based authentication should always be used in conjunction with [[HTTPS Protocol|HTTPS]] to encrypt the data transmitted between the client and the server, protecting it from being intercepted and read by unauthorized parties (a security issue known as \"[[Man-in-the-Middle (MitM) attack|man-in-the-middle attack]]\").</p> <p>Passwords should never be stored in plain text; they should be securely hashed (and [[Salt|salted]]) in the database. The application should manage sessions securely, protecting against [[session hijacking]] and [[Session Fixation|fixation]] attacks. This includes setting secure attributes for cookies and implementing proper session expiration.</p> <p>It's important to validate and sanitize all inputs to prevent attacks such as [[SQL injection]]. To prevent automated login attempts ([[Brute Force Attack|brute force attacks]]), implementing [[CAPTCHA]] can be an effective measure.</p>"},{"location":"web/fbox/","title":"Flexbox","text":"<p>Flexbox, short for Flexible Box Module, is a layout model in [[CSS]] (Cascading Style Sheets) that allows for a more efficient way to lay out, align, and distribute space among items in a container, even when their size is unknown or dynamic. It's particularly useful in web applications for several reasons:</p> <p>The\u00a0Flexbox Layout\u00a0(Flexible Box) module aims at providing a more efficient way to lay out, align and distribute space among items in a container, even when their size is unknown and/or dynamic (thus the word \u201cflex\u201d).</p> <p>The main idea behind the flex layout is to give the container the ability to alter its items\u2019 width/height (and order) to best fill the available space (mostly to accommodate to all kind of display devices and screen sizes). A flex container expands items to fill available free space or shrinks them to prevent overflow.</p> <p>Most importantly, the flexbox layout is direction-agnostic as opposed to the regular layouts (block which is vertically-based and inline which is horizontally-based). While those work well for pages, they lack flexibility (no pun intended) to support large or complex applications (especially when it comes to orientation changing, resizing, stretching, shrinking, etc.).</p>"},{"location":"web/fqdn/","title":"Fully Qualified Domain Name (FQDN)","text":"<p>A FQDN is simply part of the [[Uniform Resource Locator|URL]]. It is the full name of an entity on the Internet, including a host and a computer. It simply specifies all domain levels written in the \"hostname.domain.tld\" format. As an example, a mail server of Yahoo might be \"mail.yahoo.com\"/</p> <p></p> <p>There are elements on an FQDN hierarchy which is as follows:</p> <ul> <li>[[Hostname]] - label assigned to a server service available on a network. DNS server uses a hostname to make an IP address easy to remember. Examples include \"www\" or \"en\" </li> <li>[[Subdomains|Subdomain]] - left side of a second-level domain and indicates a section of a larger domain. For example \"support.complexsecurity.io\" is a part of complexsecurity.io and the word \"support\" is the subdomains.</li> <li>Domain name - consists of a second-level and a [[Top-Level Domain (TLD)|top-level domain]]. For example, in \"complexsecurity.io\", \"complexsecurity\" is the second-level domain and \".io\" is the top-level domain.</li> </ul>"},{"location":"web/frames/","title":"Web Development Frameworks","text":"<p>A web framework often referred to as a web application framework is a pre-built set of libraries, software tools, and best practices that support the overall\u00a0software development\u00a0of web apps.</p> <ul> <li>It handle multiple routine tasks and proffer a structured way to organize code, making development more maintainable and efficient.</li> <li>It eases the\u00a0web development procedure\u00a0and, hence, makes it simpler to build a website and web apps.</li> <li>Using a web development framework can aid in guaranteeing that the final product possesses scalability, reliability, and maintainability, thanks to the consistent development approach it offers.</li> </ul> <p>Some common ones include:</p> <ul> <li>[[Laravel]] ([[PHP]])</li> <li>[[Express]] ([[NodeJS|Node.JS]])</li> <li>[[Django]] ([[Python]])</li> <li>[[Rails]] ([[Ruby]])</li> </ul>"},{"location":"web/funcinject/","title":"Function Injection","text":"<p>Function Injection is a type of security vulnerability in web applications, particularly relevant in languages like [[PHP]], where code execution is highly dynamic. It occurs when an application allows user input to influence the names of functions that are executed. This vulnerability can lead to serious consequences, including unauthorized [[Knowledge Base/Remote Code Execution|code execution]] and compromise of the server.</p> <p>In languages like PHP, functions can be called dynamically using variable function names. For instance, if you have a variable <code>$func</code> containing the string 'execute', calling <code>$func()</code> would be equivalent to calling <code>execute()</code>.</p> <p>Function injection exploits occur when the application improperly allows user input to determine which function is called. If an attacker can control the name of the function being called, they could execute any function within the application's scope, including built-in PHP functions.</p> <p>An example of vulnerable code:</p> <pre><code>$function_name = $_GET['func'];\n$function_name(); // Dangerous: Calls a function based on user input\n</code></pre> <p>Some potential risks include:</p> <ul> <li>Arbitrary Code Execution: An attacker could execute functions that modify or leak data, manipulate files, or perform other malicious actions.</li> <li>Escalating Privileges: If combined with other vulnerabilities, function injection could lead to [[privilege escalation]], allowing an attacker to perform actions as a more privileged user.</li> </ul>"},{"location":"web/fup/","title":"File Uploads","text":"<p>File upload vulnerabilities are when a web server allows users to upload files to its filesystem without sufficiently validating things like their name, type, contents, or size. Failing to properly enforce restrictions on these could mean that even a basic image upload function can be used to upload arbitrary and potentially dangerous files instead. This could even include server-side script files that enable remote code execution.</p> <p>In some cases, the act of uploading the file is in itself enough to cause damage. Other attacks may involve a follow-up [[HTTP Protocol|HTTP]] request for the file, typically to trigger its execution by the server.</p> <p>It's rare for websites in the wild to have no restrictions whatsoever on which files users are allowed to upload. More commonly, developers implement what they believe to be robust validation that is either inherently flawed or can be easily bypassed.</p> <p>For example, they may attempt to blacklist dangerous file types, but fail to account for parsing discrepancies when checking the file extensions. As with any blacklist, it's also easy to accidentally omit more obscure file types that may still be dangerous.</p> <p>In other cases, the website may attempt to check the file type by verifying properties that can be easily manipulated by an attacker using tools like Burp Proxy or Repeater.</p> <p>Ultimately, even robust validation measures may be applied inconsistently across the network of hosts and directories that form the website, resulting in discrepancies that can be exploited.</p>"},{"location":"web/fuzzing/","title":"Web Fuzzing","text":"<p>Fuzz testing or fuzzing is an automated software testing method that injects invalid, malformed, or unexpected inputs into a system to reveal software defects and vulnerabilities.</p> <p>A fuzzing tool injects these inputs into the system and then monitors for exceptions such as crashes or information leakage.</p> <p>Put more simply, fuzzing introduces unexpected inputs into a system and watches to see if the system has any negative reactions to the inputs that indicate security, performance, or quality gaps or issues.</p> <p>In web apps, fuzzing is a method of sending malformed or abnormal data to a system in order to get it to misbehave in some way, which could lead to the discovery of vulnerabilities.</p> <p>Finding hidden files, sending random data to forms, or even login attempts to web applications can be considered fuzzing.</p> <p>[[Brute Force Attack|Brute forcing]] can be considered a part of fuzzing. In brute force, the attacker uses valid data, for example, to check if a login attempt works. But with Fuzzing, they can send random data to break the expected behavior of a system.</p> <p>For example, if you use a tool like [[Ffuf]] and load it with hundreds of username-password combinations to try on a website, it is fuzzing. And that\u2019s exactly what we will do using Ffuf.</p> <p>Make sure you have written permission if you are going to try this tool on a third-party website.</p>"},{"location":"web/get/","title":"Get HTTP Method","text":"<p>An HTTP GET request is a way your web browser asks for information from a website. IT is used to request data from a specific resource, typically a [[Server]]. When you enter a URL, your browser makes a GET request to the server hosting the resource.</p> <p>The request is essentially asking the server to send the data associated with that URL back to the browser. If you request a web page, the server responds by sending the [[HTML]], [[CSS]] and [[JavaScript]] files needed to display that page.</p>"},{"location":"web/hbars/","title":"Handlebars","text":"<p>Handlebars is a popular templating language used in web development. It provides a simple and expressive way to create templates for dynamic [[HTML]] generation. Handlebars templates are logic-less, meaning they focus on the structure and presentation of the content without incorporating programming logic directly within the templates.</p> <p>Handlebars uses a syntax similar to Mustache, another templating language. The syntax involves using double curly braces (<code>{{</code> and <code>}}</code>) to enclose placeholders or expressions that will be replaced with actual values during template rendering.</p> <p>Example:</p> <pre><code>&lt;p&gt;{{ name }}&lt;/p&gt;\n</code></pre> <p>Variables can be inserted into templates using the <code>{{ variable }}</code> syntax. These variables are replaced with actual values when the template is rendered.</p> <p>Example:</p> <pre><code>&lt;p&gt;{{ user.name }}&lt;/p&gt;\n</code></pre> <p>Handlebars allows the use of simple expressions and helpers for more complex operations. These expressions are enclosed in double curly braces.</p> <p>Example:</p> <pre><code>&lt;p&gt;{{ add x y }}&lt;/p&gt;\n</code></pre> <p>Handlebars provides the <code>{{#each}}</code> block helper for iterating over arrays or objects. It allows developers to loop through data and generate repetitive HTML structures.</p> <p>Example:</p> <pre><code>{{#each items}}\n  &lt;p&gt;{{ this }}&lt;/p&gt;\n{{/each}}\n</code></pre> <p>Handlebars supports conditional rendering using the <code>{{#if}}</code> block helper. It allows developers to conditionally include or exclude content based on logical conditions.</p> <p>Example:</p> <pre><code>{{#if isAdmin}}\n  &lt;p&gt;Welcome, admin!&lt;/p&gt;\n{{else}}\n  &lt;p&gt;Welcome, user!&lt;/p&gt;\n{{/if}}\n</code></pre> <p>Handlebars is often used with [[JavaScript]] and can be seamlessly integrated into various web development frameworks. It promotes the separation of concerns by keeping logic outside of the templates and is known for its simplicity and ease of use. Additionally, Handlebars templates are compatible with a wide range of server-side and client-side JavaScript environments.</p>"},{"location":"web/header/","title":"Header Injection","text":"<p>Header Injection is a type of vulnerability in web applications where an attacker is able to inject malicious header values into [[HTTP Protocol|HTTP]] responses. This vulnerability typically occurs when user input is improperly sanitized before being included in the header output. It can lead to various security issues, including [[Cross-Site Scripting]] (XSS), website redirection, [[Web Cache Poisoning]], and [[Session Fixation]].</p> <p>Header Injection involves injecting malicious content into HTTP response headers. By manipulating headers, an attacker can alter how the HTTP response is processed by the browser or intermediate proxies.</p> <p>Common Vulnerable Headers: - Location Header: Used for redirection. Injecting a malicious URL can redirect users to phishing or malware sites. - Set-Cookie Header: Manipulating [[Cookies|cookie]] headers can lead to session fixation or hijacking. - Content-Type Header: Altering the content type can change how the response is interpreted by the browser.</p> <p>This vulnerability often arises when a web application incorporates user-supplied data into HTTP response headers without proper validation or escaping. For example, data from form inputs, query parameters, or cookies might be insecurely included in response headers.</p> <p>In a web application, the following PHP code is vulnerable to header injection:</p> <pre><code>header(\"Location: \" . $_GET['url']);\n</code></pre> <p>If the <code>url</code> parameter is not properly sanitized, it can be exploited to redirect users to a malicious site.</p>"},{"location":"web/headers/","title":"HTTP Headers","text":"<p>The HTTP header is part of the [[HTTP Protocol|Hypertext Transfer Protocol]] (HTTP) and transmits additional information during HTTP requests or responses. In addition to the data that is delivered to a browser by the web server of the called website, server and browser exchange meta information about the document via the HTTP header.</p> <p>An HTTP request contains a header area with information such as the date of the request, the referrer, or the preferred language. The HTTP response also contains a header field in which the server sends its information to the user's browser. This information exchange is usually invisible to the end user.</p> <p>HTTP headers include fields which themselves consist of one line. Each line contains a name/value pair - called key-value pair - separated by a colon and is terminated by a line break.</p> <p>Values that can be used for the HTTP header are defined in the RFC (\"Requests for Comments\"). In addition to the specified fields, there are also non-standard headers that can be used to add user-defined information. These headers usually start with an\u00a0<code>X-</code>.</p> <p>Some of the most common HTTP Headers include:</p> <ul> <li>Accept - defines the media types the [[client]] is able to accept from the [[server]]</li> <li>User-Agent - identifies the browser or client app making the request, enabling the server to tailor the response to the client.</li> <li>Authorization - used to send client's credentials to server when client is attempting to access a protected resource.</li> <li>Content-Type - identifies the media type of content in the request body.</li> <li>Cookie - client can use [[Cookies|cookies]] to send previously stored cookies back to the server.</li> <li>Cache-Control - controls caching behaviour in the client's browser or intermediate caches.</li> <li>Server - includes name and version of the server software that generated the response.</li> <li>Set-Cookie - instructs client to store a cookie with the specified name, value and additional attributes.</li> <li>Content-Length - specifies the size of the response body in bytes.</li> </ul> <p>They can also be categorized and grouped together such as:</p> <ul> <li>General Headers - contextual and used to describe the message.</li> <li>Entity Headers - used to describe the content transferred by a message.</li> <li>Request Headers - used in an HTTP request and do not relate to the content.</li> <li>Response Headers - used in an HTTP response and do not relate to the content.</li> <li>Security Headers - class of response headers used to specify certain rules and policies to be followed.</li> </ul>"},{"location":"web/hpp/","title":"HTTP Parameter Pollution (HPP)","text":"<p>HTTP Parameter Pollution (HPP) is a web security vulnerability that occurs when a web application does not properly handle input with multiple parameters with the same name, leading to unexpected and potentially harmful behavior.</p> <p>[[HTTP Protocol|HTTP]] requests can contain parameters that are used by web applications to perform actions or retrieve data. These parameters can be part of the [[Uniform Resource Locator|URL]] (in the case of GET requests) or in the body of the request (typically in POST requests).</p> <p>In an HTTP Parameter Pollution attack, an attacker deliberately injects additional HTTP parameters or manipulates existing ones with the same name. The goal is to exploit the way the web application processes these parameters.</p> <p>The impact of HPP depends on how the application handles multiple parameters with the same name. Some applications might take the first parameter value, others the last, while some might concatenate the values. This behavior can be exploited to manipulate the application's logic or access unauthorized data.</p> <ol> <li>Types of HPP:<ul> <li>Local HPP: This occurs when the polluted parameter is used within the same application. It might lead to bypassing input validation checks, [[cross-site scripting]] (XSS), [[SQL injection]], etc.</li> <li>Remote HPP: This involves polluting parameters that are built into URLs and then sent to other applications. It can be used to manipulate external systems or trick applications into generating malicious URLs.</li> </ul> </li> </ol> <p>Attackers can use HPP to modify the logic of an application, bypass security controls, or access unauthorized data. For example, if an application's access control depends on a parameter value, manipulating this value might grant higher privileges than intended.</p>"},{"location":"web/hsts/","title":"HTTP Strict Transport Security","text":"<p>HSTS stands for\u00a0HTTP Strict Transport Security. It is a method used by websites to declare that they should only be accessed using a secure connection ([[HTTPS Protocol|HTTPS]]). </p> <p>If a website declares an HSTS policy, the browser must refuse all [[HTTP Protocol|HTTP]] connections and prevent users from accepting insecure [[SSL certificates]]. HSTS is currently supported by\u00a0most major browsers (only some mobile browsers fail to use it.</p> <p>Typically, when you enter a URL in the web browser, you skip the protocol part. For example, you type www.acunetix.com, not http://www.acunetix.com. </p> <p>In such a case, the browser assumes that you want to use the HTTP protocol so it makes an HTTP request to www.acunetix.com.</p> <p>At this stage, the web server replies with a redirect (301 response code) that points to the HTTPS site. The browser makes an HTTPS connection to www.acunetix.com. This is when the HSTS security policy protection begins using an HTTP response header:</p> <pre><code>Strict-Transport-Security: max-age=31536000; includeSubDomains; preload\n</code></pre> <p>The Strict-Transport-Security header gives specific instructions to the browser. From now on, every connection to the site and its subdomains for the next year (31536000 seconds) from the moment this header is received must be an HTTPS connection. </p> <p>HTTP connections are not allowed at all. If the browser receives a request to load a resource using HTTP, it must try an HTTPS request instead. If HTTPS is not available, the connection must be terminated.</p> <p>Additionally, if the certificate is not valid, you will be prevented from making a connection. Usually, if a certificate is not valid (expired, self-signed, signed by an unknown CA, etc.) the browser displays a warning that you can circumvent. </p> <p>However, if the site has HSTS, the browser will not let you circumvent the warning at all. To access the site, you must remove the site from the HSTS list within the browser.</p> <p>The Strict-Transport-Security header is sent for a given website and covers a particular domain name. Therefore, if you have the HSTS header for www.acunetix.com, it will not cover acunetix.com but only the www subdomain.</p> <p>This is why, for complete protection, your website should include a call to the base domain (in this case, acunetix.com) and receive a Strict-Transport-Security header for that domain with the includeSubDomains directive.</p> <p></p>"},{"location":"web/html/","title":"HTML","text":"<p>HyperText Markup Language is the language used to create web pages. It is a markup language that tells web browsers how to structure and display content on a webpage. It allows the creation and structure of sections, paragraphs, and links using HTML elements such as tags and attributes.</p> <p>HTML documents are files that end with a\u00a0.html\u00a0or\u00a0.htm\u00a0extension. A web browser reads the HTML file and renders its content so that internet users can view it.</p> <p>All HTML pages have a series of HTML elements, consisting of a set of tags and attributes. HTML elements are the building blocks of a web page. A tag tells the web browser where an element begins and ends, whereas an attribute describes the characteristics of an element.</p> <p>The three main parts of an element are:\u00a0</p> <ul> <li>Opening tag - used to state where an element starts to take effect</li> <li>Content - the output that other users see</li> <li>Closing tag - same as opening tag, but with a forward slash before the element name</li> </ul> <p>Another critical part of an HTML element is its attribute, which has two sections \u2013 a name and attribute value. The name identifies the additional information that a user wants to add, while the attribute value gives further specifications.</p>"},{"location":"web/htmlencoding/","title":"HTML Encoding","text":"<p>HTML encoding is a method used to convert characters into a format that can be safely transmitted or displayed in a web environment. This process is essential because certain characters have special meanings in HTML and might cause issues if used directly in HTML code.</p> <p>[[HTML]] uses specific character sets like [[ASCII]] or [[Unicode]]. However, characters like \"&lt;\", \"&gt;\", and \"&amp;\" have special meanings in HTML (as tags or entities). To display these characters as regular text, they must be encoded.</p> <p>Special characters are encoded using character references. These references can take two forms:</p> <ul> <li>Named Character References: These are readable names that represent characters, like <code>&amp;lt;</code> for the less-than sign (\"&lt;\").</li> <li>Numeric Character References: These use a number to represent a character, like <code>&amp;#60;</code> for the less-than sign.</li> </ul>"},{"location":"web/htmli/","title":"HTML Injection","text":"<p>HTML Injection, often known as \"virtual defacements,\" is one of the easiest and most widespread vulnerabilities that occur when a web page neglects to sanitize user-supplied data or validate the output. </p> <p>As a result, the attacker can create his payloads and inject malicious HTML codes into the web\u00a0application through the susceptible fields, allowing him to change the webpage content and even steal sensitive data.</p> <p>Attackers often inject malicious [[JavaScript]], [[VBScript]], [[ActiveX]],\u00a0and/or\u00a0[[HTML]] into vulnerable applications to deceive the user in order to gather data from them.\u00a0 </p> <p>Cross-site scripting (XSS) vulnerabilities can be used by attackers to bypass authentication controls there by gaining access to sensitive data on your system. Well crafted malicious code can even help the attacker gain access to the entire system.</p> <p>This vulnerability occurs when user input is not correctly sanitized and the output is not encoded. An injection allows the attacker to send a malicious HTML page to a victim. The targeted browser will not be able to distinguish (trust) legitimate parts from malicious parts of the page, and consequently will parse and execute the whole page in the victim\u2019s context.</p> <p>There is a wide range of methods and attributes that could be used to render HTML content. If these methods are provided with an untrusted input, then there is an high risk of HTML injection vulnerability. </p> <p>For example, malicious HTML code can be injected via the\u00a0innerHTML\u00a0JavaScript method, usually used to render user-inserted HTML code. If strings are not correctly sanitized, the method can enable HTML injection. A JavaScript function that can be used for this purpose is\u00a0document.write().</p>"},{"location":"web/http/","title":"HTTP Protocol","text":"<p>HTTP is the foundation of the World Wide Web, and is used to load webpages using hypertext links. HTTP is an [[Application Layer]] protocol designed to transfer information between networked devices and runs on top of other layers of the [[Network Protocol Stack]]. </p> <p>It is a protocol for fetching resources such as HTML documents and is the foundation of any data exchange on the Web and it is a [[client]]-[[server]] protocol. A complete document is reconstructed from the different sub documents fetched, for instance, text, layout description, images, videos, scripts and more.</p> <p>Without HTTP, it would be difficult to imagine how the internet would work. There would be no web pages, no URLs and no hyperlinks. Instead, users would need to know the exact [[IP Address]] of the server hosting the information they want to access, and they would need to use a low-level protocol like [[TCP-IP]].</p>"},{"location":"web/http1/","title":"HTTP1.0","text":"<p>HTTP/1.0 is the first version of the Hypertext Transfer Protocol ([[HTTP Protocol|HTTP]]) that was widely used for the World Wide Web. As a basic protocol, it established the foundation for web communication, allowing for the transfer of [[HTML]] documents and other resources over the internet.</p> <p>HTTP/1.0 opens a new [[Transmission Control Protocol|TCP]] connection for each HTTP request/response cycle, leading to increased latency due to the overhead of establishing connections. Like all HTTP versions, it is stateless, meaning each request is independent and the server retains no information between requests.</p> <p>HTTP/1.0 has more limited capabilities in headers compared to later versions, impacting functionalities like caching and authentication.</p> <p>In contrast to other versions:</p> <ul> <li>[[HTTP1.1|HTTP/1.1]]: Introduced features like persistent connections (keeping connections open for multiple requests), chunked transfer encoding, and additional cache control options. It's more efficient in handling web traffic.</li> <li>[[HTTP2|HTTP/2]]: Further improves efficiency with features like multiplexing (multiple requests over a single connection), server push, and header compression. It's binary, rather than textual, making it more compact and faster to parse.</li> </ul>"},{"location":"web/http11/","title":"HTTP1.1","text":"<p>HTTP/1.1, an upgrade from the original [[HTTP1.0|HTTP/1.0]], has been the standard web protocol for many years. It introduced several enhancements like persistent connections, chunked transfers, and additional cache control mechanisms. </p> <p>However, it processes requests sequentially on each [[Transmission Control Protocol|TCP]] connection, which can lead to inefficiencies and slower performance (a problem known as \"[[Head-of-Line Blocking]]\").</p> <p>In terms of security, HTTP/1.1 itself is not inherently insecure, but it lacks encryption. When used over [[TLS]] ([[HTTPS Protocol|HTTP]]), it's secure against eavesdropping and tampering.</p> <p>Comparatively, [[HTTP2|HTTP/2]] offers significant improvements:</p> <p>HTTP/2's multiplexing allows multiple requests and responses simultaneously over a single connection, reducing latency. HTTP/2 can send resources proactively, not just in response to requests. This makes HTTP/2 more efficient in parsing and reduces errors compared to HTTP/1.1's text-based approach. It reduces overhead, especially in scenarios with many small requests.</p>"},{"location":"web/http2/","title":"HTTP2","text":"<p>HTTP/2 is the second major version of the [[HTTP Protocol|HTTP]] network protocol, used by the World Wide Web. It was developed by the HTTP Working Group of the Internet Engineering Task Force (IETF) and was published in 2015.</p> <p>HTTP/2, developed as an improvement over [[HTTP1.1|HTTP/1.1]], brings significant advancements aimed at efficiency and speed. Key enhancements include:</p> <ol> <li>Binary Framing Layer: This change from HTTP/1.1's text-based format helps to more efficiently parse, multiplex, and prioritize streams.</li> <li>Multiplexing of Requests: HTTP/2 can send multiple requests for data in parallel over a single TCP connection. This drastically reduces the latency that was caused by HTTP/1.1's one-request-per-connection model.</li> <li>Stream Prioritization: Clients can prioritize streams, allowing more important resources to be sent earlier.</li> <li>Server Push: Servers can proactively send resources to a client's cache for future use, improving load times.</li> <li>Header Compression: HTTP/2 compresses headers using the [[HPACK]] compression format, reducing overhead.</li> <li>Enhanced Security: Although not inherent in the protocol, HTTP/2 is often implemented alongside [[TLS]] (Transport Layer Security), encouraging encrypted connections.</li> </ol>"},{"location":"web/httpdown/","title":"HTTP Downgrade Attack","text":"<p>An HTTP downgrade attack is a cyber attack where an attacker intercepts the communication between a user's browser and a website, forcing the connection to revert from a secure [[HTTPS Protocol|HTTPS]] connection to an unsecured [[HTTP Protocol|HTTP]] connection.</p> <p>In general, any system that employs any form of backward compatibility can be susceptible to a downgrade attack. The balance between maximum utility and maximum security is a difficult one to strike: however tempting it may be to enforce your visitors to keep their systems updated, you want people to be able to access your server using older technology.</p> <p>Downgrade attacks can take many forms, but they all have a few elements in common. Most of them are a [[Man-in-the-Middle (MitM) attack]]). </p> <p>To prevent a downgrade attack, you must address its attack vector. If the vulnerability is due to support for export-grade ciphers, then the appropriate measure is to stop supporting such ciphers. If, on the other hand, the vulnerability is associated with support for previous versions of TLS or SSL, this needs to be addressed.</p> <p>Implementing a\u00a0secure and stable TLS configuration\u00a0is one of the best measures you can take to address a host of causes that can lead to a downgrade attack. This includes providing support only to strong protocols such as TLS 1.2 and 1.3 (i.e., removing backward compatibility) and solid ciphers with no known downgrade vulnerabilities.</p> <p>Enabling the TLS_FALLBACK_SCSV signal\u00a0as part of your TLS configuration is another good step in preventing downgrade attacks. Suppose you do decide to support lower protocol versions. In that case, this will prevent your server from downgrading its protocol if the client can meet it at a higher version but is advertising a lower one (possibly due to man-in-the-middle interference).</p>"},{"location":"web/httponly/","title":"HttpOnly Flag","text":"<p>The <code>HttpOnly</code> [[Cookies|cookie]] flag is a directive used when setting HTTP cookies to help mitigate the risk of client-side script access to the protected cookie. This flag is set by the server when sending the <code>Set-Cookie</code> HTTP header and instructs the web browser to restrict access to the cookie from client-side scripts.</p> <p>The primary purpose of the <code>HttpOnly</code> flag is to provide a security measure against [[cross-site scripting]] (XSS) attacks. By marking the cookie as <code>HttpOnly</code>, it ensures that the cookie cannot be accessed through client-side scripting languages like [[JavaScript]]. </p> <p>This means that even if a script injection vulnerability exists in the website, the attacker cannot easily steal <code>HttpOnly</code>-protected cookies via JavaScript. It's an additional layer of security for session cookies and other sensitive cookies, as it helps to prevent unauthorized access and exfiltration of cookie values.</p> <p>When a server sets a cookie, it can add the <code>HttpOnly</code> flag in the <code>Set-Cookie</code> HTTP header:</p> <pre><code>Set-Cookie: sessionId=abc123; HttpOnly\n</code></pre> <p>In this example, the <code>sessionId</code> cookie is marked as <code>HttpOnly</code>, which means it will not be accessible via JavaScript running in the browser (e.g., through <code>document.cookie</code>). While the <code>HttpOnly</code> flag is a valuable tool for mitigating the impact of XSS attacks, it is not a complete solution. It does not prevent the attacks themselves but limits what an attacker can do, particularly with regard to stealing cookies.</p> <p>To maximize security, <code>HttpOnly</code> should be used in conjunction with other flags like [[Secure Flag|Secure]] (which ensures cookies are sent only over [[HTTPS Protocol|HTTPS]]) and proper input validation techniques to prevent XSS vulnerabilities in the first place.</p>"},{"location":"web/https/","title":"HTTPS Protocol","text":"<p>HTTPS is the secure version of [[HTTP Protocol|HTTP]]. HTTPS is encrypted in order to increase security of data transfer. HTTPS uses an encryption protocol to encrypt communications. The protocol is called Transport Layer Security (TLS), although formerly it was known as Secure Sockets Layer (SSL).</p> <p>The protocol secures communications by using what is known as an asymmetric public key infrastructure. This type of security system uses two different keys to encrypt communications between two parties:</p> <ul> <li>Private key - key is controlled by the owner of a website and it is kept private. It lives on the web server and used to decrypt information encrypted by the public key.</li> <li>Public key - key is available to everyone who wants to interact with the server in a way that is secure. Information encrypted by the public key can only be decrypted by the private key.</li> </ul> <p>HTTPS prevents websites from having their information broadcast in a way that\u2019s easily viewed by anyone snooping on the network. When information is sent over regular HTTP, the information is broken into packets of data that can be easily \u201csniffed\u201d using free software. </p> <p>This makes communication over the an unsecure medium, such as public Wi-Fi, highly vulnerable to interception. In fact, all communications that occur over HTTP occur in [[Clear-Text|plain text]], making them highly accessible to anyone with the correct tools.</p> <p>HTTPS is not a separate protocol from HTTP. It is simply using TLS/SSL encryption over the HTTP protocol. When a user connects to a webpage, the webpage will send over its SSL certificate which contains the public key necessary to start the secure session. The two computers, the [[client]] and the [[Server]], then go through a process called an SSL/TLS [[handshake]], which is a series of back-and-forth communications used to establish a secure connection.</p>"},{"location":"web/iframe/","title":"iFrame","text":"<p>An iframe, short for inline frame, is an [[HTML]] element used to embed another HTML document within a webpage. It's like a window within a webpage that displays content from another webpage.</p> <p>They are commonly used to embed specific content like external ads, videos, tags, or other interactive elements into the page.</p> <p>The \\ tag is easy to implement and supports various attributes like src, width, and height. While iframes are useful for content separation and embedding diverse types of content, they also pose potential security risks and can impact website performance and SEO.  <p>Browsers apply the [[same origin policy]] to iframes for security, restricting access between the parent page and the iframe content from different domains. [[Cross-Origin Resource Sharing (CORS)]] and mechanisms like the postMessage API are used to enable safe cross-domain communications in modern web development.</p>"},{"location":"web/iis/","title":"Microsoft IIS","text":"<p>Internet Information Services, also known as IIS, is a Microsoft web server that runs on Windows operating system and is used to exchange static and dynamic web content with internet users. </p> <p>IIS can be used to host, deploy, and manage web applications using technologies such as [[ASP.NET]] and [[PHP]].</p> <p>An IIS web server runs on the Microsoft .[[Dotnet|NET]] platform on the Windows OS. It\u2019s versatile and stable, and it\u2019s been widely used in production for many years. Version 10 is the most current.</p>"},{"location":"web/indexpage/","title":"Index HTML File","text":"<p>The \"index.html\" file is an [[HTML]] file that serves as the home page for a website. It is often the first file that visitors to a website will see. Usually, it is automatically opened when visitors enter the domain without specifying a specific file.</p> <p>The index.html page is the most common name used for the default page shown on a website if no other page is specified when a visitor requests the site. In other words, index.html is the name used for the homepage of the website.</p>"},{"location":"web/jinja2/","title":"Jinja2","text":"<p>Jinja2 is a popular and powerful template engine for [[Python]] web applications. It is used to generate dynamic content in web pages and other text-based documents. Jinja2 is widely used in web frameworks like [[Flask]] and [[Django]], as well as other Python applications where templating is needed.</p> <p>Jinja2 uses a template syntax that allows the embedding of dynamic content within static templates. Jinja2 also supports template inheritance, which allows you to define a base template and then create child templates.</p> <p>For security, Jinja2 automatically escapes content by default to prevent [[Cross-Site Scripting]] attacks.</p>"},{"location":"web/joomla/","title":"Joomla","text":"<p>Joomla is an open source\u00a0content management system. It helps you build powerful dynamic websites and applications. It has an intuitive interface that helps you use its features and functionality to the fullest.</p> <p>Joomla is written in\u00a0PHP\u00a0and use MySQL database to store the data while using object-oriented programming techniques. It can be set up with one-click install through web hosting control panel. </p> <p>Joomla uses\u00a0Model-View-Controller\u00a0(MVC) design architecture. According to the MVC pattern when Joomla process a request, it first analyzes the URL to evaluate which component will process the request. The model contains the data used by the component. </p> <p>It is also the Model\u2019s responsibility to update the database when and where required. The view is accountable for producing the output. It can contact with the model to get the needed information. After the view has produced the output, the component gives back the control to the Joomla framework which then executes the template.</p>"},{"location":"web/jwt/","title":"JSON Web Tokens","text":"<p>JSON Web Token is an open industry standard used to share information between two entities, usually a client (like your app\u2019s frontend) and a server (your app\u2019s backend).</p> <p>They contain [[JavaScript Object Notation|JSON]] objects which have the information that needs to be shared. Each JWT is also signed using cryptography (hashing) to ensure that the JSON contents (also known as JWT claims) cannot be altered by the client or a malicious party.</p> <p>JSON web tokens (JWTs) are a standardized format for sending cryptographically signed JSON data between systems. They can theoretically contain any kind of data, but are most commonly used to send information (\"claims\") about users as part of authentication, session handling, and access control mechanisms.</p> <p>Unlike with classic session tokens, all of the data that a server needs is stored client-side within the JWT itself. This makes JWTs a popular choice for highly distributed websites where users need to interact seamlessly with multiple back-end servers.</p> <p>A JWT consists of 3 parts: a\u00a0header, a\u00a0payload, and a\u00a0signature. These are each separated by a dot, as shown in the following example:</p> <pre><code>eyJraWQiOiI5MTM2ZGRiMy1jYjBhLTRhMTktYTA3ZS1lYWRmNWE0NGM4YjUiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJwb3J0c3dpZ2dlciIsImV4cCI6MTY0ODAzNzE2NCwibmFtZSI6IkNhcmxvcyBNb250b3lhIiwic3ViIjoiY2FybG9zIiwicm9sZSI6ImJsb2dfYXV0aG9yIiwiZW1haWwiOiJjYXJsb3NAY2FybG9zLW1vbnRveWEubmV0IiwiaWF0IjoxNTE2MjM5MDIyfQ.SYZBPIBg2CRjXAJ8vCER0LA_ENjII1JakvNQoP-Hw6GG1zfl4JyngsZReIfqRvIAEi5L4HV0q7_9qGhQZvy9ZdxEJbwTxRs_6Lb-fZTDpW6lKYNdMyjw45_alSCZ1fypsMWz_2mTpQzil0lOtps5Ei_z7mM7M8gCwe_AGpI53JxduQOaB5HkT5gVrv9cKu9CsW5MS6ZbqYXpGyOG5ehoxqm8DL5tFYaW3lB50ELxi0KsuTKEbD0t5BCl0aCR2MBJWAbN-xeLwEenaqBiwPVvKixYleeDQiBEIylFdNNIMviKRgXiYuAvMziVPbwSgkZVHeEdF5MQP1Oe2Spac-6IfA\n</code></pre> <p>Header and payload parts of a JWT are just base64 encoded JSON objects. The header contains metadata about the token itself, while the payload contains the actual \"claims\" about the user. For example, you can decode the payload from the token above to reveal the following claims:</p> <pre><code>{\n    \"iss\": \"portswigger\",\n    \"exp\": 1648037164,\n    \"name\": \"Carlos Montoya\",\n    \"sub\": \"carlos\",\n    \"role\": \"blog_author\",\n    \"email\": \"carlos@carlos-montoya.net\",\n    \"iat\": 1516239022\n}\n</code></pre> <p>The server that issues the token typically generates the signature by hashing the header and payload. In some cases, they also encrypt the resulting hash. Either way, this process involves a secret signing key. This mechanism provides a way for servers to verify that none of the data within the token has been tampered with since it was issued:</p> <p>As the signature is directly derived from the rest of the token, changing a single byte of the header or payload results in a mismatched signature.</p> <p>Without knowing the server's secret signing key, it shouldn't be possible to generate the correct signature for a given header or payload.</p>"},{"location":"web/lfi/","title":"Local File Inclusion","text":"<p>Local file inclusion (also known as LFI) is the process of including files, that are already locally present on the server, through the exploiting of vulnerable inclusion procedures implemented in the application. </p> <p>This vulnerability occurs, for example, when a page receives, as input, the path to the file that has to be included and this input is not properly sanitized, allowing directory traversal characters (such as dot-dot-slash) to be injected. Although most examples point to vulnerable PHP scripts, we should keep in mind that it is also common in other technologies such as JSP, ASP and others.</p>"},{"location":"web/loadb/","title":"Load Balancer","text":"<p>A load balancer is a device or software that distributes network or application traffic across multiple servers. This distribution is designed to optimize resource use, maximize throughput, minimize response time, and avoid overload on any single server. Load balancers are essential in high-traffic network environments, particularly for ensuring reliability and performance of websites, applications, and databases.</p> <p>A load balancer efficiently routes incoming network traffic across multiple servers (also known as a server farm or server pool) in a way that none of the servers are overburdened. This ensures that application or website performance is optimized.</p> <p>Load balancers use various algorithms to distribute traffic, such as round-robin, least connections, IP hash, and others. The choice depends on the specific requirements of the environment. Load balancers continuously check the health of servers to ensure traffic is only directed to servers that are currently operational. This helps in avoiding downtime.</p> <p>Certain applications require that a user's session be maintained on a single server. Load balancers can handle such \"sticky sessions\" to ensure user experience consistency. Load balancers allow systems to easily scale in response to varying traffic loads. They also enable maintenance and updates without service interruption.</p> <p>Modern load balancers, often termed as Application Delivery Controllers, offer advanced features like SSL termination, [[application layer]] (Layer 7) load balancing, and other security features. By spreading the workload, load balancers improve application responsiveness and increase availability of applications and websites.</p> <p>In [[cloud computing]], load balancers are used to distribute traffic across a cloud service's multiple instances. Load balancers can also provide additional security features like protecting against [[Denial of Service (DoS) Attacks]] and managing traffic spikes.</p>"},{"location":"web/lstore/","title":"LocalStorage","text":"<p><code>localStorage</code> is a feature of the [[Web Storage API]] provided by modern web browsers that allows websites and applications to store data in the user's browser. This data is stored across browser sessions, meaning it persists even after the browser is closed and reopened. </p> <p><code>localStorage</code> is used for storing key-value pairs on the client side and is accessible only by web pages from the same origin (same protocol, domain, and port).</p> <p>Unlike [[sessionStorage]], which is cleared when the browsing session ends (i.e., when the browser tab is closed), <code>localStorage</code> retains data even after the browser is closed and reopened. Data stored in <code>localStorage</code> is specific to the document's origin and is accessible only to pages from the same origin.</p> <p><code>localStorage</code> typically offers a significant amount of storage space (often around 5-10 MB per origin), much more than what cookies provide. <code>localStorage</code> operations are synchronous, meaning they occur in the order they are called. This can impact performance when dealing with large amounts of data or high-frequency read/write operations.</p> <p><code>localStorage</code> is ideal for saving user preferences, such as theme or layout choices, that should persist across browser sessions. It can be used to cache data locally to improve load times and reduce the need for repeated server requests. <code>localStorage</code> helps in maintaining the state of web applications or games without needing to send data back to the server.</p> <p>An example usage:</p> <pre><code>// Storing data in localStorage\nlocalStorage.setItem('key', 'value');\n\n// Retrieving data from localStorage\nlet data = localStorage.getItem('key');\n\n// Removing data from localStorage\nlocalStorage.removeItem('key');\n\n// Clearing all data from localStorage\nlocalStorage.clear();\n</code></pre> <p>In this JavaScript example, data is stored in <code>localStorage</code> using <code>setItem</code>, retrieved with <code>getItem</code>, removed with <code>removeItem</code>, and all data in <code>localStorage</code> can be cleared with <code>clear</code>.</p>"},{"location":"web/mako/","title":"Mako","text":"<p>Mako is a lightweight and fast templating engine for [[Python]]. It is designed to provide a simple and expressive syntax for dynamic content generation in web applications and other Python projects. Mako templates are typically used to embed dynamic content within [[HTML]], [[Extensible Markup Language|XML]], or other text-based files.</p> <p>Mako templates use a Python-like syntax, making it easy for Python developers to create dynamic content without learning a new templating language. The template syntax is designed to be familiar and expressive.</p> <p>Mako templates support the insertion of dynamic content, variables, and expressions directly into the template. This allows developers to generate HTML or other text-based content dynamically based on variables or data retrieved from the application.</p> <p>Mako supports template inheritance, allowing developers to create a base template with common structure and sections. Subsequent templates can then extend or override specific sections of the base template. This promotes code reusability and maintainability.</p> <p>Mako provides filters and macros that can be applied to content within templates. Filters allow developers to modify or format content, while macros enable the creation of reusable template components.</p> <p>Mako is known for its performance and efficiency. It compiles templates into Python code, and the compiled code can be cached for faster execution. This makes Mako suitable for high-performance web applications.</p> <p>Mako can be easily integrated with various Python web frameworks, such as Pyramid and [[Flask]]. It allows developers to use Mako templates seamlessly within the context of web applications.</p> <p>An example Mako template:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;${title}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;${heading}&lt;/h1&gt;\n    &lt;ul&gt;\n        % for item in items:\n            &lt;li&gt;${item}&lt;/li&gt;\n        % endfor\n    &lt;/ul&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>In this example, <code>${...}</code> syntax is used for variable interpolation, and <code>%...%</code> is used for control structures like loops. The Mako template allows dynamic generation of HTML content based on variables such as <code>title</code>, <code>heading</code>, and <code>items</code>.</p>"},{"location":"web/mini/","title":"JavaScript Minification","text":"<p>JavaScript minification is a process used to optimize [[JavaScript]] files for web applications. The primary goal is to reduce the file size, which in turn speeds up page loading times. Minification involves several key steps:</p> <ol> <li>Removing Unnecessary Characters: This includes spaces, new lines, comments, and block delimiters which are not required for the JavaScript to execute.</li> <li>Renaming Variables and Functions: Shorter names are substituted for original ones. For example, a variable named userEmailAddress might be shortened to a.</li> <li>Shortening Function and Variable Declarations: This can include converting function declarations into shorter, anonymous functions.</li> <li>Optimizing Code Structure and Statements: This might include simplifying loops and conditionals or using shorter syntax where possible.</li> <li>Removing Dead Code: Any code that is not used or is unreachable is removed.</li> </ol>"},{"location":"web/must/","title":"Mustache","text":"<p>Mustache is a logic-less templating system designed to be simple, expressive, and widely applicable across various programming languages. It serves as a lightweight and easy-to-understand templating solution for embedding dynamic content within static templates. </p> <p>Mustache intentionally avoids including programming logic in its templates. It doesn't support conditional statements, loops, or complex operations. Instead, it focuses on data interpolation.</p> <p>Mustache uses tags to denote placeholders in the template that will be replaced with actual data during rendering. Tags are enclosed by curly braces (<code>{{</code> and <code>}}</code>). The syntax of Mustache is minimal and easy to understand. It consists mainly of tags for variable substitution, sections, and inverted sections.</p> <p>Variables are inserted into the template using double curly braces. For example, <code>{{name}}</code> might be replaced with the value of the \"name\" variable. Sections are used for conditionally rendering blocks of content based on the existence or truthiness of a variable. Sections are denoted by the <code>{{#section}}...{{/section}}</code> syntax.</p> <p>Inverted sections are used to conditionally render content when a variable is false or undefined. They are denoted by the <code>{{^inverted_section}}...{{/inverted_section}}</code> syntax. Mustache supports partials, which allow templates to include and reuse other templates. Partials are denoted by the <code>{{&gt; partial_name}}</code> syntax.</p> <p>Mustache is designed to be whitespace-insensitive, meaning that whitespace around tags is generally ignored. Mustache templates can be used in various programming languages, making them portable and versatile.</p> <p>Mustache has implementations in numerous programming languages, including [[JavaScript]], [[Ruby]], [[Python]], [[Java]], and more. This enables developers to use the same templates across different parts of their application stack.</p> <p>Mustache's simplicity and flexibility make it a popular choice for templating in scenarios where a lightweight and logic-less approach is desired. It is commonly used in web development for rendering [[HTML]] templates, as well as in other contexts where data needs to be dynamically inserted into text-based templates.</p>"},{"location":"web/neg/","title":"Negotiate Authentication","text":"<p>Negotiate authentication is one of the [[HTTP Protocol|HTTP]] authentication mechanisms used to secure web applications and services. It is primarily associated with Microsoft Windows environments and is often referred to as \"Negotiate\" or \"SPNEGO\" ([[Simple and Protected GSSAPI Negotiation Mechanism]]). Negotiate authentication is designed to provide a mechanism for [[Single Sign-On (SSO)]] and interoperability with various authentication protocols, including [[NTLM]] and [[Kerberos Authentication|Kerberos]].</p> <p>The term \"Negotiate\" indicates that the client and server negotiate the authentication protocol to use during the authentication process. The negotiation typically happens as follows:</p> <ul> <li>The client sends an initial HTTP request to the server without any authentication information.</li> <li>The server responds with a <code>WWW-Authenticate</code> header field that includes \"Negotiate\" as one of the supported authentication methods.</li> <li>The client selects an appropriate authentication protocol (e.g., Kerberos or NTLM) based on its capabilities and the server's preferences.</li> <li>The client sends another HTTP request, this time including the selected authentication protocol (e.g., \"Negotiate\" followed by the authentication token).</li> </ul> <p>Negotiate authentication allows clients to use either the Kerberos protocol (if available) or the NTLM protocol for authentication. It prioritizes the use of Kerberos when possible, as it is considered more secure than NTLM.</p> <p>Negotiate authentication enables SSO within a Windows domain or Kerberos realm. Once a user logs in to their Windows computer, they can access web resources without having to re-enter their credentials.</p> <p>In the Negotiate authentication process, the client and server exchange security tokens. These tokens are used to prove the identity of the client. The tokens can be Kerberos tickets or NTLM challenge-response tokens, depending on the chosen authentication protocol.</p> <p>Negotiate authentication relies on the [[Generic Security Services Application Programming Interface (GSSAPI)]], which provides a framework for secure communication. GSSAPI enables the negotiation of security mechanisms and the exchange of security tokens.</p> <p>Negotiate authentication is primarily associated with Microsoft technologies, but it can also be used in non-Microsoft environments, provided that the server and client support the Negotiate mechanism and the chosen authentication protocol. If Kerberos authentication is not available or fails, the client may fall back to using NTLM authentication for compatibility.</p>"},{"location":"web/nginx/","title":"Nginx","text":"<p>NGINX\u00a0(pronounced \u201cengine X\u201d) is open-source web server software designed to handle a high number of connections simultaneously. These characteristics make it one of the most powerful and scalable server software options on the market:</p> <p>NGINX is often used as a [[reverse proxy]]. This means you\u2019ll typically find it stationed behind a\u00a0[[firewall]]\u00a0in a private network, where it forwards client requests to the appropriate server. \u00a0 NGINX also acts as a load balancer. This means it distributes requests across multiple servers so that they won\u2019t become overloaded. In turn, this setup leads to faster web speeds for users.</p> <p>Nginx is built to offer\u00a0low memory usage\u00a0and high concurrency. Rather than creating new processes for each web request, Nginx uses an asynchronous, event-driven approach where requests are handled in a single thread.</p> <p>With Nginx, one master process can control multiple worker processes. The master maintains the worker processes, while the workers do the actual processing. Because Nginx is asynchronous, each request can be executed by the worker concurrently without blocking other requests.</p> <p>Some common features seen in Nginx include:</p> <ul> <li>Reverse proxy with caching</li> <li>IPv6</li> <li>Load balancing</li> <li>FastCGI support with caching</li> <li>WebSockets</li> <li>Handling of static files, index files, and auto-indexing</li> <li>TLS/SSL with SNI</li> </ul>"},{"location":"web/open/","title":"Open Redirects","text":"<p>Open redirects are a security vulnerability that occurs when a web application or server is configured to automatically redirect users to a specified URL without adequately validating that URL. This flaw can be exploited by attackers to redirect users to malicious websites, often as part of [[phishing]] attacks.</p> <p>In an open redirect scenario, the application accepts a URL as a parameter and then redirects the user to this URL. If the application doesn't properly validate this URL, it can redirect users to any site, including malicious ones. Attackers exploit this by crafting URLs that include the legitimate website's domain followed by a redirect instruction to a malicious site. To an unsuspecting user, the URL appears trustworthy because it starts with a known, legitimate domain.</p> <p>Consider a website <code>example.com</code> with a login page that, after successful login, redirects users to the page they were initially trying to visit. This is a common and legitimate use of redirection. The URL might look like this:</p> <pre><code>https://www.example.com/login?redirect=www.example.com/dashboard\n</code></pre> <p>In an open redirect vulnerability scenario, an attacker could craft a URL like:</p> <pre><code>https://www.example.com/login?redirect=www.malicious.com\n</code></pre> <p>If <code>example.com</code> doesn't properly validate the <code>redirect</code> parameter, it will redirect the user to <code>malicious.com</code> after login, potentially leading to phishing, malware infection, or other malicious activities.</p> <p>Attackers can trick users into believing they are visiting a trusted site while actually directing them to a malicious one. Users can be redirected to sites that host malware, leading to potential infections. Exploiting open redirects can damage the reputation of the legitimate site that is used for redirection.</p>"},{"location":"web/opencart/","title":"OpenCart","text":"<p>OpenCart is an open-source [[content management system]] (CMS) specifically designed for creating and managing online stores. OpenCart is free to download and use. Being open-source, it allows developers to modify and customize the software according to their specific needs.</p> <p>OpenCart comes equipped with all the necessary features for setting up an online store, including product management, shopping cart functionality, order management, and payment gateway integrations.</p> <p>It also allows users to manage multiple stores from a single admin interface. This is particularly useful for businesses that operate several distinct e-commerce websites.</p>"},{"location":"web/parfuzz/","title":"Parameter Fuzzing","text":"<p>Parameter fuzzing, also known as web parameter tampering or input fuzzing, is a technique used in cybersecurity and web application testing. It involves manipulating or \"fuzzing\" the parameters of a web application to test for vulnerabilities.</p> <p>The goal is to identify potential security flaws in web apps by testing how they handle unexpected or malicious input, including testing for vulnerabilities like [[SQL injection]], [[Cross-Site Scripting]], [[Command Injection]], [[Buffer Overflows]] and more.</p> <p>Some common parameters that are fuzzed include:</p> <ul> <li>[[Uniform Resource Locator|URL]] parameters - values in the query string of a URL</li> <li>Form fields - inputs in web forms, including hidden fields</li> <li>[[Cookies]] - data stored on the client-side and sent with requests</li> <li>[[HTTP Headers]] - information sent in request and response headers</li> </ul> <p>The process involves changing these parameters and observing the app's response, including techniques like:</p> <ul> <li>Injecting special characters - entering characters like quotes, backslashes and semicolons</li> <li>Overloading inputs - providing unexpected long strings or large amounts of data</li> <li>Using known malicious inputs - injecting payloads known to exploit certain vulnerabilities</li> </ul> <p>There are various tools to automate the process such as [[Ffuf]].</p>"},{"location":"web/proxies/","title":"Web Proxies","text":"<p>A [[proxy]] server is a web server that acts as a gateway between a [[client]] application, for example, a browser, and the real [[server]]. It makes requests to the real server on behalf of the client or sometimes fulfils the claim itself.</p> <p>Web proxy servers have two primary purposes, namely to filter requests and improve performances. Additionally, there are proxy servers that sit between web servers and web clients known as a reverse proxy.</p> <p>[[Reverse proxy]] servers pass on requests from web clients to web servers. They are used to cache images and pages to reduce the load on web servers significantly.</p>"},{"location":"web/pug/","title":"Pug (Jade)","text":"<p>Pug (formerly known as Jade) is a high-performance, feature-rich templating engine for [[NodeJS|Node.js]] and browsers. It's designed to facilitate writing [[HTML]] in a more efficient and readable manner. Pug templates use a simpler, whitespace-sensitive syntax with fewer characters and less repetition compared to plain HTML.</p> <p>Pug offers a clean and concise syntax, using indentation instead of closing tags, making the templates easier to read and write. It allows dynamic content rendering, meaning you can pass variables and objects from your Node.js application to the template, and Pug will render the HTML accordingly.</p> <p>Pug supports various control structures like conditionals and loops, which can be embedded directly in the template. It supports template inheritance, which is a powerful feature for reusing template code. You can define a base template (layout) and extend it in other templates. </p> <p>These are akin to functions in programming languages and can be used to create reusable pieces of template code. Pug allows you to use filters to pre-process text blocks, such as markdown or stylus.</p> <p>Pug syntax is different from traditional HTML. It\u2019s whitespace-sensitive and uses indentation to indicate nesting of elements, which eliminates the need for closing tags.</p> <p>Example of a basic Pug template:</p> <pre><code>doctype html\nhtml(lang=\"en\")\n  head\n    title= pageTitle\n  body\n    h1 Pug - Node Template Engine\n    #container.col\n      if user\n        p Welcome, #{user}!\n      else\n        p Welcome, guest!\n</code></pre> <p>This template would render into the following HTML:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n  &lt;head&gt;\n    &lt;title&gt;[Value of pageTitle]&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Pug - Node Template Engine&lt;/h1&gt;\n    &lt;div id=\"container\" class=\"col\"&gt;\n      &lt;!-- Content based on the 'user' variable --&gt;\n      [Dynamic content based on the presence of 'user']\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>To use Pug in a Node.js application (like an Express.js app), you typically set Pug as the view engine and then render templates in response to requests.</p> <pre><code>const express = require('express');\nconst app = express();\n\napp.set('view engine', 'pug');\n\napp.get('/', (req, res) =&gt; {\n  res.render('index', { pageTitle: 'Home', user: 'John Doe' });\n});\n\napp.listen(3000);\n</code></pre> <p>Info</p> <p>In this example, <code>res.render('index', { pageTitle: 'Home', user: 'John Doe' })</code> will render the <code>index.pug</code> file, injecting the <code>pageTitle</code> and <code>user</code> values into it.</p>"},{"location":"web/pure/","title":"Pure","text":"<p>PureCSS is a lightweight set of CSS modules that can be used in every web project. It features a customizable responsive grid with sets of built-in vertical and horizontal menus, including dropdowns, buttons that work with\u00a0a\u00a0and\u00a0button\u00a0elements, flexible form alignments, and an overall clean, minimalist look that can be easily extended. </p>"},{"location":"web/put/","title":"Put HTTP Method","text":"<p>The <code>PUT</code> [[HTTP Verbs|HTTP method]] is used in web development as part of the [[HTTP protocol]] to update or replace the resource identified by a specific URL. It's one of the methods defined by the HTTP/1.1 specification and is commonly utilized in [[REST APIs|RESTful APIs]] and web services for modifying existing resources.</p> <p><code>PUT</code> requests are used to send data to the server to update or replace the resource at the specified URL. <code>PUT</code> is idempotent, meaning that making multiple identical <code>PUT</code> requests has the same effect as making a single request. The data to be updated or replaced is typically included in the body of the <code>PUT</code> request.</p> <p>If proper authentication and authorization controls are not in place, an attacker might exploit the <code>PUT</code> method to modify content or data. For instance, without adequate security checks, an attacker could send a <code>PUT</code> request to modify sensitive data or configuration files.</p> <p>Insecurely implemented <code>PUT</code> requests can lead to data integrity issues, where critical information is altered or overwritten unintentionally or maliciously. Like other HTTP methods, the data included in <code>PUT</code> requests should be validated and sanitized to prevent injection attacks, such as [[SQL injection]], and to ensure that the data conforms to expected formats.</p>"},{"location":"web/ratelimit/","title":"Rate Limiting","text":"<p>Rate limiting in the context of web applications is a technique used to control the amount of incoming requests a user can make to a server within a given timeframe. This is a crucial feature for both maintaining the performance of the web server and enhancing its security, particularly against [[Brute Force Attack|brute force attacks]].</p> <p>Web applications set a limit on how many requests a user (or [[IP address]]) can make in a certain period. If the number of requests exceeds this limit, additional requests are either delayed or blocked. The rate limits can be configured based on various criteria, such as per-user limits, per-IP address limits, or overall limits for the server.</p> <p>One common application of rate limiting is to prevent brute force login attacks. By limiting the number of login attempts that can be made in a short period, the web application can significantly reduce the effectiveness of an attacker trying to guess passwords. </p> <p>When a user hits the rate limit, the server might respond with a <code>429 Too Many Requests</code> HTTP status code, require additional authentication (like [[CAPTCHA]]), or temporarily block access from the user's IP address.</p> <p>Rate limiting helps in managing server resources by preventing any single user or a group of users from overloading the server with too many requests. It's also used to prevent abuse of [[APIs]] and web services, ensuring fair usage and availability for all users.</p>"},{"location":"web/rep/","title":"Robots Exclusion Protocol (REP)","text":"<p>REP stands for Robots Exclusion Protocol, a group of web standards that govern how robots (such as [[Search Engine Crawlers]]) crawl the web, access and index content, and serve that content up to users. The protocol consists of standards and practices that website administrators use to regulate the behavior of robots and web crawlers to prevent overloading their sites and to keep certain parts of their sites private.</p> <p>The primary content of REP is the \"[[Robots.txt]]\" file. It's a text file placed at the root of a website (e.g., <code>https://example.com/robots.txt</code>) that provides instructions to web crawlers about which parts of the site should or shouldn\u2019t be crawled and indexed. The file uses a simple syntax to indicate allowed and disallowed paths for user agents (crawlers).</p> <p>Meta tags in [[HTML]] documents can be used to control crawler access on a page-by-page basis. For example, a <code>&lt;meta name=\"robots\" content=\"noindex\"&gt;</code> tag tells crawlers not to index that specific page.</p> <p>The \"X-Robots-Tag\" header is used to control how specified parts of a website are indexed, similar to the meta tags but can be applied to any HTTP-served content, not just HTML pages. </p> <p>While not strictly part of the REP, sitemaps are often used in conjunction with <code>robots.txt</code> to guide crawlers to the content that should be indexed. They provide structured information about the pages on the site, their relative importance, and how often they are updated.</p> <p>While REP can be used to ask crawlers not to index certain parts of a site, it is not a security measure. Anything sensitive should not be left unprotected on the assumption that a <code>robots.txt</code> file will keep it hidden. The structure of a <code>robots.txt</code> file can inadvertently reveal the presence of sensitive directories or pages to potential attackers.</p>"},{"location":"web/reqanal/","title":"Web Request Analysis","text":"<p>Web request analysis in the context of web security and penetration testing is the process of examining the [[HTTP Verbs|requests]] and [[HTTP Response Codes|responses]] exchanged between a web client (like a browser) and a server. This analysis is crucial for understanding how data is transmitted, identifying security vulnerabilities, and evaluating the behavior of web applications under various conditions.</p> <p>You should analyze the [[HTTP methods]] (GET, POST, PUT, DELETE, etc.) used and the structure of the [[Uniform Resource Locator|URLs]] to understand how the application processes different types of requests.</p> <p>Examine the data sent in request parameters (query strings, form data) and payloads. This is critical for identifying injection points for attacks like [[SQL Injection]], [[Cross-Site Scripting]] (XSS), and [[Cross-Site Request Forgery]] (CSRF).</p> <p>Inspect [[HTTP headers]] and [[cookies]] for information about session management, caching policies, and security configurations (like security headers). Headers like User-Agent, Referer, and Cookie can provide insights into session handling and potential vulnerabilities.</p> <p>Review how the application manages authentication and authorization in requests. This includes analyzing tokens, session cookies, and other mechanisms that control access to resources.</p> <p>Study the server\u2019s responses to understand how it handles different requests, including error messages, status codes, and headers. Responses can reveal information about the server, its configuration, and how it handles invalid input.</p> <p>Understand how the application manages state, particularly in stateless protocols like [[HTTP Protocol|HTTP]], often through cookies or session tokens.</p> <p>If the application uses [[APIs]] ([[REST APIs|RESTful]], [[SOAP]], [[GraphQL]]), analyzing the requests and responses specific to these APIs is important for understanding the API structure and potential API-specific vulnerabilities.</p> <p>Identify security configurations in requests and responses, such as [[Content Security Policy]] (CSP) headers, [[HTTP Strict Transport Security]] (HSTS), and others that indicate the application\u2019s security posture.</p> <p>Tools like [[Burp Suite]], [[OWASP ZAP]], and [[Wireshark]] are commonly used for intercepting, viewing, and modifying web requests and responses. These tools are essential for in-depth web request analysis.</p>"},{"location":"web/respcodes/","title":"HTTP Response Codes","text":"<p>HTTP status codes are codes returned by a [[server]] in response to a client's request. The codes are part of the HTTP response and indicate the status of the request. The codes are mainly divided into 5 categories:</p> <ul> <li>1xx (Informational) - indicate a provisional response and are less common in daily use.</li> <li>2xx (Successful) - indicate the client's request was successfully received, understood and accepted.</li> <li>3xx (Redirection) - signify that further action needs to be taken by the client to complete the request.</li> <li>4xx (Client Error) - represent errors made by the client.</li> <li>5xx (Server Error) - indicate problems on the server's end.</li> </ul> <p>Some of the most common HTTP status codes seen are:</p> HTTP Status Code Description 200 OK Page has been fetched, action accepted and delivered to the client 301 Permanent Redirect Page requests has moved to a new URL which is permanent 302 Temporary Redirect Requested URL redirected to another website which is temporary 304 Not Modified Request not changed so client can resume the same cache in the future 400 Bad Request Server not able to understand anything 401 Unauthorized Requires user authentication 403 Forbidden Request understood, but refuses to fulfill it 404 Not Found Request a URL and the server has not found anything 500 Internal Server Error Requesting a URL is not fulfilled as the server encounters an unexpected condition 501 Not Implemented Server not able to recognize the request method and not able to support any resource"},{"location":"web/restapis/","title":"REST APIs","text":"<p>REST stands for\u00a0Representational State Transfer. This means that when a [[client]] requests a resource using a REST API, the [[server]]\u00a0transfers\u00a0back the current\u00a0state\u00a0of the resource in a standardized\u00a0representation.</p> <p>REST APIs work by fielding requests for a resource and returning all relevant information about the resource, translated into a format that clients can easily interpret (this format is determined by the API receiving requests). Clients can also modify items on the server and even add new items to the server through a REST API.</p> <p>REST APIs must follow six requirements:</p> <ul> <li>Client-Server Separation - client sends request to server and server responds back. Servers cannot make requests and clients cannot respond</li> <li>Uniform Interface - all requests/responses must follow a common protocol. For most REST APIs, the common language is [[HTTP Protocol|HTTP]].</li> </ul> <p>To use HTTP with a REST API, the client sends a request in a specific format:</p> <pre><code>GET https://www.googleapis.com/youtube/v3/channels?part=contentDetails\n</code></pre> <p>It contains 2 pieces of information:</p> <ul> <li>GET is the [[HTTP Verbs|HTTP method]].</li> <li>https://www.googleapis.com/youtube/v3/channels?part=contentDetails is the [[Uniform Resource Locator|URL]]</li> </ul> <p>Info</p> <p>URL is also called an endpoint as it is the location where the API interacts with the client.</p> <p>After validating the request, the host returns info about the target resource - usually sent in [[JavaScript Object Notation|JSON]]. </p> <p>Continuing the requirements:</p> <ul> <li>Stateless - all calls must be stateless. Every interacting is independent and each request and response provides all info required to complete the interaction.</li> <li>Layered System - servers/layers in API requests are there to add security, handle and distribute traffic or assist with other functions. Messages between client and target should always be formatted and processed the same way.</li> <li>Cacheable - when a server sends its response to a client, the response should indicate whether the resource provided can be cached and for how long.</li> <li>Code on Demand - API can send computer code to client in its response.</li> </ul> <p>Important</p> <p>If an API adheres to this set of rules, it is a RESTful API</p>"},{"location":"web/robots/","title":"Robots.txt","text":"<p><code>robots.txt</code> is a text file webmasters create to instruct web robots (typically [[Search Engine Crawlers]]) how to crawl and index pages on their website. It is part of the [[Robots Exclusion Protocol (REP)]], a group of web standards that regulate how robots crawl the web, access and index content, and serve that content up to users.</p> <p>The file is placed in the root directory of the website (e.g., <code>http://example.com/robots.txt</code>). It contains directives for user agents (crawlers), specifying which parts of the site should or should not be crawled. Common directives include \"[[User-agent]]\" (the type of crawler the rule applies to), \"Disallow\" (paths that should not be crawled), and \"Allow\" (paths that can be crawled, typically used to override a Disallow rule).</p> <p><code>robots.txt</code> can be a valuable resource during the reconnaissance phase of a penetration test. It can reveal the structure of a website and expose hidden or sensitive directories and files that are not intended for public viewing but are not properly secured.</p> <p>The file might list directories the web administrator wants to keep away from crawlers. These could include admin panels, login pages, or directories containing sensitive data, which could be potential targets for further investigation.</p> <p>It helps in understanding the application's structure, which is crucial for a comprehensive penetration test. It might reveal areas of the site that are less likely to be exposed to regular traffic and potentially less secure.</p> <p>While <code>robots.txt</code> can provide useful information, it's important to note that not all webmasters accurately or thoroughly document the structure of their site in this file. Some might intentionally put misleading information in <code>robots.txt</code>.</p> <p><code>robots.txt</code> is a request, not an enforcement. Malicious bots are not likely to honor this file, so sensitive directories and files listed in <code>robots.txt</code> should also be protected through proper security measures.</p> <p>If sensitive paths are listed in <code>robots.txt</code>, it could inadvertently act as a guide for malicious actors. Therefore, it's a best practice not to rely on <code>robots.txt</code> to protect sensitive areas of a website.</p>"},{"location":"web/routes/","title":"Web Routes","text":"<p>In the context of web applications, \"web routes\" or \"routing\" refers to the mechanism that maps incoming [[HTTP Protocol|HTTP]] requests to specific handlers based on their URL patterns. It's a crucial aspect of modern web application design, as it directs user requests to the appropriate content or functionality.</p> <p>Routes determine how an application responds to a client request for a specific endpoint, which is a [[Uniform Resource Locator|URI]] (or path) and a specific HTTP request method (GET, POST, PUT, DELETE, etc.). Each route can be associated with a specific function or controller action in the application, which handles the request and returns the appropriate response.</p> <p>Most modern web frameworks (like [[Express|Express.js]] in [[NodeJS|Node.js]], [[Django]] in [[Python]], [[Laravel]] in [[PHP]], and [[Ruby on Rails]]) have built-in routing capabilities. They allow developers to easily define routes in a structured and readable way.</p> <p>In [[REST APIs|RESTful]] web services, routes are often designed to correspond to resource-based paths. For example, <code>GET /articles</code> might retrieve a list of articles, while <code>POST /articles</code> might create a new article. This approach aligns with the REST architecture's principles, which emphasize scalability, statelessness, and a uniform interface.</p> <p>Dynamic and Static Routes:</p> <ul> <li>Static Routes: Fixed and do not change, e.g., <code>/about</code> or <code>/contact</code>.</li> <li>Dynamic Routes: Include variable path segments that can change, e.g., <code>/users/:userId/posts/:postId</code>, where <code>:userId</code> and <code>:postId</code> are variables.</li> </ul> <p>In [[Single Page Application (SPA) Routing|SPAs]] (like those built with [[AngularJS|Angular]], [[ReactJS|React]], or [[Vue.js|Vue]]), routing is often handled on the client-side to dynamically load and display content without requiring a full page reload. Well-defined routes contribute to better Search Engine Optimization (SEO), as they allow for clear, descriptive URLs.</p> <p>Routing also involves handling invalid paths or errors, typically through '404 Not Found' or '500 Internal Server Error' routes. In the [[Model-View-Controller (MVC)|MVC (Model-View-Controller)]] pattern, routes play a crucial role in connecting the Controller layer (handling logic) to specific URLs.</p>"},{"location":"web/samesite/","title":"SameSite Flag","text":"<p>The <code>SameSite</code> flag is an attribute used in [[HTTP Protocol|HTTP]] [[cookies]] to help mitigate the risk of cross-origin information leakage. It also provides some protection against [[cross-site request forgery]] attacks. Essentially, it instructs the browser how to handle cookies based on where the request originated. The <code>SameSite</code> attribute can take three values:</p> <ol> <li>None: The cookie will be sent in all requests, both same-site and cross-site. When <code>SameSite=None</code> is used, the [[Secure Flag|Secure]] attribute must also be set, meaning the cookie will only be sent over secure ([[HTTPS Protocol|HTTPS]]) connections.</li> <li>Lax: The default setting in most modern browsers if the <code>SameSite</code> attribute is not specified. Under <code>Lax</code> mode, cookies are withheld on cross-site subrequests (like loading images or frames), but are sent when the user navigates to the URL from an external site (e.g., by following a link).</li> <li>Strict: Under this setting, the cookie will only be sent in a first-party context and not be sent along with requests initiated by third party websites. This can prevent the user's state from being sent in cross-origin requests, providing strong protection against CSRF attacks but potentially impacting user experience, as some cross-origin requests may rely on those cookies.</li> </ol>"},{"location":"web/sass/","title":"SASS","text":"<p>Sass (Syntactically Awesome Style Sheets) is an extension of [[CSS]]. Style sheet languages control where and how text appears on a webpage, from frame size and colour to menu positions.</p> <p>CSS is used all over the web, but that doesn\u2019t make it the smoothest coding experience. It was designed to help developers write instructions on how to present text on a screen rather than to work with variables or perform complex decision-making tasks.</p> <p>Sass is a preprocessor language that\u2019s interpreted into CSS. A preprocessor language takes input data and converts it to an output that\u2019s used as input by another program.</p> <p>This means when you run Sass code, you\u2019re actually converting your code to CSS. That CSS code output is then used directly by a browser.</p>"},{"location":"web/scss/","title":"SCSS","text":"<p>The term SCSS is an acronym for Sassy Cascading Style Sheets. It is basically a more advanced and evolved variant of the [[CSS]] language. It comes with more advanced features- thus often called Sassy CSS. This language is a preprocessor one, and we need to compile or interrupt it into the CSS language. The SCSS language comes with a file extension, namely .scss.</p> <p>SCSS assists a user in adding various extra features to the CSS, such as nesting, variables, etc. These extra features make the process of writing the SCSS language quicker and easier as compared to that of writing the standard language of CSS. The SCSS language may make use of the CSS function and code. The SCSS stays totally compliant with the syntax of CSS- and it also supports the full power of the [[SASS]].</p>"},{"location":"web/secure/","title":"Secure Flag","text":"<p>The <code>Secure</code> cookie flag is an option used when setting [[HTTP Protocol|HTTP]] [[cookies]] to ensure that the cookie is sent only over secure [[HTTPS Protocol|HTTPS]] connections. This flag is an important security feature for web applications, as it helps prevent the cookie from being exposed to [[Man-in-the-Middle (MitM) attack|man-in-the-middle (MitM) attacks]].</p> <p>When a cookie is set with the <code>Secure</code> flag, it instructs the web browser to only send the cookie if the connection is HTTPS. This prevents the cookie from being sent over unencrypted HTTP connections, where it could be easily intercepted and stolen. The flag is crucial for protecting sensitive information contained in cookies, like session IDs or authentication tokens, from being exposed over non-secure channels.</p> <p>When a server sets a cookie, it can include the Secure flag in the Set-Cookie HTTP header:</p> <pre><code>Set-Cookie: sessionId=abc123; Secure\n</code></pre> <p>In this example, the <code>sessionId</code> cookie is marked as <code>Secure</code>, indicating that the browser should only send it over an HTTPS connection. </p> <p>For enhanced security, the <code>Secure</code> flag is often used in conjunction with the [[HttpOnly Flag|HttpOnly]] flag, which prevents the cookie from being accessed via client-side scripts. Implementing the <code>Secure</code> flag requires that the website supports HTTPS. All requests should be served over HTTPS to ensure that cookies are always transmitted securely.</p> <p>While the <code>Secure</code> flag is essential for protecting cookies during transmission, it does not prevent other types of attacks like cross-site scripting (XSS). Therefore, it should be part of a comprehensive security strategy.</p>"},{"location":"web/services/","title":"Web Services","text":"<p>Web services are a standardized way of integrating web-based applications using open standards over an internet protocol backbone. Essentially, they are software systems designed to support interoperable machine-to-machine interaction over a network.</p> <p>Web services typically operate over [[HTTP Protocol|HTTP]]/[[HTTPS Protocol|HTTPS]] and use [[Extensible Markup Language|XML]]-based messaging systems like [[SOAP]] (Simple Object Access Protocol) to encode messages. One of the main advantages of web services is their ability to operate across different platforms and languages. For instance, a web service written in [[Java]] can be accessed by a client application written in [[Dotnet|.NET]].</p> <p>They are designed to be used by other applications, and various applications can communicate with each other and share data and services among themselves. Web services are described using a standard format known as [[WSDL|WSDL (Web Services Description Language)]]. This allows any client that understands WSDL to discover and invoke the service</p> <p>Apart from SOAP, there's also [[REST APIs|REST]] (Representational State Transfer) which uses standard HTTP methods like GET, POST, PUT, DELETE for communication. RESTful services are widely popular due to their simplicity and ease of use.</p> <p>Web services are used in various applications such as financial services, e-commerce, [[Customer Relationship Management (CRM) Software|CRM (Customer Relationship Management)]], and more. They enable businesses to communicate with each other and with clients over the Internet.</p>"},{"location":"web/sessstore/","title":"SessionStorage","text":"<p><code>sessionStorage</code> is a web storage feature provided by modern web browsers that allows web applications to store data as key-value pairs within the user's browser session. This data is accessible only on the same tab, and unlike [[LocalStorage]], it gets cleared when the tab or browser is closed. </p> <p><code>sessionStorage</code> is part of the [[Web Storage API]], along with <code>localStorage</code>, providing a more secure and efficient way to handle data on the client side compared to traditional [[cookies]].</p> <p>Data stored in <code>sessionStorage</code> is available only within the tab in which it was set. Opening a new tab or window with the same URL will have a separate <code>sessionStorage</code> space. The data in <code>sessionStorage</code> is cleared when the tab or browser window is closed. It's not persistent like <code>localStorage</code>.</p> <p>Access to <code>sessionStorage</code> is restricted to the same origin (same scheme, host, and port), providing a degree of security against cross-origin data access. <code>sessionStorage</code> typically allows more data to be stored compared to cookies (usually at least 5MB per origin).</p> <p><code>sessionStorage</code> is ideal for storing temporary data that should only persist for the duration of a page session, like user choices or form data within a single tab. It can be used to store state in [[Single Page Applications|SPAs]] where the state should not persist after the tab is closed.</p> <p>An example usage may be:</p> <pre><code>// Storing data in sessionStorage\nsessionStorage.setItem('key', 'value');\n\n// Retrieving data from sessionStorage\nlet data = sessionStorage.getItem('key');\n\n// Removing data from sessionStorage\nsessionStorage.removeItem('key');\n\n// Clearing all data from sessionStorage for the current tab\nsessionStorage.clear();\n</code></pre> <p>In this [[JavaScript]] example, data is stored in <code>sessionStorage</code> using <code>setItem</code>, retrieved with <code>getItem</code>, removed with <code>removeItem</code>, and all data in <code>sessionStorage</code> can be cleared with <code>clear</code>.</p> <p>There are a couple of differences between this and localStorage:</p> <ul> <li>Persistence: <code>localStorage</code> data persists even when the browser is closed and reopened, while <code>sessionStorage</code> is cleared after the tab or browser is closed.</li> <li>Scope: Data in <code>localStorage</code> is accessible across all tabs and windows within the same origin, while <code>sessionStorage</code> data is limited to the tab where it was created.</li> </ul>"},{"location":"web/smarty/","title":"Smarty","text":"<p>Smarty is a popular templating engine for [[PHP]], designed to facilitate the separation of application logic and content from its presentation. This separation is beneficial in web development, where it helps make the code more manageable, maintainable, and flexible.</p> <p>Smarty is used as a template system for PHP, allowing the creation of [[HTML]] templates which contain simple placeholders for data that is populated dynamically. These templates are separate from the PHP scripts, which handle the application's logic.</p> <p>Smarty has its own syntax for embedding dynamic content in templates. It uses curly braces <code>{}</code> to denote its tags, which are then filled with data by the PHP script.</p> <p>Example: <code>Hello, {$name}!</code> - where <code>{$name}</code> is a placeholder for a variable that will be assigned by the PHP script.</p> <p>By separating the PHP code (logic) from the HTML (presentation), Smarty promotes a clean architecture, making applications easier to develop and maintain. Smarty includes a robust caching mechanism to improve the performance of web applications. It can cache the rendered templates to reduce the time spent on generating pages from the templates on subsequent requests.</p> <p>Developers can extend Smarty with custom functions, modifiers, and plug-ins. This flexibility allows for further customization to meet specific needs of a project. Smarty is widely used in PHP-based web applications. It's particularly beneficial in large applications where separation of design and code is crucial.</p> <p>Smarty is designed to be compatible with a variety of PHP versions and setups, making it a versatile choice for many developers. Smarty offers some security features, such as automatic escaping of variables, to help prevent security issues like [[Cross-Site Scripting]] (XSS).</p>"},{"location":"web/sop/","title":"Same Origin Policy","text":"<p>The same-origin policy is a web browser security mechanism that aims to prevent websites from attacking each other.</p> <p>The same-origin policy restricts scripts on one origin from accessing data from another origin. An origin consists of a URI scheme, domain and port number. For example, consider the following URL:</p> <pre><code>http://normal-website.com/example/example.html\n</code></pre> <p>This uses the scheme\u00a0[[HTTP Protocol|HTTP]], the [[Fully Qualified Domain Name (FQDN)|domain]]\u00a0\"normal-website.com\", and the [[port]] number\u00a080. The following table shows how the same-origin policy will be applied if content at the above URL tries to access other origins:</p> URL accessed Access permitted? http://normal-website.com/example/ Yes: same scheme, domain, and port http://normal-website.com/example2/ Yes: same scheme, domain, and port https://normal-website.com/example/ No: different scheme and port http://en.normal-website.com/example/ No: different domain http://www.normal-website.com/example/ No: different domain http://normal-website.com:8080/example/ No: different port <p>When a browser sends an HTTP request from one origin to another, any [[cookies]], including authentication session cookies, relevant to the other domain are also sent as part of the request. </p> <p>This means that the response will be generated within the user's session, and include any relevant data that is specific to the user. Without the same-origin policy, if you visited a malicious website, it would be able to read your emails from GMail, private messages from Facebook, etc.</p> <p>The same-origin policy generally controls the access that [[JavaScript]] code has to content that is loaded cross-domain. Cross-origin loading of page resources is generally permitted. For example, the SOP allows embedding of images via the\u00a0\u00a0tag, media via the\u00a0\\&lt;video&gt;\u00a0tag and JavaScript includes with the\u00a0\\&lt;script&gt;\u00a0tag. </p> <p>Note</p> <p>However, while these external resources can be loaded by the page, any JavaScript on the page won't be able to read the contents of these resources.</p> <p>There are various exceptions to the same-origin policy:</p> <ul> <li>Some objects are writable but not readable cross-domain, such as the\u00a0location\u00a0object or the\u00a0location.href\u00a0property from iframes or new windows.</li> <li>Some objects are readable but not writable cross-domain, such as the\u00a0length\u00a0property of the\u00a0window\u00a0object (which stores the number of frames being used on the page) and the\u00a0closed\u00a0property.</li> <li>The\u00a0replace\u00a0function can generally be called cross-domain on the\u00a0location\u00a0object.</li> <li>You can call certain functions cross-domain. For example, you can call the functions\u00a0close,\u00a0blur\u00a0and\u00a0focus\u00a0on a new window. The\u00a0postMessage\u00a0function can also be called on iframes and new windows in order to send messages from one domain to another.</li> </ul> <p>Due to legacy requirements, the same-origin policy is more relaxed when dealing with cookies, so they are often accessible from all [[subdomains]] of a site even though each subdomain is technically a different origin. You can partially mitigate this risk using the\u00a0HttpOnly\u00a0cookie flag.</p>"},{"location":"web/sparoute/","title":"Single Page Application (SPA) Routing","text":"<p>Single Page Application (SPA) Routing refers to the technique used in single-page applications to handle navigation between different sections of the application without the need for reloading the entire page from the server. </p> <p>In traditional web applications, navigating to different parts of the site involves requesting new pages from the server, which reloads the entire page content. In contrast, SPAs dynamically rewrite the current page in response to user actions, leading to a more fluid and responsive user experience.</p> <p>In SPAs, routing is handled on the client side (in the user's browser) using [[JavaScript]]. When a user interacts with the application and requests a different part of the application (like a new page), the JavaScript intercepts the browser's navigation and handles the URL change without a full page reload.</p> <p>Modern web applications often use the History API provided by browsers to manipulate the URL's path and query string. This allows SPA routing to maintain browser history (forward and back navigation) without reloading pages.</p> <p>The application dynamically loads new content (usually in the form of [[HTML]], [[JavaScript Object Notation|JSON]], or [[Extensible Markup Language|XML]]) from the server and updates the existing page, rather than requesting entire new pages. Most SPA frameworks and libraries, such as [[AngularJS|Angular]], [[ReactJS|React]], [[Vue.js]], and others, have built-in routing solutions or popular routing libraries that manage the complexities of SPA routing, like Angular Router or React Router.</p> <p>SPA routers manage deep links and allow users to bookmark specific states of the application. Historically, SPAs faced challenges with search engine optimization (SEO) due to their dynamic nature. Modern techniques and improvements in search engine technologies have largely mitigated these issues.</p> <p>SPAs generally rely on JavaScript. Proper routing ensures that users without JavaScript or with JavaScript errors still have access to basic functionality, often through server-side rendering or pre-rendering strategies.</p>"},{"location":"web/spas/","title":"Single Page Applications","text":"<p>Single Page Applications (SPAs) are a type of web application or website that dynamically rewrite the current page rather than loading entire new pages from the server. This approach results in a smoother, more seamless user experience, similar to a desktop application. In an SPA, most of the necessary [[HTML]], [[JavaScript]], and [[CSS]] is either retrieved with a single page load or dynamically loaded and added to the page as necessary, usually in response to user actions.</p> <p>In SPAs, much of the content is rendered on the client side (in the user's browser), using JavaScript. This means that after the initial page load, the SPA does not need to reload or refresh the whole page for most user interactions. </p> <p>SPAs heavily use [[AJAX]] (Asynchronous JavaScript and XML) to fetch data from the server asynchronously. This allows the application to request data in the background and update parts of the webpage without reloading the entire page. Since SPAs don't require full page reloads, they can provide a more fluid and app-like user experience, with less waiting time for page reloads.</p> <p>The application consists of a single HTML page that gets dynamically updated. This single page acts as a shell for all the different views of the application.</p> <p>Several JavaScript frameworks and libraries are popular for building SPAs, including:</p> <ul> <li>[[ReactJS|React]] (developed by Facebook)</li> <li>[[AngularJS|Angular]] (developed by Google)</li> <li>[[Vue.js]]</li> <li>[[Ember.js]]</li> <li>[[Backbone.js]]</li> </ul> <p>Once loaded, SPAs can offer significantly faster interactions and smoother transitions, as only data, not entire pages, are exchanged with the server. Since much of the rendering is done client-side, SPAs can reduce the load on the server. SPAs can provide limited offline functionality, as the core application is already loaded in the browser.</p> <p>Traditional SPAs may have issues with search engine optimization (SEO) since content is loaded dynamically, which can be problematic for web crawlers. The first load of an SPA can be slower since the browser may need to load more resources initially. Managing the application state can be more complex in SPAs compared to traditional multi-page applications.</p> <p>SPAs are well-suited for applications where user experience and interactivity are priorities, such as social networks, SaaS platforms, and email clients. They are less suited for content-heavy sites where SEO is a primary concern.</p> <p>There are a variety of different types of session attacks including:</p> <ul> <li>[[Session Hijacking]] - in session hijacking attacks, the attacker takes advantage of insecure session IDs, finds a way to obtain them, and uses them to authenticate to the server and impersonate the victim.</li> <li>[[Session Fixation]] - occurs when an attacker can fixate a valid session ID. The attacker will then have to trick the victim into logging into the application using the aforementioned session ID. If the victim does so, the attacker can proceed to a session hijacking attack (since the session ID is already known).</li> <li>[[Cross-Site Scripting]] - with a focus on user sessions</li> <li>[[Cross-Site Request Forgery]] - attack that forces an end-user to execute inadvertent actions on a web app in which they are currently authenticated. This attack is usually mounted with the help of attacker-crafted web pages that the victim must visit or interact with. These web pages contain malicious requests that essentially inherit the identity and privileges of the victim to perform an undesired function on the victim's behalf.</li> <li>[[Open Redirects]] - open redirects occur when an attacker can redirect a victim to an attacker-controlled site by abusing a legitimate application's redirection functionality. In such cases, all the attacker has to do is specify a website under their control in a redirection URL of a legitimate website and pass it to a victim. It is possible when the legitimate app's redirection functionality does not perform any kind of validation regarding the websites where the redirection points to.</li> </ul>"},{"location":"web/ssidir/","title":"SSI Directive","text":"<p>Server-Side Includes (SSI) directives are commands used in web development to include dynamic content or execute server-side scripts within [[HTML]] documents. These directives are processed by the web server before sending the content to the client's browser. SSI directives are typically used to modularize and enhance the functionality of web pages. </p> <ol> <li>Include Directive (<code>&lt;!--#include --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#include virtual=\"file_path\" --&gt;</code></li> <li>This directive includes the content of another file into the current HTML document.</li> <li>Example: <code>&lt;!--#include virtual=\"/includes/header.html\" --&gt;</code></li> </ul> </li> <li>Echo Directive (<code>&lt;!--#echo --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#echo var=\"variable_name\" --&gt;</code></li> <li>This directive displays the value of a specified server variable or environment variable.</li> <li>Example: <code>&lt;!--#echo var=\"REMOTE_ADDR\" --&gt;</code></li> </ul> </li> <li>If Directive (<code>&lt;!--#if --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#if expr=\"conditional_expression\" --&gt; ... &lt;!--#endif --&gt;</code></li> <li>Allows conditional execution of content based on a specified condition.</li> <li>Example:</li> </ul> </li> </ol> <pre><code>&lt;!--#if expr=\"${QUERY_STRING='show'}\" --&gt;\n  This content is displayed when the 'show' parameter is present in the query string.\n&lt;!--#endif --&gt;\n</code></pre> <ol> <li>Set Directive (<code>&lt;!--#set --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#set var=\"variable_name\" value=\"new_value\" --&gt;</code></li> <li>Sets the value of a server variable or environment variable for later use.</li> <li>Example: <code>&lt;!--#set var=\"my_variable\" value=\"Hello, World!\" --&gt;</code></li> </ul> </li> <li>Config Directive (<code>&lt;!--#config --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#config option=\"directive_name\" value=\"directive_value\" --&gt;</code></li> <li>Configures various settings for SSI processing.</li> <li>Example: <code>&lt;!--#config timefmt=\"%A, %B %d, %Y\" --&gt;</code></li> </ul> </li> <li>Include Virtual Directive (<code>&lt;!--#include virtual --&gt;</code>):<ul> <li>Similar to the <code>include</code> directive but uses a virtual path instead of a file system path.</li> <li>Syntax: <code>&lt;!--#include virtual=\"/virtual_path/file.html\" --&gt;</code></li> </ul> </li> <li>FSize Directive (<code>&lt;!--#fsize --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#fsize file=\"file_path\" --&gt;</code></li> <li>Displays the size of a specified file.</li> <li>Example: <code>&lt;!--#fsize file=\"/images/logo.png\" --&gt;</code></li> </ul> </li> <li>Flastmod Directive (<code>&lt;!--#flastmod --&gt;</code>):<ul> <li>Syntax: <code>&lt;!--#flastmod file=\"file_path\" --&gt;</code></li> <li>Displays the last modification date of a specified file.</li> <li>Example: <code>&lt;!--#flastmod file=\"/documents/report.doc\" --&gt;</code></li> </ul> </li> </ol>"},{"location":"web/ssl/","title":"SSL","text":"<p>SSL, short for Secure Sockets Layer, is a standard security technology for establishing an encrypted link between a web server and a browser. This secure link ensures that all data transmitted between the web server and browser remains private and integral. SSL is a critical technology for securing internet connections and protecting sensitive data from being intercepted by attackers.</p> <p>SSL provides encryption for data in transit, which means that any information exchanged between the user and the website cannot be read by anyone else. SSL also involves authenticating the server to the client, typically through [[SSL certificates]]. This ensures that users are communicating with the intended website and not a malicious site.</p> <p>Websites use SSL certificates to establish their identity. These certificates are issued by [[Certificate Authorities (CAs)]] and contain the website's public key and the identity of the website. When a user connects to an SSL-secured website, an \"[[SSL Handshake]]\" occurs, where the server and browser establish the encryption parameters for the session.</p> <p>How it works:</p> <ul> <li>When a user accesses an SSL-secured website (indicated by [[HTTPS Protocol|HTTPS]] in the URL and often a padlock icon in the browser), the browser requests the server's SSL certificate.</li> <li>The server sends its certificate, including its public key.</li> <li>The browser checks the certificate against a list of trusted CAs and ensures that the certificate is valid, has not expired, and is being used by the website for which it has been issued.</li> <li>If the certificate is valid, the browser uses the server\u2019s public key to encrypt data and send it to the server.</li> <li>The server decrypts the data using its private key, and the secure session begins.</li> </ul> <p>Although SSL is still widely used as a term, the SSL protocol itself is considered outdated and has been replaced by [[TLS]] (Transport Layer Security). TLS is an improved version of SSL and addresses various security issues found in the earlier SSL protocols. Despite this, the term SSL continues to be commonly used to refer to both SSL and TLS technologies.</p> <p>It is essential for protecting data as it moves between servers and clients, particularly for websites that handle sensitive data like credit card information, personal data, and login credentials. Websites with [[SSL-TLS|SSL/TLS]] are often viewed as more trustworthy by users. Modern browsers also warn users when they are about to access a website that is not secured by SSL/TLS.</p>"},{"location":"web/sslcerts/","title":"SSL Certificates","text":"<p>SSL certificates are what enable websites to use\u00a0[[HTTPS Protocol|HTTPS]], which is more secure than\u00a0[[HTTP Protocol|HTTP]]. An SSL certificate is a data file hosted in a website's\u00a0origin server. SSL certificates make SSL/TLS encryption possible, and they contain the website's\u00a0public key and the website's identity, along with related information.</p> <p>Devices attempting to communicate with the origin server will reference this file to obtain the public key and verify the server's identity. The private key is kept secret and secure.</p> <p>SSL certificates include the following information in a single data file:</p> <ul> <li>The domain name\u00a0that the certificate was issued for</li> <li>Which person, organization, or device it was issued to</li> <li>Which certificate authority issued it</li> <li>The certificate authority's digital signature</li> <li>Associated subdomains</li> <li>Issue date of the certificate</li> <li>Expiration date of the certificate</li> <li>The public key (the private key is kept secret)</li> </ul> <p>The public and private keys used for SSL are essentially long strings of characters used for encrypting and signing data. Data encrypted with the public key can only be decrypted with the private key.</p> <p>The certificate is hosted on a website's origin server, and is sent to any devices that request to load the website. Most browsers enable users to view the SSL certificate.</p>"},{"location":"web/sslhand/","title":"SSL Handshakes","text":"<p>The [[SSL]] (Secure Sockets Layer) Handshake is a process that occurs at the beginning of an [[SSL-TLS|SSL/TLS]] session, which is used for secure communications over the internet. It's an integral part of establishing an SSL/TLS connection, and it involves several steps to authenticate the server (and optionally the client), as well as to negotiate the encryption algorithms and keys that will be used for the session.</p> <p>The handshake begins with the client (typically a web browser) sending a \"Client Hello\" message to the server. This message includes the client's SSL/TLS version, the list of supported cipher suites (encryption algorithms), and a randomly generated session key. In response, the server sends a \"Server Hello\" message, containing its SSL/TLS version, the cipher suite selected from the client's list, and its own randomly generated session key.</p> <p>The server then provides its [[SSL certificates|SSL Certificate]], which includes its public key. If the server requires client authentication, it will request the client's certificate. The client verifies the server's SSL certificate against a list of trusted [[Certificate Authorities (CAs)]]. It checks whether the certificate is valid, has not expired, and is being used by the website for which it has been issued.</p> <p>The client uses the public key from the server's certificate to encrypt a pre-master secret and sends it to the server. Both the client and server use the pre-master secret to generate a common session key. The server sends a \"Finished\" message, which is encrypted with the session key, indicating that the server part of the handshake is complete.</p> <p>The client sends its own \"Finished\" message, also encrypted, to the server.</p> <p>After the handshake, both the client and server have verified each other\u2019s identities (in case of mutual authentication) and agreed upon encryption methods and keys. All data transmitted between the client and server is encrypted with the session key, ensuring secure communication.</p> <p>Though often referred to as the SSL Handshake, SSL is an older protocol and has largely been replaced by [[TLS]] (Transport Layer Security), which is more secure. The [[TLS Handshake]] follows a similar process but includes additional security enhancements.</p> <p>The handshake is crucial for setting up a secure session. It ensures that the data exchanged between client and server is encrypted and secure from eavesdropping or tampering. It also serves to authenticate the server (and optionally the client), reducing the risk of [[Man-in-the-Middle (MitM) attack|man-in-the-middle attacks]].</p>"},{"location":"web/storapi/","title":"Web Storage API","text":"<p>The Web Storage API is a feature provided by modern web browsers that allows websites to store data in the form of key-value pairs within the user's browser. It's part of a suite of features for client-side storage and is more secure and efficient than older methods like [[cookies]]. The Web Storage API provides two mechanisms for storing data: [[LocalStorage]] and [[sessionStorage]].</p> <p>There are two storage types:</p> <ul> <li><code>localStorage</code>: Stores data with no expiration date. The data persists even after the browser window is closed and reopened. It's used for long-term storage of data on the client side.</li> <li><code>sessionStorage</code>: Stores data for one session and is cleared when the browser tab is closed. It's useful for data that should be persisted only while the page session exists, like the state of the current application.</li> </ul> <p>Both <code>localStorage</code> and <code>sessionStorage</code> usually offer more storage capacity compared to cookies (often around 5-10 MB per origin). The stored data is accessible only by web pages from the same origin (same protocol, domain, and port), providing security against cross-origin access. Data is stored in key-value pairs, making it straightforward to store and retrieve data.</p> <p>An example may be using <code>localStorage</code> in JavaScript to store and retrieve data:</p> <pre><code>// Store data\nlocalStorage.setItem(\"key\", \"value\");\n\n// Retrieve data\nlet data = localStorage.getItem(\"key\");\n\n// Remove data\nlocalStorage.removeItem(\"key\");\n</code></pre> <p>And using sessionStorage:</p> <pre><code>// Store data for the session\nsessionStorage.setItem(\"sessionKey\", \"sessionValue\");\n\n// Retrieve session data\nlet sessionData = sessionStorage.getItem(\"sessionKey\");\n</code></pre> <p>The Web Storage API provides more space to store data compared to cookies. Unlike cookies, the data in <code>localStorage</code> and <code>sessionStorage</code> is not sent to the server with every [[HTTP Protocol]] request, reducing traffic and improving performance. The API is simpler and more intuitive for storing and retrieving data than cookies.</p> <p>Web storage can be susceptible to [[Cross-Site Scripting|XSS]] attacks. If an attacker can inject malicious scripts into a web page, they may access and manipulate web storage data. Sensitive data should not be stored in web storage due to the potential for client-side script access.</p>"},{"location":"web/subs/","title":"Subdomains","text":"<p>Subdomains are subdivisions or extensions of a primary domain in the [[DNS|domain name system]] (DNS) hierarchy. They are used to organize and navigate different sections of a website and can represent different services, products, or functions of the main website. Essentially, a subdomain is a way to create a separate website area without needing to register a new domain name.</p> <p>Subdomains are the part of a domain that comes before the main domain name and domain extension. They can help you organize your website. For example,\u00a0docs.google.com. In this URL, \"docs\" is the subdomain.</p> <p>Subdomains function as a separate website from its domain. This distinction enables you to develop a section of your website without muddling your site\u2019s overall intent.</p>"},{"location":"web/svg/","title":"Scalable Vector Graphic","text":"<p>SVG (Scalable Vector Graphics) content refers to SVG elements or scripts embedded within SVG files that are used for malicious purposes, particularly in the context of web security. </p> <p>SVG is an [[Extensible Markup Language|XML]]-based vector image format, and like any other XML or [[HTML]]-like data, it can be used to execute [[JavaScript]] or other types of code, leading to security vulnerabilities such as [[Cross-Site Scripting]] (XSS) attacks.</p> <p>SVG files can contain JavaScript, which might be executed when the SVG is rendered. For instance, the \\"},{"location":"web/templatedirs/","title":"Template Directives","text":"<p>Template directives are commands or instructions embedded within a template that guide the [[Template Engines]] on how to process and render the content. These directives provide additional logic and control over the template's behavior, allowing developers to define conditions, loops, and other dynamic behaviors within the static structure of the template. </p> <p>The specific syntax and capabilities of directives depend on the template engine being used.</p> <p>Some common types of template directives:</p> <p>Conditionals ([[Handlebars]]):</p> <pre><code>{{#if condition}}\n  &lt;!-- Content to display if the condition is true --&gt;\n{{else}}\n  &lt;!-- Content to display if the condition is false --&gt;\n{{/if}}\n</code></pre> <p>Conditionals ([[Jinja2]]):</p> <pre><code>{% if condition %}\n  {# Content to display if the condition is true #}\n{% else %}\n  {# Content to display if the condition is false #}\n{% endif %}\n</code></pre> <p>Loops (Handlebars):</p> <pre><code>{{#each items}}\n  &lt;!-- Content to repeat for each item in the 'items' array --&gt;\n{{/each}}\n</code></pre> <p>Loops (Jinja2):</p> <pre><code>{% for item in items %}\n  {# Content to repeat for each item in the 'items' list #}\n{% endfor %}\n</code></pre> <p>Variable Output (Handlebars):</p> <pre><code>{{variable}}\n</code></pre> <p>Variable Output (Jinja2):</p> <pre><code>{{ variable }}\n</code></pre> <p>Partial Templates (Handlebars):</p> <pre><code>{{&gt; partial}}\n</code></pre> <p>Partial Templates (Jinja2):</p> <pre><code>{% include 'partial.html' %}\n</code></pre> <p>Template Inheritance (Jinja2):</p> <pre><code>{% extends 'base.html' %}\n{% block content %}\n  {# Content specific to this template #}\n{% endblock %}\n</code></pre> <p>Comments (Handlebars):</p> <pre><code>{{!-- This is a comment in Handlebars --}}\n</code></pre> <p>Comments (Jinja2):</p> <pre><code>{# This is a comment in Jinja2 #}\n</code></pre> <p>Escaping and Raw Output (Handlebars):</p> <pre><code>{{{rawHtml}}} &lt;!-- Outputs HTML without escaping --&gt;\n</code></pre> <p>Escaping and Raw Output (Jinja2):</p> <pre><code>{{ rawHtml | safe }} {# Outputs HTML without escaping #}\n</code></pre>"},{"location":"web/templateengines/","title":"Template Engines","text":"<p>Template engines, in the context of web applications, are tools or libraries that facilitate the dynamic generation of [[HTML]] or other markup languages based on templates and data. They allow developers to separate the presentation layer (HTML or other markup) from the underlying logic and data, promoting a cleaner and more maintainable code structure. </p> <p>Template engines are commonly used in server-side web development to generate dynamic content that is sent to the client's browser.</p> <p>Templates are predefined structures that contain placeholders or variables representing dynamic content. These placeholders are replaced with actual data during the rendering process. Template engines enable the dynamic generation of HTML or other markup by combining templates with data.</p> <p>Template engines bind data to placeholders in templates, ensuring that the final output reflects the current state of the application or the requested data. Template engines promote the separation of concerns by isolating the presentation logic (templating) from business logic.</p> <p>Info</p> <p>This separation makes code more modular, maintainable, and easier to understand.</p> <p>Templates can be reused across multiple pages or components, leading to consistent design and layout. Template engines often support control structures such as conditionals (if statements) and loops, allowing for dynamic content generation based on logic.</p> <p>Some template engines support partial templates or includes, allowing developers to break down complex layouts into smaller, reusable components. Template inheritance is a feature that enables the creation of a base template with common elements (e.g., header, footer) and the extension of this template in specific pages or views.</p> <p>Popular Template Engines:</p> <ul> <li>[[Mustache]]: A logic-less template syntax that can be used in various programming languages.</li> <li>[[Handlebars]]: An extension of Mustache with additional features for logic and helpers.</li> <li>[[Jinja2]]: A template engine for Python commonly used in web frameworks like [[Flask]].</li> <li>[[EJS (Embedded JavaScript)]]: A simple templating language that embeds [[JavaScript]] code within templates.</li> <li>[[Thymeleaf]]: A [[Java]]-based template engine often used with [[Spring Framework]].</li> </ul> <p>Template engines should handle user input carefully to prevent vulnerabilities such as [[Cross-Site Scripting]] (XSS). Proper escaping and sanitization are essential.</p>"},{"location":"web/thyme/","title":"Thymeleaf","text":"<p>Thymeleaf is a modern server-side [[Java]] [[Template Engines|template engine]] for web and standalone environments. It is used for dynamic web content generation and is particularly well-suited for integration with Java web applications. Thymeleaf follows a natural templating approach where templates are designed to be human-readable and can be used both as static prototypes and dynamic templates.</p> <p>Thymeleaf templates are designed to be easily readable by humans, making them suitable for use as static prototypes. This helps front-end and back-end developers collaborate effectively. Thymeleaf seamlessly integrates with Java frameworks, making it a popular choice for Java-based web applications. It supports integration with [[Spring Framework]], [[Spring Boot]], and other Java frameworks.</p> <p>Thymeleaf performs server-side rendering, generating [[HTML]] on the server before sending it to the client. This approach is suitable for web applications that rely on dynamic content generation on the server side.</p> <p>Thymeleaf uses its own expression language (Thymeleaf Standard Expression or simply Thymeleaf expressions) for dynamic content binding. These expressions are written within HTML tags and allow for easy integration with Java objects.</p> <p>Example:</p> <pre><code>&lt;p&gt;Hello, &lt;span th:text=\"${user.name}\"&gt;User&lt;/span&gt;!&lt;/p&gt;\n</code></pre> <p>Thymeleaf supports the creation of reusable template fragments and layouts, promoting code modularity and reusability.</p> <p>Example (Fragment):</p> <pre><code>&lt;!-- Fragment: header.html --&gt;\n&lt;header&gt;\n    &lt;h1&gt;Website Title&lt;/h1&gt;\n&lt;/header&gt;\n</code></pre> <p>Example (Layout):</p> <pre><code>&lt;!-- Layout: layout.html --&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Layout Example&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;div th:replace=\"fragments/header :: header\"&gt;&lt;/div&gt;\n    &lt;div th:replace=\"content\"&gt;&lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Thymeleaf supports conditional processing and iteration over collections, allowing developers to create dynamic content based on business logic.</p> <p>Example:</p> <pre><code>&lt;ul&gt;\n    &lt;li th:each=\"item : ${items}\" th:text=\"${item}\"&gt;Item&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre> <p>Thymeleaf provides features for handling internationalization and localization of content, making it suitable for multi-language applications. Thymeleaf is an open-source project that has gained popularity due to its simplicity, versatility, and ease of integration with Java-based web frameworks. It is widely used in enterprise-level Java web applications.</p>"},{"location":"web/tlds/","title":"Top-Level Domains (TLDs)","text":"<p>In the\u00a0[[DNS]] hierarchy, a top-level domain (TLD) represents the first stop after the root zone. In simpler terms, a TLD is everything that follows the final dot of a domain. For example, in the domain name \u2018google.com\u2019, \u2018.com\u2019 is the TLD. </p> <p>Info</p> <p>Some other popular TLDs include \u2018.org\u2019, \u2018.uk\u2019, and \u2018.edu\u2019.</p> <p>There are 5 official types of TLDs:</p> <ol> <li>Generic Top-Level Domains (gTLD) - most popular and familiar types of domain extensions, open for registration by anyone (com, net, biz, io)</li> <li>Sponsored Top-level Domains (sTLD) - proposed and supervised by private organizations (edu, gov, cat, travel)</li> <li>Country Code Top-level Domains (ccTLD) - used for specific countries and territories (us, es, co.uk, ch, ca)</li> <li>Infrastructure Top-Level Domain (ARPA) - only one TLD (ARPA), managed by IANA used for technical web infrastructure purposes.</li> <li>Test Top-Level Domains (tTLD) - reserved for documentation purposes and local testing (example, invalid, localhost, test)</li> </ol>"},{"location":"web/trace/","title":"Trace HTTP Method","text":"<p>The <code>TRACE</code> HTTP method is a diagnostic method defined in the HTTP/1.1 protocol. Its primary purpose is to enable a client to see what is being received at the other end of the request chain and use that data for testing or diagnostic information. The <code>TRACE</code> method simply echoes back the received request so that a client can see any changes or additions made by intermediate servers.</p> <p>When a <code>TRACE</code> request is made to a web server, the server responds with a message that includes the exact request that it received. This includes the request line, any headers, and the body of the request.</p> <p>The <code>TRACE</code> method can present a web security risk, primarily through a type of attack known as [[Cross-Site Tracing (XST)]]:</p> <ul> <li>XST is an advanced form of [[Cross-Site Scripting|Cross-Site Scripting (XSS)]]. An attacker can exploit the <code>TRACE</code> method to steal cookies or other authentication information from browsers. This is especially concerning if the [[HttpOnly flag]] is not set on cookies, as an XST attack can be used to bypass this protection. The attacker crafts a malicious script that forces the victim's browser to send an HTTP TRACE request to the server. The response to this TRACE request includes the victim's cookies and other header information, which the script then captures.</li> <li>The <code>HttpOnly</code> flag is used to protect cookies from being accessed by client-side scripts. However, if an application supports the <code>TRACE</code> method, it might be possible for an attacker to use XST to bypass this protection and access <code>HttpOnly</code> cookies.</li> </ul>"},{"location":"web/twig/","title":"Twig","text":"<p>Twig is a [[Template Engines|template engine]] for the [[PHP]] programming language. It is a flexible and powerful templating language that allows developers to embed dynamic content into their [[HTML]], [[Extensible Markup Language|XML]], or other markup languages. Twig was created by the developers of the [[Symfony]] web framework but can be used independently of Symfony in any PHP project.</p> <p>Twig uses a clean and readable syntax, making it easy for developers to understand and maintain templates. Twig has built-in security features to help prevent common security vulnerabilities such as [[cross-site scripting]] (XSS) attacks. It automatically escapes output by default, which helps to avoid the injection of malicious code.</p> <p>Twig is extensible, allowing developers to define their own custom tags, filters, and functions, making it adaptable to various project requirements. Twig supports template inheritance, allowing developers to create a base template and extend or override specific blocks in child templates. This promotes code reusability and maintainability.</p> <p>Twig provides control structures like loops, conditions, and iterators, enabling developers to implement logic within templates. Twig includes a variety of built-in filters and functions for manipulating data and formatting output. Additionally, developers can create custom filters and functions as needed.</p> <p>While Twig can be used independently, it is closely associated with the Symfony framework. Symfony uses Twig as its default templating engine. A simple example of Twig syntax may be:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{{ page_title }}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, {{ user.name }}!&lt;/h1&gt;\n\n    {% if user.isAdmin %}\n        &lt;p&gt;Welcome, Administrator!&lt;/p&gt;\n    {% else %}\n        &lt;p&gt;Welcome, regular user!&lt;/p&gt;\n    {% endif %}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>In this example, <code>{{ page_title }}</code>, <code>{{ user.name }}</code>, and <code>{% if user.isAdmin %}</code> are examples of Twig syntax for printing variables and implementing control structures. Twig templates are processed on the server side, and the resulting HTML is sent to the client.</p>"},{"location":"web/url/","title":"Uniform Resource Locator","text":"<p>A Uniform Resource Locator (URL) is the address of a resource on the Internet and the protocol used to access it.</p> <p>It indicates the location of a web resource like a street address indicates where a person lives physically \u2014 because of this, an URL is often referred to as \u201cweb address\u201d.</p> <p>A URL contains the following information:</p> <ul> <li>The protocol used to access the resource.</li> <li>The location of the [[server]] (whether by IP address or domain name).</li> <li>The [[port]] number on the server (optional).</li> <li>The location of the resource in the directory structure of the server.</li> <li>A fragment identifier (optional).</li> </ul> <p>Info</p> <p>A URL is a type of uniform resource identifier (URI). In common practice, the term URI isn\u2019t used, or is used synonymously with URL, even though this is technically incorrect.</p>"},{"location":"web/urlenc/","title":"URL Encoding","text":"<p>A URL is composed from a limited set of characters belonging to the US-ASCII character set. These characters include digits (0-9), letters(A-Z, a-z), and a few special characters (\"-\",\u00a0\".\",\u00a0\"_\",\u00a0\"~\").</p> <p>ASCII control characters (e.g. backspace, vertical tab, horizontal tab, line feed etc), unsafe characters like\u00a0space,\u00a0\\,\u00a0&lt;,\u00a0&gt;,\u00a0{,\u00a0}\u00a0etc, and any character outside the ASCII charset is not allowed to be placed directly within URLs.</p> <p>Moreover, there are some characters that have special meaning within URLs. These characters are called\u00a0reserved\u00a0characters. Some examples of reserved characters are\u00a0?,\u00a0/,\u00a0#,\u00a0:\u00a0etc. Any data transmitted as part of the URL, whether in query string or path segment, must not contain these characters.</p> <p>To transmit these characters, they must be encoded.</p> <p>URL Encoding converts reserved, unsafe, and non-ASCII characters in URLs to a format that is universally accepted and understood by all web browsers and servers. It first converts the character to one or more bytes. Then each byte is represented by two hexadecimal digits preceded by a percent sign (%) - (e.g.\u00a0%xy). The percent sign is used as an escape character.</p> <p>URL encoding is also called percent encoding since it uses percent sign (%) as an escape character.</p> <p>One of the most frequent URL Encoded character you\u2019re likely to encounter is\u00a0space. The ASCII value of\u00a0space\u00a0character in decimal is\u00a032, which when converted to hex comes out to be\u00a020. Now we just precede the hexadecimal representation with a percent sign (%), which gives us the URL encoded value -\u00a0%20.</p>"},{"location":"web/useragent/","title":"User-Agent","text":"<p>The information contained within a User-Agent HTTP request header is also known as the User-Agent (UA) string. This string contains information on the device.</p> <p>For example, if you browse the web on your smartphone, your device will send a HTTP request header to the web server, saying that it is a mobile device. The website will then respond and show you the mobile version of the page.</p> <p>An example User-Agent string can be:</p> <pre><code>Mozilla/5.0 (Linux; Android 12; Pixel 6) AppleWebKit/537.36 (KHTML, like Gecko)\nChrome/93.0.4577.62 Mobile Safari/537.36\n</code></pre> <ul> <li>Mozilla/5.0 - Largely ignored as has no relevance to the associated device</li> <li>Linux; Android 12 - details about the OS</li> <li>For mobile UA-strings, the \"Pixel 6\" section provides the device name or device model number</li> <li>AppleWebKit/537.6 - indicates what browser rendering engine is used. A rendering engine is what transforms HTML into a webpage on the screen</li> <li>KHTML, like Gecko - ensure compatibility for historical reasons</li> <li>Chrome/93.0.4577.62 Mobile Safari/537.36 - more detail on the browser and its version number.</li> </ul>"},{"location":"web/verbs/","title":"HTTP Verbs","text":"<p>The [[HTTP Protocol]] includes a collection of methods that are used to interact with server-side resources. There are commonly referred to as\u00a0HTTP request methods\u00a0or\u00a0HTTP verbs\u00a0and are intended to cover all possible types of interaction with resources.</p> <p>While\u00a0HTTP Request Methods\u00a0typically perform different operations, there is an overlap in functionality, and depending on the task, several HTTP requests will have to be made before it is complete. There are also HTTP method properties to consider, including whether a HTTP request is safe, idempotent, or\u00a0cacheable.</p> <p>Some of the most commonly used HTTP Request Methods include:</p> Method Description GET Requests a specific resource. Additional data can be passed via query strings in the URL POST Sends data to the server. Handle many types of input. Data appended in request body after [[HTTP Headers]] HEAD Requests headers returned from a GET request PUT Create new resources on the server DELETE Deletes an existing resource on the server OPTIONS Returns information about the server, such as methods accepted PATCH Applies partial modifications to the resource specified"},{"location":"web/verbtam/","title":"HTTP Verb Tampering","text":"<p>HTTP verb tampering is a type of web security vulnerability that occurs when a web server incorrectly handles [[HTTP Verbs|HTTP methods]] or verbs. This vulnerability arises when the server is configured to respond differently to various HTTP methods, but does not properly restrict or validate these methods for different resources. </p> <p>Attackers can exploit this vulnerability by using unexpected or less commonly used HTTP methods (such as [[PUT HTTP Method|PUT]], [[DELETE HTTP Method|DELETE]], [[TRACE HTTP Method|TRACE]], [[CONNECT HTTP Method|CONNECT]], etc.) to bypass security controls, access unauthorized content, or perform unauthorized actions.</p> <p>Some common HTTP methods:</p> <ul> <li>GET: Retrieve data from the server.</li> <li>POST: Send data to the server to create/update a resource.</li> <li>PUT: Replace all current representations of the target resource with the request payload.</li> <li>DELETE: Remove the specified resource.</li> <li>HEAD: Similar to GET, but it retrieves only the header information and not the body of the response.</li> <li>OPTIONS: Describe the communication options for the target resource.</li> <li>TRACE: Perform a message loop-back test along the path to the target resource.</li> <li>CONNECT: Establish a tunnel to the server identified by the target resource.</li> </ul> <p>Suppose a web application correctly restricts sensitive actions to POST requests (like form submissions) but does not similarly restrict GET requests. An attacker might be able to perform the same actions by crafting a GET request with the same parameters, bypassing any server-side checks that are only applied to POST requests.</p> <p>A website might only check for GET and POST methods and restrict certain actions to these methods. However, the server might still accept other methods like PUT or DELETE. An attacker could use these methods to modify (PUT) or delete (DELETE) content on the server if proper checks are not in place.</p> <p>If the TRACE method is enabled, an attacker might use it to perform a [[cross-site scripting]] (XSS) attack. The attacker could trick a victim into sending an HTTP TRACE request with a malicious script in the headers. The server\u2019s TRACE response would include this script, which could then be executed in the context of the victim\u2019s browser.</p> <p>Imagine a web application that manages blog posts. The application allows users to create, edit, and delete their blog posts. To simplify the scenario, let's assume the application uses the following HTTP methods:</p> <ul> <li><code>POST</code> to create a new blog post.</li> <li><code>PUT</code> to edit an existing blog post.</li> <li><code>DELETE</code> to remove a blog post.</li> </ul> <p>However, due to a misconfiguration or oversight in security, the application does not properly enforce access control on the <code>DELETE</code> method. An attacker discovers that while the application properly checks user permissions for <code>POST</code> and <code>PUT</code> requests, it does not do so for <code>DELETE</code> requests. This means any authenticated user can delete any blog post, even if they don't have permission to do so.</p> <p>Here's an example of how an attacker might exploit this vulnerability using a simple HTTP request. This could be done using a tool like [[cURL]]:</p> <pre><code>curl -X DELETE \"http://example.com/blogpost?id=123\" -H \"Cookie: sessionid=valid_user_session\"\n</code></pre> <ul> <li><code>-X DELETE</code>: Specifies the HTTP method to use, which is <code>DELETE</code> in this case.</li> <li><code>\"http://example.com/blogpost?id=123\"</code>: The URL of the blog post to delete. The attacker targets blog post with ID <code>123</code>.</li> <li><code>-H \"Cookie: sessionid=valid_user_session\"</code>: Includes a header with a valid session ID to authenticate as a legitimate user.</li> </ul> <p>For mitigation tactics:</p> <ul> <li>Proper Configuration: Configure the server to allow only necessary HTTP methods for each resource. Unnecessary methods like TRACE or CONNECT should be disabled if not needed.</li> <li>Input Validation: Implement strict input validation on the server side to ensure that only appropriate actions are taken for each HTTP method.</li> <li>Security Checks: Apply consistent security checks across all HTTP methods to prevent bypassing controls by simply changing the method.</li> <li>Testing: Regularly test web applications for HTTP method vulnerabilities using tools and techniques like penetration testing.</li> </ul>"},{"location":"web/vhosts/","title":"Virtual Hosts (VHOSTS)","text":"<p>A virtual host refers to a method used by web [[server|servers]], such as [[Apache]] HTTP Server or [[Nginx]], to host multiple websites or web applications on a single physical server.</p> <p>Each virtual host is associated with one or more [[Fully Qualified Domain Name (FQDN)|domain names]] (or hostnames) and is configured to serve content and respond to requests as if it were a separate, dedicated server.</p> <p>Virtual hosting is a way to efficiently use server resources and enable the hosting of multiple websites on a single server.</p> <p>It allows websites with different domain names to share the same server and [[IP address]] but still have their own isolated configurations, content directories, and settings.</p> <p>There are two main types of virtual hosts:</p> <ol> <li>Name-based Virtual Hosts: In this approach, the web server uses the \"Host\" [[HTTP Headers|header]] in HTTP requests to determine which virtual host should handle the incoming request. This allows multiple domain names to share the same IP address. It's the most common method for hosting multiple websites on a single server.</li> <li>IP-based Virtual Hosts: With IP-based virtual hosting, each virtual host has its own unique IP address. This means that different IP addresses are assigned to different virtual hosts, and requests to a specific IP address are directed to the corresponding virtual host. This method is less common than name-based virtual hosting and often requires additional IP addresses.</li> </ol>"},{"location":"web/viewstate/","title":"ViewState","text":"<p>ViewState is a feature specific to [[ASP.NET]], a web application framework developed by Microsoft. It is used to persist the state of web pages and controls between HTTP requests. In the stateless nature of web browsing, ViewState provides a way to store values across postbacks (when a user interacts with a form and sends it back to the server).</p> <p>When a user interacts with a web page, such as entering data into a form field, the state of the page (like the contents of the form fields) needs to be maintained when the form is submitted. ViewState helps in preserving this information.</p> <p>ViewState is stored in a hidden form field with the name <code>__VIEWSTATE</code>. This field contains a [[Base64]]-encoded string, representing the state of the page when it was last processed on the server. The state of the controls on the page is serialized to a string and sent to the client as part of the HTML. When the page is posted back to the server, the server deserializes the string to restore the state of the controls.</p> <p>ViewState can become large if a lot of data needs to be maintained, which can increase page load times and affect performance. If not properly encrypted or validated, ViewState can be a vector for attacks. Attackers might tamper with the data in the ViewState, leading to issues like [[Cross-Site Scripting]] (XSS) or [[ViewState Tampering|ViewState tampering]] attacks.</p> <p>To secure ViewState, it's essential to encrypt the ViewState data and use [[Message Authentication Code (MAC)|message authentication codes (MACs)]] to ensure the data has not been tampered with. ASP.NET provides options for encrypting and validating ViewState.</p> <p>ViewState is commonly used to maintain the state of controls on a web page between postbacks. For example, if a user enters text into a textbox and submits the form, ViewState can be used to ensure the text stays in the textbox when the page reloads. ViewState is suitable for storing small amounts of data that are specific to a particular page, like user inputs and selections.</p> <p>ViewState is a Base64-encoded string that represents the state of the page's controls and is used to maintain this state across postbacks. It's placed in a hidden field in the HTML of the page. An example token may be:</p> <pre><code>&lt;input\n  type=\"hidden\"\n  name=\"__VIEWSTATE\"\n  id=\"__VIEWSTATE\"\n  value=\"/wEPDwUKLTk1MzY5NTQwNGRkx5bdB2CfJsF+8o5cFT+zeV8=\"\n/&gt;\n</code></pre> <ul> <li>The <code>name</code> and <code>id</code> are set to <code>__VIEWSTATE</code>, which is standard for ASP.NET applications.</li> <li>The <code>value</code> attribute contains the ViewState data. This is a Base64-encoded string, which, when decoded, contains the state of the page's controls.</li> </ul> <p>Important</p> <p>The actual content of the ViewState value is specific to the state of the particular page and its controls. It can vary greatly in length and complexity.</p> <p>In a secure ASP.NET application, this value should also be integrity-protected (with a MAC) and potentially encrypted, depending on the sensitivity of the data it contains and the application's security configuration. The example shown here is a simplified representation and does not include these security features.</p>"},{"location":"web/wam/","title":"Web Application Mapping","text":"<p>Web application mapping is a critical phase in web application security assessments, including penetration testing. It involves systematically analyzing a web application to understand its structure, functionality, and points of interaction.</p> <p>This process is essential for identifying potential security vulnerabilities and planning targeted attacks to test the application's resilience against cyber threats.</p> <p>Mapping out the structure of the application, including directories, files, and [[Uniform Resource Locator|URLs]] is a key aspect of mapping. This involves identifying the layout of the web application, the relationship between different pages, and how they are linked together.</p> <p>You must also recognize all the entry points for user input, such as forms, query parameters, and [[HTTP headers]]. These entry points are crucial for subsequent stages of penetration testing, as they are often the target for injection attacks (like [[SQL injection]], [[Cross-Site Scripting|XSS]]).</p> <p>Find all accessible resources on the web application, including hidden or less obvious directories, files, and [[APIs|APIs]]. This might involve using tools to crawl the application and uncover resources that are not linked from visible content.</p> <p>Understand how the web application works, what each part does, and how different functions interact with each other. This includes understanding the business logic of the application to identify logic flaws.</p> <p>Review how sessions are managed, including [[cookies]] and session tokens. This is important for identifying vulnerabilities in session handling that could be exploited.</p> <p>Examine how the web application handles user authentication and authorization, to spot potential weaknesses or misconfigurations in access controls.</p> <p>Identify the technologies used in the web application, such as the server-side platform, [[Databases (KB)|database]], and any frameworks or libraries. Knowledge of the technology stack is crucial for understanding the types of vulnerabilities that might be present.</p>"},{"location":"web/wavs/","title":"Web Application Vulnerability Scanning","text":"<p>Vulnerability scanning is commonly considered to be the most efficient way to check your site against a huge list of known vulnerabilities - and identify potential weaknesses in the security of your applications. Vulnerability scanning can be used as part of a standalone assessment, or as part of a continuous overall security monitoring strategy.</p> <p>Vulnerability scanners are automated tools that scan web applications to look for security vulnerabilities. They test web applications for common security problems such as\u00a0[[Cross-Site Scripting|cross-site scripting (XSS)]],\u00a0[[SQL injection]], and\u00a0[[Cross-Site Request Forgery|cross-site request forgery (CSRF)]].</p> <p>More capable scanners may be able to delve further into an application by utilizing more advanced techniques. Pioneering application system testing techniques mean that\u00a0Burp Scanner, the engine powering Burp Suite application security testing products, can find vulnerabilities many other scanners would miss, including\u00a0[[Asynchronous SQL Injection]]\u00a0and\u00a0[[Blind SSRF]]\u00a0for instance.</p>"},{"location":"web/webconfig/","title":"Web Configuration Testing","text":"<p>Web configuration testing in cybersecurity is the practice of examining and verifying the settings and setup of a web application and its hosting environment to identify and fix security weaknesses.</p> <p>This involves checking how the web [[Server|servers]], [[Databases (KB)]], and other components in the application's ecosystem are configured to ensure they don't have vulnerabilities or misconfigurations that could be exploited by attackers.</p> <p>The goal is to ensure that every aspect of the web application's deployment is secure and doesn't leave any gaps for potential security breaches.</p>"},{"location":"web/wix/","title":"Wix","text":"<p>Wix is a powerful, code-free website builder that comes equipped with business tools that can help you build something as simple as a personal blog to something as complex as an enterprise-grade hub for your online business. It is also another common [[Content Management System]].</p> <p>It has built-in features for eCommerce, marketing, scheduling, branding and more.</p> <p>The main features that define Wix are:</p> <ul> <li>Cloud platform - Wix is a cloud service that can be accessed from your browser and which users can visit at any time, from any device (computer, mobile or tablet).</li> <li>Wix templates - Wix offers hundreds of templates to choose from, offering your website a professional appearance to meet the needs and characteristics of each company.</li> <li>Easy to use - Wix offers a simple and intuitive editor that allows you to create different parts of a website, using the \u2018drag and drop\u2019 system \u2013 meaning there\u2019s no need to write any code (HTML, CSS or JavaScript, for example).</li> <li>Versatility - With Wix, you can develop a range of different types of websites, from a corporate site to a professional online shop from which to sell products and services online.</li> <li>Includes hosting - By registering on Wix, you\u2019ll gain storage space to host your new website.</li> <li>Freemium - The Wix business model allows users to access basic web-development services for free, with the option to access more advanced options through a paid service.</li> </ul>"},{"location":"web/wordpress/","title":"WordPress","text":"<p>WordPress is an open-source content management system (CMS). It\u2019s a popular tool for individuals without any coding experience who want to build websites and blogs. The software doesn\u2019t cost anything. Anyone can install, use, and modify it for free.</p> <p>In the beginning, WordPress was mainly used to create blogs. Fast-forward to today, the software has improved, and you can create any type of website you want. You can build hobby or lifestyle blogs, professional portfolios, business websites, e-commerce stores, mobile applications, and membership sites.</p> <p>WordPress is a free, open-source website creation platform. On a more technical level, WordPress is a [[Content Management System|content management system]] (CMS) written in PHP that uses a MySQL database. In non-geek speak, WordPress is the easiest and most powerful blogging and website builder in existence today.</p> <p>WordPress powers both the\u00a0backend\u00a0of the website (the interface where a user logs in to make changes or add new content) and the\u00a0frontend\u00a0(the visible part of the website that your visitors see on the web).</p>"},{"location":"web/wpforms/","title":"WPForms","text":"<p>WPForms is a popular [[WordPress]] plugin designed to simplify the process of creating various forms for websites running on the WordPress content management system. It's known for its user-friendly drag-and-drop interface, which allows users to build contact forms, email subscription forms, online order forms, payment forms, surveys, polls, and other types of forms without needing to write code.</p> <p>Some key features include:</p> <ul> <li>Drag-and-Drop Form Builder: Enables easy creation of forms.</li> <li>Pre-built Form Templates: Offers a variety of templates for common form types.</li> <li>Responsive Mobile-Friendly: Forms work well on all devices.</li> <li>Smart Conditional Logic: Allows you to show or hide fields based on user responses.</li> <li>Spam Protection: Includes features like [[CAPTCHA]] and honeypot fields to prevent spam submissions.</li> <li>Integration with Email Marketing Services: Connects with services like [[Mailchimp]], [[AWeber]], etc.</li> <li>Payment Integration: Supports PayPal, Stripe, and other payment processors for collecting payments.</li> </ul> <p>As with any software, WPForms may have vulnerabilities that can be discovered over time. The WordPress community, including the developers of WPForms, actively works to identify and fix such vulnerabilities. It's important to note the following regarding its security:</p> <ol> <li>Regular Updates: WPForms is regularly updated to patch known vulnerabilities and improve functionality. Keeping the plugin updated to the latest version is crucial for security.</li> <li>WordPress Ecosystem: WPForms operates within the WordPress ecosystem, which means its security also depends on the overall security of the WordPress site it's installed on. This includes using strong passwords, keeping WordPress core and all plugins/themes updated, and implementing general WordPress security best practices.</li> <li>Past Vulnerabilities: Like many plugins, WPForms may have had vulnerabilities in the past which were identified and patched. Details about specific vulnerabilities can typically be found in the plugin\u2019s changelog or security advisories.</li> <li>Security Plugins and Measures: Using security plugins and implementing additional security measures (like using [[SSL]]/[[HTTPS Protocol|HTTPS]], secure hosting, etc.) can further protect WordPress sites using WPForms.</li> </ol>"},{"location":"web/wwwauth/","title":"WWW-Authenticate","text":"<p>The <code>WWW-Authenticate</code> header field is an [[HTTP Headers|HTTP header]] used in the process of HTTP authentication. It is typically sent by a web server as part of an HTTP response when the server requires authentication from the client (typically a web browser or other user agent) to access a specific resource or perform a particular action.</p> <p>The <code>WWW-Authenticate</code> header informs the client about the authentication method(s) supported by the server and provides the necessary information for the client to initiate the authentication process. The client, upon receiving this header, can then respond with an appropriate authentication request.</p> <p>Common authentication methods specified in the <code>WWW-Authenticate</code> header include:</p> <ul> <li>[[Basic HTTP Authentication|Basic Authentication]]: This method involves sending a base64-encoded username and password combination in the <code>Authorization</code> header of the client's subsequent request. For example:</li> </ul> <pre><code>WWW-Authenticate: Basic realm=\"Example\"\n</code></pre> <p>The client responds with:</p> <pre><code>Authorization: Basic base64-encoded-credentials\n</code></pre> <ul> <li>[[Digest Authentication]]: This method uses a challenge-response mechanism to authenticate the client. The server sends a challenge in the \"WWW-Authenticate\" header and the client responds with a hash of the challenge, password and other information. For example:</li> </ul> <pre><code>WWW-Authenticate: Digest realm=\"Example\", qop=\"auth\", nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\", opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"\n</code></pre> <p>The client responds with a hashed version of the challenge and other data in the Authorization header.</p> <ul> <li>[[Bearer Token Authentication]]: This method involves sending a token in the Authorization header, typically used for [[Knowledge Base/OAuth]] 2.0 and other token-based authentication systems. For example:</li> </ul> <pre><code>WWW-Authenticate: Bearer realm=\"Example\", error=\"invalid_token\", error_description=\"The access token expired\"\n</code></pre> <p>The client responds with:</p> <pre><code>Authorization: Bearer access-token\n</code></pre> <ul> <li>[[Negotiate Authentication]]: This method is used for [[Single Sign-On (SSO)]] scenarios and allows clients to authenticate using various authentication protocols such as [[NTLM]] and [[Kerberos Authentication]]. For example:</li> </ul> <pre><code>WWW-Authenticate: Negotiate\n</code></pre> <p>The realm parameter in the WWW-Authenticate header typically specifies a description of the protected area or the authentication realm, helping users understand why authentication is required.</p> <p>Info</p> <p>When a client receives a <code>WWW-Authenticate</code> header, it prompts the user for the necessary credentials and constructs an appropriate <code>Authorization</code> header to include in subsequent requests. The server then validates the credentials and decides whether to grant access to the requested resource.</p>"},{"location":"web/xfor/","title":"X-Forwarded-For","text":"<p>The <code>X-Forwarded-For</code> (XFF) header is an [[HTTP headers|HTTP header]] field that is used to identify the originating [[IP address]] of a client connecting to a web server through an HTTP [[proxy]] or a [[load balancer]]. This header is a de facto standard for identifying the original IP address of a client when web servers are configured to receive traffic via proxy servers or load balancers.</p> <p>The primary purpose of the <code>X-Forwarded-For</code> header is to provide a way to track the original client's IP address in web server logs, which is crucial for debugging, security audits, and compliance with legal requirements. When a client makes a request to a server through a proxy, the proxy server adds the client\u2019s IP address to the <code>X-Forwarded-For</code> header before forwarding the request to the server. If there are multiple proxies in the chain, the header can contain a list of IP addresses, each representing a node in the chain.</p> <p>In the context of penetration testing (pentesting), the <code>X-Forwarded-For</code> header can be used in various ways:</p> <ol> <li>Spoofing IP Address: An attacker or a pentester can modify or spoof the <code>X-Forwarded-For</code> header to simulate requests from different IP addresses. This can be used to test how the server or application handles requests from various locations or to bypass IP-based access controls.</li> <li>Bypassing Security Measures: Some security measures, like rate limiting or IP-based access control, rely on the IP address. By manipulating the <code>X-Forwarded-For</code> header, a pentester can test whether these security measures are effectively implemented or if they can be bypassed.</li> <li>Identifying Misconfigurations: The <code>X-Forwarded-For</code> header can be used to identify misconfigurations in proxy servers or load balancers. For example, if a server trusts any IP address in the <code>X-Forwarded-For</code> header without proper validation, it might be susceptible to IP spoofing.</li> <li>Testing Logging and Monitoring Systems: By using different values in the <code>X-Forwarded-For</code> header, pentesters can check if the logging and monitoring systems are accurately capturing and reporting the original client IP addresses.</li> <li>Exploring Trust Relationships: In some network architectures, certain actions or accesses might be allowed based on the source IP. Modifying the <code>X-Forwarded-For</code> header can reveal how trust relationships are handled between different network entities.</li> </ol>"},{"location":"web/xforip/","title":"X-Forwarded-IP","text":"<p>The <code>X-Forwarded-IP</code> header, much like the [[X-Forwarded-For]] (XFF) header, is an [[HTTP Headers|HTTP header]] used in web traffic. However, it's important to note that <code>X-Forwarded-IP</code> is not a standard header and might not be consistently recognized or used. In environments where it is used, it typically serves the same purpose as the XFF header - to identify the original IP address of a client when the request goes through [[Proxy|proxies]] or [[Load Balancer|load balancers]].</p> <p>If implemented, the <code>X-Forwarded-IP</code> header would be used to record the IP address of the client making a request to a web server through a proxy or load balancer, much like the <code>X-Forwarded-For</code> header. In practice, when a client sends a request to a server via a proxy, the proxy may add the client\u2019s original IP address in the <code>X-Forwarded-IP</code> header before forwarding the request.</p> <p>Since <code>X-Forwarded-IP</code> is not a widely recognized standard, its usage in penetration testing would depend on whether the target system implements and respects this header. If it does, then its potential uses are similar to <code>X-Forwarded-For</code>:</p> <ol> <li>IP Spoofing: A pentester might modify the <code>X-Forwarded-IP</code> header to simulate requests from different IP addresses, testing how the server or application responds to these changes and whether IP-based security controls can be bypassed.</li> <li>Bypassing Security Filters: If the application or server uses the <code>X-Forwarded-IP</code> for access control or rate limiting, modifying this header could help in bypassing these restrictions.</li> <li>Identifying Misconfigurations and Flaws: The presence and handling of an <code>X-Forwarded-IP</code> header could reveal misconfigurations in the server or application, especially if it blindly trusts the header without proper validation.</li> <li>Testing Logging and Monitoring: Altering the <code>X-Forwarded-IP</code> header can help in assessing whether monitoring and logging mechanisms are accurately recording client IP addresses and detecting potential header manipulations.</li> </ol>"},{"location":"web/xhtml/","title":"XHTML","text":"<p>XHTML, which stands for Extensible Hypertext Markup Language, is a markup language that extends versions of the widely used Hypertext Markup Language ([[HTML]]). XHTML is part of the family of XML markup languages and is essentially a stricter and cleaner version of HTML, adhering more closely to [[Extensible Markup Language|XML]] standards.</p> <p>XHTML documents must be well-formed XML documents. This means they must adhere to stricter syntax rules compared to HTML, such as properly nested and closed tags, and case sensitivity for tags and attributes.</p> <p>XHTML was designed to be almost fully backward compatible with HTML. It uses the same elements (like <code>&lt;p&gt;</code>, <code>&lt;div&gt;</code>, <code>&lt;a&gt;</code>, etc.) as HTML but applies the stricter syntax rules of XML. XHTML 1.0, the first major version, came in three DTDs ([[DTD (Document Type Definition)|Document Type Definitions]]): Strict, Transitional, and Frameset. Strict is the most stringent in terms of adhering to XML standards.</p> <p>The development of XHTML aimed to create a markup language that could be used with a wider range of devices (not just web browsers) and improve web standards compliance. XHTML should be served with an XML [[MIME-Type|MIME]] type, such as <code>application/xhtml+xml</code>. When served with this MIME type, it is expected that browsers will parse it strictly as XML.</p> <p>Being an XML application, XHTML documents can be parsed and processed by standard XML tools, which allows for greater flexibility and interoperability in web development. XHTML's popularity has declined with the advent of HTML5, which offers new features and more flexible syntax rules. HTML5 aims to incorporate the benefits of XHTML while maintaining compatibility with legacy HTML.</p> <p>XHTML is still used in web development, particularly in environments where strict compliance with XML is required or beneficial. Like HTML, XHTML supports accessibility standards and internationalization, making web content more accessible to people with disabilities and in different languages.</p> <p>XHTML5 is a variant of HTML5 that follows XML syntax rules. It combines the new features of HTML5 with the strict syntax of XML.</p>"},{"location":"web/xslt/","title":"Extensible Stylesheet Language Transformations Server-Side Injection (XSLT)","text":"<p>Extensible Stylesheet Language Transformations (XSLT) Server-Side Injection is a web security vulnerability that occurs when an application accepts user input and unsafely processes it as part of an [[XSLT (Extensible Stylesheet Language Transformations)|XLST]] stylesheet.</p> <p>XSLT is a language used for transforming [[Extensible Markup Language|XML]] documents into other formats, like [[HTML]], plain text, or other XML formats. If an application dynamically generates XSLT stylesheets based on user-supplied input without proper [[Input Sanitization|sanitization]] or validation, it can lead to this type of injection vulnerability.</p> <p>XSLT is a powerful language used for transforming XML documents. It allows for complex manipulation and conversion of XML data into different document types. XSLT stylesheets define rules for how the transformation should occur.</p> <p>The vulnerability arises when a web application includes user-controlled input in an XSLT stylesheet without proper sanitization. Malicious users can inject harmful XSLT code, which the server then processes. This process can potentially allow attackers to execute arbitrary code or commands on the server, access or modify sensitive data, or perform other malicious actions.</p> <p>An attacker exploits this vulnerability by injecting malicious XSLT code into a point where the application accepts input, like a form or URL parameter. When the application processes this input as part of an XSLT transformation, the malicious code is executed.</p> <p>Depending on the server\u2019s configuration and the nature of the XSLT processor, impacts can range from unauthorized data disclosure to [[Knowledge Base/Remote Code Execution]].</p>"},{"location":"web/xss/","title":"Cross-Site Scripting","text":"<p>Cross-site scripting (also known as XSS) is a web security vulnerability that allows an attacker to compromise the interactions that users have with a vulnerable application. It allows an attacker to circumvent the [[Same Origin Policy|same origin policy]], which is designed to segregate different websites from each other.</p> <p>Cross-site scripting vulnerabilities normally allow an attacker to masquerade as a victim user, to carry out any actions that the user is able to perform, and to access any of the user's data. If the victim user has privileged access within the application, then the attacker might be able to gain full control over all of the application's functionality and data.</p> <p>Cross-site scripting works by manipulating a vulnerable web site so that it returns malicious [[JavaScript]] to users. When the malicious code executes inside a victim's browser, the attacker can fully compromise their interaction with the application.</p> <p>Websites that do not validate user input before using them in their outputs are typically susceptible to XSS attacks. While various frameworks (such as\u00a0[[ActiveX]], Flash, [[CSS]],\u00a0and\u00a0[[VBScript]]) are sensitive to XSS, dynamic websites commonly notice the attack since such sites mostly rely on JavaScript.</p> <p>XSS attacks are of three types:</p> <ul> <li>[[Reflected XSS]]</li> <li>[[Stored XSS]]</li> <li>[[DOM-based XSS]]</li> </ul> <p>You can confirm most kinds of XSS vulnerability by injecting a payload that causes your own browser to execute some arbitrary JavaScript. It's long been common practice to use the\u00a0alert()\u00a0function for this purpose because it's short, harmless, and pretty hard to miss when it's successfully called.</p> <p>Unfortunately, there's a slight hitch if you use Chrome. From version 92 onward (July 20th, 2021), cross-origin iframes are prevented from calling\u00a0alert(). As these are used to construct some of the more advanced XSS attacks, you'll sometimes need to use an alternative PoC payload such as print().</p>"},{"location":"web/xxe/","title":"External XML Entities","text":"<p>External XML entities in the context of [[Extensible Markup Language|XML]] and web security are a type of XML entity that references content external to the XML document itself. In XML, entities are a way of representing certain items, typically as a reference to include content. External entities can be used to include external content in an XML document, but they can also pose significant security risks if not handled properly.</p> <p>An external XML entity is defined in a [[Document Type Definition (DTD)]] or in an XML schema and typically references content from an external source, like a file on the server or a URL. When the XML parser processes the XML document, it can replace these external entity references with the actual content from the external source.</p> <p>An external XML entity is usually declared in the DTD using something like:</p> <pre><code>&lt;!ENTITY entity_name SYSTEM \"external_resource\"&gt;\n</code></pre> <p>Where <code>entity_name</code> is the name of the entity, and <code>external_resource</code> is the URI of the external content. In the XML document, these entities are referenced using the <code>&amp;</code> symbol followed by the entity name; for example, <code>&amp;entity_name;</code>.</p> <p>External entities can be exploited in an [[XML External Entities (XXE)|XXE attack]]. If an attacker can insert or manipulate external entity references in an XML document and the XML parser processes these entities, it can lead to various security issues, such as:</p> <ul> <li>Data Exfiltration: Reading sensitive files from the server and sending the data out.</li> <li>[[Server-Side Request Forgery]] (SSRF): Making requests to internal systems that the server has access to.</li> <li>[[Denial of Service (DoS) Attacks|Denail of Service (DoS) Attacks]]: By referencing entities that lead to large amounts of data being processed or recursive entity loading.</li> </ul>"}]}